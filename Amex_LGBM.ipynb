{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pyagoubi/Credit-Default-Prediction/blob/main/Amex_LGBM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Installing GPU support for LGBM"
      ],
      "metadata": {
        "id": "V3TRv4u9uCmi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall lightgbm"
      ],
      "metadata": {
        "id": "2U4C0_FO1qcp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lightgbm --install-option=--gpu --install-option=\"--opencl-include-dir=/usr/local/cuda/include/\" --install-option=\"--opencl-library=/usr/local/cuda/lib64/libOpenCL.so\""
      ],
      "metadata": {
        "id": "3Cq_ajZs_4Pz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOOdZDzIItEG",
        "outputId": "8dc0964c-e5e3-47c9-cce9-e005bf63ba3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#Mounting Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6lJRhid0ItBS"
      },
      "outputs": [],
      "source": [
        "#set WD\n",
        "import os\n",
        "os.chdir('/content/drive/MyDrive/Amex/parquet')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMo1TkPZp0N4"
      },
      "source": [
        "# Load Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GRgokt4bp0N4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd, numpy as np # CPU libraries\n",
        "import matplotlib.pyplot as plt, gc, os\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBRegressor\n",
        "from xgboost import XGBClassifier\n",
        "import csv, itertools\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "import xgboost\n",
        "\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from xgboost import plot_importance\n",
        "from sklearn.inspection import permutation_importance\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tqdm.auto import tqdm\n",
        "import lightgbm as lgb\n",
        "\n",
        "import joblib\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import itertools\n",
        "from tqdm.auto import tqdm\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import lightgbm as lgb\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sct61n7Yp0N5"
      },
      "outputs": [],
      "source": [
        "#Global Variables\n",
        "\n",
        "# VERSION NAME FOR SAVED MODEL FILES\n",
        "VER = 20\n",
        "\n",
        "# TRAIN RANDOM SEED\n",
        "SEED = 42\n",
        "\n",
        "# FILL NAN VALUE\n",
        "NAN_VALUE = -127 # will fit in int8\n",
        "\n",
        "# FOLDS PER MODEL\n",
        "FOLDS = 5\n",
        "\n",
        "NUM_PARTS = 4\n",
        "\n",
        "\n",
        "TRAIN_PATH = 'train.parquet'\n",
        "TEST_PATH = 'test.parquet'\n",
        "TARGET_PATH = 'train_labels.csv'\n",
        "SAVE_PATH = '/content/drive/MyDrive/Amex/parquet/XGB final/'\n",
        "SUBMISSION_FILE_PATH = '/content/drive/MyDrive/Amex/parquet/sample_submission.csv'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEV9Z8ZIp0N6"
      },
      "source": [
        "# Preprocessing and Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QWJevsrgp0N6"
      },
      "outputs": [],
      "source": [
        "#read train or test file\n",
        "def read_file(path = '', usecols = None):\n",
        "    # LOAD DATAFRAME\n",
        "    if usecols is not None: df = pd.read_parquet(path, columns=usecols)\n",
        "    else: df = pd.read_parquet(path) #df = cudf.read_parquet(path)\n",
        "    df['customer_ID'] = df['customer_ID'].str[-16:].apply(int, base =16)\n",
        "    df.S_2 = pd.to_datetime( df.S_2 )\n",
        "    print('shape of data:', df.shape)\n",
        "    return df\n",
        "\n",
        "#as we use the parquet dataset all nan values in int columns are replaced with -1, this function reverts that\n",
        "def revertnan(df):\n",
        "  df[df==-1] = np.nan \n",
        "  return df\n",
        "\n",
        "#fill all na values\n",
        "def fill_na(df, NAN_VALUE):\n",
        "  df = df.fillna(NAN_VALUE)\n",
        "  return df\n",
        "\n",
        "#create feature that captures the number of statements a customer has in the dataset\n",
        "def numberobs_feature(df):\n",
        "  df['number_of_observations'] = df.groupby('customer_ID')['customer_ID'].transform('count')\n",
        "  df.loc[df['B_33'].isnull() & (df.number_of_observations==1),'number_of_observations'] = 0.5\n",
        "  return df\n",
        "\n",
        "#subtraction of payment variables from balance variables\n",
        "def afterpay(df):\n",
        "  # compute \"after pay\" features\n",
        "  for bcol in [f'B_{i}_last' for i in [11,14,17]]+['D_39_last','D_131_last']+[f'S_{i}_last' for i in [16,23]]:\n",
        "    for pcol in ['P_2_last','P_3_last']:\n",
        "      if bcol in df.columns:\n",
        "        df[f'{bcol}-{pcol}'] = df[bcol] - df[pcol]\n",
        "  return df\n",
        "\n",
        "#classification of columns\n",
        "def get_features(df):\n",
        "  all_cols = [c for c in list(df.columns) if c not in ['customer_ID','S_2']]\n",
        "  cat_features = [\"B_30\",\"B_38\",\"D_114\",\"D_116\",\"D_117\",\"D_120\",\"D_126\",\"D_63\",\"D_64\",\"D_66\",\"D_68\"]\n",
        "  num_features = [col for col in all_cols if col not in cat_features]\n",
        "  return all_cols, cat_features, num_features\n",
        "\n",
        "#aggregating rows per customer and creating aggregation features\n",
        "def agg_functions(df, num_features, cat_features, numberobs = False#, exclnullCols, \n",
        "                  #dummy_nan_col\n",
        "                  ):\n",
        "  \n",
        "  test_num_agg = df.groupby(\"customer_ID\")[num_features].agg(['mean', 'std', 'max', 'min', 'last', 'first'])\n",
        "  print('num agg complete')  \n",
        "  test_cat_agg = df.groupby(\"customer_ID\")[cat_features].agg(['count', 'last', 'nunique'])\n",
        "  print('cat agg complete')\n",
        "\n",
        "  df = pd.concat([test_num_agg, test_cat_agg],   #dummy_nan_col_agg, \n",
        "                   # test_nan_agg], \n",
        "                   axis=1)\n",
        "  \n",
        "  print('concat complete')\n",
        "  df.columns = ['_'.join(x) for x in df.columns]\n",
        "\n",
        "  for col in num_features:\n",
        "    if col not in ['number_of_observations']:\n",
        "      last = f'{col}_last'\n",
        "      first = f'{col}_first'\n",
        "      df[f'{col}_abschange'] = df[last] -df[first]  \n",
        "\n",
        "  if numberobs ==True:\n",
        "    print('drop numberobs')\n",
        "    to_drop = ['number_of_observations_mean',  'number_of_observations_max','number_of_observations_std', 'number_of_observations_min', 'number_of_observations_first']\n",
        "    df.drop(to_drop, axis = 1, inplace = True)\n",
        "    df.rename(columns={'number_of_observations_last':'number_of_observations'}, inplace = True)\n",
        "    print('drop numberobs complete')\n",
        "  \n",
        "  #drop all \"first\"-columns\n",
        "  droplist = list(df.loc[:, df.columns.str.contains('first')].columns)\n",
        "  df.drop(droplist, axis = 1, inplace = True)\n",
        "  print('drop first complete')\n",
        "  \n",
        "  del test_num_agg, test_cat_agg\n",
        "  _ = gc.collect()\n",
        "  print('shape after engineering', df.shape )\n",
        "  return df\n",
        "\n",
        "#feature that contains the difference between last and mean\n",
        "def add_meandev(df, num_features):\n",
        "  \n",
        "  for i in [f for f in num_features if f not in ['number_of_observations']]:\n",
        "    last = f'{i}_last'\n",
        "    mean = f'{i}_mean' \n",
        "    df[f'{i}_meandev'] = np.nan\n",
        "    df.loc[(df[last] != np.nan), f'{i}_meandev'] = df[last] -df[mean]\n",
        "\n",
        "  return df\n",
        "\n",
        "#add labels to the train set\n",
        "def add_targets(df, TARGET_PATH):\n",
        "  # ADD TARGETS\n",
        "  targets = pd.read_csv(TARGET_PATH)\n",
        "  targets['customer_ID'] = targets['customer_ID'].str[-16:].apply(int, base =16)\n",
        "  targets = targets.set_index('customer_ID')\n",
        "  df = df.merge(targets, left_index=True, right_index=True, how='left', sort = True)\n",
        "  df.target = df.target.astype('int8')\n",
        "  del targets\n",
        "  df = df.reset_index()\n",
        "  return df\n",
        "\n",
        "#first difference of the last statement for all numeric features\n",
        "def get_difference(df, num_features, train_set = None, Part =None):\n",
        "    df1 = []\n",
        "    customer_ids = []\n",
        "    for customer_id, cus in tqdm(df.groupby(['customer_ID'])):\n",
        "        # Get the differences\n",
        "        diff_df1 = cus[num_features].diff(1).iloc[[-1]].values.astype(np.float32)\n",
        "        # Append to lists\n",
        "        df1.append(diff_df1)\n",
        "        customer_ids.append(customer_id)\n",
        "    # Concatenate\n",
        "    df1 = np.concatenate(df1, axis = 0)\n",
        "    # Transform to dataframe\n",
        "    df1 = pd.DataFrame(df1, columns = [col + '_diff1' for col in df[num_features].columns])\n",
        "    # Add customer id\n",
        "    df1['customer_ID'] = customer_ids\n",
        "    df1.set_index('customer_ID', inplace = True)\n",
        "    if train_set == True: df1.to_parquet(f'{SAVE_PATH}diff_{VER}.parquet')\n",
        "    elif train_set == False: df1.to_parquet(f'{SAVE_PATH}diff_test_{VER}_num{Part}.parquet')\n",
        "    return df1\n",
        "\n",
        "#use label encoding for categorical variables\n",
        "def label_encoding(df, cat_cols):\n",
        "  cat_cols = [f'{i}_last' for i in cat_cols]\n",
        "  for col in cat_cols:\n",
        "    encoder = LabelEncoder()\n",
        "    df[col] = encoder.fit_transform(df[col])\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#all preprocessing/fe functions\n",
        "def preprocess(PATH = TRAIN_PATH, TARGET_PATH = TARGET_PATH, train_set = True, test = None, Part = None):\n",
        "  if train_set == True:\n",
        "    df = read_file(path = TRAIN_PATH)\n",
        "  else:\n",
        "    df = test\n",
        "  print('read file complete')\n",
        "  df = revertnan(df)\n",
        "  print('revertnan complete')\n",
        "  df = numberobs_feature(df)\n",
        "  print('numberobs complete')\n",
        "  all_cols, cat_features, num_features = get_features(df)\n",
        "  print('get features complete')\n",
        "  diff1 = get_difference(df, num_features, train_set = train_set, Part = Part)\n",
        "  #if train_set == True: diff1 = pd.read_parquet(f'{SAVE_PATH}diff_12.parquet')\n",
        "  #elif train_set == False: diff1 = pd.read_parquet(f'{SAVE_PATH}diff_test_12_num{Part}.parquet')\n",
        "  print('get diff complete')\n",
        "  df = agg_functions(df, num_features, cat_features, numberobs = True)\n",
        "  df = df.merge(diff1, left_index=True, right_index=True, how='left') \n",
        "  del diff1\n",
        "  _ = gc.collect()\n",
        "  print('agg features complete')\n",
        "  df = add_meandev(df, num_features)\n",
        "  print('meandev complete')\n",
        "  df = afterpay(df)\n",
        "  print('afterpay complete')\n",
        "  df = label_encoding(df, cat_cols=cat_features)\n",
        "  print('label encoding complete')\n",
        "  df = fill_na(df, NAN_VALUE)\n",
        "  print('fillna complete')\n",
        "  gc.collect()\n",
        "  if train_set == True:\n",
        "    df = add_targets(df, TARGET_PATH)\n",
        "  return df"
      ],
      "metadata": {
        "id": "ESGxGlx23_r9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = preprocess(PATH = TRAIN_PATH)"
      ],
      "metadata": {
        "id": "wneXMBFCxsi7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361,
          "referenced_widgets": [
            "88c7a1d0f73f4af182feef3f6755c060",
            "708c2a3b0f9a413c8b24b4f46d40054e",
            "502c1def21654c4fab74435edd5a4eed",
            "0dfb94bc26a84c73b1d384bb1e5708c7",
            "65b003890180493a96a6cadd7b6e0c69",
            "039f088036474d9780dedd08e344ae87",
            "a2490fc4b2a84a0bad3f69d6298b7fef",
            "742d2f42c5434fb585563a75aaba8ec2",
            "cd27ec552b6b4638a6563e8601bda279",
            "2caf60765f07453d8cd79e729cf8d93e",
            "f47bb8e5f1fd478fa27f46d6ef344976"
          ]
        },
        "outputId": "c813588a-2aa3-44e0-c6c5-a16db78e9411"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape of data: (5531451, 190)\n",
            "read file complete\n",
            "revertnan complete\n",
            "numberobs complete\n",
            "get features complete\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/458913 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "88c7a1d0f73f4af182feef3f6755c060"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "get diff complete\n",
            "num agg complete\n",
            "cat agg complete\n",
            "concat complete\n",
            "drop numberobs\n",
            "drop numberobs complete\n",
            "drop first complete\n",
            "shape after engineering (458913, 1096)\n",
            "agg features complete\n",
            "meandev complete\n",
            "afterpay complete\n",
            "label encoding complete\n",
            "fillna complete\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#save training dataset\n",
        "train.to_parquet(f'{SAVE_PATH}train_{VER}.parquet')"
      ],
      "metadata": {
        "id": "9_72R0miBzTK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#reading training dataset if saved\n",
        "train = pd.read_parquet(f'{SAVE_PATH}train_{VER}.parquet')"
      ],
      "metadata": {
        "id": "rZn6fq8A6S-s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#getting categorical feature names as the model requires these, preprocessing fn could be improved by running this function before preprocessing, then no additional run is required\n",
        "data = read_file(path = TRAIN_PATH)\n",
        "all_cols, cat_features, num_features = get_features(data)\n",
        "del data\n",
        "cat_features = [f\"{cf}_last\" for cf in cat_features]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVfIbRmjQwLs",
        "outputId": "886bdf73-dc4e-43a7-c9df-4918f09afdb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape of data: (5531451, 190)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#get all feature names\n",
        "def get_feature_list(df):\n",
        "  features = df.columns[1:-1]\n",
        "  print(f'There are {len(features)} features!')\n",
        "  return features"
      ],
      "metadata": {
        "id": "dLSwWNVkwika"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = get_feature_list(train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zuPN-LUvwih1",
        "outputId": "26cda1b7-881a-417a-be53-416b9bb2a1a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1465 features!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#save feature names\n",
        "def save_features(features):\n",
        "  with open(f'{SAVE_PATH}features_V{VER}.csv', 'w') as csvfile:\n",
        "    # creating a csv writer object\n",
        "    writer = csv.writer(csvfile)    \n",
        "    writer.writerow(features) "
      ],
      "metadata": {
        "id": "UVJBCPcPFqHf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_features(features)"
      ],
      "metadata": {
        "id": "q_BYp1ZEHfsr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#read features if saved\n",
        "features = pd.read_csv(f'{SAVE_PATH}features_V{VER}.csv')\n",
        "features = pd.Index(features.columns)\n"
      ],
      "metadata": {
        "id": "r2xe0RQw307T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Model"
      ],
      "metadata": {
        "id": "4YdNxSUbxUyq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#competition metric\n",
        "def amex_metric_mod(y_true, y_pred):\n",
        "\n",
        "    labels     = np.transpose(np.array([y_true, y_pred]))\n",
        "    labels     = labels[labels[:, 1].argsort()[::-1]]\n",
        "    weights    = np.where(labels[:,0]==0, 20, 1)\n",
        "    cut_vals   = labels[np.cumsum(weights) <= int(0.04 * np.sum(weights))]\n",
        "    top_four   = np.sum(cut_vals[:,0]) / np.sum(labels[:,0])\n",
        "\n",
        "    gini = [0,0]\n",
        "    for i in [1,0]:\n",
        "        labels         = np.transpose(np.array([y_true, y_pred]))\n",
        "        labels         = labels[labels[:, i].argsort()[::-1]]\n",
        "        weight         = np.where(labels[:,0]==0, 20, 1)\n",
        "        weight_random  = np.cumsum(weight / np.sum(weight))\n",
        "        total_pos      = np.sum(labels[:, 0] *  weight)\n",
        "        cum_pos_found  = np.cumsum(labels[:, 0] * weight)\n",
        "        lorentz        = cum_pos_found / total_pos\n",
        "        gini[i]        = np.sum((lorentz - weight_random) * weight)\n",
        "\n",
        "    return 0.5 * (gini[1]/gini[0] + top_four)"
      ],
      "metadata": {
        "id": "vs-L3HSwybZq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#LGB Parameters\n",
        "def get_lgb_parameters():\n",
        "  \n",
        "  lgb_parms = {\n",
        "        'objective': 'binary',\n",
        "        'metric': 'binary_logloss',\n",
        "        'boosting': 'dart',\n",
        "        'seed': SEED,\n",
        "        'num_leaves': 100,\n",
        "        'learning_rate': 0.01,\n",
        "        'feature_fraction': 0.20,\n",
        "        'bagging_freq': 10,\n",
        "        'bagging_fraction': 0.50,\n",
        "        'n_jobs': -1,\n",
        "        'lambda_l2': 2,\n",
        "        'min_data_in_leaf': 40,\n",
        "        'device_type': 'gpu'\n",
        "        }\n",
        "  \n",
        "  return lgb_parms"
      ],
      "metadata": {
        "id": "oGTdE15Ax1yH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lgb_parms = get_lgb_parameters()"
      ],
      "metadata": {
        "id": "3iP8P1w5x1uj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#training the model \n",
        "def train_model(df, SEED=SEED, SAVE_PATH =SAVE_PATH, VER=VER, cat_features = cat_features):\n",
        "  features_importance= pd.DataFrame({'Feature':[], 'Importance':[]})\n",
        "  oof = []\n",
        "  TRAIN_SUBSAMPLE = 1.0\n",
        "  gc.collect()\n",
        "  kaggle_metrics_folds =[]\n",
        "\n",
        "  skf = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=SEED)\n",
        "  for fold,(train_idx, valid_idx) in enumerate(skf.split(\n",
        "            df, df.target )):\n",
        "\n",
        "    \n",
        "    print('#'*25)\n",
        "    print('### Fold',fold+1)\n",
        "    print('### Train size',len(train_idx),'Valid size',len(valid_idx))\n",
        "    print(f'### Training with {int(TRAIN_SUBSAMPLE*100)}% fold data...')\n",
        "    print('#'*25)\n",
        "    \n",
        "    # TRAIN, VALID, TEST FOR FOLD K\n",
        "    X_train = df.loc[train_idx, features]\n",
        "    y_train = df.loc[train_idx, 'target']\n",
        "\n",
        "    X_valid = df.loc[valid_idx, features]\n",
        "    y_valid = df.loc[valid_idx, 'target']\n",
        "    \n",
        "\n",
        "    lgb_train = lgb.Dataset(X_train, y_train, categorical_feature = cat_features)\n",
        "    lgb_valid = lgb.Dataset(X_valid, y_valid, categorical_feature = cat_features)\n",
        "\n",
        "    print('datasets created')\n",
        "    \n",
        "    # TRAIN MODEL FOLD K\n",
        "\n",
        "    model = lgb.train(\n",
        "            params = lgb_parms,\n",
        "            train_set = lgb_train,\n",
        "            num_boost_round = 10500,\n",
        "            valid_sets = [lgb_train, lgb_valid],\n",
        "            early_stopping_rounds = 1500,\n",
        "            verbose_eval = 300\n",
        "            #feval = lgb_amex_metric\n",
        "            )\n",
        "    joblib.dump(model, f'{SAVE_PATH}lgbm_V{VER}_fold{fold}_seed{SEED}.pkl')\n",
        "\n",
        "    fold_importance_df= pd.DataFrame({'Feature':[], 'Importance':[]})\n",
        "    fold_importance_df['Feature']= features\n",
        "    fold_importance_df['Importance']= model.feature_importance()\n",
        "    fold_importance_df[\"fold\"] = fold + 1\n",
        "    features_importance = pd.concat([features_importance, fold_importance_df], axis=0)\n",
        "            \n",
        "    # INFER OOF FOLD K\n",
        "    oof_preds = model.predict(df.loc[valid_idx, features], num_iteration=model.best_iteration)\n",
        "    acc = amex_metric_mod(y_valid.values, oof_preds)\n",
        "    print('Kaggle Metric =',acc,'\\n')\n",
        "    kaggle_metrics_folds.append(acc)\n",
        "    \n",
        "    # SAVE OOF\n",
        "    df_pred = df.loc[valid_idx, ['customer_ID','target'] ].copy()\n",
        "    df_pred['oof_pred'] = oof_preds\n",
        "    oof.append( df_pred )\n",
        "    \n",
        "    del  X_train, y_train #,Xy_train,\n",
        "    del X_valid, y_valid, model\n",
        "    _ = gc.collect()\n",
        "    \n",
        "  print('#'*25)\n",
        "  oof = pd.concat(oof,axis=0,ignore_index=True).set_index('customer_ID')\n",
        "  acc = amex_metric_mod(oof.target.values, oof.oof_pred.values)\n",
        "  print('OVERALL CV Kaggle Metric =',acc)\n",
        "  print(kaggle_metrics_folds)\n",
        "\n",
        "  oof.to_parquet(f'{SAVE_PATH}oof_V{VER}.csv')\n",
        "  features_importance.to_parquet(f'{SAVE_PATH}importance_V{VER}.csv')\n",
        "  return oof, features_importance"
      ],
      "metadata": {
        "id": "glTabRzUx1nn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "oof, features_importance = train_model(train)"
      ],
      "metadata": {
        "id": "AxBFuMW5x1kM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "oof = pd.read_parquet(f'{SAVE_PATH}oof_V{VER}.csv')"
      ],
      "metadata": {
        "id": "8-9Iu9xfUP3c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare and predict test data"
      ],
      "metadata": {
        "id": "-FSci_IVK90h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CALCULATE SIZE OF EACH SEPARATE TEST PART\n",
        "def get_rows(customers, test, NUM_PARTS = NUM_PARTS, verbose = ''):\n",
        "    chunk = len(customers)//NUM_PARTS\n",
        "    if verbose != '':\n",
        "        print(f'We will process {verbose} data as {NUM_PARTS} separate parts.')\n",
        "        print(f'There will be {chunk} customers in each part (except the last part).')\n",
        "        print('Below are number of rows in each part:')\n",
        "    rows = []\n",
        "\n",
        "    for k in range(NUM_PARTS):\n",
        "        if k==NUM_PARTS-1: cc = customers[k*chunk:]\n",
        "        else: cc = customers[k*chunk:(k+1)*chunk]\n",
        "        s = test.loc[test.customer_ID.isin(cc)].shape[0]\n",
        "        rows.append(s)\n",
        "    if verbose != '': print( rows )\n",
        "    return rows,chunk"
      ],
      "metadata": {
        "id": "uDCUADjDKwWb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_rowsnumcust(TEST_PATH, NUM_PARTS=NUM_PARTS):\n",
        "  print(f'Reading test data...')\n",
        "  test = read_file(path = TEST_PATH, usecols = ['customer_ID','S_2'])\n",
        "  customers = test[['customer_ID']].drop_duplicates().sort_index().values.flatten()\n",
        "  rows,num_cust = get_rows(customers, test[['customer_ID']], NUM_PARTS = NUM_PARTS, verbose = 'test')\n",
        "  return rows,num_cust,customers"
      ],
      "metadata": {
        "id": "eq3hBpd44pR2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rows,num_cust, customers = get_rowsnumcust(TEST_PATH, NUM_PARTS=NUM_PARTS)"
      ],
      "metadata": {
        "id": "hgVJ0VjZy4By",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97a47942-9a84-44e4-f541-22787759270c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading test data...\n",
            "shape of data: (11363762, 2)\n",
            "We will process test data as 4 separate parts.\n",
            "There will be 231155 customers in each part (except the last part).\n",
            "Below are number of rows in each part:\n",
            "[2841209, 2839857, 2842105, 2840591]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# INFER TEST DATA IN PARTS\n",
        "skip_rows = 0\n",
        "skip_cust = 0\n",
        "test_preds = []\n",
        "\n",
        "for k in range(NUM_PARTS):\n",
        "  # READ PART OF TEST DATA\n",
        "  print(f'\\nReading test data...')\n",
        "  test = read_file(path = TEST_PATH)\n",
        "  test = test.sort_index()\n",
        "  test = test.iloc[skip_rows:skip_rows+rows[k]]\n",
        "  skip_rows += rows[k]\n",
        "  print(f'=> Test part {k+1} has shape', test.shape )\n",
        "    \n",
        "  # PROCESS AND FEATURE ENGINEER PART OF TEST DATA\n",
        "  test = preprocess(train_set = False, test = test, Part =k)\n",
        "  if k==NUM_PARTS-1: test = test.loc[customers[skip_cust:]]\n",
        "  else: test = test.loc[customers[skip_cust:skip_cust+num_cust]]\n",
        "  skip_cust += num_cust\n",
        " \n",
        "\n",
        "  print('X_test complete')\n",
        "  #dtest = xgb.DMatrix(data=X_test)\n",
        "  print('dtest complete')\n",
        "  #del test\n",
        "  gc.collect()\n",
        "\n",
        "\n",
        "  # INFER LGB MODELS ON TEST DATA\n",
        "  model = joblib.load(f'{SAVE_PATH}lgbm_V{VER}_fold0_seed{SEED}.pkl')\n",
        "  print('load model complete')\n",
        "  preds = model.predict(test[features])\n",
        "  print('preds complete')\n",
        "  for f in range(1,FOLDS):\n",
        "    del model\n",
        "    gc.collect()\n",
        "    model = joblib.load(f'{SAVE_PATH}lgbm_V{VER}_fold{f}_seed{SEED}.pkl')\n",
        "    print(f'load {f} complete')\n",
        "    preds += model.predict(test[features])\n",
        "    print(f'preds {f} complete')\n",
        "  preds /= FOLDS\n",
        "  test_preds.append(preds)\n",
        "\n",
        "  # CLEAN MEMORY\n",
        "  del test, model\n",
        "  _ = gc.collect()\n",
        "\n",
        "test_preds = np.concatenate(test_preds)\n",
        "test = pd.DataFrame(index=customers,data={'prediction':test_preds})\n",
        "sub = pd.read_csv(SUBMISSION_FILE_PATH)[['customer_ID']]\n",
        "sub['customer_ID_hash'] = sub['customer_ID'].str[-16:].apply(int, base =16)\n",
        "sub = sub.set_index('customer_ID_hash')\n",
        "sub = sub.merge(test[['prediction']], left_index=True, right_index=True, how='left')\n",
        "sub = sub.reset_index(drop=True)\n",
        "\n",
        "sub.to_csv(f'{SAVE_PATH}submission_xgb_v{VER}.csv',index=False)\n",
        "print('Submission file shape is', sub.shape )\n",
        "sub.head()"
      ],
      "metadata": {
        "id": "8pnE74mOdQVW"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "Kopie von Amex LGBM_fin_pd_V20.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "88c7a1d0f73f4af182feef3f6755c060": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_708c2a3b0f9a413c8b24b4f46d40054e",
              "IPY_MODEL_502c1def21654c4fab74435edd5a4eed",
              "IPY_MODEL_0dfb94bc26a84c73b1d384bb1e5708c7"
            ],
            "layout": "IPY_MODEL_65b003890180493a96a6cadd7b6e0c69"
          }
        },
        "708c2a3b0f9a413c8b24b4f46d40054e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_039f088036474d9780dedd08e344ae87",
            "placeholder": "​",
            "style": "IPY_MODEL_a2490fc4b2a84a0bad3f69d6298b7fef",
            "value": "100%"
          }
        },
        "502c1def21654c4fab74435edd5a4eed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_742d2f42c5434fb585563a75aaba8ec2",
            "max": 458913,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cd27ec552b6b4638a6563e8601bda279",
            "value": 458913
          }
        },
        "0dfb94bc26a84c73b1d384bb1e5708c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2caf60765f07453d8cd79e729cf8d93e",
            "placeholder": "​",
            "style": "IPY_MODEL_f47bb8e5f1fd478fa27f46d6ef344976",
            "value": " 458913/458913 [09:52&lt;00:00, 805.58it/s]"
          }
        },
        "65b003890180493a96a6cadd7b6e0c69": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "039f088036474d9780dedd08e344ae87": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2490fc4b2a84a0bad3f69d6298b7fef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "742d2f42c5434fb585563a75aaba8ec2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd27ec552b6b4638a6563e8601bda279": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2caf60765f07453d8cd79e729cf8d93e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f47bb8e5f1fd478fa27f46d6ef344976": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}