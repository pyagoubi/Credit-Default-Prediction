{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pyagoubi/Credit-Default-Prediction/blob/main/Amex_XGBoost_fin_pd.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "586Vr_8-44vN",
        "outputId": "89db65a7-2eb3-4034-e15b-79578f26d07a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive not mounted, so nothing to flush and unmount.\n"
          ]
        }
      ],
      "source": [
        "################### Installing RAPIDS on colab\n",
        "from google.colab import drive\n",
        "drive.flush_and_unmount()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JpiHdOzpItYq"
      },
      "outputs": [],
      "source": [
        "!pip install pynvml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "93jraPg5ItVz"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/rapidsai/rapidsai-csp-utils.git\n",
        "!python rapidsai-csp-utils/colab/env-check.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rrK8Fk6HItSc"
      },
      "outputs": [],
      "source": [
        "!bash rapidsai-csp-utils/colab/update_gcc.sh\n",
        "import os\n",
        "os._exit(00)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CJ30xrtVItPK"
      },
      "outputs": [],
      "source": [
        "# This will install CondaColab.  This will restart your kernel one last time.  Run this cell by itself and only run the next cell once you see the session crash.\n",
        "import condacolab\n",
        "condacolab.install()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nbtk8dTYItMI"
      },
      "outputs": [],
      "source": [
        "# you can now run the rest of the cells as normal\n",
        "import condacolab\n",
        "condacolab.check()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FNQ2SZDcItJM"
      },
      "outputs": [],
      "source": [
        "# Installing RAPIDS is now 'python rapidsai-csp-utils/colab/install_rapids.py <release> <packages>'\n",
        "# The <release> options are 'stable' and 'nightly'.  Leaving it blank or adding any other words will default to stable.\n",
        "!python rapidsai-csp-utils/colab/install_rapids.py stable\n",
        "import os\n",
        "os.environ['NUMBAPRO_NVVM'] = '/usr/local/cuda/nvvm/lib64/libnvvm.so'\n",
        "os.environ['NUMBAPRO_LIBDEVICE'] = '/usr/local/cuda/nvvm/libdevice/'\n",
        "os.environ['CONDA_PREFIX'] = '/usr/local'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOOdZDzIItEG",
        "outputId": "c598cd4e-ebce-4fe5-9d40-beb0e609d4d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "#Mounting Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "6lJRhid0ItBS"
      },
      "outputs": [],
      "source": [
        "#set WD\n",
        "import os\n",
        "os.chdir('/content/drive/MyDrive/Amex/parquet')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rda9uzwxp0N0"
      },
      "source": [
        "# XGBoost \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMo1TkPZp0N4"
      },
      "source": [
        "# Load Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRgokt4bp0N4",
        "outputId": "fb92d7ec-ddb5-4fdb-f29a-ff2b64300dca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RAPIDS version 21.12.02\n"
          ]
        }
      ],
      "source": [
        "# LOAD LIBRARIES\n",
        "import pandas as pd, numpy as np # CPU libraries\n",
        "import cupy, cudf # GPU libraries\n",
        "import matplotlib.pyplot as plt, gc, os\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBRegressor\n",
        "from xgboost import XGBClassifier\n",
        "import csv, itertools\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from xgboost import plot_importance\n",
        "from sklearn.inspection import permutation_importance\n",
        "\n",
        "import itertools\n",
        "\n",
        "\n",
        "print('RAPIDS version',cudf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Sct61n7Yp0N5"
      },
      "outputs": [],
      "source": [
        "# VERSION NAME FOR SAVED MODEL FILES\n",
        "VER = 7\n",
        "\n",
        "# TRAIN RANDOM SEED\n",
        "SEED = 42\n",
        "\n",
        "# FILL NAN VALUE\n",
        "NAN_VALUE = -127 # will fit in int8\n",
        "\n",
        "# FOLDS PER MODEL\n",
        "FOLDS = 5\n",
        "\n",
        "NUM_PARTS = 4\n",
        "\n",
        "\n",
        "TRAIN_PATH = 'train.parquet'\n",
        "TEST_PATH = 'test.parquet'\n",
        "TARGET_PATH = 'train_labels.csv'\n",
        "SAVE_PATH = '/content/drive/MyDrive/Amex/parquet/XGB final/'\n",
        "SUBMISSION_FILE_PATH = '/content/drive/MyDrive/Amex/parquet/sample_submission.csv'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEV9Z8ZIp0N6"
      },
      "source": [
        "# Process and Feature Engineer Train Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "QWJevsrgp0N6"
      },
      "outputs": [],
      "source": [
        "def read_file(path = '', usecols = None):\n",
        "    # LOAD DATAFRAME\n",
        "    if usecols is not None:df = pd.read_parquet(path, columns=usecols)# df = cudf.read_parquet(path, columns=usecols)\n",
        "    else: df = pd.read_parquet(path) #df = cudf.read_parquet(path)\n",
        "    # REDUCE DTYPE FOR CUSTOMER AND DATE\n",
        "    #df['customer_ID'] = df['customer_ID'].str[-16:].str.hex_to_int().astype('int64')\n",
        "    df.S_2 = cudf.to_datetime( df.S_2 )\n",
        "    #df.S_2 = pd.to_datetime( df.S_2 )\n",
        "    print('shape of data:', df.shape)\n",
        "    \n",
        "    return df\n",
        "\n",
        "def to_pd(df):\n",
        "  df = df.to_pandas()\n",
        "  return df\n",
        "\n",
        "def to_cu(df):\n",
        "  df = cudf.from_pandas(df)\n",
        "  return df\n",
        "\n",
        "def revertnan(df):\n",
        "  #df = df.to_pandas()\n",
        "  df[df==-1] = np.nan \n",
        "  #df = cudf.from_pandas(df)\n",
        "  return df\n",
        "\n",
        "def fill_na(df, NAN_VALUE):\n",
        "  df = df.fillna(NAN_VALUE)\n",
        "  return df\n",
        "\n",
        "def numberobs_feature(df):\n",
        "  #df = df.to_pandas()\n",
        "  df['number_of_observations'] = df.groupby('customer_ID')['customer_ID'].transform('count')\n",
        "  df.loc[df['B_33'].isnull() & (df.number_of_observations==1),'number_of_observations'] = 0.5\n",
        "  #df = cudf.from_pandas(df)\n",
        "  return df\n",
        "\n",
        "def afterpay(df):\n",
        "  # compute \"after pay\" features\n",
        "  for bcol in [f'B_{i}' for i in [11,14,17]]+['D_39','D_131']+[f'S_{i}' for i in [16,23]]:\n",
        "    for pcol in ['P_2','P_3']:\n",
        "      if bcol in df.columns:\n",
        "        df[f'{bcol}-{pcol}'] = df[bcol] - df[pcol]\n",
        "  return df\n",
        "\n",
        "def get_features(df):\n",
        "  all_cols = [c for c in list(df.columns) if c not in ['customer_ID','S_2']]\n",
        "  cat_features = [\"B_30\",\"B_38\",\"D_114\",\"D_116\",\"D_117\",\"D_120\",\"D_126\",\"D_63\",\"D_64\",\"D_66\",\"D_68\"]\n",
        "  num_features = [col for col in all_cols if col not in cat_features]\n",
        "  return all_cols, cat_features, num_features\n",
        "\n",
        "def agg_functions(df, num_features, cat_features, numberobs = False#, exclnullCols, \n",
        "                  #dummy_nan_col\n",
        "                  ):\n",
        "  \n",
        "  test_num_agg = df.groupby(\"customer_ID\")[num_features].agg(['mean', 'std', 'max', 'min', 'first', 'last'])\n",
        "\n",
        "  #test_nan_agg = df.groupby(\"customer_ID\")[exclnullCols].agg(['last'])\n",
        "  ##dummy_nan_col_agg = df.groupby(\"customer_ID\")[dummy_nan_col].agg(['sum'])\n",
        "  #df_presence_agg = df.groupby(\"customer_ID\")['number_of_observations'].agg(['last'])\n",
        "  \n",
        "  test_cat_agg = df.groupby(\"customer_ID\")[cat_features].agg(['count', 'last', 'nunique'])\n",
        "\n",
        "\n",
        "  # df = cudf.concat([test_num_agg, test_cat_agg],   #dummy_nan_col_agg, \n",
        "  #                  # test_nan_agg], \n",
        "  #                  axis=1)\n",
        "  df = pd.concat([test_num_agg, test_cat_agg],   #dummy_nan_col_agg, \n",
        "  #                  # test_nan_agg], \n",
        "  #                  axis=1)\n",
        "\n",
        "  \n",
        "  df.columns = ['_'.join(x) for x in df.columns]\n",
        "\n",
        "  if numberobs ==True:\n",
        "    to_drop = ['number_of_observations_mean', 'number_of_observations_std', 'number_of_observations_max','number_of_observations_min', 'number_of_observations_first']\n",
        "    df.drop(to_drop, axis = 1, inplace = True)\n",
        "    df.rename(columns={'number_of_observations_last':'number_of_observations'}, inplace = True)\n",
        "\n",
        "  del test_num_agg, test_cat_agg\n",
        "  _ = gc.collect()\n",
        "  print('shape after engineering', df.shape )\n",
        "  return df\n",
        "\n",
        "def add_meandev(df, num_features):\n",
        "  #df = df.to_pandas()\n",
        "  \n",
        "  for i in [f for f in num_features if f not in ['number_of_observations']]:\n",
        "    #first = f'{i}_first'\n",
        "    last = f'{i}_last'\n",
        "    #min = f'{i}_min'\n",
        "    #max = f'{i}_max' \n",
        "    mean = f'{i}_mean' \n",
        "    df[f'{i}_meandev'] = np.nan\n",
        "    df.loc[(df[last] != np.nan), f'{i}_meandev'] = df[last] -df[mean]\n",
        "\n",
        "  #df = cudf.from_pandas(df)\n",
        "  return df\n",
        "\n",
        "def dropfirst(df):\n",
        "  df = df.to_pandas()\n",
        "  droplist = list(df.loc[:, df.columns.str.contains('first')].columns)\n",
        "  df.drop(droplist, axis = 1, inplace = True)\n",
        "  df = cudf.from_pandas(df)\n",
        "  print('shape after engineering', df.shape )\n",
        "  return df\n",
        "\n",
        "def add_targets(df, TARGET_PATH):\n",
        "  # ADD TARGETS\n",
        "  targets = pd.read_csv(TARGET_PATH) #cudf.read_csv(TARGET_PATH)\n",
        "  #targets['customer_ID'] = targets['customer_ID'].str[-16:].str.hex_to_int().astype('int64')\n",
        "  targets = targets.set_index('customer_ID')\n",
        "  targets = targets.to_pandas()\n",
        "  df = df.to_pandas()\n",
        "  df = df.merge(targets, left_index=True, right_index=True, how='left', sort = True)\n",
        "  df.target = df.target.astype('int8')\n",
        "  del targets\n",
        "\n",
        "  # NEEDED TO MAKE CV DETERMINISTIC (cudf merge above randomly shuffles rows)\n",
        "  df = df.reset_index()\n",
        "  return df\n",
        "\n",
        "def add_B_29(df, B_29):\n",
        "  df.drop('B_29_last', axis = 1, inplace = True)\n",
        "  df = df.merge(B_29, left_index=True, right_index=True, how='left')\n",
        "  del B_29\n",
        "  _ =gc.collect()\n",
        "  df = df.sort_index()\n",
        "  return df\n",
        "\n",
        "def add_Bratios(df):\n",
        "  B_features =df.loc[:, (df.columns.str.contains('B_')) & (df.columns.str.endswith('last'))& (df.columns.str.contains('-')==False)].columns.tolist()\n",
        "  Bpairs = itertools.combinations(B_features,2)\n",
        "  Bpairs = list(Bpairs)\n",
        "  for m,k in Bpairs:\n",
        "    df[f'{m}_{k}'] = np.nan\n",
        "    df.loc[(df[m] != np.nan) & (df[k] != np.nan) & (df[k] != 0),f'{m}_{k}'] = df[m]/df[k]\n",
        "  del Bpairs\n",
        "  _= gc.collect()\n",
        "  return df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#all functions compact\n",
        "def preprocess(PATH = TRAIN_PATH, TARGET_PATH = TARGET_PATH, train_set = True, test = None):\n",
        "  if train_set == True:\n",
        "    df = read_file(path = TRAIN_PATH)\n",
        "  else:\n",
        "    df = test\n",
        "  df = to_pd(df)\n",
        "  df = revertnan(df)\n",
        "  df = numberobs_feature(df)\n",
        "  df = to_cu(df)\n",
        "  df = afterpay(df)\n",
        "  all_cols, cat_features, num_features = get_features(df)\n",
        "  df = agg_functions(df, num_features, cat_features, numberobs = True)\n",
        "  # if train_set == True:\n",
        "  #   B_29 = cudf.read_csv('/content/drive/MyDrive/Amex/parquet/XGB final/B_29_fin.csv')\n",
        "  #   B_29.drop('Unnamed: 0', axis=1, inplace=True)\n",
        "  #   B_29 = B_29.set_index('customer_ID')\n",
        "  # else:\n",
        "  #   B_29 = df['B_29_last']\n",
        "  # df = add_B_29(df, B_29 = B_29)\n",
        "  df = to_pd(df)\n",
        "  df = add_meandev(df, num_features)\n",
        "  # df = add_Bratios(df)\n",
        "  df = to_cu(df)\n",
        "  df = fill_na(df, NAN_VALUE)\n",
        "  #df = dropfirst(df)\n",
        "  #display(df)\n",
        "  #display(df)\n",
        "  if train_set == True:\n",
        "    df = add_targets(df, TARGET_PATH)\n",
        "  return df"
      ],
      "metadata": {
        "id": "ESGxGlx23_r9"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = preprocess(PATH = TRAIN_PATH)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wneXMBFCxsi7",
        "outputId": "14b8700e-0e4b-435f-965c-6ec91586c5fd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "shape of data: (5531451, 190)\n",
            "shape after engineering (458913, 1180)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train"
      ],
      "metadata": {
        "id": "rSUTZf5R4JKT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#del train\n",
        "gc.collect()\n",
        "#train['number_of_observations']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IvDct2Dakbao",
        "outputId": "ab005c67-889e-4cdc-b091-2e39930efc58"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "216"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_feature_list(df):\n",
        "  features = df.columns[1:-1]\n",
        "  print(f'There are {len(features)} features!')\n",
        "  return features"
      ],
      "metadata": {
        "id": "dLSwWNVkwika"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = get_feature_list(train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zuPN-LUvwih1",
        "outputId": "fba6a9a4-7a19-48e5-e105-8e17d782f43f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1371 features!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train['number_of_observations']"
      ],
      "metadata": {
        "id": "IDRqx5cpzaI-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train[['D_131_last','D_131_meandev']]"
      ],
      "metadata": {
        "id": "3LgvaXfvjCo_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HSld8WXE0HLy",
        "outputId": "766f147d-5de4-47b6-ee3d-96d80445aba2"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15403"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "vM8QQf1z0HBZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train XGB"
      ],
      "metadata": {
        "id": "4YdNxSUbxUyq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def amex_metric_mod(y_true, y_pred):\n",
        "\n",
        "    labels     = np.transpose(np.array([y_true, y_pred]))\n",
        "    labels     = labels[labels[:, 1].argsort()[::-1]]\n",
        "    weights    = np.where(labels[:,0]==0, 20, 1)\n",
        "    cut_vals   = labels[np.cumsum(weights) <= int(0.04 * np.sum(weights))]\n",
        "    top_four   = np.sum(cut_vals[:,0]) / np.sum(labels[:,0])\n",
        "\n",
        "    gini = [0,0]\n",
        "    for i in [1,0]:\n",
        "        labels         = np.transpose(np.array([y_true, y_pred]))\n",
        "        labels         = labels[labels[:, i].argsort()[::-1]]\n",
        "        weight         = np.where(labels[:,0]==0, 20, 1)\n",
        "        weight_random  = np.cumsum(weight / np.sum(weight))\n",
        "        total_pos      = np.sum(labels[:, 0] *  weight)\n",
        "        cum_pos_found  = np.cumsum(labels[:, 0] * weight)\n",
        "        lorentz        = cum_pos_found / total_pos\n",
        "        gini[i]        = np.sum((lorentz - weight_random) * weight)\n",
        "\n",
        "    return 0.5 * (gini[1]/gini[0] + top_four)"
      ],
      "metadata": {
        "id": "vs-L3HSwybZq"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_xgb_parameters():\n",
        "\n",
        "  # XGB MODEL PARAMETERS\n",
        "  # xgb_parms = { \n",
        "  #   'max_depth':4, \n",
        "  #   'learning_rate':0.05, \n",
        "  #   'subsample':0.8,\n",
        "  #   'colsample_bytree':0.6, \n",
        "  #   'eval_metric':'logloss',\n",
        "  #   'objective':'binary:logistic',\n",
        "  #   'tree_method':'gpu_hist',\n",
        "  #   'predictor':'gpu_predictor',\n",
        "  #   'random_state':SEED\n",
        "  # }\n",
        "  xgb_parms = {\n",
        "   'lambda': 0.19846538518330817, \n",
        "   'alpha': 0.11499421368543077, \n",
        "   'colsample_bytree': 1.0, \n",
        "   'subsample': 0.6, \n",
        "   'learning_rate': 0.01, \n",
        "   'max_depth': 8, \n",
        "   'min_child_weight': 56,\n",
        "   'eval_metric':'logloss',\n",
        "   'objective':'binary:logistic',\n",
        "   'tree_method':'gpu_hist',\n",
        "   'predictor':'gpu_predictor',\n",
        "   'random_state':SEED  \n",
        "   }\n",
        "  return xgb_parms"
      ],
      "metadata": {
        "id": "oGTdE15Ax1yH"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_parms = get_xgb_parameters()"
      ],
      "metadata": {
        "id": "3iP8P1w5x1uj"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NEEDED WITH DeviceQuantileDMatrix BELOW\n",
        "class IterLoadForDMatrix(xgb.core.DataIter):\n",
        "    def __init__(self, df=None, features=None, target=None, batch_size=256*1024):\n",
        "        self.features = features\n",
        "        self.target = target\n",
        "        self.df = df\n",
        "        self.it = 0 # set iterator to 0\n",
        "        self.batch_size = batch_size\n",
        "        self.batches = int( np.ceil( len(df) / self.batch_size ) )\n",
        "        super().__init__()\n",
        "\n",
        "    def reset(self):\n",
        "        '''Reset the iterator'''\n",
        "        self.it = 0\n",
        "\n",
        "    def next(self, input_data):\n",
        "        '''Yield next batch of data.'''\n",
        "        if self.it == self.batches:\n",
        "            return 0 # Return 0 when there's no more batch.\n",
        "        \n",
        "        a = self.it * self.batch_size\n",
        "        b = min( (self.it + 1) * self.batch_size, len(self.df) )\n",
        "        dt = cudf.DataFrame(self.df.iloc[a:b])\n",
        "        input_data(data=dt[self.features], label=dt[self.target]) #, weight=dt['weight'])\n",
        "        self.it += 1\n",
        "        return 1"
      ],
      "metadata": {
        "id": "68d26hD_x1rR"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = train.to_pandas()"
      ],
      "metadata": {
        "id": "CPN1Mfq4y6Nu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(df, SEED=SEED, SAVE_PATH =SAVE_PATH, VER=VER):\n",
        "  importances = []\n",
        "  oof = []\n",
        "  TRAIN_SUBSAMPLE = 1.0\n",
        "  gc.collect()\n",
        "\n",
        "  skf = KFold(n_splits=FOLDS, shuffle=True, random_state=SEED)\n",
        "  for fold,(train_idx, valid_idx) in enumerate(skf.split(\n",
        "            df, df.target )):\n",
        "    # TRAIN WITH SUBSAMPLE OF TRAIN FOLD DATA\n",
        "    if TRAIN_SUBSAMPLE<1.0:\n",
        "        np.random.seed(SEED)\n",
        "        train_idx = np.random.choice(train_idx, \n",
        "                       int(len(train_idx)*TRAIN_SUBSAMPLE), replace=False)\n",
        "        np.random.seed(None)\n",
        "    \n",
        "    print('#'*25)\n",
        "    print('### Fold',fold+1)\n",
        "    print('### Train size',len(train_idx),'Valid size',len(valid_idx))\n",
        "    print(f'### Training with {int(TRAIN_SUBSAMPLE*100)}% fold data...')\n",
        "    print('#'*25)\n",
        "    \n",
        "    # TRAIN, VALID, TEST FOR FOLD K\n",
        "    Xy_train = IterLoadForDMatrix(train.loc[train_idx], features, 'target')\n",
        "    X_valid = df.loc[valid_idx, features]\n",
        "    y_valid = df.loc[valid_idx, 'target']\n",
        "    \n",
        "    dtrain = xgb.DeviceQuantileDMatrix(Xy_train, max_bin=256)\n",
        "    dvalid = xgb.DMatrix(data=X_valid, label=y_valid)\n",
        "    \n",
        "    # TRAIN MODEL FOLD K\n",
        "    model = xgb.train(xgb_parms, \n",
        "                dtrain=dtrain,\n",
        "                evals=[(dtrain,'train'),(dvalid,'valid')],\n",
        "                num_boost_round=9999,\n",
        "                early_stopping_rounds=100,\n",
        "                verbose_eval=100) \n",
        "    model.save_model(f'{SAVE_PATH}XGB_v{VER}_fold{fold}.xgb')\n",
        "    \n",
        "    # GET FEATURE IMPORTANCE FOR FOLD K\n",
        "    dd = model.get_score(importance_type='weight')\n",
        "    df_pred = pd.DataFrame({'feature':dd.keys(),f'importance_{fold}':dd.values()})\n",
        "    importances.append(df_pred)\n",
        "            \n",
        "    # INFER OOF FOLD K\n",
        "    oof_preds = model.predict(dvalid)\n",
        "    acc = amex_metric_mod(y_valid.values, oof_preds)\n",
        "    print('Kaggle Metric =',acc,'\\n')\n",
        "    \n",
        "    # SAVE OOF\n",
        "    df_pred = df.loc[valid_idx, ['customer_ID','target'] ].copy()\n",
        "    df_pred['oof_pred'] = oof_preds\n",
        "    oof.append( df_pred )\n",
        "    \n",
        "    del dtrain, Xy_train, dd, df_pred\n",
        "    del X_valid, y_valid, dvalid, model\n",
        "    _ = gc.collect()\n",
        "    \n",
        "  print('#'*25)\n",
        "  oof = pd.concat(oof,axis=0,ignore_index=True).set_index('customer_ID')\n",
        "  acc = amex_metric_mod(oof.target.values, oof.oof_pred.values)\n",
        "  print('OVERALL CV Kaggle Metric =',acc)"
      ],
      "metadata": {
        "id": "glTabRzUx1nn"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AxBFuMW5x1kM",
        "outputId": "12dce82b-6322-440f-c5c2-c0adf4640da7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#########################\n",
            "### Fold 1\n",
            "### Train size 367130 Valid size 91783\n",
            "### Training with 100% fold data...\n",
            "#########################\n",
            "[0]\ttrain-logloss:0.68639\tvalid-logloss:0.68643\n",
            "[100]\ttrain-logloss:0.35618\tvalid-logloss:0.35987\n",
            "[200]\ttrain-logloss:0.26558\tvalid-logloss:0.27215\n",
            "[300]\ttrain-logloss:0.23373\tvalid-logloss:0.24271\n",
            "[400]\ttrain-logloss:0.22046\tvalid-logloss:0.23154\n",
            "[500]\ttrain-logloss:0.21372\tvalid-logloss:0.22662\n",
            "[600]\ttrain-logloss:0.20927\tvalid-logloss:0.22391\n",
            "[700]\ttrain-logloss:0.20568\tvalid-logloss:0.22214\n",
            "[800]\ttrain-logloss:0.20287\tvalid-logloss:0.22090\n",
            "[900]\ttrain-logloss:0.20033\tvalid-logloss:0.21997\n",
            "[1000]\ttrain-logloss:0.19817\tvalid-logloss:0.21924\n",
            "[1100]\ttrain-logloss:0.19603\tvalid-logloss:0.21866\n",
            "[1200]\ttrain-logloss:0.19402\tvalid-logloss:0.21818\n",
            "[1300]\ttrain-logloss:0.19219\tvalid-logloss:0.21781\n",
            "[1400]\ttrain-logloss:0.19051\tvalid-logloss:0.21746\n",
            "[1500]\ttrain-logloss:0.18882\tvalid-logloss:0.21718\n",
            "[1600]\ttrain-logloss:0.18720\tvalid-logloss:0.21694\n",
            "[1700]\ttrain-logloss:0.18559\tvalid-logloss:0.21673\n",
            "[1800]\ttrain-logloss:0.18399\tvalid-logloss:0.21655\n",
            "[1900]\ttrain-logloss:0.18255\tvalid-logloss:0.21637\n",
            "[2000]\ttrain-logloss:0.18105\tvalid-logloss:0.21620\n",
            "[2100]\ttrain-logloss:0.17961\tvalid-logloss:0.21609\n",
            "[2200]\ttrain-logloss:0.17829\tvalid-logloss:0.21602\n",
            "[2300]\ttrain-logloss:0.17684\tvalid-logloss:0.21591\n",
            "[2400]\ttrain-logloss:0.17554\tvalid-logloss:0.21582\n",
            "[2500]\ttrain-logloss:0.17422\tvalid-logloss:0.21574\n",
            "[2600]\ttrain-logloss:0.17296\tvalid-logloss:0.21570\n",
            "[2700]\ttrain-logloss:0.17168\tvalid-logloss:0.21561\n",
            "[2800]\ttrain-logloss:0.17042\tvalid-logloss:0.21555\n",
            "[2900]\ttrain-logloss:0.16916\tvalid-logloss:0.21551\n",
            "[3000]\ttrain-logloss:0.16794\tvalid-logloss:0.21545\n",
            "[3100]\ttrain-logloss:0.16672\tvalid-logloss:0.21542\n",
            "[3200]\ttrain-logloss:0.16545\tvalid-logloss:0.21537\n",
            "[3300]\ttrain-logloss:0.16418\tvalid-logloss:0.21535\n",
            "[3400]\ttrain-logloss:0.16300\tvalid-logloss:0.21532\n",
            "[3500]\ttrain-logloss:0.16191\tvalid-logloss:0.21531\n",
            "[3600]\ttrain-logloss:0.16073\tvalid-logloss:0.21528\n",
            "[3666]\ttrain-logloss:0.15993\tvalid-logloss:0.21529\n",
            "Kaggle Metric = 0.7949513256382374 \n",
            "\n",
            "#########################\n",
            "### Fold 2\n",
            "### Train size 367130 Valid size 91783\n",
            "### Training with 100% fold data...\n",
            "#########################\n",
            "[0]\ttrain-logloss:0.68640\tvalid-logloss:0.68642\n",
            "[100]\ttrain-logloss:0.35650\tvalid-logloss:0.35906\n",
            "[200]\ttrain-logloss:0.26590\tvalid-logloss:0.27087\n",
            "[300]\ttrain-logloss:0.23407\tvalid-logloss:0.24121\n",
            "[400]\ttrain-logloss:0.22086\tvalid-logloss:0.22986\n",
            "[500]\ttrain-logloss:0.21423\tvalid-logloss:0.22488\n",
            "[600]\ttrain-logloss:0.20970\tvalid-logloss:0.22210\n",
            "[700]\ttrain-logloss:0.20626\tvalid-logloss:0.22039\n",
            "[800]\ttrain-logloss:0.20335\tvalid-logloss:0.21916\n",
            "[900]\ttrain-logloss:0.20085\tvalid-logloss:0.21825\n",
            "[1000]\ttrain-logloss:0.19870\tvalid-logloss:0.21758\n",
            "[1100]\ttrain-logloss:0.19653\tvalid-logloss:0.21702\n",
            "[1200]\ttrain-logloss:0.19462\tvalid-logloss:0.21660\n",
            "[1300]\ttrain-logloss:0.19277\tvalid-logloss:0.21623\n",
            "[1400]\ttrain-logloss:0.19104\tvalid-logloss:0.21591\n",
            "[1500]\ttrain-logloss:0.18940\tvalid-logloss:0.21566\n",
            "[1600]\ttrain-logloss:0.18775\tvalid-logloss:0.21545\n",
            "[1700]\ttrain-logloss:0.18623\tvalid-logloss:0.21527\n",
            "[1800]\ttrain-logloss:0.18467\tvalid-logloss:0.21511\n",
            "[1900]\ttrain-logloss:0.18313\tvalid-logloss:0.21499\n",
            "[2000]\ttrain-logloss:0.18172\tvalid-logloss:0.21485\n",
            "[2100]\ttrain-logloss:0.18024\tvalid-logloss:0.21473\n",
            "[2200]\ttrain-logloss:0.17882\tvalid-logloss:0.21464\n",
            "[2300]\ttrain-logloss:0.17738\tvalid-logloss:0.21457\n",
            "[2400]\ttrain-logloss:0.17607\tvalid-logloss:0.21450\n",
            "[2500]\ttrain-logloss:0.17464\tvalid-logloss:0.21443\n",
            "[2600]\ttrain-logloss:0.17337\tvalid-logloss:0.21437\n",
            "[2700]\ttrain-logloss:0.17215\tvalid-logloss:0.21432\n",
            "[2800]\ttrain-logloss:0.17080\tvalid-logloss:0.21426\n",
            "[2900]\ttrain-logloss:0.16956\tvalid-logloss:0.21422\n",
            "[3000]\ttrain-logloss:0.16823\tvalid-logloss:0.21418\n",
            "[3100]\ttrain-logloss:0.16701\tvalid-logloss:0.21415\n",
            "[3200]\ttrain-logloss:0.16585\tvalid-logloss:0.21413\n",
            "[3300]\ttrain-logloss:0.16464\tvalid-logloss:0.21412\n",
            "[3400]\ttrain-logloss:0.16351\tvalid-logloss:0.21410\n",
            "[3500]\ttrain-logloss:0.16233\tvalid-logloss:0.21409\n",
            "[3600]\ttrain-logloss:0.16115\tvalid-logloss:0.21409\n",
            "[3637]\ttrain-logloss:0.16069\tvalid-logloss:0.21408\n",
            "Kaggle Metric = 0.7962063035674977 \n",
            "\n",
            "#########################\n",
            "### Fold 3\n",
            "### Train size 367130 Valid size 91783\n",
            "### Training with 100% fold data...\n",
            "#########################\n",
            "[0]\ttrain-logloss:0.68641\tvalid-logloss:0.68646\n",
            "[100]\ttrain-logloss:0.35593\tvalid-logloss:0.36034\n",
            "[200]\ttrain-logloss:0.26517\tvalid-logloss:0.27291\n",
            "[300]\ttrain-logloss:0.23331\tvalid-logloss:0.24386\n",
            "[400]\ttrain-logloss:0.22004\tvalid-logloss:0.23283\n",
            "[500]\ttrain-logloss:0.21347\tvalid-logloss:0.22807\n",
            "[600]\ttrain-logloss:0.20890\tvalid-logloss:0.22547\n",
            "[700]\ttrain-logloss:0.20545\tvalid-logloss:0.22384\n",
            "[800]\ttrain-logloss:0.20258\tvalid-logloss:0.22268\n",
            "[900]\ttrain-logloss:0.20001\tvalid-logloss:0.22185\n",
            "[1000]\ttrain-logloss:0.19773\tvalid-logloss:0.22117\n",
            "[1100]\ttrain-logloss:0.19566\tvalid-logloss:0.22063\n",
            "[1200]\ttrain-logloss:0.19370\tvalid-logloss:0.22022\n",
            "[1300]\ttrain-logloss:0.19188\tvalid-logloss:0.21988\n",
            "[1400]\ttrain-logloss:0.19011\tvalid-logloss:0.21959\n",
            "[1500]\ttrain-logloss:0.18841\tvalid-logloss:0.21938\n",
            "[1600]\ttrain-logloss:0.18679\tvalid-logloss:0.21919\n",
            "[1700]\ttrain-logloss:0.18525\tvalid-logloss:0.21900\n",
            "[1800]\ttrain-logloss:0.18375\tvalid-logloss:0.21882\n",
            "[1900]\ttrain-logloss:0.18221\tvalid-logloss:0.21869\n",
            "[2000]\ttrain-logloss:0.18085\tvalid-logloss:0.21859\n",
            "[2100]\ttrain-logloss:0.17943\tvalid-logloss:0.21850\n",
            "[2200]\ttrain-logloss:0.17800\tvalid-logloss:0.21842\n",
            "[2300]\ttrain-logloss:0.17663\tvalid-logloss:0.21833\n",
            "[2400]\ttrain-logloss:0.17532\tvalid-logloss:0.21826\n",
            "[2500]\ttrain-logloss:0.17399\tvalid-logloss:0.21816\n",
            "[2600]\ttrain-logloss:0.17274\tvalid-logloss:0.21810\n",
            "[2700]\ttrain-logloss:0.17144\tvalid-logloss:0.21803\n",
            "[2800]\ttrain-logloss:0.17015\tvalid-logloss:0.21798\n",
            "[2900]\ttrain-logloss:0.16885\tvalid-logloss:0.21796\n",
            "[3000]\ttrain-logloss:0.16766\tvalid-logloss:0.21791\n",
            "[3100]\ttrain-logloss:0.16631\tvalid-logloss:0.21790\n",
            "[3200]\ttrain-logloss:0.16509\tvalid-logloss:0.21785\n",
            "[3300]\ttrain-logloss:0.16387\tvalid-logloss:0.21781\n",
            "[3400]\ttrain-logloss:0.16270\tvalid-logloss:0.21780\n",
            "[3500]\ttrain-logloss:0.16145\tvalid-logloss:0.21776\n",
            "[3600]\ttrain-logloss:0.16020\tvalid-logloss:0.21776\n",
            "[3620]\ttrain-logloss:0.15995\tvalid-logloss:0.21776\n",
            "Kaggle Metric = 0.7935022512866272 \n",
            "\n",
            "#########################\n",
            "### Fold 4\n",
            "### Train size 367131 Valid size 91782\n",
            "### Training with 100% fold data...\n",
            "#########################\n",
            "[0]\ttrain-logloss:0.68640\tvalid-logloss:0.68646\n",
            "[100]\ttrain-logloss:0.35603\tvalid-logloss:0.36075\n",
            "[200]\ttrain-logloss:0.26529\tvalid-logloss:0.27317\n",
            "[300]\ttrain-logloss:0.23343\tvalid-logloss:0.24389\n",
            "[400]\ttrain-logloss:0.22009\tvalid-logloss:0.23274\n",
            "[500]\ttrain-logloss:0.21351\tvalid-logloss:0.22794\n",
            "[600]\ttrain-logloss:0.20891\tvalid-logloss:0.22537\n",
            "[700]\ttrain-logloss:0.20549\tvalid-logloss:0.22372\n",
            "[800]\ttrain-logloss:0.20262\tvalid-logloss:0.22261\n",
            "[900]\ttrain-logloss:0.20014\tvalid-logloss:0.22177\n",
            "[1000]\ttrain-logloss:0.19789\tvalid-logloss:0.22111\n",
            "[1100]\ttrain-logloss:0.19583\tvalid-logloss:0.22057\n",
            "[1200]\ttrain-logloss:0.19391\tvalid-logloss:0.22014\n",
            "[1300]\ttrain-logloss:0.19206\tvalid-logloss:0.21975\n",
            "[1400]\ttrain-logloss:0.19033\tvalid-logloss:0.21942\n",
            "[1500]\ttrain-logloss:0.18872\tvalid-logloss:0.21918\n",
            "[1600]\ttrain-logloss:0.18701\tvalid-logloss:0.21897\n",
            "[1700]\ttrain-logloss:0.18542\tvalid-logloss:0.21875\n",
            "[1800]\ttrain-logloss:0.18386\tvalid-logloss:0.21861\n",
            "[1900]\ttrain-logloss:0.18232\tvalid-logloss:0.21848\n",
            "[2000]\ttrain-logloss:0.18083\tvalid-logloss:0.21835\n",
            "[2100]\ttrain-logloss:0.17938\tvalid-logloss:0.21824\n",
            "[2200]\ttrain-logloss:0.17792\tvalid-logloss:0.21813\n",
            "[2300]\ttrain-logloss:0.17650\tvalid-logloss:0.21801\n",
            "[2400]\ttrain-logloss:0.17514\tvalid-logloss:0.21795\n",
            "[2500]\ttrain-logloss:0.17370\tvalid-logloss:0.21788\n",
            "[2600]\ttrain-logloss:0.17244\tvalid-logloss:0.21783\n",
            "[2700]\ttrain-logloss:0.17108\tvalid-logloss:0.21781\n",
            "[2800]\ttrain-logloss:0.16975\tvalid-logloss:0.21776\n",
            "[2900]\ttrain-logloss:0.16842\tvalid-logloss:0.21773\n",
            "[3000]\ttrain-logloss:0.16715\tvalid-logloss:0.21770\n",
            "[3100]\ttrain-logloss:0.16586\tvalid-logloss:0.21764\n",
            "[3200]\ttrain-logloss:0.16457\tvalid-logloss:0.21761\n",
            "[3300]\ttrain-logloss:0.16336\tvalid-logloss:0.21760\n",
            "[3400]\ttrain-logloss:0.16210\tvalid-logloss:0.21756\n",
            "[3500]\ttrain-logloss:0.16098\tvalid-logloss:0.21753\n",
            "[3600]\ttrain-logloss:0.15988\tvalid-logloss:0.21754\n",
            "[3604]\ttrain-logloss:0.15984\tvalid-logloss:0.21754\n",
            "Kaggle Metric = 0.790471415119967 \n",
            "\n",
            "#########################\n",
            "### Fold 5\n",
            "### Train size 367131 Valid size 91782\n",
            "### Training with 100% fold data...\n",
            "#########################\n",
            "[0]\ttrain-logloss:0.68641\tvalid-logloss:0.68642\n",
            "[100]\ttrain-logloss:0.35663\tvalid-logloss:0.35890\n",
            "[200]\ttrain-logloss:0.26605\tvalid-logloss:0.27070\n",
            "[300]\ttrain-logloss:0.23427\tvalid-logloss:0.24110\n",
            "[400]\ttrain-logloss:0.22103\tvalid-logloss:0.22983\n",
            "[500]\ttrain-logloss:0.21438\tvalid-logloss:0.22495\n",
            "[600]\ttrain-logloss:0.20978\tvalid-logloss:0.22225\n",
            "[700]\ttrain-logloss:0.20633\tvalid-logloss:0.22057\n",
            "[800]\ttrain-logloss:0.20338\tvalid-logloss:0.21933\n",
            "[900]\ttrain-logloss:0.20098\tvalid-logloss:0.21848\n",
            "[1000]\ttrain-logloss:0.19876\tvalid-logloss:0.21779\n",
            "[1100]\ttrain-logloss:0.19675\tvalid-logloss:0.21722\n",
            "[1200]\ttrain-logloss:0.19467\tvalid-logloss:0.21676\n",
            "[1300]\ttrain-logloss:0.19281\tvalid-logloss:0.21638\n",
            "[1400]\ttrain-logloss:0.19113\tvalid-logloss:0.21611\n",
            "[1500]\ttrain-logloss:0.18938\tvalid-logloss:0.21581\n",
            "[1600]\ttrain-logloss:0.18782\tvalid-logloss:0.21556\n",
            "[1700]\ttrain-logloss:0.18622\tvalid-logloss:0.21535\n",
            "[1800]\ttrain-logloss:0.18469\tvalid-logloss:0.21516\n",
            "[1900]\ttrain-logloss:0.18315\tvalid-logloss:0.21499\n",
            "[2000]\ttrain-logloss:0.18173\tvalid-logloss:0.21486\n",
            "[2100]\ttrain-logloss:0.18033\tvalid-logloss:0.21474\n",
            "[2200]\ttrain-logloss:0.17894\tvalid-logloss:0.21462\n",
            "[2300]\ttrain-logloss:0.17753\tvalid-logloss:0.21452\n",
            "[2400]\ttrain-logloss:0.17611\tvalid-logloss:0.21442\n",
            "[2500]\ttrain-logloss:0.17478\tvalid-logloss:0.21433\n",
            "[2600]\ttrain-logloss:0.17344\tvalid-logloss:0.21424\n",
            "[2700]\ttrain-logloss:0.17219\tvalid-logloss:0.21416\n",
            "[2800]\ttrain-logloss:0.17092\tvalid-logloss:0.21409\n",
            "[2900]\ttrain-logloss:0.16968\tvalid-logloss:0.21405\n",
            "[3000]\ttrain-logloss:0.16843\tvalid-logloss:0.21401\n",
            "[3100]\ttrain-logloss:0.16723\tvalid-logloss:0.21397\n",
            "[3200]\ttrain-logloss:0.16603\tvalid-logloss:0.21391\n",
            "[3300]\ttrain-logloss:0.16483\tvalid-logloss:0.21390\n",
            "[3400]\ttrain-logloss:0.16356\tvalid-logloss:0.21384\n",
            "[3500]\ttrain-logloss:0.16235\tvalid-logloss:0.21379\n",
            "[3600]\ttrain-logloss:0.16115\tvalid-logloss:0.21377\n",
            "[3700]\ttrain-logloss:0.16004\tvalid-logloss:0.21374\n",
            "[3800]\ttrain-logloss:0.15891\tvalid-logloss:0.21372\n",
            "[3900]\ttrain-logloss:0.15783\tvalid-logloss:0.21371\n",
            "[4000]\ttrain-logloss:0.15668\tvalid-logloss:0.21369\n",
            "[4100]\ttrain-logloss:0.15558\tvalid-logloss:0.21367\n",
            "[4200]\ttrain-logloss:0.15451\tvalid-logloss:0.21365\n",
            "[4300]\ttrain-logloss:0.15338\tvalid-logloss:0.21365\n",
            "[4400]\ttrain-logloss:0.15218\tvalid-logloss:0.21362\n",
            "[4499]\ttrain-logloss:0.15115\tvalid-logloss:0.21362\n",
            "Kaggle Metric = 0.798093632075475 \n",
            "\n",
            "#########################\n",
            "OVERALL CV Kaggle Metric = 0.7945773954764357\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "base = 0.791536\n",
        "ohne na Behandlung = 0.790870\n",
        "na fill nach agg = 0.7916640\n",
        "revertnan und na_fill nach agg = 0.791823\n",
        "mit number of obs (und na_fill nach agg) = 0.79223834\n",
        "so mit growth feature = 0.79185923 ??\n",
        "mit abschange = 0.7917617 ??\n",
        "mit abschange nicht skaliert = 0.791859 ?\n",
        "number of obs in buckets (größer 10) + abschange = 0.7915386 ?\n",
        "mit number_of_obs und min-max = 0.792181\n",
        "mit number of obs (und na_fill nach agg)fillna vor meandev + mean deviation = 0.792464\n",
        "mit number of obs (und na_fill nach agg) fillna nach meandev + mean deviation = 0.79237036 (=VER 1, 0.794 public lb)\n",
        "s.o. + after pay features = 0.79310\n",
        "VER 3: s.o. mit getunten Hyperparametern = 0.794355 (V3, 0.796 public lb)\n",
        "s.o. mit B_29 = 0.794610 (v5, 0.796 public lb)\n",
        "so ohne B_29 mit 1:100 Bratios = 0.7951046\n",
        "so mit allen Bratios = 0.7952144 (0.795 lb)\n",
        "VER 3 + first: 0.794577\n",
        "\n"
      ],
      "metadata": {
        "id": "0pXdNTZV-CMC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "0izMrfetbpRm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7-e9YSq-M99",
        "outputId": "8a81cedc-5da1-44fb-818f-6c3bcf7849cf"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "279"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del train"
      ],
      "metadata": {
        "id": "2T5tEgrlKwZV"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepare Testdata"
      ],
      "metadata": {
        "id": "-FSci_IVK90h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CALCULATE SIZE OF EACH SEPARATE TEST PART\n",
        "def get_rows(customers, test, NUM_PARTS = 4, verbose = ''):\n",
        "    chunk = len(customers)//NUM_PARTS\n",
        "    if verbose != '':\n",
        "        print(f'We will process {verbose} data as {NUM_PARTS} separate parts.')\n",
        "        print(f'There will be {chunk} customers in each part (except the last part).')\n",
        "        print('Below are number of rows in each part:')\n",
        "    rows = []\n",
        "\n",
        "    for k in range(NUM_PARTS):\n",
        "        if k==NUM_PARTS-1: cc = customers[k*chunk:]\n",
        "        else: cc = customers[k*chunk:(k+1)*chunk]\n",
        "        s = test.loc[test.customer_ID.isin(cc)].shape[0]\n",
        "        rows.append(s)\n",
        "    if verbose != '': print( rows )\n",
        "    return rows,chunk"
      ],
      "metadata": {
        "id": "uDCUADjDKwWb"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_rowsnumcust(TEST_PATH, NUM_PARTS=NUM_PARTS):\n",
        "  print(f'Reading test data...')\n",
        "  test = read_file(path = TEST_PATH, usecols = ['customer_ID','S_2'])\n",
        "  customers = test[['customer_ID']].drop_duplicates().sort_index().values.flatten()\n",
        "  rows,num_cust = get_rows(customers, test[['customer_ID']], NUM_PARTS = NUM_PARTS, verbose = 'test')\n",
        "  return rows,num_cust,customers"
      ],
      "metadata": {
        "id": "eq3hBpd44pR2"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def infer_test(rows,num_cust,customers, VER=VER,features=features, SUBMISSION_FILE_PATH = SUBMISSION_FILE_PATH ):\n",
        "  # INFER TEST DATA IN PARTS\n",
        "  skip_rows = 0\n",
        "  skip_cust = 0\n",
        "  test_preds = []\n",
        "\n",
        "  for k in range(NUM_PARTS):\n",
        "    # READ PART OF TEST DATA\n",
        "    print(f'\\nReading test data...')\n",
        "    test = read_file(path = TEST_PATH)\n",
        "    test = test.iloc[skip_rows:skip_rows+rows[k]]\n",
        "    skip_rows += rows[k]\n",
        "    print(f'=> Test part {k+1} has shape', test.shape )\n",
        "    \n",
        "    # PROCESS AND FEATURE ENGINEER PART OF TEST DATA\n",
        "    test = preprocess(train_set = False, test = test) \n",
        "    if k==NUM_PARTS-1: test = test.loc[customers[skip_cust:]]\n",
        "    else: test = test.loc[customers[skip_cust:skip_cust+num_cust]]\n",
        "    skip_cust += num_cust\n",
        "    \n",
        "    # TEST DATA FOR XGB\n",
        "    X_test = test[features]\n",
        "    dtest = xgb.DMatrix(data=X_test)\n",
        "    test = test[['P_2_mean']] # reduce memory\n",
        "    del X_test\n",
        "    gc.collect()\n",
        "\n",
        "    # INFER XGB MODELS ON TEST DATA\n",
        "    model = xgb.Booster()\n",
        "    model.load_model(f'{SAVE_PATH}XGB_v{VER}_fold0.xgb')\n",
        "    preds = model.predict(dtest)\n",
        "    for f in range(1,FOLDS):\n",
        "        model.load_model(f'{SAVE_PATH}XGB_v{VER}_fold{f}.xgb')\n",
        "        preds += model.predict(dtest)\n",
        "    preds /= FOLDS\n",
        "    test_preds.append(preds)\n",
        "\n",
        "    # CLEAN MEMORY\n",
        "    del dtest, model\n",
        "    _ = gc.collect()\n",
        "\n",
        "  test_preds = np.concatenate(test_preds)\n",
        "  test = cudf.DataFrame(index=customers,data={'prediction':test_preds})\n",
        "  sub = cudf.read_csv(SUBMISSION_FILE_PATH)[['customer_ID']]\n",
        "  sub['customer_ID_hash'] = sub['customer_ID'].str[-16:].str.hex_to_int().astype('int64')\n",
        "  sub = sub.set_index('customer_ID_hash')\n",
        "  sub = sub.merge(test[['prediction']], left_index=True, right_index=True, how='left')\n",
        "  sub = sub.reset_index(drop=True)\n",
        "\n",
        "  sub.to_csv(f'{SAVE_PATH}submission_xgb_v{VER}.csv',index=False)\n",
        "  print('Submission file shape is', sub.shape )\n",
        "  sub.head()"
      ],
      "metadata": {
        "id": "ZaJkk90pKwQA"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_pred():\n",
        "  rows,num_cust, customers = get_rowsnumcust(TEST_PATH, NUM_PARTS=NUM_PARTS)\n",
        "  infer_test(rows=rows,num_cust=num_cust, customers=customers)\n"
      ],
      "metadata": {
        "id": "dJ0oN686KwLG"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_pred()"
      ],
      "metadata": {
        "id": "G5v5tPfX-My7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3a8cc4e-1ceb-4303-db6f-4718b11466bc"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading test data...\n",
            "shape of data: (11363762, 2)\n",
            "We will process test data as 4 separate parts.\n",
            "There will be 231155 customers in each part (except the last part).\n",
            "Below are number of rows in each part:\n",
            "[2841209, 2839857, 2842105, 2840591]\n",
            "\n",
            "Reading test data...\n",
            "shape of data: (11363762, 190)\n",
            "=> Test part 1 has shape (2841209, 190)\n",
            "shape after engineering (231155, 1180)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:132: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Reading test data...\n",
            "shape of data: (11363762, 190)\n",
            "=> Test part 2 has shape (2839857, 190)\n",
            "shape after engineering (231155, 1180)\n",
            "\n",
            "Reading test data...\n",
            "shape of data: (11363762, 190)\n",
            "=> Test part 3 has shape (2842105, 190)\n",
            "shape after engineering (231155, 1180)\n",
            "\n",
            "Reading test data...\n",
            "shape of data: (11363762, 190)\n",
            "=> Test part 4 has shape (2840591, 190)\n",
            "shape after engineering (231156, 1180)\n",
            "Submission file shape is (924621, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gc.collect()"
      ],
      "metadata": {
        "id": "VvWLlyLv39x5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47139ddd-da38-4f1e-faf2-1f03c156b2fd"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "88"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ENDE"
      ],
      "metadata": {
        "id": "GvDANWlLDq5W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#train test split\n",
        "train_df, test_df = train_test_split(train, test_size=0.25, stratify=train['target'])"
      ],
      "metadata": {
        "id": "SKwzqHdATmks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna\n",
        "import optuna"
      ],
      "metadata": {
        "id": "yZqlM7OVdL2b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# optuna\n",
        "\n",
        "def objective(trial, IterLoadForDMatrix, train_df, test_df, features):\n",
        "    \n",
        "    param = {\n",
        "        'booster':'gbtree',\n",
        "        'tree_method':'gpu_hist', \n",
        "        \"objective\": \"binary:logistic\",\n",
        "        'lambda': trial.suggest_loguniform(\n",
        "            'lambda', 1e-3, 10.0\n",
        "        ),\n",
        "        'alpha': trial.suggest_loguniform(\n",
        "            'alpha', 1e-3, 10.0\n",
        "        ),\n",
        "        'colsample_bytree': trial.suggest_float(\n",
        "            'colsample_bytree', 0.5,1,step=0.1\n",
        "        ),\n",
        "        'subsample': trial.suggest_float(\n",
        "            'subsample', 0.5,1,step=0.1\n",
        "        ),\n",
        "        'learning_rate': trial.suggest_float(\n",
        "            'learning_rate', 0.01,0.05,step=0.005\n",
        "        ),\n",
        "        'max_depth': trial.suggest_int(\n",
        "            'max_depth', 4,9,1\n",
        "        ),\n",
        "        'random_state': 99,\n",
        "        'min_child_weight': trial.suggest_int(\n",
        "            'min_child_weight', 1,256,1\n",
        "        ),\n",
        "    }\n",
        "    \n",
        "    \n",
        "\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    oof = []\n",
        "    gc.collect()\n",
        "    \n",
        "\n",
        "        \n",
        "    # TRAIN, VALID, TEST FOR FOLD K\n",
        "    Xy_train = IterLoadForDMatrix(train_df, features, 'target')\n",
        "        \n",
        "    X_valid = test_df.loc[:, features]\n",
        "    y_valid = test_df.loc[:, 'target']\n",
        "      \n",
        "    dtrain = xgb.DeviceQuantileDMatrix(Xy_train, max_bin=256)\n",
        "    dvalid = xgb.DMatrix(data=X_valid, label=y_valid)\n",
        "      \n",
        "        \n",
        "\n",
        "        \n",
        "        # TRAIN MODEL FOLD K\n",
        "    model = xgb.train(param, \n",
        "                  dtrain=dtrain,\n",
        "                  evals=[(dtrain,'train'),(dvalid,'valid')],\n",
        "                  num_boost_round=9999,\n",
        "                  early_stopping_rounds=100,\n",
        "                  verbose_eval=300\n",
        "                  ) \n",
        "      \n",
        "        \n",
        "        # INFER OOF FOLD K\n",
        "    oof_preds = model.predict(dvalid)\n",
        "        #acc = amex_metric_mod(y_valid.values, oof_preds)\n",
        "    \n",
        "    \n",
        "        # SAVE OOF\n",
        "    df = test_df.loc[:, ['customer_ID','target'] ].copy()\n",
        "    df['oof_pred'] = oof_preds\n",
        "    oof.append(df)\n",
        "\n",
        "              \n",
        "\n",
        "\n",
        "    del dtrain, Xy_train, df\n",
        "    del X_valid, y_valid, dvalid, model\n",
        "    _ = gc.collect()\n",
        "    \n",
        "\n",
        "    oof = pd.concat(oof,axis=0,ignore_index=True).set_index('customer_ID')\n",
        "    metric = amex_metric_mod(oof.target.values, oof.oof_pred.values)\n",
        "        \n",
        "    return metric"
      ],
      "metadata": {
        "id": "ZWgF-Jq3TOJY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(lambda trial: objective(\n",
        "        trial, IterLoadForDMatrix, train_df, test_df, features), n_trials= 100) "
      ],
      "metadata": {
        "id": "JrMDm4JITOFj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2f26e32-06ed-4da1-d335-d14a5c83cb6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-08-01 22:22:24,836]\u001b[0m A new study created in memory with name: no-name-4863041f-6924-4558-9691-d5053d28eb41\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[22:22:39] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.66094\tvalid-logloss:0.66104\n",
            "[300]\ttrain-logloss:0.20971\tvalid-logloss:0.21971\n",
            "[600]\ttrain-logloss:0.19954\tvalid-logloss:0.21720\n",
            "[900]\ttrain-logloss:0.19182\tvalid-logloss:0.21666\n",
            "[1200]\ttrain-logloss:0.18473\tvalid-logloss:0.21647\n",
            "[1473]\ttrain-logloss:0.17880\tvalid-logloss:0.21644\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-08-01 22:24:54,137]\u001b[0m Trial 0 finished with value: 0.7916683328681577 and parameters: {'lambda': 0.027517637245856656, 'alpha': 0.01961380463369411, 'colsample_bytree': 0.5, 'subsample': 0.7, 'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 203}. Best is trial 0 with value: 0.7916683328681577.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[22:25:07] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.66995\tvalid-logloss:0.67011\n",
            "[300]\ttrain-logloss:0.20145\tvalid-logloss:0.21984\n",
            "[600]\ttrain-logloss:0.18783\tvalid-logloss:0.21703\n",
            "[900]\ttrain-logloss:0.17787\tvalid-logloss:0.21647\n",
            "[1200]\ttrain-logloss:0.16889\tvalid-logloss:0.21624\n",
            "[1289]\ttrain-logloss:0.16647\tvalid-logloss:0.21631\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-08-01 22:28:00,043]\u001b[0m Trial 1 finished with value: 0.7930665800408387 and parameters: {'lambda': 0.040050278461401155, 'alpha': 0.7429338562118817, 'colsample_bytree': 0.7, 'subsample': 1.0, 'learning_rate': 0.035, 'max_depth': 9, 'min_child_weight': 188}. Best is trial 1 with value: 0.7930665800408387.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[22:28:13] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.66446\tvalid-logloss:0.66453\n",
            "[300]\ttrain-logloss:0.21473\tvalid-logloss:0.22157\n",
            "[600]\ttrain-logloss:0.20580\tvalid-logloss:0.21782\n",
            "[900]\ttrain-logloss:0.20007\tvalid-logloss:0.21680\n",
            "[1200]\ttrain-logloss:0.19490\tvalid-logloss:0.21641\n",
            "[1500]\ttrain-logloss:0.19003\tvalid-logloss:0.21620\n",
            "[1633]\ttrain-logloss:0.18801\tvalid-logloss:0.21618\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-08-01 22:30:31,948]\u001b[0m Trial 2 finished with value: 0.7931976046011235 and parameters: {'lambda': 2.0759991262490445, 'alpha': 0.14516699713364045, 'colsample_bytree': 0.6, 'subsample': 0.7, 'learning_rate': 0.045000000000000005, 'max_depth': 5, 'min_child_weight': 202}. Best is trial 2 with value: 0.7931976046011235.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[22:30:45] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.66326\tvalid-logloss:0.66361\n",
            "[300]\ttrain-logloss:0.16720\tvalid-logloss:0.21865\n",
            "[506]\ttrain-logloss:0.14189\tvalid-logloss:0.21829\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-08-01 22:32:29,135]\u001b[0m Trial 3 finished with value: 0.7900436896004479 and parameters: {'lambda': 8.170956320923727, 'alpha': 0.014507350578292432, 'colsample_bytree': 0.5, 'subsample': 0.5, 'learning_rate': 0.045000000000000005, 'max_depth': 9, 'min_child_weight': 6}. Best is trial 2 with value: 0.7931976046011235.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[22:32:42] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68648\tvalid-logloss:0.68651\n",
            "[300]\ttrain-logloss:0.23615\tvalid-logloss:0.24480\n",
            "[600]\ttrain-logloss:0.21020\tvalid-logloss:0.22506\n",
            "[900]\ttrain-logloss:0.19972\tvalid-logloss:0.22073\n",
            "[1200]\ttrain-logloss:0.19233\tvalid-logloss:0.21878\n",
            "[1500]\ttrain-logloss:0.18621\tvalid-logloss:0.21765\n",
            "[1800]\ttrain-logloss:0.18087\tvalid-logloss:0.21695\n",
            "[2100]\ttrain-logloss:0.17594\tvalid-logloss:0.21646\n",
            "[2400]\ttrain-logloss:0.17165\tvalid-logloss:0.21613\n",
            "[2700]\ttrain-logloss:0.16752\tvalid-logloss:0.21592\n",
            "[3000]\ttrain-logloss:0.16340\tvalid-logloss:0.21575\n",
            "[3300]\ttrain-logloss:0.15965\tvalid-logloss:0.21562\n",
            "[3600]\ttrain-logloss:0.15614\tvalid-logloss:0.21551\n",
            "[3900]\ttrain-logloss:0.15251\tvalid-logloss:0.21546\n",
            "[3935]\ttrain-logloss:0.15216\tvalid-logloss:0.21546\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-08-01 22:40:37,587]\u001b[0m Trial 4 finished with value: 0.7937071894431 and parameters: {'lambda': 4.813457241008532, 'alpha': 0.06200467596226268, 'colsample_bytree': 0.5, 'subsample': 0.9, 'learning_rate': 0.01, 'max_depth': 7, 'min_child_weight': 14}. Best is trial 4 with value: 0.7937071894431.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[22:40:51] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68323\tvalid-logloss:0.68329\n",
            "[300]\ttrain-logloss:0.22713\tvalid-logloss:0.23249\n",
            "[600]\ttrain-logloss:0.21397\tvalid-logloss:0.22247\n",
            "[900]\ttrain-logloss:0.20803\tvalid-logloss:0.21939\n",
            "[1200]\ttrain-logloss:0.20374\tvalid-logloss:0.21799\n",
            "[1500]\ttrain-logloss:0.20013\tvalid-logloss:0.21722\n",
            "[1800]\ttrain-logloss:0.19686\tvalid-logloss:0.21672\n",
            "[2100]\ttrain-logloss:0.19375\tvalid-logloss:0.21646\n",
            "[2400]\ttrain-logloss:0.19082\tvalid-logloss:0.21623\n",
            "[2700]\ttrain-logloss:0.18792\tvalid-logloss:0.21608\n",
            "[3000]\ttrain-logloss:0.18528\tvalid-logloss:0.21594\n",
            "[3300]\ttrain-logloss:0.18241\tvalid-logloss:0.21584\n",
            "[3600]\ttrain-logloss:0.17971\tvalid-logloss:0.21576\n",
            "[3791]\ttrain-logloss:0.17806\tvalid-logloss:0.21575\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-08-01 22:48:07,302]\u001b[0m Trial 5 finished with value: 0.7939719750110332 and parameters: {'lambda': 0.013247742475008572, 'alpha': 0.018509188940509118, 'colsample_bytree': 0.9, 'subsample': 0.6, 'learning_rate': 0.015, 'max_depth': 7, 'min_child_weight': 202}. Best is trial 5 with value: 0.7939719750110332.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[22:48:20] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.66731\tvalid-logloss:0.66742\n",
            "[300]\ttrain-logloss:0.21142\tvalid-logloss:0.22137\n",
            "[600]\ttrain-logloss:0.20140\tvalid-logloss:0.21790\n",
            "[900]\ttrain-logloss:0.19495\tvalid-logloss:0.21696\n",
            "[1200]\ttrain-logloss:0.18889\tvalid-logloss:0.21648\n",
            "[1500]\ttrain-logloss:0.18367\tvalid-logloss:0.21633\n",
            "[1548]\ttrain-logloss:0.18277\tvalid-logloss:0.21633\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-08-01 22:50:52,578]\u001b[0m Trial 6 finished with value: 0.7920212390719875 and parameters: {'lambda': 0.6448641688825628, 'alpha': 2.911844147220834, 'colsample_bytree': 0.8, 'subsample': 1.0, 'learning_rate': 0.04, 'max_depth': 6, 'min_child_weight': 241}. Best is trial 5 with value: 0.7939719750110332.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[22:51:06] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68632\tvalid-logloss:0.68640\n",
            "[300]\ttrain-logloss:0.22494\tvalid-logloss:0.24100\n",
            "[600]\ttrain-logloss:0.19743\tvalid-logloss:0.22274\n",
            "[900]\ttrain-logloss:0.18636\tvalid-logloss:0.21929\n",
            "[1200]\ttrain-logloss:0.17830\tvalid-logloss:0.21791\n",
            "[1500]\ttrain-logloss:0.17166\tvalid-logloss:0.21718\n",
            "[1800]\ttrain-logloss:0.16609\tvalid-logloss:0.21673\n",
            "[2100]\ttrain-logloss:0.16112\tvalid-logloss:0.21649\n",
            "[2400]\ttrain-logloss:0.15649\tvalid-logloss:0.21629\n",
            "[2700]\ttrain-logloss:0.15222\tvalid-logloss:0.21619\n",
            "[3000]\ttrain-logloss:0.14803\tvalid-logloss:0.21613\n",
            "[3125]\ttrain-logloss:0.14611\tvalid-logloss:0.21615\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-08-01 23:00:54,485]\u001b[0m Trial 7 finished with value: 0.7942657620268125 and parameters: {'lambda': 0.6861938017065641, 'alpha': 0.005103680677939387, 'colsample_bytree': 1.0, 'subsample': 1.0, 'learning_rate': 0.01, 'max_depth': 9, 'min_child_weight': 47}. Best is trial 7 with value: 0.7942657620268125.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[23:01:08] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68313\tvalid-logloss:0.68317\n",
            "[300]\ttrain-logloss:0.21663\tvalid-logloss:0.22971\n",
            "[600]\ttrain-logloss:0.19622\tvalid-logloss:0.22058\n",
            "[900]\ttrain-logloss:0.18398\tvalid-logloss:0.21811\n",
            "[1200]\ttrain-logloss:0.17420\tvalid-logloss:0.21693\n",
            "[1500]\ttrain-logloss:0.16575\tvalid-logloss:0.21633\n",
            "[1800]\ttrain-logloss:0.15824\tvalid-logloss:0.21600\n",
            "[2100]\ttrain-logloss:0.15099\tvalid-logloss:0.21581\n",
            "[2400]\ttrain-logloss:0.14435\tvalid-logloss:0.21575\n",
            "[2508]\ttrain-logloss:0.14207\tvalid-logloss:0.21576\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-08-01 23:06:23,337]\u001b[0m Trial 8 finished with value: 0.7936360580659519 and parameters: {'lambda': 1.1391073270287757, 'alpha': 0.0026113254220730903, 'colsample_bytree': 0.5, 'subsample': 0.8, 'learning_rate': 0.015, 'max_depth': 7, 'min_child_weight': 5}. Best is trial 7 with value: 0.7942657620268125.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[23:06:36] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68329\tvalid-logloss:0.68333\n",
            "[300]\ttrain-logloss:0.22750\tvalid-logloss:0.23337\n",
            "[600]\ttrain-logloss:0.21264\tvalid-logloss:0.22277\n",
            "[900]\ttrain-logloss:0.20587\tvalid-logloss:0.21959\n",
            "[1200]\ttrain-logloss:0.20100\tvalid-logloss:0.21803\n",
            "[1500]\ttrain-logloss:0.19674\tvalid-logloss:0.21715\n",
            "[1800]\ttrain-logloss:0.19297\tvalid-logloss:0.21660\n",
            "[2100]\ttrain-logloss:0.18941\tvalid-logloss:0.21624\n",
            "[2400]\ttrain-logloss:0.18599\tvalid-logloss:0.21594\n",
            "[2700]\ttrain-logloss:0.18262\tvalid-logloss:0.21572\n",
            "[3000]\ttrain-logloss:0.17944\tvalid-logloss:0.21557\n",
            "[3300]\ttrain-logloss:0.17634\tvalid-logloss:0.21547\n",
            "[3600]\ttrain-logloss:0.17327\tvalid-logloss:0.21536\n",
            "[3725]\ttrain-logloss:0.17206\tvalid-logloss:0.21536\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-08-01 23:12:54,851]\u001b[0m Trial 9 finished with value: 0.7938780541152959 and parameters: {'lambda': 0.005881926790367044, 'alpha': 3.761020527165246, 'colsample_bytree': 0.6, 'subsample': 0.8, 'learning_rate': 0.015, 'max_depth': 6, 'min_child_weight': 82}. Best is trial 7 with value: 0.7942657620268125.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[23:13:08] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.67732\tvalid-logloss:0.67737\n",
            "[300]\ttrain-logloss:0.22613\tvalid-logloss:0.22996\n",
            "[600]\ttrain-logloss:0.21577\tvalid-logloss:0.22234\n",
            "[900]\ttrain-logloss:0.21069\tvalid-logloss:0.21965\n",
            "[1200]\ttrain-logloss:0.20699\tvalid-logloss:0.21830\n",
            "[1500]\ttrain-logloss:0.20383\tvalid-logloss:0.21749\n",
            "[1800]\ttrain-logloss:0.20112\tvalid-logloss:0.21699\n",
            "[2100]\ttrain-logloss:0.19856\tvalid-logloss:0.21667\n",
            "[2400]\ttrain-logloss:0.19605\tvalid-logloss:0.21641\n",
            "[2700]\ttrain-logloss:0.19366\tvalid-logloss:0.21623\n",
            "[3000]\ttrain-logloss:0.19143\tvalid-logloss:0.21611\n",
            "[3300]\ttrain-logloss:0.18930\tvalid-logloss:0.21597\n",
            "[3600]\ttrain-logloss:0.18724\tvalid-logloss:0.21590\n",
            "[3713]\ttrain-logloss:0.18647\tvalid-logloss:0.21591\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-08-01 23:17:46,183]\u001b[0m Trial 10 finished with value: 0.7932816796099602 and parameters: {'lambda': 0.0010261535763642071, 'alpha': 0.0010005833709620631, 'colsample_bytree': 1.0, 'subsample': 0.9, 'learning_rate': 0.025, 'max_depth': 4, 'min_child_weight': 88}. Best is trial 7 with value: 0.7942657620268125.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[23:17:59] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.67658\tvalid-logloss:0.67665\n",
            "[300]\ttrain-logloss:0.21295\tvalid-logloss:0.22298\n",
            "[600]\ttrain-logloss:0.20147\tvalid-logloss:0.21835\n",
            "[900]\ttrain-logloss:0.19356\tvalid-logloss:0.21712\n",
            "[1200]\ttrain-logloss:0.18664\tvalid-logloss:0.21659\n",
            "[1500]\ttrain-logloss:0.18019\tvalid-logloss:0.21622\n",
            "[1800]\ttrain-logloss:0.17400\tvalid-logloss:0.21612\n",
            "[1876]\ttrain-logloss:0.17236\tvalid-logloss:0.21618\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-08-01 23:22:15,980]\u001b[0m Trial 11 finished with value: 0.793795661927035 and parameters: {'lambda': 0.18649235296097572, 'alpha': 0.006314146500178859, 'colsample_bytree': 1.0, 'subsample': 0.5, 'learning_rate': 0.025, 'max_depth': 8, 'min_child_weight': 136}. Best is trial 7 with value: 0.7942657620268125.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[23:22:29] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68646\tvalid-logloss:0.68651\n",
            "[300]\ttrain-logloss:0.23846\tvalid-logloss:0.24453\n",
            "[600]\ttrain-logloss:0.21569\tvalid-logloss:0.22515\n",
            "[900]\ttrain-logloss:0.20844\tvalid-logloss:0.22088\n",
            "[1200]\ttrain-logloss:0.20357\tvalid-logloss:0.21887\n",
            "[1500]\ttrain-logloss:0.19959\tvalid-logloss:0.21776\n",
            "[1800]\ttrain-logloss:0.19623\tvalid-logloss:0.21712\n",
            "[2100]\ttrain-logloss:0.19307\tvalid-logloss:0.21668\n",
            "[2400]\ttrain-logloss:0.19008\tvalid-logloss:0.21631\n",
            "[2700]\ttrain-logloss:0.18716\tvalid-logloss:0.21609\n",
            "[3000]\ttrain-logloss:0.18442\tvalid-logloss:0.21590\n",
            "[3300]\ttrain-logloss:0.18162\tvalid-logloss:0.21573\n",
            "[3600]\ttrain-logloss:0.17888\tvalid-logloss:0.21562\n",
            "[3900]\ttrain-logloss:0.17628\tvalid-logloss:0.21553\n",
            "[4200]\ttrain-logloss:0.17382\tvalid-logloss:0.21543\n",
            "[4500]\ttrain-logloss:0.17140\tvalid-logloss:0.21540\n",
            "[4525]\ttrain-logloss:0.17120\tvalid-logloss:0.21539\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-08-01 23:32:38,537]\u001b[0m Trial 12 finished with value: 0.7943557866488324 and parameters: {'lambda': 0.15418153458312894, 'alpha': 0.06813177040891014, 'colsample_bytree': 0.9, 'subsample': 0.6, 'learning_rate': 0.01, 'max_depth': 8, 'min_child_weight': 139}. Best is trial 12 with value: 0.7943557866488324.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[23:32:52] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68646\tvalid-logloss:0.68650\n",
            "[300]\ttrain-logloss:0.23757\tvalid-logloss:0.24412\n",
            "[600]\ttrain-logloss:0.21456\tvalid-logloss:0.22481\n",
            "[900]\ttrain-logloss:0.20713\tvalid-logloss:0.22068\n",
            "[1200]\ttrain-logloss:0.20201\tvalid-logloss:0.21867\n",
            "[1500]\ttrain-logloss:0.19786\tvalid-logloss:0.21761\n",
            "[1800]\ttrain-logloss:0.19420\tvalid-logloss:0.21697\n",
            "[2100]\ttrain-logloss:0.19086\tvalid-logloss:0.21654\n",
            "[2400]\ttrain-logloss:0.18768\tvalid-logloss:0.21622\n",
            "[2700]\ttrain-logloss:0.18448\tvalid-logloss:0.21596\n",
            "[3000]\ttrain-logloss:0.18155\tvalid-logloss:0.21582\n",
            "[3300]\ttrain-logloss:0.17864\tvalid-logloss:0.21565\n",
            "[3600]\ttrain-logloss:0.17577\tvalid-logloss:0.21552\n",
            "[3900]\ttrain-logloss:0.17301\tvalid-logloss:0.21544\n",
            "[4200]\ttrain-logloss:0.17038\tvalid-logloss:0.21538\n",
            "[4500]\ttrain-logloss:0.16778\tvalid-logloss:0.21533\n",
            "[4800]\ttrain-logloss:0.16519\tvalid-logloss:0.21529\n",
            "[4972]\ttrain-logloss:0.16375\tvalid-logloss:0.21529\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-08-01 23:44:11,902]\u001b[0m Trial 13 finished with value: 0.7956672220772174 and parameters: {'lambda': 0.2185304199028929, 'alpha': 0.20239986432467147, 'colsample_bytree': 0.9, 'subsample': 0.6, 'learning_rate': 0.01, 'max_depth': 8, 'min_child_weight': 118}. Best is trial 13 with value: 0.7956672220772174.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[23:44:25] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.67656\tvalid-logloss:0.67664\n",
            "[300]\ttrain-logloss:0.21208\tvalid-logloss:0.22287\n",
            "[600]\ttrain-logloss:0.20022\tvalid-logloss:0.21800\n",
            "[900]\ttrain-logloss:0.19232\tvalid-logloss:0.21679\n",
            "[1200]\ttrain-logloss:0.18530\tvalid-logloss:0.21631\n",
            "[1500]\ttrain-logloss:0.17887\tvalid-logloss:0.21608\n",
            "[1800]\ttrain-logloss:0.17253\tvalid-logloss:0.21590\n",
            "[1979]\ttrain-logloss:0.16889\tvalid-logloss:0.21588\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-08-01 23:48:43,755]\u001b[0m Trial 14 finished with value: 0.7929174702629913 and parameters: {'lambda': 0.16066794154691608, 'alpha': 0.2546056323058142, 'colsample_bytree': 0.8, 'subsample': 0.6, 'learning_rate': 0.025, 'max_depth': 8, 'min_child_weight': 140}. Best is trial 13 with value: 0.7956672220772174.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[23:48:57] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.67980\tvalid-logloss:0.67990\n",
            "[300]\ttrain-logloss:0.21371\tvalid-logloss:0.22471\n",
            "[600]\ttrain-logloss:0.20089\tvalid-logloss:0.21876\n",
            "[900]\ttrain-logloss:0.19265\tvalid-logloss:0.21708\n",
            "[1200]\ttrain-logloss:0.18561\tvalid-logloss:0.21635\n",
            "[1500]\ttrain-logloss:0.17925\tvalid-logloss:0.21594\n",
            "[1800]\ttrain-logloss:0.17320\tvalid-logloss:0.21569\n",
            "[2100]\ttrain-logloss:0.16750\tvalid-logloss:0.21556\n",
            "[2295]\ttrain-logloss:0.16388\tvalid-logloss:0.21557\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-08-01 23:54:17,888]\u001b[0m Trial 15 finished with value: 0.7931771491358758 and parameters: {'lambda': 0.0990298179165763, 'alpha': 0.47795153814583785, 'colsample_bytree': 0.9, 'subsample': 0.6, 'learning_rate': 0.02, 'max_depth': 8, 'min_child_weight': 103}. Best is trial 13 with value: 0.7956672220772174.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[23:54:31] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68647\tvalid-logloss:0.68651\n",
            "[300]\ttrain-logloss:0.23934\tvalid-logloss:0.24498\n",
            "[600]\ttrain-logloss:0.21668\tvalid-logloss:0.22543\n",
            "[900]\ttrain-logloss:0.20957\tvalid-logloss:0.22111\n",
            "[1200]\ttrain-logloss:0.20482\tvalid-logloss:0.21904\n",
            "[1500]\ttrain-logloss:0.20098\tvalid-logloss:0.21793\n",
            "[1800]\ttrain-logloss:0.19770\tvalid-logloss:0.21725\n",
            "[2100]\ttrain-logloss:0.19471\tvalid-logloss:0.21680\n",
            "[2400]\ttrain-logloss:0.19189\tvalid-logloss:0.21647\n",
            "[2700]\ttrain-logloss:0.18909\tvalid-logloss:0.21625\n",
            "[3000]\ttrain-logloss:0.18657\tvalid-logloss:0.21608\n",
            "[3300]\ttrain-logloss:0.18388\tvalid-logloss:0.21590\n",
            "[3600]\ttrain-logloss:0.18127\tvalid-logloss:0.21579\n",
            "[3900]\ttrain-logloss:0.17880\tvalid-logloss:0.21568\n",
            "[4200]\ttrain-logloss:0.17644\tvalid-logloss:0.21561\n",
            "[4500]\ttrain-logloss:0.17412\tvalid-logloss:0.21556\n",
            "[4800]\ttrain-logloss:0.17179\tvalid-logloss:0.21551\n",
            "[5100]\ttrain-logloss:0.16954\tvalid-logloss:0.21546\n",
            "[5400]\ttrain-logloss:0.16736\tvalid-logloss:0.21541\n",
            "[5610]\ttrain-logloss:0.16580\tvalid-logloss:0.21541\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-08-02 00:06:54,512]\u001b[0m Trial 16 finished with value: 0.7938687365856112 and parameters: {'lambda': 0.2941005315963989, 'alpha': 0.0590768841258766, 'colsample_bytree': 0.9, 'subsample': 0.6, 'learning_rate': 0.01, 'max_depth': 8, 'min_child_weight': 159}. Best is trial 13 with value: 0.7956672220772174.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[00:07:08] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.67329\tvalid-logloss:0.67340\n",
            "[300]\ttrain-logloss:0.20877\tvalid-logloss:0.22113\n",
            "[600]\ttrain-logloss:0.19604\tvalid-logloss:0.21754\n",
            "[900]\ttrain-logloss:0.18638\tvalid-logloss:0.21666\n",
            "[1110]\ttrain-logloss:0.18025\tvalid-logloss:0.21649\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-08-02 00:09:40,284]\u001b[0m Trial 17 finished with value: 0.7936164456212695 and parameters: {'lambda': 0.04359420871351157, 'alpha': 0.9269659641904361, 'colsample_bytree': 0.8, 'subsample': 0.5, 'learning_rate': 0.03, 'max_depth': 8, 'min_child_weight': 110}. Best is trial 13 with value: 0.7956672220772174.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[00:09:53] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.67960\tvalid-logloss:0.67973\n",
            "[300]\ttrain-logloss:0.20288\tvalid-logloss:0.22280\n",
            "[600]\ttrain-logloss:0.18596\tvalid-logloss:0.21774\n",
            "[900]\ttrain-logloss:0.17435\tvalid-logloss:0.21640\n",
            "[1200]\ttrain-logloss:0.16432\tvalid-logloss:0.21588\n",
            "[1500]\ttrain-logloss:0.15514\tvalid-logloss:0.21573\n",
            "[1513]\ttrain-logloss:0.15474\tvalid-logloss:0.21572\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-08-02 00:14:22,545]\u001b[0m Trial 18 finished with value: 0.7945551115881642 and parameters: {'lambda': 0.00316672716769826, 'alpha': 0.08813030286065213, 'colsample_bytree': 0.9, 'subsample': 0.7, 'learning_rate': 0.02, 'max_depth': 9, 'min_child_weight': 55}. Best is trial 13 with value: 0.7956672220772174.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[00:14:36] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.67961\tvalid-logloss:0.67975\n",
            "[300]\ttrain-logloss:0.20377\tvalid-logloss:0.22276\n",
            "[600]\ttrain-logloss:0.18744\tvalid-logloss:0.21775\n",
            "[900]\ttrain-logloss:0.17596\tvalid-logloss:0.21646\n",
            "[1200]\ttrain-logloss:0.16654\tvalid-logloss:0.21593\n",
            "[1500]\ttrain-logloss:0.15731\tvalid-logloss:0.21569\n",
            "[1800]\ttrain-logloss:0.14934\tvalid-logloss:0.21560\n",
            "[1804]\ttrain-logloss:0.14918\tvalid-logloss:0.21561\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-08-02 00:19:27,023]\u001b[0m Trial 19 finished with value: 0.7935487126787917 and parameters: {'lambda': 0.003154701655433623, 'alpha': 0.20384805130640907, 'colsample_bytree': 0.7, 'subsample': 0.7, 'learning_rate': 0.02, 'max_depth': 9, 'min_child_weight': 58}. Best is trial 13 with value: 0.7956672220772174.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[00:19:40] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.67959\tvalid-logloss:0.67973\n",
            "[300]\ttrain-logloss:0.20028\tvalid-logloss:0.22277\n",
            "[600]\ttrain-logloss:0.18139\tvalid-logloss:0.21775\n",
            "[900]\ttrain-logloss:0.16840\tvalid-logloss:0.21648\n",
            "[1200]\ttrain-logloss:0.15744\tvalid-logloss:0.21596\n",
            "[1500]\ttrain-logloss:0.14725\tvalid-logloss:0.21577\n",
            "[1797]\ttrain-logloss:0.13797\tvalid-logloss:0.21573\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-08-02 00:25:20,064]\u001b[0m Trial 20 finished with value: 0.7944133517344045 and parameters: {'lambda': 0.0028514035268136033, 'alpha': 1.6055702931899118, 'colsample_bytree': 0.9, 'subsample': 0.8, 'learning_rate': 0.02, 'max_depth': 9, 'min_child_weight': 46}. Best is trial 13 with value: 0.7956672220772174.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[00:25:34] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.67968\tvalid-logloss:0.67981\n",
            "[300]\ttrain-logloss:0.20372\tvalid-logloss:0.22357\n",
            "[600]\ttrain-logloss:0.18452\tvalid-logloss:0.21810\n",
            "[900]\ttrain-logloss:0.17025\tvalid-logloss:0.21660\n",
            "[1200]\ttrain-logloss:0.15793\tvalid-logloss:0.21609\n",
            "[1500]\ttrain-logloss:0.14626\tvalid-logloss:0.21595\n",
            "[1516]\ttrain-logloss:0.14567\tvalid-logloss:0.21592\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-08-02 00:31:05,392]\u001b[0m Trial 21 finished with value: 0.7931303954450128 and parameters: {'lambda': 0.0011749652675451798, 'alpha': 8.01634330752871, 'colsample_bytree': 0.9, 'subsample': 0.8, 'learning_rate': 0.02, 'max_depth': 9, 'min_child_weight': 43}. Best is trial 13 with value: 0.7956672220772174.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[00:31:19] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.67300\tvalid-logloss:0.67318\n",
            "[300]\ttrain-logloss:0.19557\tvalid-logloss:0.21977\n",
            "[600]\ttrain-logloss:0.17673\tvalid-logloss:0.21688\n",
            "[900]\ttrain-logloss:0.16161\tvalid-logloss:0.21627\n",
            "[1125]\ttrain-logloss:0.15138\tvalid-logloss:0.21623\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-08-02 00:34:48,449]\u001b[0m Trial 22 finished with value: 0.7941455715028345 and parameters: {'lambda': 0.004301504258950281, 'alpha': 1.569688056786435, 'colsample_bytree': 1.0, 'subsample': 0.7, 'learning_rate': 0.03, 'max_depth': 9, 'min_child_weight': 63}. Best is trial 13 with value: 0.7956672220772174.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[00:35:02] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68292\tvalid-logloss:0.68305\n",
            "[300]\ttrain-logloss:0.20397\tvalid-logloss:0.22661\n",
            "[600]\ttrain-logloss:0.18267\tvalid-logloss:0.21893\n",
            "[900]\ttrain-logloss:0.17003\tvalid-logloss:0.21702\n",
            "[1200]\ttrain-logloss:0.16009\tvalid-logloss:0.21622\n",
            "[1500]\ttrain-logloss:0.15151\tvalid-logloss:0.21589\n",
            "[1800]\ttrain-logloss:0.14346\tvalid-logloss:0.21572\n",
            "[2100]\ttrain-logloss:0.13605\tvalid-logloss:0.21563\n",
            "[2358]\ttrain-logloss:0.12994\tvalid-logloss:0.21560\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-08-02 00:42:20,555]\u001b[0m Trial 23 finished with value: 0.7949449700647302 and parameters: {'lambda': 0.00998402275676324, 'alpha': 0.35825179262028417, 'colsample_bytree': 0.8, 'subsample': 0.9, 'learning_rate': 0.015, 'max_depth': 9, 'min_child_weight': 33}. Best is trial 13 with value: 0.7956672220772174.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[00:42:34] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68302\tvalid-logloss:0.68313\n",
            "[300]\ttrain-logloss:0.21163\tvalid-logloss:0.22813\n",
            "[600]\ttrain-logloss:0.19212\tvalid-logloss:0.21966\n",
            "[900]\ttrain-logloss:0.18091\tvalid-logloss:0.21751\n",
            "[1200]\ttrain-logloss:0.17205\tvalid-logloss:0.21653\n",
            "[1500]\ttrain-logloss:0.16446\tvalid-logloss:0.21613\n",
            "[1800]\ttrain-logloss:0.15754\tvalid-logloss:0.21584\n",
            "[2100]\ttrain-logloss:0.15122\tvalid-logloss:0.21566\n",
            "[2400]\ttrain-logloss:0.14486\tvalid-logloss:0.21564\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-08-02 00:48:50,721]\u001b[0m Trial 24 finished with value: 0.795338242294328 and parameters: {'lambda': 0.014116529264441124, 'alpha': 0.3498631754667191, 'colsample_bytree': 0.8, 'subsample': 0.9, 'learning_rate': 0.015, 'max_depth': 8, 'min_child_weight': 32}. Best is trial 13 with value: 0.7956672220772174.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[00:49:04] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68313\tvalid-logloss:0.68320\n",
            "[300]\ttrain-logloss:0.21868\tvalid-logloss:0.23019\n",
            "[600]\ttrain-logloss:0.20017\tvalid-logloss:0.22079\n",
            "[900]\ttrain-logloss:0.19007\tvalid-logloss:0.21823\n",
            "[1200]\ttrain-logloss:0.18242\tvalid-logloss:0.21708\n",
            "[1500]\ttrain-logloss:0.17575\tvalid-logloss:0.21650\n",
            "[1800]\ttrain-logloss:0.16970\tvalid-logloss:0.21618\n",
            "[2100]\ttrain-logloss:0.16426\tvalid-logloss:0.21601\n",
            "[2400]\ttrain-logloss:0.15888\tvalid-logloss:0.21588\n",
            "[2700]\ttrain-logloss:0.15396\tvalid-logloss:0.21578\n",
            "[2983]\ttrain-logloss:0.14939\tvalid-logloss:0.21575\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-08-02 00:55:28,579]\u001b[0m Trial 25 finished with value: 0.794634498472057 and parameters: {'lambda': 0.013395956185006925, 'alpha': 0.30321193917272904, 'colsample_bytree': 0.8, 'subsample': 0.9, 'learning_rate': 0.015, 'max_depth': 7, 'min_child_weight': 27}. Best is trial 13 with value: 0.7956672220772174.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[00:55:42] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68307\tvalid-logloss:0.68315\n",
            "[300]\ttrain-logloss:0.21610\tvalid-logloss:0.22887\n",
            "[600]\ttrain-logloss:0.19982\tvalid-logloss:0.22022\n",
            "[900]\ttrain-logloss:0.19106\tvalid-logloss:0.21781\n",
            "[1200]\ttrain-logloss:0.18418\tvalid-logloss:0.21675\n",
            "[1500]\ttrain-logloss:0.17828\tvalid-logloss:0.21621\n",
            "[1800]\ttrain-logloss:0.17285\tvalid-logloss:0.21588\n",
            "[2100]\ttrain-logloss:0.16782\tvalid-logloss:0.21567\n",
            "[2400]\ttrain-logloss:0.16289\tvalid-logloss:0.21557\n",
            "[2700]\ttrain-logloss:0.15823\tvalid-logloss:0.21546\n",
            "[2900]\ttrain-logloss:0.15532\tvalid-logloss:0.21544\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-08-02 01:02:14,227]\u001b[0m Trial 26 finished with value: 0.7944622028378758 and parameters: {'lambda': 0.012214579453032634, 'alpha': 0.4257502463675535, 'colsample_bytree': 0.7, 'subsample': 0.9, 'learning_rate': 0.015, 'max_depth': 8, 'min_child_weight': 77}. Best is trial 13 with value: 0.7956672220772174.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[01:02:27] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68645\tvalid-logloss:0.68650\n",
            "[300]\ttrain-logloss:0.23609\tvalid-logloss:0.24457\n",
            "[600]\ttrain-logloss:0.21030\tvalid-logloss:0.22496\n",
            "[900]\ttrain-logloss:0.20018\tvalid-logloss:0.22065\n",
            "[1200]\ttrain-logloss:0.19319\tvalid-logloss:0.21872\n",
            "[1500]\ttrain-logloss:0.18745\tvalid-logloss:0.21768\n",
            "[1800]\ttrain-logloss:0.18248\tvalid-logloss:0.21700\n",
            "[2100]\ttrain-logloss:0.17804\tvalid-logloss:0.21654\n",
            "[2400]\ttrain-logloss:0.17394\tvalid-logloss:0.21624\n",
            "[2700]\ttrain-logloss:0.17009\tvalid-logloss:0.21603\n",
            "[3000]\ttrain-logloss:0.16636\tvalid-logloss:0.21584\n",
            "[3300]\ttrain-logloss:0.16278\tvalid-logloss:0.21571\n",
            "[3600]\ttrain-logloss:0.15944\tvalid-logloss:0.21560\n",
            "[3900]\ttrain-logloss:0.15609\tvalid-logloss:0.21555\n",
            "[4200]\ttrain-logloss:0.15281\tvalid-logloss:0.21550\n",
            "[4500]\ttrain-logloss:0.14967\tvalid-logloss:0.21546\n",
            "[4800]\ttrain-logloss:0.14657\tvalid-logloss:0.21543\n",
            "[5100]\ttrain-logloss:0.14353\tvalid-logloss:0.21541\n",
            "[5257]\ttrain-logloss:0.14194\tvalid-logloss:0.21539\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-08-02 01:13:22,936]\u001b[0m Trial 27 finished with value: 0.7943654397347306 and parameters: {'lambda': 0.059469576682489735, 'alpha': 0.04257187692969981, 'colsample_bytree': 0.8, 'subsample': 0.9, 'learning_rate': 0.01, 'max_depth': 7, 'min_child_weight': 27}. Best is trial 13 with value: 0.7956672220772174.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[01:13:36] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68309\tvalid-logloss:0.68316\n",
            "[300]\ttrain-logloss:0.21727\tvalid-logloss:0.22932\n",
            "[600]\ttrain-logloss:0.20169\tvalid-logloss:0.22060\n",
            "[900]\ttrain-logloss:0.19384\tvalid-logloss:0.21823\n",
            "[1200]\ttrain-logloss:0.18763\tvalid-logloss:0.21716\n",
            "[1500]\ttrain-logloss:0.18228\tvalid-logloss:0.21659\n",
            "[1800]\ttrain-logloss:0.17758\tvalid-logloss:0.21625\n",
            "[2100]\ttrain-logloss:0.17308\tvalid-logloss:0.21600\n",
            "[2400]\ttrain-logloss:0.16882\tvalid-logloss:0.21591\n",
            "[2700]\ttrain-logloss:0.16496\tvalid-logloss:0.21585\n",
            "[3000]\ttrain-logloss:0.16067\tvalid-logloss:0.21577\n",
            "[3065]\ttrain-logloss:0.15984\tvalid-logloss:0.21578\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-08-02 01:20:13,044]\u001b[0m Trial 28 finished with value: 0.7931756216928036 and parameters: {'lambda': 0.022456900649147696, 'alpha': 0.7769455485865373, 'colsample_bytree': 0.7, 'subsample': 1.0, 'learning_rate': 0.015, 'max_depth': 8, 'min_child_weight': 105}. Best is trial 13 with value: 0.7956672220772174.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[01:20:27] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.67703\tvalid-logloss:0.67708\n",
            "[300]\ttrain-logloss:0.22188\tvalid-logloss:0.22728\n",
            "[600]\ttrain-logloss:0.21180\tvalid-logloss:0.22069\n",
            "[900]\ttrain-logloss:0.20657\tvalid-logloss:0.21856\n",
            "[1200]\ttrain-logloss:0.20245\tvalid-logloss:0.21746\n",
            "[1500]\ttrain-logloss:0.19893\tvalid-logloss:0.21688\n",
            "[1800]\ttrain-logloss:0.19568\tvalid-logloss:0.21650\n",
            "[2100]\ttrain-logloss:0.19252\tvalid-logloss:0.21624\n",
            "[2400]\ttrain-logloss:0.18943\tvalid-logloss:0.21607\n",
            "[2700]\ttrain-logloss:0.18650\tvalid-logloss:0.21602\n",
            "[3000]\ttrain-logloss:0.18375\tvalid-logloss:0.21595\n",
            "[3134]\ttrain-logloss:0.18244\tvalid-logloss:0.21594\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-08-02 01:24:56,356]\u001b[0m Trial 29 finished with value: 0.7928743419315648 and parameters: {'lambda': 0.07169247067553208, 'alpha': 0.13185628496719326, 'colsample_bytree': 0.8, 'subsample': 0.8, 'learning_rate': 0.025, 'max_depth': 5, 'min_child_weight': 161}. Best is trial 13 with value: 0.7956672220772174.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[01:25:09] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68653\tvalid-logloss:0.68655\n",
            "[300]\ttrain-logloss:0.24213\tvalid-logloss:0.24709\n",
            "[600]\ttrain-logloss:0.21941\tvalid-logloss:0.22707\n",
            "[900]\ttrain-logloss:0.21263\tvalid-logloss:0.22247\n",
            "[1200]\ttrain-logloss:0.20842\tvalid-logloss:0.22019\n",
            "[1500]\ttrain-logloss:0.20509\tvalid-logloss:0.21885\n",
            "[1800]\ttrain-logloss:0.20234\tvalid-logloss:0.21801\n",
            "[2100]\ttrain-logloss:0.19989\tvalid-logloss:0.21744\n",
            "[2400]\ttrain-logloss:0.19768\tvalid-logloss:0.21699\n",
            "[2700]\ttrain-logloss:0.19564\tvalid-logloss:0.21666\n",
            "[3000]\ttrain-logloss:0.19369\tvalid-logloss:0.21644\n",
            "[3300]\ttrain-logloss:0.19187\tvalid-logloss:0.21625\n",
            "[3600]\ttrain-logloss:0.18999\tvalid-logloss:0.21608\n",
            "[3900]\ttrain-logloss:0.18814\tvalid-logloss:0.21595\n",
            "[4200]\ttrain-logloss:0.18638\tvalid-logloss:0.21586\n",
            "[4500]\ttrain-logloss:0.18470\tvalid-logloss:0.21580\n",
            "[4800]\ttrain-logloss:0.18304\tvalid-logloss:0.21574\n",
            "[5100]\ttrain-logloss:0.18141\tvalid-logloss:0.21568\n",
            "[5244]\ttrain-logloss:0.18060\tvalid-logloss:0.21567\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-08-02 01:34:25,232]\u001b[0m Trial 30 finished with value: 0.7950265794247443 and parameters: {'lambda': 0.007730118702440496, 'alpha': 0.04014402130478168, 'colsample_bytree': 0.6, 'subsample': 0.9, 'learning_rate': 0.01, 'max_depth': 7, 'min_child_weight': 244}. Best is trial 13 with value: 0.7956672220772174.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[01:34:38] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68653\tvalid-logloss:0.68655\n",
            "[300]\ttrain-logloss:0.24209\tvalid-logloss:0.24707\n",
            "[600]\ttrain-logloss:0.21934\tvalid-logloss:0.22703\n",
            "[900]\ttrain-logloss:0.21260\tvalid-logloss:0.22247\n",
            "[1200]\ttrain-logloss:0.20834\tvalid-logloss:0.22018\n",
            "[1500]\ttrain-logloss:0.20503\tvalid-logloss:0.21885\n",
            "[1800]\ttrain-logloss:0.20231\tvalid-logloss:0.21803\n",
            "[2100]\ttrain-logloss:0.19978\tvalid-logloss:0.21744\n",
            "[2400]\ttrain-logloss:0.19752\tvalid-logloss:0.21699\n",
            "[2700]\ttrain-logloss:0.19550\tvalid-logloss:0.21669\n",
            "[3000]\ttrain-logloss:0.19351\tvalid-logloss:0.21647\n",
            "[3300]\ttrain-logloss:0.19168\tvalid-logloss:0.21628\n",
            "[3600]\ttrain-logloss:0.18989\tvalid-logloss:0.21611\n",
            "[3900]\ttrain-logloss:0.18804\tvalid-logloss:0.21598\n",
            "[4200]\ttrain-logloss:0.18625\tvalid-logloss:0.21588\n",
            "[4500]\ttrain-logloss:0.18454\tvalid-logloss:0.21580\n",
            "[4800]\ttrain-logloss:0.18282\tvalid-logloss:0.21576\n",
            "[5100]\ttrain-logloss:0.18118\tvalid-logloss:0.21571\n",
            "[5400]\ttrain-logloss:0.17952\tvalid-logloss:0.21568\n",
            "[5700]\ttrain-logloss:0.17788\tvalid-logloss:0.21563\n",
            "[5949]\ttrain-logloss:0.17653\tvalid-logloss:0.21560\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-08-02 01:45:04,731]\u001b[0m Trial 31 finished with value: 0.7945189860670294 and parameters: {'lambda': 0.006919184059839187, 'alpha': 0.03189701737096819, 'colsample_bytree': 0.6, 'subsample': 0.9, 'learning_rate': 0.01, 'max_depth': 7, 'min_child_weight': 241}. Best is trial 13 with value: 0.7956672220772174.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[01:45:18] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68646\tvalid-logloss:0.68649\n",
            "[300]\ttrain-logloss:0.23700\tvalid-logloss:0.24444\n",
            "[600]\ttrain-logloss:0.21367\tvalid-logloss:0.22528\n",
            "[900]\ttrain-logloss:0.20619\tvalid-logloss:0.22112\n",
            "[1200]\ttrain-logloss:0.20124\tvalid-logloss:0.21913\n",
            "[1500]\ttrain-logloss:0.19731\tvalid-logloss:0.21801\n",
            "[1800]\ttrain-logloss:0.19395\tvalid-logloss:0.21733\n",
            "[2100]\ttrain-logloss:0.19084\tvalid-logloss:0.21685\n",
            "[2400]\ttrain-logloss:0.18806\tvalid-logloss:0.21653\n",
            "[2700]\ttrain-logloss:0.18543\tvalid-logloss:0.21629\n",
            "[3000]\ttrain-logloss:0.18307\tvalid-logloss:0.21613\n",
            "[3300]\ttrain-logloss:0.18058\tvalid-logloss:0.21600\n",
            "[3600]\ttrain-logloss:0.17827\tvalid-logloss:0.21590\n",
            "[3900]\ttrain-logloss:0.17605\tvalid-logloss:0.21585\n",
            "[4200]\ttrain-logloss:0.17403\tvalid-logloss:0.21581\n",
            "[4500]\ttrain-logloss:0.17200\tvalid-logloss:0.21576\n",
            "[4800]\ttrain-logloss:0.16985\tvalid-logloss:0.21572\n",
            "[5100]\ttrain-logloss:0.16785\tvalid-logloss:0.21570\n",
            "[5263]\ttrain-logloss:0.16681\tvalid-logloss:0.21569\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-08-02 01:55:54,629]\u001b[0m Trial 32 finished with value: 0.7939985745463222 and parameters: {'lambda': 0.02578324969152047, 'alpha': 0.14579964683767513, 'colsample_bytree': 0.7, 'subsample': 1.0, 'learning_rate': 0.01, 'max_depth': 8, 'min_child_weight': 176}. Best is trial 13 with value: 0.7956672220772174.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[01:56:08] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68323\tvalid-logloss:0.68327\n",
            "[300]\ttrain-logloss:0.22562\tvalid-logloss:0.23210\n",
            "[600]\ttrain-logloss:0.21203\tvalid-logloss:0.22221\n",
            "[900]\ttrain-logloss:0.20592\tvalid-logloss:0.21921\n",
            "[1200]\ttrain-logloss:0.20148\tvalid-logloss:0.21780\n",
            "[1500]\ttrain-logloss:0.19780\tvalid-logloss:0.21702\n",
            "[1800]\ttrain-logloss:0.19458\tvalid-logloss:0.21655\n",
            "[2100]\ttrain-logloss:0.19145\tvalid-logloss:0.21621\n",
            "[2400]\ttrain-logloss:0.18854\tvalid-logloss:0.21595\n",
            "[2700]\ttrain-logloss:0.18583\tvalid-logloss:0.21580\n",
            "[3000]\ttrain-logloss:0.18306\tvalid-logloss:0.21566\n",
            "[3300]\ttrain-logloss:0.18053\tvalid-logloss:0.21560\n",
            "[3600]\ttrain-logloss:0.17808\tvalid-logloss:0.21553\n",
            "[3630]\ttrain-logloss:0.17781\tvalid-logloss:0.21553\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-08-02 02:02:36,045]\u001b[0m Trial 33 finished with value: 0.7937273717511268 and parameters: {'lambda': 0.009079497822616949, 'alpha': 0.41525232856113786, 'colsample_bytree': 0.6, 'subsample': 0.9, 'learning_rate': 0.015, 'max_depth': 7, 'min_child_weight': 220}. Best is trial 13 with value: 0.7956672220772174.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[02:02:49] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68655\tvalid-logloss:0.68658\n",
            "[300]\ttrain-logloss:0.24268\tvalid-logloss:0.24822\n",
            "[600]\ttrain-logloss:0.21770\tvalid-logloss:0.22742\n",
            "[900]\ttrain-logloss:0.20867\tvalid-logloss:0.22254\n",
            "[1200]\ttrain-logloss:0.20271\tvalid-logloss:0.22021\n",
            "[1500]\ttrain-logloss:0.19807\tvalid-logloss:0.21900\n",
            "[1800]\ttrain-logloss:0.19425\tvalid-logloss:0.21827\n",
            "[2100]\ttrain-logloss:0.19083\tvalid-logloss:0.21775\n",
            "[2400]\ttrain-logloss:0.18762\tvalid-logloss:0.21735\n",
            "[2700]\ttrain-logloss:0.18473\tvalid-logloss:0.21705\n",
            "[3000]\ttrain-logloss:0.18198\tvalid-logloss:0.21685\n",
            "[3300]\ttrain-logloss:0.17930\tvalid-logloss:0.21665\n",
            "[3600]\ttrain-logloss:0.17673\tvalid-logloss:0.21652\n",
            "[3900]\ttrain-logloss:0.17421\tvalid-logloss:0.21641\n",
            "[4200]\ttrain-logloss:0.17182\tvalid-logloss:0.21634\n",
            "[4500]\ttrain-logloss:0.16933\tvalid-logloss:0.21629\n",
            "[4800]\ttrain-logloss:0.16694\tvalid-logloss:0.21625\n",
            "[4969]\ttrain-logloss:0.16569\tvalid-logloss:0.21623\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-08-02 02:11:22,072]\u001b[0m Trial 34 finished with value: 0.7936092792592556 and parameters: {'lambda': 0.021958373257991815, 'alpha': 0.01089535532240781, 'colsample_bytree': 0.8, 'subsample': 1.0, 'learning_rate': 0.01, 'max_depth': 6, 'min_child_weight': 28}. Best is trial 13 with value: 0.7956672220772174.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[02:11:35] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.66982\tvalid-logloss:0.67000\n",
            "[300]\ttrain-logloss:0.19909\tvalid-logloss:0.21927\n",
            "[600]\ttrain-logloss:0.18368\tvalid-logloss:0.21666\n",
            "[900]\ttrain-logloss:0.17174\tvalid-logloss:0.21604\n",
            "[1051]\ttrain-logloss:0.16610\tvalid-logloss:0.21602\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-08-02 02:14:08,935]\u001b[0m Trial 35 finished with value: 0.7934511185012628 and parameters: {'lambda': 0.018242308722653765, 'alpha': 0.17220169021491225, 'colsample_bytree': 0.7, 'subsample': 0.8, 'learning_rate': 0.035, 'max_depth': 9, 'min_child_weight': 124}. Best is trial 13 with value: 0.7956672220772174.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[02:14:22] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68344\tvalid-logloss:0.68347\n",
            "[300]\ttrain-logloss:0.23358\tvalid-logloss:0.23705\n",
            "[600]\ttrain-logloss:0.21906\tvalid-logloss:0.22508\n",
            "[900]\ttrain-logloss:0.21337\tvalid-logloss:0.22142\n",
            "[1200]\ttrain-logloss:0.20966\tvalid-logloss:0.21953\n",
            "[1500]\ttrain-logloss:0.20673\tvalid-logloss:0.21838\n",
            "[1800]\ttrain-logloss:0.20424\tvalid-logloss:0.21768\n",
            "[2100]\ttrain-logloss:0.20207\tvalid-logloss:0.21719\n",
            "[2400]\ttrain-logloss:0.20003\tvalid-logloss:0.21684\n",
            "[2700]\ttrain-logloss:0.19813\tvalid-logloss:0.21657\n",
            "[3000]\ttrain-logloss:0.19624\tvalid-logloss:0.21635\n",
            "[3300]\ttrain-logloss:0.19451\tvalid-logloss:0.21621\n",
            "[3600]\ttrain-logloss:0.19275\tvalid-logloss:0.21606\n",
            "[3900]\ttrain-logloss:0.19110\tvalid-logloss:0.21598\n",
            "[4200]\ttrain-logloss:0.18940\tvalid-logloss:0.21587\n",
            "[4500]\ttrain-logloss:0.18779\tvalid-logloss:0.21583\n",
            "[4800]\ttrain-logloss:0.18618\tvalid-logloss:0.21575\n",
            "[5100]\ttrain-logloss:0.18461\tvalid-logloss:0.21569\n",
            "[5249]\ttrain-logloss:0.18379\tvalid-logloss:0.21567\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-08-02 02:21:49,664]\u001b[0m Trial 36 finished with value: 0.7932835908630012 and parameters: {'lambda': 0.03691757044632181, 'alpha': 0.03980810045478292, 'colsample_bytree': 0.8, 'subsample': 0.9, 'learning_rate': 0.015, 'max_depth': 5, 'min_child_weight': 191}. Best is trial 13 with value: 0.7956672220772174.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[02:22:03] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.66062\tvalid-logloss:0.66076\n",
            "[300]\ttrain-logloss:0.20313\tvalid-logloss:0.21882\n",
            "[600]\ttrain-logloss:0.19061\tvalid-logloss:0.21688\n",
            "[900]\ttrain-logloss:0.18077\tvalid-logloss:0.21657\n",
            "[1200]\ttrain-logloss:0.17175\tvalid-logloss:0.21643\n",
            "[1270]\ttrain-logloss:0.16981\tvalid-logloss:0.21641\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-08-02 02:24:27,286]\u001b[0m Trial 37 finished with value: 0.7926530535355301 and parameters: {'lambda': 0.0018424588755074057, 'alpha': 0.024044099873473876, 'colsample_bytree': 0.5, 'subsample': 0.9, 'learning_rate': 0.05, 'max_depth': 8, 'min_child_weight': 254}. Best is trial 13 with value: 0.7956672220772174.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[02:24:40] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68648\tvalid-logloss:0.68651\n",
            "[300]\ttrain-logloss:0.23771\tvalid-logloss:0.24503\n",
            "[600]\ttrain-logloss:0.21337\tvalid-logloss:0.22532\n",
            "[900]\ttrain-logloss:0.20473\tvalid-logloss:0.22095\n",
            "[1200]\ttrain-logloss:0.19929\tvalid-logloss:0.21903\n",
            "[1500]\ttrain-logloss:0.19485\tvalid-logloss:0.21794\n",
            "[1800]\ttrain-logloss:0.19104\tvalid-logloss:0.21727\n",
            "[2100]\ttrain-logloss:0.18762\tvalid-logloss:0.21681\n",
            "[2400]\ttrain-logloss:0.18435\tvalid-logloss:0.21645\n",
            "[2700]\ttrain-logloss:0.18148\tvalid-logloss:0.21623\n",
            "[3000]\ttrain-logloss:0.17854\tvalid-logloss:0.21603\n",
            "[3300]\ttrain-logloss:0.17591\tvalid-logloss:0.21591\n",
            "[3600]\ttrain-logloss:0.17333\tvalid-logloss:0.21582\n",
            "[3900]\ttrain-logloss:0.17073\tvalid-logloss:0.21569\n",
            "[4200]\ttrain-logloss:0.16817\tvalid-logloss:0.21566\n",
            "[4500]\ttrain-logloss:0.16565\tvalid-logloss:0.21560\n",
            "[4800]\ttrain-logloss:0.16329\tvalid-logloss:0.21555\n",
            "[5100]\ttrain-logloss:0.16090\tvalid-logloss:0.21552\n",
            "[5400]\ttrain-logloss:0.15859\tvalid-logloss:0.21550\n",
            "[5615]\ttrain-logloss:0.15703\tvalid-logloss:0.21550\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-08-02 02:34:51,015]\u001b[0m Trial 38 finished with value: 0.7933248607643573 and parameters: {'lambda': 0.3491926691489567, 'alpha': 0.10056376046736239, 'colsample_bytree': 0.6, 'subsample': 1.0, 'learning_rate': 0.01, 'max_depth': 7, 'min_child_weight': 71}. Best is trial 13 with value: 0.7956672220772174.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[02:35:04] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.67955\tvalid-logloss:0.67973\n",
            "[300]\ttrain-logloss:0.19277\tvalid-logloss:0.22255\n",
            "[600]\ttrain-logloss:0.16815\tvalid-logloss:0.21798\n",
            "[900]\ttrain-logloss:0.15089\tvalid-logloss:0.21685\n",
            "[1200]\ttrain-logloss:0.13692\tvalid-logloss:0.21645\n",
            "[1500]\ttrain-logloss:0.12457\tvalid-logloss:0.21640\n",
            "[1537]\ttrain-logloss:0.12288\tvalid-logloss:0.21643\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-08-02 02:40:43,580]\u001b[0m Trial 39 finished with value: 0.7938755301590734 and parameters: {'lambda': 2.6823628216752136, 'alpha': 1.2580614399854955, 'colsample_bytree': 0.8, 'subsample': 0.8, 'learning_rate': 0.02, 'max_depth': 9, 'min_child_weight': 16}. Best is trial 13 with value: 0.7956672220772174.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[02:40:57] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.67031\tvalid-logloss:0.67038\n",
            "[300]\ttrain-logloss:0.21178\tvalid-logloss:0.22085\n",
            "[600]\ttrain-logloss:0.20147\tvalid-logloss:0.21770\n",
            "[900]\ttrain-logloss:0.19361\tvalid-logloss:0.21690\n",
            "[1200]\ttrain-logloss:0.18669\tvalid-logloss:0.21658\n",
            "[1259]\ttrain-logloss:0.18545\tvalid-logloss:0.21653\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-08-02 02:43:33,444]\u001b[0m Trial 40 finished with value: 0.7925327230430682 and parameters: {'lambda': 0.00634540344081371, 'alpha': 0.5315594792474522, 'colsample_bytree': 0.7, 'subsample': 0.5, 'learning_rate': 0.035, 'max_depth': 8, 'min_child_weight': 217}. Best is trial 13 with value: 0.7956672220772174.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[02:43:47] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68313\tvalid-logloss:0.68321\n",
            "[300]\ttrain-logloss:0.21875\tvalid-logloss:0.23023\n",
            "[600]\ttrain-logloss:0.20022\tvalid-logloss:0.22087\n",
            "[900]\ttrain-logloss:0.19024\tvalid-logloss:0.21840\n",
            "[1200]\ttrain-logloss:0.18264\tvalid-logloss:0.21724\n",
            "[1500]\ttrain-logloss:0.17608\tvalid-logloss:0.21663\n",
            "[1800]\ttrain-logloss:0.17022\tvalid-logloss:0.21631\n",
            "[2100]\ttrain-logloss:0.16481\tvalid-logloss:0.21606\n",
            "[2400]\ttrain-logloss:0.15941\tvalid-logloss:0.21594\n",
            "[2700]\ttrain-logloss:0.15436\tvalid-logloss:0.21584\n",
            "[3000]\ttrain-logloss:0.14943\tvalid-logloss:0.21578\n",
            "[3157]\ttrain-logloss:0.14704\tvalid-logloss:0.21577\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-08-02 02:50:26,302]\u001b[0m Trial 41 finished with value: 0.7942849186538108 and parameters: {'lambda': 0.013701137934517564, 'alpha': 0.3121405202630271, 'colsample_bytree': 0.8, 'subsample': 0.9, 'learning_rate': 0.015, 'max_depth': 7, 'min_child_weight': 28}. Best is trial 13 with value: 0.7956672220772174.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[02:50:40] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68327\tvalid-logloss:0.68332\n",
            "[300]\ttrain-logloss:0.22578\tvalid-logloss:0.23288\n",
            "[600]\ttrain-logloss:0.20907\tvalid-logloss:0.22234\n",
            "[900]\ttrain-logloss:0.20099\tvalid-logloss:0.21931\n",
            "[1200]\ttrain-logloss:0.19509\tvalid-logloss:0.21792\n",
            "[1500]\ttrain-logloss:0.18991\tvalid-logloss:0.21717\n",
            "[1800]\ttrain-logloss:0.18535\tvalid-logloss:0.21669\n",
            "[2100]\ttrain-logloss:0.18121\tvalid-logloss:0.21637\n",
            "[2400]\ttrain-logloss:0.17715\tvalid-logloss:0.21619\n",
            "[2700]\ttrain-logloss:0.17340\tvalid-logloss:0.21604\n",
            "[3000]\ttrain-logloss:0.16972\tvalid-logloss:0.21589\n",
            "[3300]\ttrain-logloss:0.16620\tvalid-logloss:0.21581\n",
            "[3600]\ttrain-logloss:0.16285\tvalid-logloss:0.21575\n",
            "[3784]\ttrain-logloss:0.16081\tvalid-logloss:0.21573\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-08-02 02:57:20,863]\u001b[0m Trial 42 finished with value: 0.7937866076468583 and parameters: {'lambda': 0.010317595272390437, 'alpha': 0.260506210459073, 'colsample_bytree': 0.9, 'subsample': 0.9, 'learning_rate': 0.015, 'max_depth': 6, 'min_child_weight': 34}. Best is trial 13 with value: 0.7956672220772174.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[02:57:34] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68314\tvalid-logloss:0.68320\n",
            "[300]\ttrain-logloss:0.21761\tvalid-logloss:0.23033\n",
            "[600]\ttrain-logloss:0.19787\tvalid-logloss:0.22101\n",
            "[900]\ttrain-logloss:0.18672\tvalid-logloss:0.21858\n",
            "[1200]\ttrain-logloss:0.17828\tvalid-logloss:0.21754\n",
            "[1500]\ttrain-logloss:0.17101\tvalid-logloss:0.21697\n",
            "[1800]\ttrain-logloss:0.16457\tvalid-logloss:0.21665\n",
            "[2100]\ttrain-logloss:0.15862\tvalid-logloss:0.21643\n",
            "[2400]\ttrain-logloss:0.15271\tvalid-logloss:0.21628\n",
            "[2578]\ttrain-logloss:0.14937\tvalid-logloss:0.21627\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-08-02 03:03:18,711]\u001b[0m Trial 43 finished with value: 0.7939665823679727 and parameters: {'lambda': 0.04510935505851824, 'alpha': 0.6586564480522287, 'colsample_bytree': 0.8, 'subsample': 1.0, 'learning_rate': 0.015, 'max_depth': 7, 'min_child_weight': 16}. Best is trial 13 with value: 0.7956672220772174.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[03:03:32] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68646\tvalid-logloss:0.68650\n",
            "[300]\ttrain-logloss:0.23474\tvalid-logloss:0.24467\n",
            "[600]\ttrain-logloss:0.20690\tvalid-logloss:0.22503\n",
            "[900]\ttrain-logloss:0.19445\tvalid-logloss:0.22073\n",
            "[1200]\ttrain-logloss:0.18501\tvalid-logloss:0.21877\n",
            "[1500]\ttrain-logloss:0.17695\tvalid-logloss:0.21769\n",
            "[1800]\ttrain-logloss:0.16978\tvalid-logloss:0.21702\n",
            "[2100]\ttrain-logloss:0.16320\tvalid-logloss:0.21654\n",
            "[2400]\ttrain-logloss:0.15710\tvalid-logloss:0.21628\n",
            "[2700]\ttrain-logloss:0.15133\tvalid-logloss:0.21607\n",
            "[3000]\ttrain-logloss:0.14583\tvalid-logloss:0.21593\n",
            "[3300]\ttrain-logloss:0.14067\tvalid-logloss:0.21583\n",
            "[3600]\ttrain-logloss:0.13564\tvalid-logloss:0.21577\n",
            "[3720]\ttrain-logloss:0.13356\tvalid-logloss:0.21577\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-08-02 03:12:58,341]\u001b[0m Trial 44 finished with value: 0.7939835063726175 and parameters: {'lambda': 0.004779317741091576, 'alpha': 2.395041430453339, 'colsample_bytree': 0.7, 'subsample': 0.9, 'learning_rate': 0.01, 'max_depth': 7, 'min_child_weight': 3}. Best is trial 13 with value: 0.7956672220772174.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[03:13:12] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.66719\tvalid-logloss:0.66731\n",
            "[300]\ttrain-logloss:0.20723\tvalid-logloss:0.22049\n",
            "[600]\ttrain-logloss:0.19503\tvalid-logloss:0.21732\n",
            "[900]\ttrain-logloss:0.18585\tvalid-logloss:0.21644\n",
            "[1200]\ttrain-logloss:0.17807\tvalid-logloss:0.21620\n",
            "[1500]\ttrain-logloss:0.17079\tvalid-logloss:0.21620\n",
            "[1534]\ttrain-logloss:0.17009\tvalid-logloss:0.21618\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-08-02 03:15:48,080]\u001b[0m Trial 45 finished with value: 0.7924455628910047 and parameters: {'lambda': 0.016275388773212572, 'alpha': 0.3001445465868136, 'colsample_bytree': 0.9, 'subsample': 0.9, 'learning_rate': 0.04, 'max_depth': 6, 'min_child_weight': 89}. Best is trial 13 with value: 0.7956672220772174.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[03:16:01] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68362\tvalid-logloss:0.68364\n",
            "[300]\ttrain-logloss:0.23832\tvalid-logloss:0.24072\n",
            "[600]\ttrain-logloss:0.22282\tvalid-logloss:0.22733\n",
            "[900]\ttrain-logloss:0.21671\tvalid-logloss:0.22301\n",
            "[1200]\ttrain-logloss:0.21275\tvalid-logloss:0.22073\n",
            "[1500]\ttrain-logloss:0.20966\tvalid-logloss:0.21936\n",
            "[1800]\ttrain-logloss:0.20713\tvalid-logloss:0.21845\n",
            "[2100]\ttrain-logloss:0.20493\tvalid-logloss:0.21784\n",
            "[2400]\ttrain-logloss:0.20289\tvalid-logloss:0.21741\n",
            "[2700]\ttrain-logloss:0.20098\tvalid-logloss:0.21704\n",
            "[3000]\ttrain-logloss:0.19920\tvalid-logloss:0.21680\n",
            "[3300]\ttrain-logloss:0.19750\tvalid-logloss:0.21659\n",
            "[3600]\ttrain-logloss:0.19588\tvalid-logloss:0.21642\n",
            "[3900]\ttrain-logloss:0.19425\tvalid-logloss:0.21626\n",
            "[4200]\ttrain-logloss:0.19264\tvalid-logloss:0.21613\n",
            "[4500]\ttrain-logloss:0.19111\tvalid-logloss:0.21600\n",
            "[4800]\ttrain-logloss:0.18958\tvalid-logloss:0.21591\n",
            "[5100]\ttrain-logloss:0.18813\tvalid-logloss:0.21584\n",
            "[5400]\ttrain-logloss:0.18670\tvalid-logloss:0.21578\n",
            "[5687]\ttrain-logloss:0.18535\tvalid-logloss:0.21577\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-08-02 03:23:03,523]\u001b[0m Trial 46 finished with value: 0.7922264962606407 and parameters: {'lambda': 0.001892828605941157, 'alpha': 0.10918906909230569, 'colsample_bytree': 0.8, 'subsample': 0.8, 'learning_rate': 0.015, 'max_depth': 4, 'min_child_weight': 40}. Best is trial 13 with value: 0.7956672220772174.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[03:23:17] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.67980\tvalid-logloss:0.67988\n",
            "[300]\ttrain-logloss:0.20900\tvalid-logloss:0.22492\n",
            "[600]\ttrain-logloss:0.18978\tvalid-logloss:0.21879\n",
            "[900]\ttrain-logloss:0.17783\tvalid-logloss:0.21713\n",
            "[1200]\ttrain-logloss:0.16796\tvalid-logloss:0.21650\n",
            "[1500]\ttrain-logloss:0.15905\tvalid-logloss:0.21613\n",
            "[1800]\ttrain-logloss:0.15074\tvalid-logloss:0.21602\n",
            "[1885]\ttrain-logloss:0.14852\tvalid-logloss:0.21604\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-08-02 03:27:47,685]\u001b[0m Trial 47 finished with value: 0.7926457106888345 and parameters: {'lambda': 0.5321720504266635, 'alpha': 0.01121591561727739, 'colsample_bytree': 1.0, 'subsample': 0.8, 'learning_rate': 0.02, 'max_depth': 7, 'min_child_weight': 14}. Best is trial 13 with value: 0.7956672220772174.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[03:28:01] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68639\tvalid-logloss:0.68645\n",
            "[300]\ttrain-logloss:0.23253\tvalid-logloss:0.24272\n",
            "[600]\ttrain-logloss:0.20753\tvalid-logloss:0.22380\n",
            "[900]\ttrain-logloss:0.19830\tvalid-logloss:0.21989\n",
            "[1200]\ttrain-logloss:0.19189\tvalid-logloss:0.21812\n",
            "[1500]\ttrain-logloss:0.18650\tvalid-logloss:0.21711\n",
            "[1800]\ttrain-logloss:0.18200\tvalid-logloss:0.21652\n",
            "[2100]\ttrain-logloss:0.17776\tvalid-logloss:0.21612\n",
            "[2400]\ttrain-logloss:0.17393\tvalid-logloss:0.21585\n",
            "[2700]\ttrain-logloss:0.17023\tvalid-logloss:0.21564\n",
            "[3000]\ttrain-logloss:0.16651\tvalid-logloss:0.21547\n",
            "[3300]\ttrain-logloss:0.16328\tvalid-logloss:0.21534\n",
            "[3600]\ttrain-logloss:0.16008\tvalid-logloss:0.21527\n",
            "[3900]\ttrain-logloss:0.15678\tvalid-logloss:0.21521\n",
            "[4200]\ttrain-logloss:0.15361\tvalid-logloss:0.21512\n",
            "[4500]\ttrain-logloss:0.15052\tvalid-logloss:0.21511\n",
            "[4512]\ttrain-logloss:0.15039\tvalid-logloss:0.21510\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-08-02 03:38:49,105]\u001b[0m Trial 48 finished with value: 0.7950312863229725 and parameters: {'lambda': 0.09410839787264685, 'alpha': 0.059280642329330765, 'colsample_bytree': 0.9, 'subsample': 0.9, 'learning_rate': 0.01, 'max_depth': 8, 'min_child_weight': 68}. Best is trial 13 with value: 0.7956672220772174.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[03:39:02] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68641\tvalid-logloss:0.68646\n",
            "[300]\ttrain-logloss:0.23397\tvalid-logloss:0.24358\n",
            "[600]\ttrain-logloss:0.20953\tvalid-logloss:0.22458\n",
            "[900]\ttrain-logloss:0.20066\tvalid-logloss:0.22057\n",
            "[1200]\ttrain-logloss:0.19493\tvalid-logloss:0.21877\n",
            "[1500]\ttrain-logloss:0.19027\tvalid-logloss:0.21782\n",
            "[1800]\ttrain-logloss:0.18616\tvalid-logloss:0.21727\n",
            "[2100]\ttrain-logloss:0.18248\tvalid-logloss:0.21684\n",
            "[2400]\ttrain-logloss:0.17904\tvalid-logloss:0.21656\n",
            "[2700]\ttrain-logloss:0.17576\tvalid-logloss:0.21632\n",
            "[3000]\ttrain-logloss:0.17264\tvalid-logloss:0.21624\n",
            "[3300]\ttrain-logloss:0.16972\tvalid-logloss:0.21616\n",
            "[3600]\ttrain-logloss:0.16681\tvalid-logloss:0.21608\n",
            "[3900]\ttrain-logloss:0.16413\tvalid-logloss:0.21604\n",
            "[3938]\ttrain-logloss:0.16380\tvalid-logloss:0.21605\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-08-02 03:48:10,231]\u001b[0m Trial 49 finished with value: 0.7939408028535327 and parameters: {'lambda': 0.9721461496149661, 'alpha': 0.04886536647878381, 'colsample_bytree': 0.9, 'subsample': 1.0, 'learning_rate': 0.01, 'max_depth': 8, 'min_child_weight': 97}. Best is trial 13 with value: 0.7956672220772174.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[03:48:23] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68643\tvalid-logloss:0.68647\n",
            "[300]\ttrain-logloss:0.23650\tvalid-logloss:0.24387\n",
            "[600]\ttrain-logloss:0.21315\tvalid-logloss:0.22465\n",
            "[900]\ttrain-logloss:0.20535\tvalid-logloss:0.22050\n",
            "[1200]\ttrain-logloss:0.19999\tvalid-logloss:0.21853\n",
            "[1500]\ttrain-logloss:0.19551\tvalid-logloss:0.21741\n",
            "[1800]\ttrain-logloss:0.19189\tvalid-logloss:0.21680\n",
            "[2100]\ttrain-logloss:0.18828\tvalid-logloss:0.21635\n",
            "[2400]\ttrain-logloss:0.18501\tvalid-logloss:0.21605\n",
            "[2700]\ttrain-logloss:0.18174\tvalid-logloss:0.21580\n",
            "[3000]\ttrain-logloss:0.17874\tvalid-logloss:0.21565\n",
            "[3300]\ttrain-logloss:0.17579\tvalid-logloss:0.21554\n",
            "[3600]\ttrain-logloss:0.17294\tvalid-logloss:0.21544\n",
            "[3900]\ttrain-logloss:0.17000\tvalid-logloss:0.21537\n",
            "[4200]\ttrain-logloss:0.16719\tvalid-logloss:0.21531\n",
            "[4500]\ttrain-logloss:0.16458\tvalid-logloss:0.21526\n",
            "[4629]\ttrain-logloss:0.16341\tvalid-logloss:0.21525\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-08-02 03:59:15,276]\u001b[0m Trial 50 finished with value: 0.7947790942814394 and parameters: {'lambda': 0.10721855274781993, 'alpha': 0.07445734178153599, 'colsample_bytree': 1.0, 'subsample': 0.7, 'learning_rate': 0.01, 'max_depth': 8, 'min_child_weight': 114}. Best is trial 13 with value: 0.7956672220772174.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[03:59:29] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68643\tvalid-logloss:0.68647\n",
            "[300]\ttrain-logloss:0.23650\tvalid-logloss:0.24387\n",
            "[600]\ttrain-logloss:0.21311\tvalid-logloss:0.22461\n",
            "[900]\ttrain-logloss:0.20538\tvalid-logloss:0.22046\n",
            "[1200]\ttrain-logloss:0.20003\tvalid-logloss:0.21849\n",
            "[1500]\ttrain-logloss:0.19562\tvalid-logloss:0.21743\n",
            "[1800]\ttrain-logloss:0.19203\tvalid-logloss:0.21685\n",
            "[2100]\ttrain-logloss:0.18846\tvalid-logloss:0.21641\n",
            "[2400]\ttrain-logloss:0.18514\tvalid-logloss:0.21611\n",
            "[2700]\ttrain-logloss:0.18188\tvalid-logloss:0.21587\n",
            "[3000]\ttrain-logloss:0.17882\tvalid-logloss:0.21572\n",
            "[3300]\ttrain-logloss:0.17580\tvalid-logloss:0.21561\n",
            "[3600]\ttrain-logloss:0.17296\tvalid-logloss:0.21549\n",
            "[3900]\ttrain-logloss:0.17006\tvalid-logloss:0.21539\n",
            "[4023]\ttrain-logloss:0.16892\tvalid-logloss:0.21539\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-08-02 04:08:59,319]\u001b[0m Trial 51 finished with value: 0.7954315910914007 and parameters: {'lambda': 0.10303085395345181, 'alpha': 0.06803842112478907, 'colsample_bytree': 1.0, 'subsample': 0.7, 'learning_rate': 0.01, 'max_depth': 8, 'min_child_weight': 114}. Best is trial 13 with value: 0.7956672220772174.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[04:09:13] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68645\tvalid-logloss:0.68649\n",
            "[300]\ttrain-logloss:0.23789\tvalid-logloss:0.24432\n",
            "[600]\ttrain-logloss:0.21491\tvalid-logloss:0.22499\n",
            "[900]\ttrain-logloss:0.20754\tvalid-logloss:0.22080\n",
            "[1200]\ttrain-logloss:0.20247\tvalid-logloss:0.21878\n",
            "[1500]\ttrain-logloss:0.19842\tvalid-logloss:0.21769\n",
            "[1800]\ttrain-logloss:0.19491\tvalid-logloss:0.21703\n",
            "[2100]\ttrain-logloss:0.19159\tvalid-logloss:0.21658\n",
            "[2400]\ttrain-logloss:0.18854\tvalid-logloss:0.21624\n",
            "[2700]\ttrain-logloss:0.18549\tvalid-logloss:0.21599\n",
            "[3000]\ttrain-logloss:0.18263\tvalid-logloss:0.21584\n",
            "[3300]\ttrain-logloss:0.17971\tvalid-logloss:0.21571\n",
            "[3600]\ttrain-logloss:0.17686\tvalid-logloss:0.21562\n",
            "[3900]\ttrain-logloss:0.17410\tvalid-logloss:0.21558\n",
            "[3922]\ttrain-logloss:0.17391\tvalid-logloss:0.21558\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-08-02 04:18:22,016]\u001b[0m Trial 52 finished with value: 0.7945929683143209 and parameters: {'lambda': 0.23552516742302224, 'alpha': 0.022982680575411515, 'colsample_bytree': 1.0, 'subsample': 0.6, 'learning_rate': 0.01, 'max_depth': 8, 'min_child_weight': 126}. Best is trial 13 with value: 0.7956672220772174.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[04:18:35] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68642\tvalid-logloss:0.68646\n",
            "[300]\ttrain-logloss:0.23597\tvalid-logloss:0.24356\n",
            "[600]\ttrain-logloss:0.21273\tvalid-logloss:0.22450\n",
            "[900]\ttrain-logloss:0.20512\tvalid-logloss:0.22043\n",
            "[1200]\ttrain-logloss:0.19970\tvalid-logloss:0.21850\n",
            "[1500]\ttrain-logloss:0.19528\tvalid-logloss:0.21748\n",
            "[1800]\ttrain-logloss:0.19154\tvalid-logloss:0.21691\n",
            "[2100]\ttrain-logloss:0.18789\tvalid-logloss:0.21648\n",
            "[2400]\ttrain-logloss:0.18454\tvalid-logloss:0.21618\n",
            "[2700]\ttrain-logloss:0.18119\tvalid-logloss:0.21596\n",
            "[3000]\ttrain-logloss:0.17804\tvalid-logloss:0.21582\n",
            "[3300]\ttrain-logloss:0.17488\tvalid-logloss:0.21570\n",
            "[3600]\ttrain-logloss:0.17195\tvalid-logloss:0.21562\n",
            "[3900]\ttrain-logloss:0.16895\tvalid-logloss:0.21553\n",
            "[4200]\ttrain-logloss:0.16605\tvalid-logloss:0.21545\n",
            "[4409]\ttrain-logloss:0.16417\tvalid-logloss:0.21542\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-08-02 04:29:49,588]\u001b[0m Trial 53 finished with value: 0.7937012175915721 and parameters: {'lambda': 0.09924084150909186, 'alpha': 0.18989639694190116, 'colsample_bytree': 1.0, 'subsample': 0.7, 'learning_rate': 0.01, 'max_depth': 9, 'min_child_weight': 150}. Best is trial 13 with value: 0.7956672220772174.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[04:30:03] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68642\tvalid-logloss:0.68647\n",
            "[300]\ttrain-logloss:0.23432\tvalid-logloss:0.24280\n",
            "[600]\ttrain-logloss:0.21036\tvalid-logloss:0.22384\n",
            "[900]\ttrain-logloss:0.20200\tvalid-logloss:0.21999\n",
            "[1200]\ttrain-logloss:0.19610\tvalid-logloss:0.21817\n",
            "[1500]\ttrain-logloss:0.19121\tvalid-logloss:0.21720\n",
            "[1800]\ttrain-logloss:0.18673\tvalid-logloss:0.21653\n",
            "[2100]\ttrain-logloss:0.18260\tvalid-logloss:0.21615\n",
            "[2400]\ttrain-logloss:0.17876\tvalid-logloss:0.21585\n",
            "[2700]\ttrain-logloss:0.17497\tvalid-logloss:0.21565\n",
            "[3000]\ttrain-logloss:0.17143\tvalid-logloss:0.21547\n",
            "[3300]\ttrain-logloss:0.16792\tvalid-logloss:0.21530\n",
            "[3600]\ttrain-logloss:0.16439\tvalid-logloss:0.21524\n",
            "[3900]\ttrain-logloss:0.16100\tvalid-logloss:0.21518\n",
            "[3991]\ttrain-logloss:0.16005\tvalid-logloss:0.21518\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-08-02 04:39:44,905]\u001b[0m Trial 54 finished with value: 0.7958030742195551 and parameters: {'lambda': 0.14008995478980213, 'alpha': 0.0705227231490643, 'colsample_bytree': 0.9, 'subsample': 0.6, 'learning_rate': 0.01, 'max_depth': 8, 'min_child_weight': 66}. Best is trial 54 with value: 0.7958030742195551.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[04:39:58] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68642\tvalid-logloss:0.68647\n",
            "[300]\ttrain-logloss:0.23482\tvalid-logloss:0.24302\n",
            "[600]\ttrain-logloss:0.21107\tvalid-logloss:0.22403\n",
            "[900]\ttrain-logloss:0.20286\tvalid-logloss:0.22005\n",
            "[1200]\ttrain-logloss:0.19710\tvalid-logloss:0.21821\n",
            "[1500]\ttrain-logloss:0.19234\tvalid-logloss:0.21719\n",
            "[1800]\ttrain-logloss:0.18813\tvalid-logloss:0.21654\n",
            "[2100]\ttrain-logloss:0.18412\tvalid-logloss:0.21614\n",
            "[2400]\ttrain-logloss:0.18040\tvalid-logloss:0.21583\n",
            "[2700]\ttrain-logloss:0.17668\tvalid-logloss:0.21565\n",
            "[3000]\ttrain-logloss:0.17333\tvalid-logloss:0.21549\n",
            "[3300]\ttrain-logloss:0.16994\tvalid-logloss:0.21533\n",
            "[3600]\ttrain-logloss:0.16661\tvalid-logloss:0.21529\n",
            "[3653]\ttrain-logloss:0.16605\tvalid-logloss:0.21527\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-08-02 04:48:46,831]\u001b[0m Trial 55 finished with value: 0.7951964633944262 and parameters: {'lambda': 0.14189688905565326, 'alpha': 0.06391818553653354, 'colsample_bytree': 0.9, 'subsample': 0.6, 'learning_rate': 0.01, 'max_depth': 8, 'min_child_weight': 73}. Best is trial 54 with value: 0.7958030742195551.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[04:49:00] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68642\tvalid-logloss:0.68647\n",
            "[300]\ttrain-logloss:0.23448\tvalid-logloss:0.24294\n",
            "[600]\ttrain-logloss:0.21054\tvalid-logloss:0.22399\n",
            "[900]\ttrain-logloss:0.20207\tvalid-logloss:0.22002\n",
            "[1200]\ttrain-logloss:0.19622\tvalid-logloss:0.21822\n",
            "[1500]\ttrain-logloss:0.19132\tvalid-logloss:0.21720\n",
            "[1800]\ttrain-logloss:0.18686\tvalid-logloss:0.21661\n",
            "[2100]\ttrain-logloss:0.18280\tvalid-logloss:0.21622\n",
            "[2400]\ttrain-logloss:0.17895\tvalid-logloss:0.21593\n",
            "[2700]\ttrain-logloss:0.17512\tvalid-logloss:0.21571\n",
            "[3000]\ttrain-logloss:0.17160\tvalid-logloss:0.21557\n",
            "[3300]\ttrain-logloss:0.16815\tvalid-logloss:0.21542\n",
            "[3582]\ttrain-logloss:0.16490\tvalid-logloss:0.21538\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-08-02 04:57:46,481]\u001b[0m Trial 56 finished with value: 0.7947162144101027 and parameters: {'lambda': 0.4632361761322373, 'alpha': 0.06893244815356779, 'colsample_bytree': 0.9, 'subsample': 0.6, 'learning_rate': 0.01, 'max_depth': 8, 'min_child_weight': 67}. Best is trial 54 with value: 0.7958030742195551.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[04:58:00] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68641\tvalid-logloss:0.68646\n",
            "[300]\ttrain-logloss:0.23330\tvalid-logloss:0.24248\n",
            "[600]\ttrain-logloss:0.20892\tvalid-logloss:0.22357\n",
            "[900]\ttrain-logloss:0.20008\tvalid-logloss:0.21973\n",
            "[1200]\ttrain-logloss:0.19379\tvalid-logloss:0.21799\n",
            "[1500]\ttrain-logloss:0.18859\tvalid-logloss:0.21700\n",
            "[1800]\ttrain-logloss:0.18387\tvalid-logloss:0.21639\n",
            "[2100]\ttrain-logloss:0.17945\tvalid-logloss:0.21601\n",
            "[2400]\ttrain-logloss:0.17531\tvalid-logloss:0.21573\n",
            "[2700]\ttrain-logloss:0.17120\tvalid-logloss:0.21553\n",
            "[3000]\ttrain-logloss:0.16745\tvalid-logloss:0.21540\n",
            "[3300]\ttrain-logloss:0.16371\tvalid-logloss:0.21527\n",
            "[3485]\ttrain-logloss:0.16143\tvalid-logloss:0.21525\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-08-02 05:06:45,032]\u001b[0m Trial 57 finished with value: 0.7954771230437957 and parameters: {'lambda': 0.1443900761695346, 'alpha': 0.1168483152809982, 'colsample_bytree': 0.9, 'subsample': 0.6, 'learning_rate': 0.01, 'max_depth': 8, 'min_child_weight': 53}. Best is trial 54 with value: 0.7958030742195551.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[05:06:59] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68641\tvalid-logloss:0.68646\n",
            "[300]\ttrain-logloss:0.23359\tvalid-logloss:0.24264\n",
            "[600]\ttrain-logloss:0.20924\tvalid-logloss:0.22378\n",
            "[900]\ttrain-logloss:0.20038\tvalid-logloss:0.21985\n",
            "[1200]\ttrain-logloss:0.19412\tvalid-logloss:0.21810\n",
            "[1500]\ttrain-logloss:0.18906\tvalid-logloss:0.21713\n",
            "[1800]\ttrain-logloss:0.18439\tvalid-logloss:0.21655\n",
            "[2100]\ttrain-logloss:0.17996\tvalid-logloss:0.21616\n",
            "[2400]\ttrain-logloss:0.17593\tvalid-logloss:0.21588\n",
            "[2700]\ttrain-logloss:0.17181\tvalid-logloss:0.21568\n",
            "[3000]\ttrain-logloss:0.16810\tvalid-logloss:0.21555\n",
            "[3300]\ttrain-logloss:0.16440\tvalid-logloss:0.21541\n",
            "[3600]\ttrain-logloss:0.16079\tvalid-logloss:0.21537\n",
            "[3843]\ttrain-logloss:0.15790\tvalid-logloss:0.21534\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-08-02 05:16:49,492]\u001b[0m Trial 58 finished with value: 0.795017125703936 and parameters: {'lambda': 0.19846538518330817, 'alpha': 0.11499421368543077, 'colsample_bytree': 1.0, 'subsample': 0.6, 'learning_rate': 0.01, 'max_depth': 8, 'min_child_weight': 56}. Best is trial 54 with value: 0.7958030742195551.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[05:17:03] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68309\tvalid-logloss:0.68317\n",
            "[300]\ttrain-logloss:0.21919\tvalid-logloss:0.22923\n",
            "[600]\ttrain-logloss:0.20425\tvalid-logloss:0.22039\n",
            "[900]\ttrain-logloss:0.19635\tvalid-logloss:0.21797\n",
            "[1200]\ttrain-logloss:0.18983\tvalid-logloss:0.21690\n",
            "[1500]\ttrain-logloss:0.18434\tvalid-logloss:0.21631\n",
            "[1800]\ttrain-logloss:0.17900\tvalid-logloss:0.21598\n",
            "[2100]\ttrain-logloss:0.17411\tvalid-logloss:0.21580\n",
            "[2400]\ttrain-logloss:0.16950\tvalid-logloss:0.21561\n",
            "[2700]\ttrain-logloss:0.16482\tvalid-logloss:0.21555\n",
            "[2719]\ttrain-logloss:0.16458\tvalid-logloss:0.21555\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-08-02 05:23:30,599]\u001b[0m Trial 59 finished with value: 0.7940456985194877 and parameters: {'lambda': 0.12616254740438726, 'alpha': 0.2005454960714458, 'colsample_bytree': 0.9, 'subsample': 0.6, 'learning_rate': 0.015, 'max_depth': 8, 'min_child_weight': 85}. Best is trial 54 with value: 0.7958030742195551.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[05:23:44] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68309\tvalid-logloss:0.68315\n",
            "[300]\ttrain-logloss:0.21861\tvalid-logloss:0.22856\n",
            "[600]\ttrain-logloss:0.20410\tvalid-logloss:0.21998\n",
            "[900]\ttrain-logloss:0.19617\tvalid-logloss:0.21769\n",
            "[1200]\ttrain-logloss:0.18973\tvalid-logloss:0.21676\n",
            "[1500]\ttrain-logloss:0.18393\tvalid-logloss:0.21621\n",
            "[1800]\ttrain-logloss:0.17827\tvalid-logloss:0.21593\n",
            "[2100]\ttrain-logloss:0.17299\tvalid-logloss:0.21580\n",
            "[2400]\ttrain-logloss:0.16808\tvalid-logloss:0.21569\n",
            "[2490]\ttrain-logloss:0.16655\tvalid-logloss:0.21569\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-08-02 05:30:10,853]\u001b[0m Trial 60 finished with value: 0.7942871367330734 and parameters: {'lambda': 0.2686900105597162, 'alpha': 0.029837838719885133, 'colsample_bytree': 0.9, 'subsample': 0.5, 'learning_rate': 0.015, 'max_depth': 9, 'min_child_weight': 96}. Best is trial 54 with value: 0.7958030742195551.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[05:30:24] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68641\tvalid-logloss:0.68645\n",
            "[300]\ttrain-logloss:0.23302\tvalid-logloss:0.24240\n",
            "[600]\ttrain-logloss:0.20848\tvalid-logloss:0.22356\n",
            "[900]\ttrain-logloss:0.19951\tvalid-logloss:0.21973\n",
            "[1200]\ttrain-logloss:0.19316\tvalid-logloss:0.21799\n",
            "[1500]\ttrain-logloss:0.18782\tvalid-logloss:0.21703\n",
            "[1800]\ttrain-logloss:0.18294\tvalid-logloss:0.21644\n",
            "[2100]\ttrain-logloss:0.17848\tvalid-logloss:0.21607\n",
            "[2400]\ttrain-logloss:0.17429\tvalid-logloss:0.21580\n",
            "[2700]\ttrain-logloss:0.17005\tvalid-logloss:0.21560\n",
            "[3000]\ttrain-logloss:0.16622\tvalid-logloss:0.21551\n",
            "[3300]\ttrain-logloss:0.16254\tvalid-logloss:0.21540\n",
            "[3562]\ttrain-logloss:0.15929\tvalid-logloss:0.21537\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-08-02 05:39:23,478]\u001b[0m Trial 61 finished with value: 0.7941538974749596 and parameters: {'lambda': 0.07581094448649114, 'alpha': 0.05381433154555775, 'colsample_bytree': 0.9, 'subsample': 0.6, 'learning_rate': 0.01, 'max_depth': 8, 'min_child_weight': 50}. Best is trial 54 with value: 0.7958030742195551.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[05:39:37] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68642\tvalid-logloss:0.68647\n",
            "[300]\ttrain-logloss:0.23475\tvalid-logloss:0.24297\n",
            "[600]\ttrain-logloss:0.21102\tvalid-logloss:0.22401\n",
            "[900]\ttrain-logloss:0.20272\tvalid-logloss:0.22001\n",
            "[1200]\ttrain-logloss:0.19698\tvalid-logloss:0.21816\n",
            "[1500]\ttrain-logloss:0.19228\tvalid-logloss:0.21721\n",
            "[1800]\ttrain-logloss:0.18799\tvalid-logloss:0.21659\n",
            "[2100]\ttrain-logloss:0.18392\tvalid-logloss:0.21619\n",
            "[2400]\ttrain-logloss:0.18008\tvalid-logloss:0.21584\n",
            "[2700]\ttrain-logloss:0.17639\tvalid-logloss:0.21557\n",
            "[3000]\ttrain-logloss:0.17303\tvalid-logloss:0.21545\n",
            "[3300]\ttrain-logloss:0.16967\tvalid-logloss:0.21528\n",
            "[3600]\ttrain-logloss:0.16631\tvalid-logloss:0.21522\n",
            "[3900]\ttrain-logloss:0.16302\tvalid-logloss:0.21516\n",
            "[4200]\ttrain-logloss:0.15997\tvalid-logloss:0.21510\n",
            "[4313]\ttrain-logloss:0.15882\tvalid-logloss:0.21510\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-08-02 05:49:56,275]\u001b[0m Trial 62 finished with value: 0.7955379611217694 and parameters: {'lambda': 0.13957647209858337, 'alpha': 0.07998430503064803, 'colsample_bytree': 0.9, 'subsample': 0.6, 'learning_rate': 0.01, 'max_depth': 8, 'min_child_weight': 72}. Best is trial 54 with value: 0.7958030742195551.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[05:50:09] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68642\tvalid-logloss:0.68647\n",
            "[300]\ttrain-logloss:0.23519\tvalid-logloss:0.24318\n",
            "[600]\ttrain-logloss:0.21154\tvalid-logloss:0.22416\n",
            "[900]\ttrain-logloss:0.20341\tvalid-logloss:0.22021\n",
            "[1200]\ttrain-logloss:0.19776\tvalid-logloss:0.21833\n",
            "[1500]\ttrain-logloss:0.19305\tvalid-logloss:0.21730\n",
            "[1800]\ttrain-logloss:0.18883\tvalid-logloss:0.21666\n",
            "[2100]\ttrain-logloss:0.18492\tvalid-logloss:0.21627\n",
            "[2400]\ttrain-logloss:0.18127\tvalid-logloss:0.21594\n",
            "[2700]\ttrain-logloss:0.17761\tvalid-logloss:0.21569\n",
            "[3000]\ttrain-logloss:0.17428\tvalid-logloss:0.21554\n",
            "[3300]\ttrain-logloss:0.17098\tvalid-logloss:0.21539\n",
            "[3600]\ttrain-logloss:0.16757\tvalid-logloss:0.21531\n",
            "[3900]\ttrain-logloss:0.16437\tvalid-logloss:0.21525\n",
            "[3941]\ttrain-logloss:0.16394\tvalid-logloss:0.21526\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-08-02 05:59:39,039]\u001b[0m Trial 63 finished with value: 0.7951067219998548 and parameters: {'lambda': 0.35835215227487527, 'alpha': 0.09312593348213949, 'colsample_bytree': 0.9, 'subsample': 0.6, 'learning_rate': 0.01, 'max_depth': 8, 'min_child_weight': 77}. Best is trial 54 with value: 0.7958030742195551.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[05:59:52] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68646\tvalid-logloss:0.68650\n",
            "[300]\ttrain-logloss:0.23860\tvalid-logloss:0.24440\n",
            "[600]\ttrain-logloss:0.21590\tvalid-logloss:0.22497\n",
            "[900]\ttrain-logloss:0.20875\tvalid-logloss:0.22073\n",
            "[1200]\ttrain-logloss:0.20392\tvalid-logloss:0.21878\n",
            "[1500]\ttrain-logloss:0.19989\tvalid-logloss:0.21771\n",
            "[1800]\ttrain-logloss:0.19646\tvalid-logloss:0.21703\n",
            "[2100]\ttrain-logloss:0.19318\tvalid-logloss:0.21658\n",
            "[2400]\ttrain-logloss:0.19015\tvalid-logloss:0.21627\n",
            "[2700]\ttrain-logloss:0.18730\tvalid-logloss:0.21601\n",
            "[3000]\ttrain-logloss:0.18454\tvalid-logloss:0.21582\n",
            "[3300]\ttrain-logloss:0.18179\tvalid-logloss:0.21567\n",
            "[3600]\ttrain-logloss:0.17916\tvalid-logloss:0.21561\n",
            "[3900]\ttrain-logloss:0.17646\tvalid-logloss:0.21554\n",
            "[4200]\ttrain-logloss:0.17386\tvalid-logloss:0.21551\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-08-02 06:09:23,953]\u001b[0m Trial 64 finished with value: 0.7939422825542232 and parameters: {'lambda': 0.18212191885509904, 'alpha': 0.01686537283346417, 'colsample_bytree': 0.9, 'subsample': 0.5, 'learning_rate': 0.01, 'max_depth': 8, 'min_child_weight': 119}. Best is trial 54 with value: 0.7958030742195551.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[06:09:37] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68640\tvalid-logloss:0.68644\n",
            "[300]\ttrain-logloss:0.23321\tvalid-logloss:0.24272\n",
            "[600]\ttrain-logloss:0.20859\tvalid-logloss:0.22376\n",
            "[900]\ttrain-logloss:0.19962\tvalid-logloss:0.21987\n",
            "[1200]\ttrain-logloss:0.19329\tvalid-logloss:0.21810\n",
            "[1500]\ttrain-logloss:0.18800\tvalid-logloss:0.21709\n",
            "[1800]\ttrain-logloss:0.18346\tvalid-logloss:0.21657\n",
            "[2100]\ttrain-logloss:0.17908\tvalid-logloss:0.21622\n",
            "[2400]\ttrain-logloss:0.17500\tvalid-logloss:0.21599\n",
            "[2700]\ttrain-logloss:0.17091\tvalid-logloss:0.21583\n",
            "[3000]\ttrain-logloss:0.16727\tvalid-logloss:0.21568\n",
            "[3300]\ttrain-logloss:0.16370\tvalid-logloss:0.21560\n",
            "[3600]\ttrain-logloss:0.16010\tvalid-logloss:0.21551\n",
            "[3900]\ttrain-logloss:0.15667\tvalid-logloss:0.21541\n",
            "[4163]\ttrain-logloss:0.15364\tvalid-logloss:0.21539\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-08-02 06:20:11,910]\u001b[0m Trial 65 finished with value: 0.7943910112382215 and parameters: {'lambda': 0.12941973300601325, 'alpha': 0.13952392664833208, 'colsample_bytree': 1.0, 'subsample': 0.7, 'learning_rate': 0.01, 'max_depth': 8, 'min_child_weight': 60}. Best is trial 54 with value: 0.7958030742195551.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[06:20:25] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68311\tvalid-logloss:0.68318\n",
            "[300]\ttrain-logloss:0.21987\tvalid-logloss:0.22921\n",
            "[600]\ttrain-logloss:0.20548\tvalid-logloss:0.22038\n",
            "[900]\ttrain-logloss:0.19789\tvalid-logloss:0.21803\n",
            "[1200]\ttrain-logloss:0.19178\tvalid-logloss:0.21705\n",
            "[1500]\ttrain-logloss:0.18639\tvalid-logloss:0.21645\n",
            "[1800]\ttrain-logloss:0.18130\tvalid-logloss:0.21607\n",
            "[2100]\ttrain-logloss:0.17645\tvalid-logloss:0.21589\n",
            "[2400]\ttrain-logloss:0.17178\tvalid-logloss:0.21576\n",
            "[2557]\ttrain-logloss:0.16938\tvalid-logloss:0.21574\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-08-02 06:27:00,952]\u001b[0m Trial 66 finished with value: 0.7940716637142358 and parameters: {'lambda': 0.9020574154973553, 'alpha': 0.08678774233727717, 'colsample_bytree': 1.0, 'subsample': 0.6, 'learning_rate': 0.015, 'max_depth': 9, 'min_child_weight': 133}. Best is trial 54 with value: 0.7958030742195551.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[06:27:14] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68308\tvalid-logloss:0.68316\n",
            "[300]\ttrain-logloss:0.21868\tvalid-logloss:0.22904\n",
            "[600]\ttrain-logloss:0.20361\tvalid-logloss:0.22031\n",
            "[900]\ttrain-logloss:0.19559\tvalid-logloss:0.21796\n",
            "[1200]\ttrain-logloss:0.18895\tvalid-logloss:0.21694\n",
            "[1500]\ttrain-logloss:0.18337\tvalid-logloss:0.21639\n",
            "[1800]\ttrain-logloss:0.17793\tvalid-logloss:0.21611\n",
            "[2100]\ttrain-logloss:0.17286\tvalid-logloss:0.21588\n",
            "[2400]\ttrain-logloss:0.16817\tvalid-logloss:0.21573\n",
            "[2700]\ttrain-logloss:0.16340\tvalid-logloss:0.21565\n",
            "[2846]\ttrain-logloss:0.16131\tvalid-logloss:0.21563\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-08-02 06:33:56,965]\u001b[0m Trial 67 finished with value: 0.7936287202184433 and parameters: {'lambda': 0.06035891279233033, 'alpha': 0.032570650765710196, 'colsample_bytree': 0.9, 'subsample': 0.6, 'learning_rate': 0.015, 'max_depth': 8, 'min_child_weight': 79}. Best is trial 54 with value: 0.7958030742195551.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[06:34:10] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68639\tvalid-logloss:0.68644\n",
            "[300]\ttrain-logloss:0.23253\tvalid-logloss:0.24251\n",
            "[600]\ttrain-logloss:0.20769\tvalid-logloss:0.22362\n",
            "[900]\ttrain-logloss:0.19840\tvalid-logloss:0.21975\n",
            "[1200]\ttrain-logloss:0.19194\tvalid-logloss:0.21800\n",
            "[1500]\ttrain-logloss:0.18637\tvalid-logloss:0.21704\n",
            "[1800]\ttrain-logloss:0.18152\tvalid-logloss:0.21649\n",
            "[2100]\ttrain-logloss:0.17697\tvalid-logloss:0.21608\n",
            "[2400]\ttrain-logloss:0.17270\tvalid-logloss:0.21586\n",
            "[2700]\ttrain-logloss:0.16847\tvalid-logloss:0.21568\n",
            "[3000]\ttrain-logloss:0.16467\tvalid-logloss:0.21554\n",
            "[3300]\ttrain-logloss:0.16089\tvalid-logloss:0.21546\n",
            "[3600]\ttrain-logloss:0.15726\tvalid-logloss:0.21536\n",
            "[3836]\ttrain-logloss:0.15448\tvalid-logloss:0.21531\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-08-02 06:43:50,224]\u001b[0m Trial 68 finished with value: 0.7948535113378095 and parameters: {'lambda': 0.03391888333455523, 'alpha': 0.22936539035392042, 'colsample_bytree': 0.9, 'subsample': 0.7, 'learning_rate': 0.01, 'max_depth': 8, 'min_child_weight': 52}. Best is trial 54 with value: 0.7958030742195551.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[06:44:03] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68639\tvalid-logloss:0.68645\n",
            "[300]\ttrain-logloss:0.23319\tvalid-logloss:0.24225\n",
            "[600]\ttrain-logloss:0.20940\tvalid-logloss:0.22357\n",
            "[900]\ttrain-logloss:0.20106\tvalid-logloss:0.21973\n",
            "[1200]\ttrain-logloss:0.19496\tvalid-logloss:0.21801\n",
            "[1500]\ttrain-logloss:0.19001\tvalid-logloss:0.21706\n",
            "[1800]\ttrain-logloss:0.18550\tvalid-logloss:0.21649\n",
            "[2100]\ttrain-logloss:0.18121\tvalid-logloss:0.21614\n",
            "[2400]\ttrain-logloss:0.17728\tvalid-logloss:0.21589\n",
            "[2700]\ttrain-logloss:0.17331\tvalid-logloss:0.21570\n",
            "[3000]\ttrain-logloss:0.16967\tvalid-logloss:0.21557\n",
            "[3300]\ttrain-logloss:0.16595\tvalid-logloss:0.21548\n",
            "[3600]\ttrain-logloss:0.16229\tvalid-logloss:0.21547\n",
            "[3628]\ttrain-logloss:0.16195\tvalid-logloss:0.21546\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-08-02 06:54:07,519]\u001b[0m Trial 69 finished with value: 0.794409409402515 and parameters: {'lambda': 0.16802096507649394, 'alpha': 0.1682765498131721, 'colsample_bytree': 1.0, 'subsample': 0.6, 'learning_rate': 0.01, 'max_depth': 9, 'min_child_weight': 91}. Best is trial 54 with value: 0.7958030742195551.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[06:54:21] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.67653\tvalid-logloss:0.67663\n",
            "[300]\ttrain-logloss:0.21105\tvalid-logloss:0.22241\n",
            "[600]\ttrain-logloss:0.19893\tvalid-logloss:0.21800\n",
            "[900]\ttrain-logloss:0.19022\tvalid-logloss:0.21683\n",
            "[1200]\ttrain-logloss:0.18280\tvalid-logloss:0.21635\n",
            "[1500]\ttrain-logloss:0.17574\tvalid-logloss:0.21617\n",
            "[1632]\ttrain-logloss:0.17272\tvalid-logloss:0.21616\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-08-02 06:58:04,817]\u001b[0m Trial 70 finished with value: 0.7941569001500106 and parameters: {'lambda': 0.05267537096281379, 'alpha': 0.0019768442787111424, 'colsample_bytree': 0.9, 'subsample': 0.5, 'learning_rate': 0.025, 'max_depth': 8, 'min_child_weight': 105}. Best is trial 54 with value: 0.7958030742195551.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[06:58:18] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68642\tvalid-logloss:0.68647\n",
            "[300]\ttrain-logloss:0.23518\tvalid-logloss:0.24318\n",
            "[600]\ttrain-logloss:0.21150\tvalid-logloss:0.22410\n",
            "[900]\ttrain-logloss:0.20338\tvalid-logloss:0.22012\n",
            "[1200]\ttrain-logloss:0.19772\tvalid-logloss:0.21825\n",
            "[1500]\ttrain-logloss:0.19303\tvalid-logloss:0.21722\n",
            "[1800]\ttrain-logloss:0.18884\tvalid-logloss:0.21660\n",
            "[2100]\ttrain-logloss:0.18498\tvalid-logloss:0.21621\n",
            "[2400]\ttrain-logloss:0.18134\tvalid-logloss:0.21588\n",
            "[2700]\ttrain-logloss:0.17768\tvalid-logloss:0.21564\n",
            "[3000]\ttrain-logloss:0.17424\tvalid-logloss:0.21551\n",
            "[3300]\ttrain-logloss:0.17094\tvalid-logloss:0.21538\n",
            "[3600]\ttrain-logloss:0.16760\tvalid-logloss:0.21530\n",
            "[3900]\ttrain-logloss:0.16438\tvalid-logloss:0.21526\n",
            "[4122]\ttrain-logloss:0.16215\tvalid-logloss:0.21524\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-08-02 07:08:07,801]\u001b[0m Trial 71 finished with value: 0.7948076380057513 and parameters: {'lambda': 0.37803172371728155, 'alpha': 0.08355085117858521, 'colsample_bytree': 0.9, 'subsample': 0.6, 'learning_rate': 0.01, 'max_depth': 8, 'min_child_weight': 77}. Best is trial 54 with value: 0.7958030742195551.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[07:08:21] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68640\tvalid-logloss:0.68645\n",
            "[300]\ttrain-logloss:0.23226\tvalid-logloss:0.24225\n",
            "[600]\ttrain-logloss:0.20728\tvalid-logloss:0.22337\n",
            "[900]\ttrain-logloss:0.19788\tvalid-logloss:0.21959\n",
            "[1200]\ttrain-logloss:0.19103\tvalid-logloss:0.21789\n",
            "[1500]\ttrain-logloss:0.18543\tvalid-logloss:0.21696\n",
            "[1800]\ttrain-logloss:0.18032\tvalid-logloss:0.21643\n",
            "[2100]\ttrain-logloss:0.17550\tvalid-logloss:0.21608\n",
            "[2400]\ttrain-logloss:0.17110\tvalid-logloss:0.21580\n",
            "[2700]\ttrain-logloss:0.16667\tvalid-logloss:0.21560\n",
            "[3000]\ttrain-logloss:0.16260\tvalid-logloss:0.21551\n",
            "[3300]\ttrain-logloss:0.15862\tvalid-logloss:0.21538\n",
            "[3600]\ttrain-logloss:0.15469\tvalid-logloss:0.21531\n",
            "[3672]\ttrain-logloss:0.15384\tvalid-logloss:0.21530\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-08-02 07:17:50,628]\u001b[0m Trial 72 finished with value: 0.7947195834479273 and parameters: {'lambda': 0.22739544283059426, 'alpha': 0.1124553997274231, 'colsample_bytree': 0.9, 'subsample': 0.6, 'learning_rate': 0.01, 'max_depth': 8, 'min_child_weight': 41}. Best is trial 54 with value: 0.7958030742195551.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[07:18:04] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68306\tvalid-logloss:0.68313\n",
            "[300]\ttrain-logloss:0.21724\tvalid-logloss:0.22883\n",
            "[600]\ttrain-logloss:0.20134\tvalid-logloss:0.22014\n",
            "[900]\ttrain-logloss:0.19301\tvalid-logloss:0.21777\n",
            "[1200]\ttrain-logloss:0.18628\tvalid-logloss:0.21666\n",
            "[1500]\ttrain-logloss:0.18027\tvalid-logloss:0.21615\n",
            "[1800]\ttrain-logloss:0.17488\tvalid-logloss:0.21584\n",
            "[2100]\ttrain-logloss:0.16965\tvalid-logloss:0.21567\n",
            "[2400]\ttrain-logloss:0.16468\tvalid-logloss:0.21557\n",
            "[2700]\ttrain-logloss:0.15968\tvalid-logloss:0.21542\n",
            "[2824]\ttrain-logloss:0.15785\tvalid-logloss:0.21543\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-08-02 07:24:52,563]\u001b[0m Trial 73 finished with value: 0.7931421637847124 and parameters: {'lambda': 0.32529207507299907, 'alpha': 0.06540520190774653, 'colsample_bytree': 0.9, 'subsample': 0.7, 'learning_rate': 0.015, 'max_depth': 8, 'min_child_weight': 73}. Best is trial 54 with value: 0.7958030742195551.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[07:25:06] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68642\tvalid-logloss:0.68647\n",
            "[300]\ttrain-logloss:0.23411\tvalid-logloss:0.24275\n",
            "[600]\ttrain-logloss:0.21010\tvalid-logloss:0.22380\n",
            "[900]\ttrain-logloss:0.20157\tvalid-logloss:0.21986\n",
            "[1200]\ttrain-logloss:0.19550\tvalid-logloss:0.21804\n",
            "[1500]\ttrain-logloss:0.19052\tvalid-logloss:0.21708\n",
            "[1800]\ttrain-logloss:0.18606\tvalid-logloss:0.21644\n",
            "[2100]\ttrain-logloss:0.18189\tvalid-logloss:0.21603\n",
            "[2400]\ttrain-logloss:0.17795\tvalid-logloss:0.21572\n",
            "[2700]\ttrain-logloss:0.17401\tvalid-logloss:0.21550\n",
            "[3000]\ttrain-logloss:0.17046\tvalid-logloss:0.21536\n",
            "[3300]\ttrain-logloss:0.16692\tvalid-logloss:0.21518\n",
            "[3600]\ttrain-logloss:0.16349\tvalid-logloss:0.21514\n",
            "[3900]\ttrain-logloss:0.16006\tvalid-logloss:0.21509\n",
            "[4200]\ttrain-logloss:0.15701\tvalid-logloss:0.21504\n",
            "[4440]\ttrain-logloss:0.15452\tvalid-logloss:0.21503\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-08-02 07:35:54,028]\u001b[0m Trial 74 finished with value: 0.794375012455153 and parameters: {'lambda': 0.07831390156091238, 'alpha': 0.13965694752047478, 'colsample_bytree': 0.9, 'subsample': 0.6, 'learning_rate': 0.01, 'max_depth': 8, 'min_child_weight': 63}. Best is trial 54 with value: 0.7958030742195551.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[07:36:07] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68322\tvalid-logloss:0.68328\n",
            "[300]\ttrain-logloss:0.22560\tvalid-logloss:0.23178\n",
            "[600]\ttrain-logloss:0.21186\tvalid-logloss:0.22194\n",
            "[900]\ttrain-logloss:0.20552\tvalid-logloss:0.21904\n",
            "[1200]\ttrain-logloss:0.20079\tvalid-logloss:0.21773\n",
            "[1500]\ttrain-logloss:0.19687\tvalid-logloss:0.21704\n",
            "[1800]\ttrain-logloss:0.19323\tvalid-logloss:0.21661\n",
            "[2100]\ttrain-logloss:0.18984\tvalid-logloss:0.21638\n",
            "[2400]\ttrain-logloss:0.18652\tvalid-logloss:0.21611\n",
            "[2700]\ttrain-logloss:0.18324\tvalid-logloss:0.21591\n",
            "[3000]\ttrain-logloss:0.18025\tvalid-logloss:0.21585\n",
            "[3300]\ttrain-logloss:0.17713\tvalid-logloss:0.21576\n",
            "[3475]\ttrain-logloss:0.17536\tvalid-logloss:0.21577\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-08-02 07:42:57,938]\u001b[0m Trial 75 finished with value: 0.7936955532519255 and parameters: {'lambda': 1.687554935259548, 'alpha': 0.04600617654336031, 'colsample_bytree': 0.9, 'subsample': 0.6, 'learning_rate': 0.015, 'max_depth': 7, 'min_child_weight': 146}. Best is trial 54 with value: 0.7958030742195551.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[07:43:11] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68644\tvalid-logloss:0.68648\n",
            "[300]\ttrain-logloss:0.23758\tvalid-logloss:0.24389\n",
            "[600]\ttrain-logloss:0.21464\tvalid-logloss:0.22462\n",
            "[900]\ttrain-logloss:0.20724\tvalid-logloss:0.22045\n",
            "[1200]\ttrain-logloss:0.20217\tvalid-logloss:0.21855\n",
            "[1500]\ttrain-logloss:0.19788\tvalid-logloss:0.21752\n",
            "[1800]\ttrain-logloss:0.19417\tvalid-logloss:0.21686\n",
            "[2100]\ttrain-logloss:0.19058\tvalid-logloss:0.21640\n",
            "[2400]\ttrain-logloss:0.18728\tvalid-logloss:0.21613\n",
            "[2700]\ttrain-logloss:0.18410\tvalid-logloss:0.21588\n",
            "[3000]\ttrain-logloss:0.18111\tvalid-logloss:0.21571\n",
            "[3300]\ttrain-logloss:0.17815\tvalid-logloss:0.21556\n",
            "[3600]\ttrain-logloss:0.17528\tvalid-logloss:0.21549\n",
            "[3900]\ttrain-logloss:0.17238\tvalid-logloss:0.21543\n",
            "[3965]\ttrain-logloss:0.17176\tvalid-logloss:0.21543\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-08-02 07:52:38,956]\u001b[0m Trial 76 finished with value: 0.7941931414616823 and parameters: {'lambda': 0.13609426541138414, 'alpha': 0.08997934208315825, 'colsample_bytree': 1.0, 'subsample': 0.5, 'learning_rate': 0.01, 'max_depth': 8, 'min_child_weight': 100}. Best is trial 54 with value: 0.7958030742195551.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[07:52:52] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68641\tvalid-logloss:0.68646\n",
            "[300]\ttrain-logloss:0.23384\tvalid-logloss:0.24269\n",
            "[600]\ttrain-logloss:0.21015\tvalid-logloss:0.22379\n",
            "[900]\ttrain-logloss:0.20210\tvalid-logloss:0.21992\n",
            "[1200]\ttrain-logloss:0.19643\tvalid-logloss:0.21816\n",
            "[1500]\ttrain-logloss:0.19158\tvalid-logloss:0.21718\n",
            "[1800]\ttrain-logloss:0.18739\tvalid-logloss:0.21659\n",
            "[2100]\ttrain-logloss:0.18340\tvalid-logloss:0.21618\n",
            "[2400]\ttrain-logloss:0.17964\tvalid-logloss:0.21590\n",
            "[2700]\ttrain-logloss:0.17595\tvalid-logloss:0.21569\n",
            "[3000]\ttrain-logloss:0.17257\tvalid-logloss:0.21557\n",
            "[3300]\ttrain-logloss:0.16916\tvalid-logloss:0.21544\n",
            "[3600]\ttrain-logloss:0.16581\tvalid-logloss:0.21536\n",
            "[3900]\ttrain-logloss:0.16259\tvalid-logloss:0.21532\n",
            "[3947]\ttrain-logloss:0.16209\tvalid-logloss:0.21532\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-08-02 08:02:48,025]\u001b[0m Trial 77 finished with value: 0.7952310118490492 and parameters: {'lambda': 0.42314844332025625, 'alpha': 0.036865466642826104, 'colsample_bytree': 0.8, 'subsample': 0.7, 'learning_rate': 0.01, 'max_depth': 9, 'min_child_weight': 113}. Best is trial 54 with value: 0.7958030742195551.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[08:03:01] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.66342\tvalid-logloss:0.66361\n",
            "[300]\ttrain-logloss:0.19542\tvalid-logloss:0.21811\n",
            "[600]\ttrain-logloss:0.17816\tvalid-logloss:0.21666\n",
            "[831]\ttrain-logloss:0.16662\tvalid-logloss:0.21655\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-08-02 08:05:07,469]\u001b[0m Trial 78 finished with value: 0.7929572866950194 and parameters: {'lambda': 0.7282772913388539, 'alpha': 0.025806996018952793, 'colsample_bytree': 0.8, 'subsample': 0.7, 'learning_rate': 0.045000000000000005, 'max_depth': 9, 'min_child_weight': 121}. Best is trial 54 with value: 0.7958030742195551.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[08:05:21] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68306\tvalid-logloss:0.68313\n",
            "[300]\ttrain-logloss:0.21696\tvalid-logloss:0.22861\n",
            "[600]\ttrain-logloss:0.20185\tvalid-logloss:0.22004\n",
            "[900]\ttrain-logloss:0.19365\tvalid-logloss:0.21778\n",
            "[1200]\ttrain-logloss:0.18704\tvalid-logloss:0.21675\n",
            "[1500]\ttrain-logloss:0.18098\tvalid-logloss:0.21618\n",
            "[1800]\ttrain-logloss:0.17552\tvalid-logloss:0.21588\n",
            "[2100]\ttrain-logloss:0.17026\tvalid-logloss:0.21568\n",
            "[2400]\ttrain-logloss:0.16531\tvalid-logloss:0.21557\n",
            "[2544]\ttrain-logloss:0.16287\tvalid-logloss:0.21557\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-02 08:11:47,479]\u001b[0m Trial 79 finished with value: 0.7939677124238285 and parameters: {'lambda': 0.4771980751308569, 'alpha': 0.03643385474436346, 'colsample_bytree': 0.8, 'subsample': 0.7, 'learning_rate': 0.015, 'max_depth': 9, 'min_child_weight': 110}. Best is trial 54 with value: 0.7958030742195551.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[08:12:01] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68307\tvalid-logloss:0.68313\n",
            "[300]\ttrain-logloss:0.21724\tvalid-logloss:0.22864\n",
            "[600]\ttrain-logloss:0.20224\tvalid-logloss:0.22003\n",
            "[900]\ttrain-logloss:0.19417\tvalid-logloss:0.21771\n",
            "[1200]\ttrain-logloss:0.18743\tvalid-logloss:0.21667\n",
            "[1500]\ttrain-logloss:0.18151\tvalid-logloss:0.21613\n",
            "[1800]\ttrain-logloss:0.17608\tvalid-logloss:0.21580\n",
            "[2100]\ttrain-logloss:0.17087\tvalid-logloss:0.21556\n",
            "[2400]\ttrain-logloss:0.16599\tvalid-logloss:0.21546\n",
            "[2700]\ttrain-logloss:0.16125\tvalid-logloss:0.21535\n",
            "[2819]\ttrain-logloss:0.15937\tvalid-logloss:0.21536\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-02 08:19:04,604]\u001b[0m Trial 80 finished with value: 0.7949801363619604 and parameters: {'lambda': 0.25951175780284835, 'alpha': 0.017366263017740302, 'colsample_bytree': 0.8, 'subsample': 0.7, 'learning_rate': 0.015, 'max_depth': 9, 'min_child_weight': 114}. Best is trial 54 with value: 0.7958030742195551.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[08:19:18] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68646\tvalid-logloss:0.68650\n",
            "[300]\ttrain-logloss:0.23816\tvalid-logloss:0.24439\n",
            "[600]\ttrain-logloss:0.21532\tvalid-logloss:0.22505\n",
            "[900]\ttrain-logloss:0.20804\tvalid-logloss:0.22083\n",
            "[1200]\ttrain-logloss:0.20303\tvalid-logloss:0.21879\n",
            "[1500]\ttrain-logloss:0.19899\tvalid-logloss:0.21766\n",
            "[1800]\ttrain-logloss:0.19553\tvalid-logloss:0.21698\n",
            "[2100]\ttrain-logloss:0.19224\tvalid-logloss:0.21652\n",
            "[2400]\ttrain-logloss:0.18927\tvalid-logloss:0.21617\n",
            "[2700]\ttrain-logloss:0.18625\tvalid-logloss:0.21590\n",
            "[3000]\ttrain-logloss:0.18343\tvalid-logloss:0.21572\n",
            "[3300]\ttrain-logloss:0.18055\tvalid-logloss:0.21557\n",
            "[3600]\ttrain-logloss:0.17781\tvalid-logloss:0.21545\n",
            "[3900]\ttrain-logloss:0.17512\tvalid-logloss:0.21540\n",
            "[4200]\ttrain-logloss:0.17264\tvalid-logloss:0.21532\n",
            "[4500]\ttrain-logloss:0.17017\tvalid-logloss:0.21528\n",
            "[4547]\ttrain-logloss:0.16980\tvalid-logloss:0.21527\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-02 08:29:33,992]\u001b[0m Trial 81 finished with value: 0.7938931886644273 and parameters: {'lambda': 0.3795224359307563, 'alpha': 0.054217159160246234, 'colsample_bytree': 0.9, 'subsample': 0.6, 'learning_rate': 0.01, 'max_depth': 8, 'min_child_weight': 131}. Best is trial 54 with value: 0.7958030742195551.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[08:29:47] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68642\tvalid-logloss:0.68646\n",
            "[300]\ttrain-logloss:0.23573\tvalid-logloss:0.24332\n",
            "[600]\ttrain-logloss:0.21232\tvalid-logloss:0.22430\n",
            "[900]\ttrain-logloss:0.20442\tvalid-logloss:0.22029\n",
            "[1200]\ttrain-logloss:0.19889\tvalid-logloss:0.21845\n",
            "[1500]\ttrain-logloss:0.19433\tvalid-logloss:0.21742\n",
            "[1800]\ttrain-logloss:0.19031\tvalid-logloss:0.21679\n",
            "[2100]\ttrain-logloss:0.18664\tvalid-logloss:0.21636\n",
            "[2400]\ttrain-logloss:0.18320\tvalid-logloss:0.21605\n",
            "[2700]\ttrain-logloss:0.17970\tvalid-logloss:0.21585\n",
            "[3000]\ttrain-logloss:0.17658\tvalid-logloss:0.21570\n",
            "[3300]\ttrain-logloss:0.17331\tvalid-logloss:0.21557\n",
            "[3504]\ttrain-logloss:0.17113\tvalid-logloss:0.21557\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-02 08:37:55,452]\u001b[0m Trial 82 finished with value: 0.7937995203053205 and parameters: {'lambda': 0.15734914772200223, 'alpha': 0.07287324617537565, 'colsample_bytree': 0.8, 'subsample': 0.6, 'learning_rate': 0.01, 'max_depth': 8, 'min_child_weight': 85}. Best is trial 54 with value: 0.7958030742195551.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[08:38:09] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68647\tvalid-logloss:0.68651\n",
            "[300]\ttrain-logloss:0.23795\tvalid-logloss:0.24483\n",
            "[600]\ttrain-logloss:0.21370\tvalid-logloss:0.22503\n",
            "[900]\ttrain-logloss:0.20504\tvalid-logloss:0.22068\n",
            "[1200]\ttrain-logloss:0.19925\tvalid-logloss:0.21868\n",
            "[1500]\ttrain-logloss:0.19446\tvalid-logloss:0.21757\n",
            "[1800]\ttrain-logloss:0.19024\tvalid-logloss:0.21686\n",
            "[2100]\ttrain-logloss:0.18641\tvalid-logloss:0.21641\n",
            "[2400]\ttrain-logloss:0.18280\tvalid-logloss:0.21607\n",
            "[2700]\ttrain-logloss:0.17925\tvalid-logloss:0.21585\n",
            "[3000]\ttrain-logloss:0.17594\tvalid-logloss:0.21567\n",
            "[3300]\ttrain-logloss:0.17269\tvalid-logloss:0.21550\n",
            "[3600]\ttrain-logloss:0.16958\tvalid-logloss:0.21543\n",
            "[3900]\ttrain-logloss:0.16645\tvalid-logloss:0.21533\n",
            "[4200]\ttrain-logloss:0.16356\tvalid-logloss:0.21529\n",
            "[4500]\ttrain-logloss:0.16069\tvalid-logloss:0.21520\n",
            "[4621]\ttrain-logloss:0.15959\tvalid-logloss:0.21521\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-02 08:47:58,796]\u001b[0m Trial 83 finished with value: 0.793873048481733 and parameters: {'lambda': 0.67924507351022, 'alpha': 0.1558271813400051, 'colsample_bytree': 0.9, 'subsample': 0.6, 'learning_rate': 0.01, 'max_depth': 7, 'min_child_weight': 46}. Best is trial 54 with value: 0.7958030742195551.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[08:48:12] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68641\tvalid-logloss:0.68646\n",
            "[300]\ttrain-logloss:0.23542\tvalid-logloss:0.24344\n",
            "[600]\ttrain-logloss:0.21181\tvalid-logloss:0.22439\n",
            "[900]\ttrain-logloss:0.20380\tvalid-logloss:0.22032\n",
            "[1200]\ttrain-logloss:0.19824\tvalid-logloss:0.21840\n",
            "[1500]\ttrain-logloss:0.19365\tvalid-logloss:0.21736\n",
            "[1800]\ttrain-logloss:0.18971\tvalid-logloss:0.21676\n",
            "[2100]\ttrain-logloss:0.18601\tvalid-logloss:0.21638\n",
            "[2400]\ttrain-logloss:0.18254\tvalid-logloss:0.21609\n",
            "[2700]\ttrain-logloss:0.17910\tvalid-logloss:0.21585\n",
            "[3000]\ttrain-logloss:0.17593\tvalid-logloss:0.21566\n",
            "[3300]\ttrain-logloss:0.17282\tvalid-logloss:0.21553\n",
            "[3600]\ttrain-logloss:0.16975\tvalid-logloss:0.21543\n",
            "[3900]\ttrain-logloss:0.16678\tvalid-logloss:0.21536\n",
            "[4200]\ttrain-logloss:0.16386\tvalid-logloss:0.21531\n",
            "[4500]\ttrain-logloss:0.16113\tvalid-logloss:0.21528\n",
            "[4553]\ttrain-logloss:0.16062\tvalid-logloss:0.21527\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-02 08:58:32,533]\u001b[0m Trial 84 finished with value: 0.7943517151955926 and parameters: {'lambda': 0.21571329464483008, 'alpha': 0.1018527739834428, 'colsample_bytree': 0.8, 'subsample': 0.7, 'learning_rate': 0.01, 'max_depth': 8, 'min_child_weight': 93}. Best is trial 54 with value: 0.7958030742195551.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[08:58:46] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68640\tvalid-logloss:0.68646\n",
            "[300]\ttrain-logloss:0.23187\tvalid-logloss:0.24213\n",
            "[600]\ttrain-logloss:0.20657\tvalid-logloss:0.22326\n",
            "[900]\ttrain-logloss:0.19693\tvalid-logloss:0.21946\n",
            "[1200]\ttrain-logloss:0.18994\tvalid-logloss:0.21781\n",
            "[1500]\ttrain-logloss:0.18411\tvalid-logloss:0.21687\n",
            "[1800]\ttrain-logloss:0.17890\tvalid-logloss:0.21630\n",
            "[2100]\ttrain-logloss:0.17392\tvalid-logloss:0.21596\n",
            "[2400]\ttrain-logloss:0.16931\tvalid-logloss:0.21569\n",
            "[2700]\ttrain-logloss:0.16468\tvalid-logloss:0.21552\n",
            "[3000]\ttrain-logloss:0.16048\tvalid-logloss:0.21542\n",
            "[3300]\ttrain-logloss:0.15637\tvalid-logloss:0.21530\n",
            "[3476]\ttrain-logloss:0.15399\tvalid-logloss:0.21530\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-02 09:07:56,926]\u001b[0m Trial 85 finished with value: 0.7937017878829595 and parameters: {'lambda': 0.08700260866961994, 'alpha': 0.2520673624953346, 'colsample_bytree': 0.9, 'subsample': 0.6, 'learning_rate': 0.01, 'max_depth': 8, 'min_child_weight': 37}. Best is trial 54 with value: 0.7958030742195551.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[09:08:10] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68643\tvalid-logloss:0.68648\n",
            "[300]\ttrain-logloss:0.23501\tvalid-logloss:0.24319\n",
            "[600]\ttrain-logloss:0.21119\tvalid-logloss:0.22413\n",
            "[900]\ttrain-logloss:0.20292\tvalid-logloss:0.22015\n",
            "[1200]\ttrain-logloss:0.19714\tvalid-logloss:0.21828\n",
            "[1500]\ttrain-logloss:0.19234\tvalid-logloss:0.21727\n",
            "[1800]\ttrain-logloss:0.18803\tvalid-logloss:0.21665\n",
            "[2100]\ttrain-logloss:0.18397\tvalid-logloss:0.21628\n",
            "[2400]\ttrain-logloss:0.18024\tvalid-logloss:0.21594\n",
            "[2700]\ttrain-logloss:0.17645\tvalid-logloss:0.21569\n",
            "[3000]\ttrain-logloss:0.17299\tvalid-logloss:0.21557\n",
            "[3300]\ttrain-logloss:0.16949\tvalid-logloss:0.21540\n",
            "[3600]\ttrain-logloss:0.16603\tvalid-logloss:0.21530\n",
            "[3900]\ttrain-logloss:0.16269\tvalid-logloss:0.21522\n",
            "[3958]\ttrain-logloss:0.16208\tvalid-logloss:0.21522\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-02 09:17:52,595]\u001b[0m Trial 86 finished with value: 0.795529168285753 and parameters: {'lambda': 0.11787158920847005, 'alpha': 0.6271836419872412, 'colsample_bytree': 0.9, 'subsample': 0.6, 'learning_rate': 0.01, 'max_depth': 8, 'min_child_weight': 73}. Best is trial 54 with value: 0.7958030742195551.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[09:18:06] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68312\tvalid-logloss:0.68318\n",
            "[300]\ttrain-logloss:0.21979\tvalid-logloss:0.22979\n",
            "[600]\ttrain-logloss:0.20243\tvalid-logloss:0.22036\n",
            "[900]\ttrain-logloss:0.19261\tvalid-logloss:0.21795\n",
            "[1200]\ttrain-logloss:0.18476\tvalid-logloss:0.21682\n",
            "[1500]\ttrain-logloss:0.17765\tvalid-logloss:0.21628\n",
            "[1800]\ttrain-logloss:0.17101\tvalid-logloss:0.21599\n",
            "[2100]\ttrain-logloss:0.16477\tvalid-logloss:0.21580\n",
            "[2400]\ttrain-logloss:0.15898\tvalid-logloss:0.21567\n",
            "[2526]\ttrain-logloss:0.15662\tvalid-logloss:0.21566\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-02 09:23:51,375]\u001b[0m Trial 87 finished with value: 0.7956139159910147 and parameters: {'lambda': 0.12676520338802238, 'alpha': 1.1727375757399146, 'colsample_bytree': 0.8, 'subsample': 0.5, 'learning_rate': 0.015, 'max_depth': 7, 'min_child_weight': 20}. Best is trial 54 with value: 0.7958030742195551.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[09:24:04] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.67990\tvalid-logloss:0.67998\n",
            "[300]\ttrain-logloss:0.21266\tvalid-logloss:0.22515\n",
            "[600]\ttrain-logloss:0.19606\tvalid-logloss:0.21896\n",
            "[900]\ttrain-logloss:0.18486\tvalid-logloss:0.21722\n",
            "[1200]\ttrain-logloss:0.17521\tvalid-logloss:0.21642\n",
            "[1500]\ttrain-logloss:0.16621\tvalid-logloss:0.21611\n",
            "[1800]\ttrain-logloss:0.15775\tvalid-logloss:0.21601\n",
            "[1985]\ttrain-logloss:0.15260\tvalid-logloss:0.21602\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-02 09:28:53,608]\u001b[0m Trial 88 finished with value: 0.7937373780868653 and parameters: {'lambda': 7.5971571202717865, 'alpha': 1.0347335608739487, 'colsample_bytree': 0.8, 'subsample': 0.5, 'learning_rate': 0.02, 'max_depth': 7, 'min_child_weight': 13}. Best is trial 54 with value: 0.7958030742195551.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[09:29:07] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.67330\tvalid-logloss:0.67340\n",
            "[300]\ttrain-logloss:0.20435\tvalid-logloss:0.22083\n",
            "[600]\ttrain-logloss:0.18774\tvalid-logloss:0.21729\n",
            "[900]\ttrain-logloss:0.17463\tvalid-logloss:0.21652\n",
            "[1091]\ttrain-logloss:0.16709\tvalid-logloss:0.21647\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-02 09:31:38,815]\u001b[0m Trial 89 finished with value: 0.7926880089857984 and parameters: {'lambda': 0.10860907825432672, 'alpha': 2.500659901551825, 'colsample_bytree': 0.8, 'subsample': 0.5, 'learning_rate': 0.03, 'max_depth': 7, 'min_child_weight': 26}. Best is trial 54 with value: 0.7958030742195551.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[09:31:52] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.67982\tvalid-logloss:0.67988\n",
            "[300]\ttrain-logloss:0.21376\tvalid-logloss:0.22467\n",
            "[600]\ttrain-logloss:0.20127\tvalid-logloss:0.21883\n",
            "[900]\ttrain-logloss:0.19332\tvalid-logloss:0.21711\n",
            "[1200]\ttrain-logloss:0.18657\tvalid-logloss:0.21646\n",
            "[1500]\ttrain-logloss:0.18042\tvalid-logloss:0.21608\n",
            "[1800]\ttrain-logloss:0.17466\tvalid-logloss:0.21595\n",
            "[2100]\ttrain-logloss:0.16911\tvalid-logloss:0.21587\n",
            "[2197]\ttrain-logloss:0.16734\tvalid-logloss:0.21590\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-02 09:37:04,542]\u001b[0m Trial 90 finished with value: 0.7937350755257463 and parameters: {'lambda': 0.06452324479819649, 'alpha': 0.67861212483995, 'colsample_bytree': 0.7, 'subsample': 0.7, 'learning_rate': 0.02, 'max_depth': 9, 'min_child_weight': 162}. Best is trial 54 with value: 0.7958030742195551.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[09:37:18] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68300\tvalid-logloss:0.68310\n",
            "[300]\ttrain-logloss:0.21198\tvalid-logloss:0.22768\n",
            "[600]\ttrain-logloss:0.19259\tvalid-logloss:0.21931\n",
            "[900]\ttrain-logloss:0.18081\tvalid-logloss:0.21725\n",
            "[1200]\ttrain-logloss:0.17102\tvalid-logloss:0.21629\n",
            "[1500]\ttrain-logloss:0.16266\tvalid-logloss:0.21588\n",
            "[1800]\ttrain-logloss:0.15483\tvalid-logloss:0.21569\n",
            "[2034]\ttrain-logloss:0.14910\tvalid-logloss:0.21561\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-02 09:42:58,369]\u001b[0m Trial 91 finished with value: 0.7947868506650071 and parameters: {'lambda': 0.12566559982588058, 'alpha': 0.4546138506958577, 'colsample_bytree': 0.8, 'subsample': 0.6, 'learning_rate': 0.015, 'max_depth': 8, 'min_child_weight': 21}. Best is trial 54 with value: 0.7958030742195551.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[09:43:12] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68642\tvalid-logloss:0.68647\n",
            "[300]\ttrain-logloss:0.23373\tvalid-logloss:0.24268\n",
            "[600]\ttrain-logloss:0.20940\tvalid-logloss:0.22378\n",
            "[900]\ttrain-logloss:0.20060\tvalid-logloss:0.21990\n",
            "[1200]\ttrain-logloss:0.19435\tvalid-logloss:0.21810\n",
            "[1500]\ttrain-logloss:0.18921\tvalid-logloss:0.21711\n",
            "[1800]\ttrain-logloss:0.18445\tvalid-logloss:0.21653\n",
            "[2100]\ttrain-logloss:0.18013\tvalid-logloss:0.21614\n",
            "[2400]\ttrain-logloss:0.17597\tvalid-logloss:0.21589\n",
            "[2700]\ttrain-logloss:0.17180\tvalid-logloss:0.21566\n",
            "[3000]\ttrain-logloss:0.16798\tvalid-logloss:0.21557\n",
            "[3300]\ttrain-logloss:0.16421\tvalid-logloss:0.21539\n",
            "[3433]\ttrain-logloss:0.16255\tvalid-logloss:0.21539\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-02 09:51:58,587]\u001b[0m Trial 92 finished with value: 0.7952054827421116 and parameters: {'lambda': 0.15287082413857184, 'alpha': 0.5953668298104179, 'colsample_bytree': 0.9, 'subsample': 0.6, 'learning_rate': 0.01, 'max_depth': 8, 'min_child_weight': 56}. Best is trial 54 with value: 0.7958030742195551.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[09:52:12] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68306\tvalid-logloss:0.68314\n",
            "[300]\ttrain-logloss:0.21797\tvalid-logloss:0.22867\n",
            "[600]\ttrain-logloss:0.20244\tvalid-logloss:0.21995\n",
            "[900]\ttrain-logloss:0.19390\tvalid-logloss:0.21767\n",
            "[1200]\ttrain-logloss:0.18711\tvalid-logloss:0.21666\n",
            "[1500]\ttrain-logloss:0.18080\tvalid-logloss:0.21615\n",
            "[1800]\ttrain-logloss:0.17478\tvalid-logloss:0.21588\n",
            "[2100]\ttrain-logloss:0.16920\tvalid-logloss:0.21568\n",
            "[2400]\ttrain-logloss:0.16392\tvalid-logloss:0.21558\n",
            "[2700]\ttrain-logloss:0.15891\tvalid-logloss:0.21551\n",
            "[2751]\ttrain-logloss:0.15801\tvalid-logloss:0.21549\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-02 09:58:51,846]\u001b[0m Trial 93 finished with value: 0.7944406771016835 and parameters: {'lambda': 0.17794084949407385, 'alpha': 0.5361068863880656, 'colsample_bytree': 0.8, 'subsample': 0.5, 'learning_rate': 0.015, 'max_depth': 8, 'min_child_weight': 55}. Best is trial 54 with value: 0.7958030742195551.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[09:59:05] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68664\tvalid-logloss:0.68665\n",
            "[300]\ttrain-logloss:0.24888\tvalid-logloss:0.25226\n",
            "[600]\ttrain-logloss:0.22374\tvalid-logloss:0.22974\n",
            "[900]\ttrain-logloss:0.21541\tvalid-logloss:0.22419\n",
            "[1200]\ttrain-logloss:0.21008\tvalid-logloss:0.22142\n",
            "[1500]\ttrain-logloss:0.20585\tvalid-logloss:0.21979\n",
            "[1800]\ttrain-logloss:0.20237\tvalid-logloss:0.21876\n",
            "[2100]\ttrain-logloss:0.19917\tvalid-logloss:0.21802\n",
            "[2400]\ttrain-logloss:0.19622\tvalid-logloss:0.21747\n",
            "[2700]\ttrain-logloss:0.19348\tvalid-logloss:0.21704\n",
            "[3000]\ttrain-logloss:0.19086\tvalid-logloss:0.21671\n",
            "[3300]\ttrain-logloss:0.18841\tvalid-logloss:0.21648\n",
            "[3600]\ttrain-logloss:0.18601\tvalid-logloss:0.21629\n",
            "[3900]\ttrain-logloss:0.18365\tvalid-logloss:0.21613\n",
            "[4200]\ttrain-logloss:0.18136\tvalid-logloss:0.21600\n",
            "[4500]\ttrain-logloss:0.17916\tvalid-logloss:0.21589\n",
            "[4800]\ttrain-logloss:0.17700\tvalid-logloss:0.21579\n",
            "[5100]\ttrain-logloss:0.17489\tvalid-logloss:0.21575\n",
            "[5400]\ttrain-logloss:0.17277\tvalid-logloss:0.21567\n",
            "[5700]\ttrain-logloss:0.17069\tvalid-logloss:0.21560\n",
            "[6000]\ttrain-logloss:0.16866\tvalid-logloss:0.21553\n",
            "[6300]\ttrain-logloss:0.16666\tvalid-logloss:0.21548\n",
            "[6317]\ttrain-logloss:0.16654\tvalid-logloss:0.21547\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-02 10:09:01,417]\u001b[0m Trial 94 finished with value: 0.7932024493803744 and parameters: {'lambda': 0.2791679310902473, 'alpha': 1.1571560594598127, 'colsample_bytree': 0.9, 'subsample': 0.7, 'learning_rate': 0.01, 'max_depth': 5, 'min_child_weight': 7}. Best is trial 54 with value: 0.7958030742195551.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[10:09:14] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68314\tvalid-logloss:0.68321\n",
            "[300]\ttrain-logloss:0.22028\tvalid-logloss:0.23012\n",
            "[600]\ttrain-logloss:0.20333\tvalid-logloss:0.22071\n",
            "[900]\ttrain-logloss:0.19434\tvalid-logloss:0.21818\n",
            "[1200]\ttrain-logloss:0.18708\tvalid-logloss:0.21712\n",
            "[1500]\ttrain-logloss:0.18070\tvalid-logloss:0.21647\n",
            "[1800]\ttrain-logloss:0.17475\tvalid-logloss:0.21606\n",
            "[2100]\ttrain-logloss:0.16918\tvalid-logloss:0.21583\n",
            "[2400]\ttrain-logloss:0.16383\tvalid-logloss:0.21563\n",
            "[2700]\ttrain-logloss:0.15857\tvalid-logloss:0.21559\n",
            "[2711]\ttrain-logloss:0.15841\tvalid-logloss:0.21558\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-02 10:15:31,316]\u001b[0m Trial 95 finished with value: 0.7939654142595685 and parameters: {'lambda': 0.1057512260920983, 'alpha': 0.7767509066831247, 'colsample_bytree': 1.0, 'subsample': 0.6, 'learning_rate': 0.015, 'max_depth': 7, 'min_child_weight': 33}. Best is trial 54 with value: 0.7958030742195551.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[10:15:45] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68639\tvalid-logloss:0.68645\n",
            "[300]\ttrain-logloss:0.23353\tvalid-logloss:0.24241\n",
            "[600]\ttrain-logloss:0.20939\tvalid-logloss:0.22353\n",
            "[900]\ttrain-logloss:0.20063\tvalid-logloss:0.21970\n",
            "[1200]\ttrain-logloss:0.19418\tvalid-logloss:0.21793\n",
            "[1500]\ttrain-logloss:0.18885\tvalid-logloss:0.21705\n",
            "[1800]\ttrain-logloss:0.18400\tvalid-logloss:0.21648\n",
            "[2100]\ttrain-logloss:0.17946\tvalid-logloss:0.21613\n",
            "[2400]\ttrain-logloss:0.17522\tvalid-logloss:0.21586\n",
            "[2700]\ttrain-logloss:0.17116\tvalid-logloss:0.21565\n",
            "[3000]\ttrain-logloss:0.16728\tvalid-logloss:0.21552\n",
            "[3300]\ttrain-logloss:0.16352\tvalid-logloss:0.21544\n",
            "[3493]\ttrain-logloss:0.16114\tvalid-logloss:0.21544\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-02 10:24:23,936]\u001b[0m Trial 96 finished with value: 0.7954977825343013 and parameters: {'lambda': 0.05077724941024801, 'alpha': 0.3718802065551599, 'colsample_bytree': 0.8, 'subsample': 0.5, 'learning_rate': 0.01, 'max_depth': 8, 'min_child_weight': 45}. Best is trial 54 with value: 0.7958030742195551.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[10:24:37] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68641\tvalid-logloss:0.68646\n",
            "[300]\ttrain-logloss:0.23275\tvalid-logloss:0.24209\n",
            "[600]\ttrain-logloss:0.20873\tvalid-logloss:0.22333\n",
            "[900]\ttrain-logloss:0.20006\tvalid-logloss:0.21956\n",
            "[1200]\ttrain-logloss:0.19368\tvalid-logloss:0.21788\n",
            "[1500]\ttrain-logloss:0.18815\tvalid-logloss:0.21701\n",
            "[1800]\ttrain-logloss:0.18305\tvalid-logloss:0.21647\n",
            "[2100]\ttrain-logloss:0.17816\tvalid-logloss:0.21614\n",
            "[2400]\ttrain-logloss:0.17363\tvalid-logloss:0.21590\n",
            "[2700]\ttrain-logloss:0.16927\tvalid-logloss:0.21571\n",
            "[3000]\ttrain-logloss:0.16507\tvalid-logloss:0.21560\n",
            "[3300]\ttrain-logloss:0.16101\tvalid-logloss:0.21554\n",
            "[3600]\ttrain-logloss:0.15703\tvalid-logloss:0.21549\n",
            "[3668]\ttrain-logloss:0.15615\tvalid-logloss:0.21551\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-02 10:34:48,505]\u001b[0m Trial 97 finished with value: 0.7943633609137941 and parameters: {'lambda': 0.039981404693139884, 'alpha': 1.6392574174062933, 'colsample_bytree': 0.8, 'subsample': 0.5, 'learning_rate': 0.01, 'max_depth': 9, 'min_child_weight': 65}. Best is trial 54 with value: 0.7958030742195551.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[10:35:02] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68654\tvalid-logloss:0.68657\n",
            "[300]\ttrain-logloss:0.24363\tvalid-logloss:0.24790\n",
            "[600]\ttrain-logloss:0.21985\tvalid-logloss:0.22699\n",
            "[900]\ttrain-logloss:0.21213\tvalid-logloss:0.22213\n",
            "[1200]\ttrain-logloss:0.20710\tvalid-logloss:0.21979\n",
            "[1500]\ttrain-logloss:0.20321\tvalid-logloss:0.21851\n",
            "[1800]\ttrain-logloss:0.19985\tvalid-logloss:0.21765\n",
            "[2100]\ttrain-logloss:0.19678\tvalid-logloss:0.21713\n",
            "[2400]\ttrain-logloss:0.19400\tvalid-logloss:0.21674\n",
            "[2700]\ttrain-logloss:0.19128\tvalid-logloss:0.21641\n",
            "[3000]\ttrain-logloss:0.18879\tvalid-logloss:0.21619\n",
            "[3300]\ttrain-logloss:0.18630\tvalid-logloss:0.21601\n",
            "[3600]\ttrain-logloss:0.18393\tvalid-logloss:0.21585\n",
            "[3900]\ttrain-logloss:0.18158\tvalid-logloss:0.21569\n",
            "[4200]\ttrain-logloss:0.17924\tvalid-logloss:0.21561\n",
            "[4500]\ttrain-logloss:0.17694\tvalid-logloss:0.21550\n",
            "[4800]\ttrain-logloss:0.17474\tvalid-logloss:0.21545\n",
            "[5029]\ttrain-logloss:0.17306\tvalid-logloss:0.21542\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-02 10:43:57,017]\u001b[0m Trial 98 finished with value: 0.793799377870325 and parameters: {'lambda': 0.053327238813436074, 'alpha': 0.8970742772650048, 'colsample_bytree': 0.8, 'subsample': 0.5, 'learning_rate': 0.01, 'max_depth': 6, 'min_child_weight': 48}. Best is trial 54 with value: 0.7958030742195551.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[10:44:10] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68309\tvalid-logloss:0.68317\n",
            "[300]\ttrain-logloss:0.21727\tvalid-logloss:0.22892\n",
            "[600]\ttrain-logloss:0.20041\tvalid-logloss:0.22013\n",
            "[900]\ttrain-logloss:0.18993\tvalid-logloss:0.21769\n",
            "[1200]\ttrain-logloss:0.18149\tvalid-logloss:0.21673\n",
            "[1500]\ttrain-logloss:0.17347\tvalid-logloss:0.21619\n",
            "[1800]\ttrain-logloss:0.16579\tvalid-logloss:0.21590\n",
            "[2100]\ttrain-logloss:0.15847\tvalid-logloss:0.21576\n",
            "[2400]\ttrain-logloss:0.15178\tvalid-logloss:0.21566\n",
            "[2421]\ttrain-logloss:0.15130\tvalid-logloss:0.21566\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-02 10:50:44,955]\u001b[0m Trial 99 finished with value: 0.7948306866081809 and parameters: {'lambda': 0.0812614850377249, 'alpha': 4.184696566828669, 'colsample_bytree': 0.7, 'subsample': 0.5, 'learning_rate': 0.015, 'max_depth': 8, 'min_child_weight': 34}. Best is trial 54 with value: 0.7958030742195551.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "{'lambda': 0.19846538518330817, 'alpha': 0.11499421368543077, 'colsample_bytree': 1.0, 'subsample': 0.6, 'learning_rate': 0.01, 'max_depth': 8, 'min_child_weight': 56}"
      ],
      "metadata": {
        "id": "ULWkEjnVYrYA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "6eumC4KYYrUn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "aFCQcar_YrR0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "AjoCYdLUYrPJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp = cudf.DataFrame({'a':[1,2,3,4], 'b':[1,2,3,4]})\n",
        "temp.groupby(['a']).size().sort_values('a')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "id": "936VIUeZDv2F",
        "outputId": "54fbe727-896f-455d-8aee-38638327a20f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NotImplementedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-fde8ff07a142>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcudf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'b'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtemp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/site-packages/cudf/core/series.py\u001b[0m in \u001b[0;36msort_values\u001b[0;34m(self, axis, ascending, inplace, kind, na_position, ignore_index)\u001b[0m\n\u001b[1;32m   1965\u001b[0m             \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1966\u001b[0m             \u001b[0mna_position\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_position\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1967\u001b[0;31m             \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1968\u001b[0m         )\n\u001b[1;32m   1969\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/site-packages/cudf/core/indexed_frame.py\u001b[0m in \u001b[0;36msort_values\u001b[0;34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index)\u001b[0m\n\u001b[1;32m    498\u001b[0m             )\n\u001b[1;32m    499\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 500\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"`axis` not currently implemented.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotImplementedError\u001b[0m: `axis` not currently implemented."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "U3eaLtOJDvsS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def number_of_obs(df):\n",
        "  df_presence = df.groupby(['customer_ID']).size().reset_index().rename(columns={0:'number_of_observations'})\n",
        "  df = df.merge(df_presence, on='customer_ID', how = 'left')\n",
        "  df.loc[df['B_33'].isnull() & (df.number_of_observations==1),'number_of_observations'] = 0.5\n",
        "  df_presence_agg = df.groupby(\"customer_ID\")['number_of_observations'].agg(['last'])\n",
        "  df_presence_agg.columns = ['_'.join(x) for x in df_presence_agg.columns]\n",
        "  gc.collect()\n",
        "  return df"
      ],
      "metadata": {
        "id": "vfZgVBfc_jnH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = number_of_obs(train)"
      ],
      "metadata": {
        "id": "WPtVqRV3_jiv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def revertnan(df):\n",
        "  df = df.to_pandas()\n",
        "  df[df==-1] = np.nan \n",
        "  df = cudf.from_pandas(df)\n",
        "  return df"
      ],
      "metadata": {
        "id": "sP2rNYR7Bk4E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = revertnan(train)"
      ],
      "metadata": {
        "id": "c3HZWgwWJjxA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dummy_nan(df):\n",
        "\n",
        "  all_cols = [c for c in list(train.columns) if c not in ['customer_ID','S_2']]\n",
        "  cat_features = [\"B_30\",\"B_38\",\"D_114\",\"D_116\",\"D_117\",\"D_120\",\"D_126\",\"D_63\",\"D_64\",\"D_66\",\"D_68\"]\n",
        "  num_features = [col for col in all_cols if col not in cat_features]\n",
        "\n",
        "  nullvals = df.isnull().sum() / df.shape[0]\n",
        "\n",
        "  #keep only last für nan >90%\n",
        "  exclnullCols = nullvals[nullvals>0.9].index.to_arrow().to_pylist()\n",
        "\n",
        "    \n",
        "  #exclude nan>90% from aggregating functions\n",
        "  num_features = [col for col in num_features if col not in exclnullCols]\n",
        "  cat_features = [col for col in cat_features if col not in exclnullCols]\n",
        "\n",
        "  #dummy for 30% nan values\n",
        "  nullCols = nullvals[nullvals>0.3].index.to_arrow().to_pylist()\n",
        "  dummy_nan_col = [] \n",
        "  for col in nullCols:\n",
        "    df[col+'_null'] = df[col].isnull().astype(int)\n",
        "    dummy_nan_col.append(col+'_null')\n",
        "  return df, num_features, cat_features, all_cols, exclnullCols, dummy_nan_col"
      ],
      "metadata": {
        "id": "YLUsSs4J_jdX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train, num_features, cat_features, all_cols, exclnullCols, dummy_nan_col = dummy_nan(train)"
      ],
      "metadata": {
        "id": "76t2W_vs_jaG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_features = [num_features, cat_features, all_cols, exclnullCols, dummy_nan_col]"
      ],
      "metadata": {
        "id": "8tl-jSo9ujHg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# write feautures to file\n",
        "with open('/content/drive/MyDrive/Amex/parquet/XGB v3/features.csv', 'w') as f: \n",
        "    write = csv.writer(f)\n",
        "    write.writerows(list_features) \n",
        "\n"
      ],
      "metadata": {
        "id": "syoDXeWXmgk7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#read features from filw\n",
        "import csv\n",
        "\n",
        "#file = open('/content/drive/MyDrive/Amex/parquet/XGB v3/features.csv', 'r')\n",
        "\n",
        "\n",
        "with open('/content/drive/MyDrive/Amex/parquet/XGB v3/features.csv') as file_obj:\n",
        "    reader = csv.reader(file_obj)\n",
        "    feature_all = list(reader)\n",
        "\n",
        "num_features = feature_all[0]\n",
        "cat_features = feature_all[1]\n",
        "all_cols = feature_all[2]\n",
        "exclnullCols = feature_all[3]\n",
        "dummy_nan_col = feature_all[4]"
      ],
      "metadata": {
        "id": "3p8urP48q4q_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def addS2m(df):\n",
        "  df_S2min = df[['S_2','customer_ID']].groupby('customer_ID')['S_2'].agg(['min']).rename(columns={'min':'S_2_min'})\n",
        "  df = df.merge(df_S2min, on='customer_ID', how = 'left')\n",
        "  df['S_2_m'] = (df['S_2']-df['S_2_min']).dt.days.astype(int)\n",
        "  return df\n"
      ],
      "metadata": {
        "id": "GibxOrsn3LfO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = addS2m(train)"
      ],
      "metadata": {
        "id": "YO98PsIo3LcB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.drop('S_2_min', axis = 1, inplace = True)"
      ],
      "metadata": {
        "id": "gbHieBLm4RN8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gc.collect()"
      ],
      "metadata": {
        "id": "GZhzzdAGbQAH",
        "outputId": "ccdefec3-e3be-497a-ee8a-9d81b6a06c7c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1436"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def bfillffill(df):\n",
        "  for i in df.columns:\n",
        "    df.loc[df['number_of_observations']>=10, i] = df[df['number_of_observations']>=10].sort_values(by =['S_2_m'], ascending = [True]).groupby('customer_ID')[i].apply(lambda x: x.bfill().ffill())\n",
        "  return df"
      ],
      "metadata": {
        "id": "wThkjf7LDHmV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = train.to_pandas()"
      ],
      "metadata": {
        "id": "VqGkdjlp8LMm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = bfillffill(train)\n",
        "train.to_parquet('/content/drive/MyDrive/Amex/parquet/XGB v3/train_fe_v3.parquet')"
      ],
      "metadata": {
        "id": "BZ0fH826E9xO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = cudf.read_parquet('/content/drive/MyDrive/Amex/parquet/XGB v3/train_fe_v3.parquet')"
      ],
      "metadata": {
        "id": "SybjWvfOVse3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def afterpay(df):\n",
        "  # compute \"after pay\" features\n",
        "  for bcol in [f'B_{i}' for i in [11,14,17]]+['D_39','D_131']+[f'S_{i}' for i in [16,23]]:\n",
        "    for pcol in ['P_2','P_3']:\n",
        "      if bcol in df.columns:\n",
        "        df[f'{bcol}-{pcol}'] = df[bcol] - df[pcol]\n",
        "  return df"
      ],
      "metadata": {
        "id": "Vgc6rhzMVsbl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def afterpay_num_features(df, num_features):\n",
        "  # compute \"after pay\" features\n",
        "  for bcol in [f'B_{i}' for i in [11,14,17]]+['D_39','D_131']+[f'S_{i}' for i in [16,23]]:\n",
        "    for pcol in ['P_2','P_3']:\n",
        "      if bcol in df.columns:\n",
        "        nf = f'{bcol}-{pcol}'\n",
        "        num_features.append(nf)\n",
        "  return num_features"
      ],
      "metadata": {
        "id": "Gorp0rAJ7LDN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = afterpay(train)"
      ],
      "metadata": {
        "id": "KF5uVbhfVsYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_features = afterpay_num_features(train, num_features)"
      ],
      "metadata": {
        "id": "EhJUKqM5VsJ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = agg_functions(train, num_features, cat_features, exclnullCols, dummy_nan_col)"
      ],
      "metadata": {
        "id": "XPij5v6j8Ar0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.info(verbose=True)"
      ],
      "metadata": {
        "id": "CI3hiCTgkUh7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_growth(df, num_features):\n",
        "  \n",
        "  df.columns = ['_'.join(x) for x in df.columns]\n",
        "  df.drop(['number_of_observations_min', 'number_of_observations_std', 'number_of_observations_max', 'number_of_observations_mean', 'number_of_observations_first'], axis = 1, inplace = True)\n",
        "  df.rename(columns={'number_of_observations_last': 'number_of_observations'}, inplace = True)\n",
        "  \n",
        "  for i in [f for f in num_features if f not in ['number_of_observations']]:\n",
        "    first = f'{i}_first'\n",
        "    last = f'{i}_last'\n",
        "    diff = df[last] - df[first]\n",
        "    df[f'{i}_pctchange'] = np.nan\n",
        "    df.loc[(df[last]<0) & (df[first]<0) & ((df[last] - df[first]) > 0), f'{i}_pctchange'] = ((df[last] - df[first])/df[first])*-1*100/df['number_of_observations']\n",
        "    df.loc[(df[last]<0) & (df[first]<0) & ((df[last] - df[first]) < 0), f'{i}_pctchange'] = ((df[last] - df[first])/df[first])*-1*100/df['number_of_observations']\n",
        "    df.loc[(df[last]>0) & (df[first]<0), f'{i}_pctchange'] = (diff/df[first])*-1*100/df['number_of_observations']\n",
        "    df.loc[(df[last]<0) & (df[first]>0), f'{i}_pctchange'] = (diff/df[first])*100/df['number_of_observations']\n",
        "    df.loc[(df[last]>0) & (df[first]>0), f'{i}_pctchange'] = (diff/df[first])*100/df['number_of_observations']\n",
        "    df.loc[(df[last]==0) & (df[first]>0), f'{i}_pctchange'] = (diff/df[first])*100/df['number_of_observations']\n",
        "    df.loc[(df[last]==0) & (df[first]<0), f'{i}_pctchange'] = (diff/df[first])*-1*100/df['number_of_observations']\n",
        "    df.loc[(df[last]<0) & (df[first]==0), f'{i}_pctchange'] = 100/df['number_of_observations']\n",
        "    df.loc[(df[last]>0) & (df[first]==0), f'{i}_pctchange'] = -100/df['number_of_observations']\n",
        "\n",
        "  return df"
      ],
      "metadata": {
        "id": "3vh4oO57CTtn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = train.to_pandas()"
      ],
      "metadata": {
        "id": "II0vtv8qQ0MU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = add_growth(train, num_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Coq_MWLLCTq9",
        "outputId": "4272aa03-b159-42db-d8dc-8aac41fabe45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def dropfirst(df):\n",
        "  droplist = list(df.loc[:, df.columns.str.contains('first')].columns)\n",
        "  df.drop(droplist, axis = 1, inplace = True)\n",
        "  return df\n"
      ],
      "metadata": {
        "id": "8zkgCQ2uewqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = dropfirst(train)"
      ],
      "metadata": {
        "id": "BKT-QDfVffCZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pS4i30P5ewhA",
        "outputId": "d2102ab3-5a05-4c7b-a3a8-36c48d8e69ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hzmlqlmrdxgm"
      },
      "outputs": [],
      "source": [
        "train.to_parquet('/content/drive/MyDrive/Amex/parquet/XGB_norevnan/train_fe_v6_pretarget.parquet')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_parquet('/content/drive/MyDrive/Amex/parquet/XGB_norevnan/train_fe_v6_pretarget.parquet')"
      ],
      "metadata": {
        "id": "ZwxN1SMBIQ6f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5EPlkwdMp0N9"
      },
      "outputs": [],
      "source": [
        "# ADD TARGETS\n",
        "def add_targets(df):\n",
        "  targets = cudf.read_csv('train_labels.csv')\n",
        "  targets['customer_ID'] = targets['customer_ID'].str[-16:].str.hex_to_int().astype('int64')\n",
        "  targets = targets.to_pandas()\n",
        "  targets = targets.set_index('customer_ID')\n",
        "  df = df.merge(targets, on='customer_ID', how='left')\n",
        "  df.target = df.target.astype('int8')\n",
        "  del targets\n",
        "  # NEEDED TO MAKE CV DETERMINISTIC (cudf merge above randomly shuffles rows)\n",
        "  df = df.sort_index().reset_index()\n",
        "  return df\n",
        "\n",
        "train = train.to_pandas()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = add_targets(train)\n",
        "\n",
        "\n",
        "# FEATURES\n",
        "#FEATURES_all = train.columns[1:-1]\n",
        "print(f'There are {len(train.columns[1:-1])} features!')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qte4HcW61r1y",
        "outputId": "9dd3b205-7fc5-4c44-de2b-18c8464bc208"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/site-packages/pandas/core/frame.py:9203: FutureWarning: merging between different levels is deprecated and will be removed in a future version. (2 levels on the left,1 on the right)\n",
            "  validate=validate,\n",
            "/usr/local/lib/python3.7/site-packages/pandas/core/reshape/merge.py:121: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  return op.get_result()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1145 features!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train.to_parquet('/content/drive/MyDrive/Amex/parquet/XGB v3/train_fe_v6_posttarget.parquet')"
      ],
      "metadata": {
        "id": "wd5QGfJDNqab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_parquet('/content/drive/MyDrive/Amex/parquet/XGB v3/train_fe_v6_posttarget.parquet')"
      ],
      "metadata": {
        "id": "8UuFEJu-TmqS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adT_2FvOaegR",
        "outputId": "9c889872-cc87-482f-e1e8-e16cc11afa61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "88"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ylpeKGjuaedH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##############Optuna"
      ],
      "metadata": {
        "id": "zjJBOeLzTmnd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "FEATURES = train.columns[1:-1]"
      ],
      "metadata": {
        "id": "jbnU89cyTmiP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4XoB5SicTmZh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "id": "7l42EHH3NqXz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "from sklearn.model_selection import KFold\n",
        "import xgboost as xgb"
      ],
      "metadata": {
        "id": "-h8k9uftTe61"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def amex_metric_mod(y_true, y_pred):\n",
        "\n",
        "    labels     = np.transpose(np.array([y_true, y_pred]))\n",
        "    labels     = labels[labels[:, 1].argsort()[::-1]]\n",
        "    weights    = np.where(labels[:,0]==0, 20, 1)\n",
        "    cut_vals   = labels[np.cumsum(weights) <= int(0.04 * np.sum(weights))]\n",
        "    top_four   = np.sum(cut_vals[:,0]) / np.sum(labels[:,0])\n",
        "\n",
        "    gini = [0,0]\n",
        "    for i in [1,0]:\n",
        "        labels         = np.transpose(np.array([y_true, y_pred]))\n",
        "        labels         = labels[labels[:, i].argsort()[::-1]]\n",
        "        weight         = np.where(labels[:,0]==0, 20, 1)\n",
        "        weight_random  = np.cumsum(weight / np.sum(weight))\n",
        "        total_pos      = np.sum(labels[:, 0] *  weight)\n",
        "        cum_pos_found  = np.cumsum(labels[:, 0] * weight)\n",
        "        lorentz        = cum_pos_found / total_pos\n",
        "        gini[i]        = np.sum((lorentz - weight_random) * weight)\n",
        "\n",
        "    return 0.5 * (gini[1]/gini[0] + top_four)"
      ],
      "metadata": {
        "id": "EYb2LRWMTe2l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NEEDED WITH DeviceQuantileDMatrix BELOW\n",
        "class IterLoadForDMatrix(xgb.core.DataIter):\n",
        "    def __init__(self, df=None, features=None, target=None, batch_size=256*1024):\n",
        "        self.features = features\n",
        "        self.target = target\n",
        "        self.df = df\n",
        "        self.it = 0 # set iterator to 0\n",
        "        self.batch_size = batch_size\n",
        "        self.batches = int( np.ceil( len(df) / self.batch_size ) )\n",
        "        super().__init__()\n",
        "\n",
        "    def reset(self):\n",
        "        '''Reset the iterator'''\n",
        "        self.it = 0\n",
        "\n",
        "    def next(self, input_data):\n",
        "        '''Yield next batch of data.'''\n",
        "        if self.it == self.batches:\n",
        "            return 0 # Return 0 when there's no more batch.\n",
        "        \n",
        "        a = self.it * self.batch_size\n",
        "        b = min( (self.it + 1) * self.batch_size, len(self.df) )\n",
        "        dt = cudf.DataFrame(self.df.iloc[a:b])\n",
        "        input_data(data=dt[self.features], label=dt[self.target]) #, weight=dt['weight'])\n",
        "        self.it += 1\n",
        "        return 1"
      ],
      "metadata": {
        "id": "m-mOFZI6Tezf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "study.best_params"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pyrVkSTKTOCJ",
        "outputId": "592c4a3d-f987-4dd2-f70c-7b293910274e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'alpha': 5.310972242098957,\n",
              " 'colsample_bytree': 0.8,\n",
              " 'lambda': 0.28743845532511914,\n",
              " 'learning_rate': 0.008,\n",
              " 'max_depth': 6,\n",
              " 'min_child_weight': 180,\n",
              " 'n_estimators': 350,\n",
              " 'subsample': 0.8}"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###################################################END"
      ],
      "metadata": {
        "id": "7a9lEUpGTN_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "LAdI4FlN0S1h",
        "outputId": "1940accd-a17a-4711-ba7c-bbceb917b226"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           customer_ID  P_2_mean   P_2_std   P_2_max   P_2_min  P_2_last  \\\n",
              "0 -9223358381327749917  0.415868  0.057145  0.498727  0.340178  0.340178   \n",
              "1 -9223193039457028513  0.974068  0.013094  1.002478  0.964483  1.002478   \n",
              "2 -9223189665817919541  0.802447  0.038025  0.828761  0.694073  0.694073   \n",
              "3 -9223188534444851899  0.791203  0.002688  0.794826  0.786647  0.787945   \n",
              "4 -9223173911659837606  0.115666  0.078554  0.252421  0.038207  0.040486   \n",
              "\n",
              "   D_39_mean  D_39_std  D_39_max  D_39_min  ...  B_17-P_3_pctchange  \\\n",
              "0   2.615385  4.628507        16         0  ...           -3.580365   \n",
              "1   0.000000  0.000000         0         0  ...                 NaN   \n",
              "2   0.000000  0.000000         0         0  ...                 NaN   \n",
              "3   0.000000  0.000000         0         0  ...                 NaN   \n",
              "4   4.384615  6.144625        17         0  ...           -1.971803   \n",
              "\n",
              "   D_39-P_2_pctchange  D_39-P_3_pctchange  D_131-P_2_pctchange  \\\n",
              "0          190.552659          524.036584             0.675892   \n",
              "1           -0.181974           -0.497476            -0.181974   \n",
              "2            1.145043           -0.534560             1.145043   \n",
              "3            0.060692            1.783088             0.060692   \n",
              "4          564.537034          269.071045             5.952709   \n",
              "\n",
              "   D_131-P_3_pctchange  S_16-P_2_pctchange  S_16-P_3_pctchange  \\\n",
              "0            -2.470080           22.800316           10.163649   \n",
              "1            -0.497476           -0.213644           -0.560310   \n",
              "2            -0.534560            1.144989           -0.554541   \n",
              "3             1.783088            0.001919            1.738592   \n",
              "4            -2.152752            6.090257           -2.207318   \n",
              "\n",
              "   S_23-P_2_pctchange  S_23-P_3_pctchange  target  \n",
              "0           10.416552            2.722761       1  \n",
              "1           -0.192483           -0.618111       0  \n",
              "2            1.446931           -0.567667       0  \n",
              "3            0.010588            2.093982       0  \n",
              "4           71.359826            5.487043       1  \n",
              "\n",
              "[5 rows x 1160 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-503d5aa1-0483-4cf5-aa80-a5502e396e62\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>customer_ID</th>\n",
              "      <th>P_2_mean</th>\n",
              "      <th>P_2_std</th>\n",
              "      <th>P_2_max</th>\n",
              "      <th>P_2_min</th>\n",
              "      <th>P_2_last</th>\n",
              "      <th>D_39_mean</th>\n",
              "      <th>D_39_std</th>\n",
              "      <th>D_39_max</th>\n",
              "      <th>D_39_min</th>\n",
              "      <th>...</th>\n",
              "      <th>B_17-P_3_pctchange</th>\n",
              "      <th>D_39-P_2_pctchange</th>\n",
              "      <th>D_39-P_3_pctchange</th>\n",
              "      <th>D_131-P_2_pctchange</th>\n",
              "      <th>D_131-P_3_pctchange</th>\n",
              "      <th>S_16-P_2_pctchange</th>\n",
              "      <th>S_16-P_3_pctchange</th>\n",
              "      <th>S_23-P_2_pctchange</th>\n",
              "      <th>S_23-P_3_pctchange</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-9223358381327749917</td>\n",
              "      <td>0.415868</td>\n",
              "      <td>0.057145</td>\n",
              "      <td>0.498727</td>\n",
              "      <td>0.340178</td>\n",
              "      <td>0.340178</td>\n",
              "      <td>2.615385</td>\n",
              "      <td>4.628507</td>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>-3.580365</td>\n",
              "      <td>190.552659</td>\n",
              "      <td>524.036584</td>\n",
              "      <td>0.675892</td>\n",
              "      <td>-2.470080</td>\n",
              "      <td>22.800316</td>\n",
              "      <td>10.163649</td>\n",
              "      <td>10.416552</td>\n",
              "      <td>2.722761</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-9223193039457028513</td>\n",
              "      <td>0.974068</td>\n",
              "      <td>0.013094</td>\n",
              "      <td>1.002478</td>\n",
              "      <td>0.964483</td>\n",
              "      <td>1.002478</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.181974</td>\n",
              "      <td>-0.497476</td>\n",
              "      <td>-0.181974</td>\n",
              "      <td>-0.497476</td>\n",
              "      <td>-0.213644</td>\n",
              "      <td>-0.560310</td>\n",
              "      <td>-0.192483</td>\n",
              "      <td>-0.618111</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-9223189665817919541</td>\n",
              "      <td>0.802447</td>\n",
              "      <td>0.038025</td>\n",
              "      <td>0.828761</td>\n",
              "      <td>0.694073</td>\n",
              "      <td>0.694073</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.145043</td>\n",
              "      <td>-0.534560</td>\n",
              "      <td>1.145043</td>\n",
              "      <td>-0.534560</td>\n",
              "      <td>1.144989</td>\n",
              "      <td>-0.554541</td>\n",
              "      <td>1.446931</td>\n",
              "      <td>-0.567667</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-9223188534444851899</td>\n",
              "      <td>0.791203</td>\n",
              "      <td>0.002688</td>\n",
              "      <td>0.794826</td>\n",
              "      <td>0.786647</td>\n",
              "      <td>0.787945</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.060692</td>\n",
              "      <td>1.783088</td>\n",
              "      <td>0.060692</td>\n",
              "      <td>1.783088</td>\n",
              "      <td>0.001919</td>\n",
              "      <td>1.738592</td>\n",
              "      <td>0.010588</td>\n",
              "      <td>2.093982</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-9223173911659837606</td>\n",
              "      <td>0.115666</td>\n",
              "      <td>0.078554</td>\n",
              "      <td>0.252421</td>\n",
              "      <td>0.038207</td>\n",
              "      <td>0.040486</td>\n",
              "      <td>4.384615</td>\n",
              "      <td>6.144625</td>\n",
              "      <td>17</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.971803</td>\n",
              "      <td>564.537034</td>\n",
              "      <td>269.071045</td>\n",
              "      <td>5.952709</td>\n",
              "      <td>-2.152752</td>\n",
              "      <td>6.090257</td>\n",
              "      <td>-2.207318</td>\n",
              "      <td>71.359826</td>\n",
              "      <td>5.487043</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 1160 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-503d5aa1-0483-4cf5-aa80-a5502e396e62')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-503d5aa1-0483-4cf5-aa80-a5502e396e62 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-503d5aa1-0483-4cf5-aa80-a5502e396e62');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "j-kmvfG20SvN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "rqiASnl7xFVI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "mSzLp9WTxFN9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LFQyg3j3xFIx",
        "outputId": "f60d853c-4232-4032-a2d0-7252fa9b4f33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2805"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "6WK-WWzixFDW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "9Fpha6wrxFAv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "tSwJWXuRxE91"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# XGB MODEL PARAMETERS\n",
        "xgb_parms = { \n",
        "    'max_depth':4, \n",
        "    'learning_rate':0.05, \n",
        "    'subsample':0.8,\n",
        "    'colsample_bytree':0.6, \n",
        "    'eval_metric':'logloss',\n",
        "    'objective':'binary:logistic',\n",
        "    'tree_method':'gpu_hist',\n",
        "    'predictor':'gpu_predictor',\n",
        "    'random_state':SEED\n",
        "}"
      ],
      "metadata": {
        "id": "PW3hNAle0SsU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "importances = []\n",
        "oof = []\n",
        "#train = train.to_pandas() # free GPU memory\n",
        "TRAIN_SUBSAMPLE = 1.0\n",
        "gc.collect()\n",
        "\n",
        "skf = KFold(n_splits=FOLDS, shuffle=True, random_state=SEED)\n",
        "for fold,(train_idx, valid_idx) in enumerate(skf.split(\n",
        "            train, train.target )):\n",
        "    \n",
        "    # TRAIN WITH SUBSAMPLE OF TRAIN FOLD DATA\n",
        "    if TRAIN_SUBSAMPLE<1.0:\n",
        "        np.random.seed(SEED)\n",
        "        train_idx = np.random.choice(train_idx, \n",
        "                       int(len(train_idx)*TRAIN_SUBSAMPLE), replace=False)\n",
        "        np.random.seed(None)\n",
        "    \n",
        "    print('#'*25)\n",
        "    print('### Fold',fold+1)\n",
        "    print('### Train size',len(train_idx),'Valid size',len(valid_idx))\n",
        "    print(f'### Training with {int(TRAIN_SUBSAMPLE*100)}% fold data...')\n",
        "    print('#'*25)\n",
        "    \n",
        "    # TRAIN, VALID, TEST FOR FOLD K\n",
        "    Xy_train = IterLoadForDMatrix(train.loc[train_idx], FEATURES, 'target')\n",
        "    X_valid = train.loc[valid_idx, FEATURES]\n",
        "    y_valid = train.loc[valid_idx, 'target']\n",
        "    \n",
        "    dtrain = xgb.DeviceQuantileDMatrix(Xy_train, max_bin=256)\n",
        "    dvalid = xgb.DMatrix(data=X_valid, label=y_valid)\n",
        "    \n",
        "    # TRAIN MODEL FOLD K\n",
        "    model = xgb.train(xgb_parms, \n",
        "                dtrain=dtrain,\n",
        "                evals=[(dtrain,'train'),(dvalid,'valid')],\n",
        "                num_boost_round=9999,\n",
        "                early_stopping_rounds=100,\n",
        "                verbose_eval=100) \n",
        "    #model.save_model(f'XGB_v{VER}_fold{fold}.xgb')\n",
        "    \n",
        "    # GET FEATURE IMPORTANCE FOR FOLD K\n",
        "    dd = model.get_score(importance_type='weight')\n",
        "    df = pd.DataFrame({'feature':dd.keys(),f'importance_{fold}':dd.values()})\n",
        "    importances.append(df)\n",
        "            \n",
        "    # INFER OOF FOLD K\n",
        "    oof_preds = model.predict(dvalid)\n",
        "    acc = amex_metric_mod(y_valid.values, oof_preds)\n",
        "    print('Kaggle Metric =',acc,'\\n')\n",
        "    \n",
        "    # SAVE OOF\n",
        "    df = train.loc[valid_idx, ['customer_ID','target'] ].copy()\n",
        "    df['oof_pred'] = oof_preds\n",
        "    oof.append( df )\n",
        "    \n",
        "    del dtrain, Xy_train, dd, df\n",
        "    del X_valid, y_valid, dvalid, model\n",
        "    _ = gc.collect()\n",
        "    \n",
        "print('#'*25)\n",
        "oof = pd.concat(oof,axis=0,ignore_index=True).set_index('customer_ID')\n",
        "acc = amex_metric_mod(oof.target.values, oof.oof_pred.values)\n",
        "print('OVERALL CV Kaggle Metric =',acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396
        },
        "id": "e-u4aaw20Spe",
        "outputId": "d92d2cea-f2bf-4edc-885b-c57309c3609d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-84-ea451f782e2f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mnum_boost_round\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m9999\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                 \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m                 verbose_eval=100) \n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0;31m#model.save_model(f'XGB_v{VER}_fold{fold}.xgb')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m    194\u001b[0m                           \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m                           \u001b[0mmaximize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                           early_stopping_rounds=early_stopping_rounds)\n\u001b[0m\u001b[1;32m    197\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks, evals_result, maximize, verbose_eval, early_stopping_rounds)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1680\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n\u001b[1;32m   1681\u001b[0m                                                     \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1682\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m   1683\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1684\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_margin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "t7H3TDwr0Smu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Q27Bz5Bu0Sjx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train"
      ],
      "metadata": {
        "id": "PxOW0F9V0ShG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "outputId": "84188afb-c2c0-4527-968b-7f67e78d8bc4"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-3536571a9bc3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "brVd82Ln0Sec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "l2ayriSc0Sbq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "NgAPA71e0SYe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "22mriKHPstPp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "LeGeaoSLstIv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "PRDYhwufstF8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "BUTTSUOrstCx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Pq2a405Dss__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "XUxbdf-Kss9R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Ols1U1Mbss56"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "iHOYQL76xeF6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CALCULATE SIZE OF EACH SEPARATE TEST PART\n",
        "def get_rows(customers, test, NUM_PARTS = 4, verbose = ''):\n",
        "    chunk = len(customers)//NUM_PARTS\n",
        "    if verbose != '':\n",
        "        print(f'We will process {verbose} data as {NUM_PARTS} separate parts.')\n",
        "        print(f'There will be {chunk} customers in each part (except the last part).')\n",
        "        print('Below are number of rows in each part:')\n",
        "    rows = []\n",
        "\n",
        "    for k in range(NUM_PARTS):\n",
        "        if k==NUM_PARTS-1: cc = customers[k*chunk:]\n",
        "        else: cc = customers[k*chunk:(k+1)*chunk]\n",
        "        s = test.loc[test.customer_ID.isin(cc)].shape[0]\n",
        "        rows.append(s)\n",
        "    if verbose != '': print( rows )\n",
        "    return rows,chunk\n",
        "\n",
        "# COMPUTE SIZE OF 4 PARTS FOR TEST DATA\n",
        "NUM_PARTS = 4\n",
        "\n",
        "\n",
        "print(f'Reading test data...')\n",
        "test = read_file(path = TEST_PATH, usecols = ['customer_ID','S_2'])\n",
        "customers = test[['customer_ID']].drop_duplicates().sort_index().values.flatten()\n",
        "rows,num_cust = get_rows(customers, test[['customer_ID']], NUM_PARTS = NUM_PARTS, verbose = 'test')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4crug8KKoZv",
        "outputId": "d94957b4-b431-4676-b5b1-0425e868e919"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading test data...\n",
            "shape of data: (11363762, 2)\n",
            "We will process test data as 4 separate parts.\n",
            "There will be 231155 customers in each part (except the last part).\n",
            "Below are number of rows in each part:\n",
            "[2841209, 2839857, 2842105, 2840591]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features_red= pd.read_csv(f'/content/drive/MyDrive/Amex/parquet/XGB v2/features/features_xgb_v16.csv')\n",
        "features_red = list(features_red['feature'])\n",
        "\n",
        "features = [f for f in f_all if f in features_red]"
      ],
      "metadata": {
        "id": "KhhU1XTDwT9A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features"
      ],
      "metadata": {
        "id": "TarUqRjNKE2Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# INFER TEST DATA IN PARTS\n",
        "skip_rows = 0\n",
        "skip_cust = 0\n",
        "test_preds = []\n",
        "VER = 16\n",
        "\n",
        "for k in range(NUM_PARTS):\n",
        "    \n",
        "    # READ PART OF TEST DATA\n",
        "    print(f'\\nReading test data...')\n",
        "    test = read_file(path = TEST_PATH)\n",
        "    test = test.iloc[skip_rows:skip_rows+rows[k]]\n",
        "    skip_rows += rows[k]\n",
        "    print(f'=> Test part {k+1} has shape', test.shape )\n",
        "    \n",
        "    # PROCESS AND FEATURE ENGINEER PART OF TEST DATA\n",
        "    test = process_and_feature_engineer(test,cat_features, num_features, NAN_VALUE)\n",
        "    if k==NUM_PARTS-1: test = test.loc[customers[skip_cust:]]\n",
        "    else: test = test.loc[customers[skip_cust:skip_cust+num_cust]]\n",
        "    skip_cust += num_cust\n",
        "    \n",
        "    # TEST DATA FOR XGB\n",
        "    X_test = test[features]\n",
        "    dtest = xgb.DMatrix(data=X_test)\n",
        "    #test = test[['P_2_mean']] # reduce memory\n",
        "    #del X_test, test\n",
        "    gc.collect()\n",
        "\n",
        "    # INFER XGB MODELS ON TEST DATA\n",
        "    model = xgb.Booster()\n",
        "    model.load_model(f'/content/drive/MyDrive/Amex/parquet/XGB v2/models/XGB_base_v{VER}_fold0.xgb')\n",
        "    preds = model.predict(dtest)\n",
        "    for f in range(1,FOLDS):\n",
        "        model.load_model(f'/content/drive/MyDrive/Amex/parquet/XGB v2/models/XGB_base_v{VER}_fold{f}.xgb')\n",
        "        preds += model.predict(dtest)\n",
        "    preds /= FOLDS\n",
        "    test_preds.append(preds)\n",
        "\n",
        "    # CLEAN MEMORY\n",
        "    del dtest, model\n",
        "    _ = gc.collect()\n",
        "\n",
        "\n",
        "test_preds = np.concatenate(test_preds)\n",
        "test = cudf.DataFrame(index=customers,data={'prediction':test_preds})\n",
        "sub = cudf.read_csv('/content/drive/MyDrive/Amex/parquet/sample_submission.csv')[['customer_ID']]\n",
        "sub['customer_ID_hash'] = sub['customer_ID'].str[-16:].str.hex_to_int().astype('int64')\n",
        "sub = sub.set_index('customer_ID_hash')\n",
        "sub = sub.merge(test[['prediction']], left_index=True, right_index=True, how='left')\n",
        "sub = sub.reset_index(drop=True)\n",
        "\n",
        "sub.to_csv(f'submission_xgb_v{VER}.csv',index=False)"
      ],
      "metadata": {
        "id": "wAZ0pBLcQ8Sn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sub.to_csv(f'submission_xgb_v{VER}.csv',index=False)"
      ],
      "metadata": {
        "id": "hmyefydkIMp6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#################################Ende"
      ],
      "metadata": {
        "id": "ZyW8QqG8Pw_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "VULS2DKlPw8-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "1C03h8TCAf3H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gCLz4GjqKWZF"
      },
      "outputs": [],
      "source": [
        "import itertools\n",
        "features_orig = X_train.loc[:,X_train.columns.str.contains('mean')].columns.to_list()\n",
        "fpairs = itertools.combinations(features_orig,2)\n",
        "fpairs = list(fpairs)\n",
        "chunk = 10\n",
        "s = len(fpairs)//chunk +1\n",
        "\n",
        "\n",
        "overview = pd.DataFrame({'chunk':[], 'result':[]})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "fIFLZppLzNP1"
      },
      "outputs": [],
      "source": [
        "#try all multiplication pairs\n",
        "\n",
        "\n",
        "for i in range(s): \n",
        "  if i == s-1:\n",
        "    pairs = fpairs[i*chunk:]\n",
        "  else: pairs = fpairs[i*chunk:(i+1)*chunk]\n",
        "\n",
        "  if i == 0:\n",
        "    dtrain = xgb.DMatrix(data=X_train, label=y_train)\n",
        "    dvalid = xgb.DMatrix(data=X_test, label=y_test)\n",
        "    \n",
        "    model = xgb.train(xgb_parms, \n",
        "                dtrain=dtrain,\n",
        "                evals=[(dtrain,'train'),(dvalid,'valid')],\n",
        "                num_boost_round=9999,\n",
        "                early_stopping_rounds=100,\n",
        "                verbose_eval=300) \n",
        "    #model.save_model(f'/content/drive/MyDrive/Amex/parquet/XGB v2/XGB_base.xgb')\n",
        "\n",
        "    oof_preds = model.predict(dvalid)\n",
        "    acc = amex_metric_mod(y_test.iloc[:,0].values, oof_preds)\n",
        "    print(acc)\n",
        "\n",
        "    overview = overview.append({'chunk': ['base'], 'result': acc}, \n",
        "                               ignore_index = True)\n",
        "\n",
        "    del dtrain, dvalid, model\n",
        "  \n",
        "  for m,k in pairs:\n",
        "    X_train[f'{m}_{k}'] = X_train[m]*X_train[k]\n",
        "    X_test[f'{m}_{k}'] = X_test[m]*X_train[k]\n",
        "\n",
        "\n",
        "  dtrain = xgb.DMatrix(data=X_train, label=y_train)\n",
        "  dvalid = xgb.DMatrix(data=X_test, label=y_test)\n",
        "\n",
        "  model = xgb.train(xgb_parms, \n",
        "                dtrain=dtrain,\n",
        "                evals=[(dtrain,'train'),(dvalid,'valid')],\n",
        "                num_boost_round=9999,\n",
        "                early_stopping_rounds=100,\n",
        "                verbose_eval=300) \n",
        "  #model.save_model(f'/content/drive/MyDrive/Amex/parquet/XGB v2/XGB_{i}.xgb')\n",
        "\n",
        "  oof_preds = model.predict(dvalid)\n",
        "  acc = amex_metric_mod(y_test.iloc[:,0].values, oof_preds)\n",
        "\n",
        "  print(acc)\n",
        "\n",
        "  overview = overview.append({'chunk': i, 'result': acc}, ignore_index = True)\n",
        "\n",
        "  overview.to_csv(f'/content/drive/MyDrive/Amex/parquet/XGB v2/xgb_mutliply_{i}.csv',index=False)\n",
        "\n",
        "  del dtrain, dvalid, model\n",
        "\n",
        "  X_train = X_train_base.copy()\n",
        "  X_test = X_test_base.copy()\n",
        "\n",
        "  _ = gc.collect\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sm3VV2nZImrQ"
      },
      "outputs": [],
      "source": [
        "results = pd.read_csv('/content/drive/MyDrive/Amex/parquet/XGB v2/xgb_mutliply_475.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "72Y95JopImnV"
      },
      "outputs": [],
      "source": [
        "results_select = results[results.loc[:,'result']>=0.7910]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LjOOX1_BImkZ"
      },
      "outputs": [],
      "source": [
        "results_select.reset_index(drop= True, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sy8WvI-4SNSP"
      },
      "outputs": [],
      "source": [
        "results_select['chunk'] = results_select['chunk'].astype(str).astype(float)\n",
        "results_select['chunk'] = results_select['chunk'].astype(int)\n",
        "results_select"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "djOaE0B3Imhe"
      },
      "outputs": [],
      "source": [
        "#create list of features\n",
        "features_select= []\n",
        "\n",
        "for index, row in results_select.iterrows():\n",
        "  i = row['chunk'].astype(int)\n",
        "  f_temp = fpairs[i*10:(i+1)*10]\n",
        "  features_select += f_temp\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wbZyjVpREpo1"
      },
      "outputs": [],
      "source": [
        "with open('/content/drive/MyDrive/Amex/parquet/XGB v2/results.csv', 'w') as csvfile: \n",
        "    # creating a csv writer object \n",
        "    writer = csv.writer(csvfile) \n",
        "\n",
        "    header = ['feature', 'F1', 'F2', 'result', 'keep']    \n",
        "    writer.writerow(header) \n",
        "\n",
        "def write_results(res):\n",
        "  f = open('/content/drive/MyDrive/Amex/parquet/XGB v2/results.csv', 'a', newline = '')\n",
        "  writer = csv.writer(f)\n",
        "  writer.writerow(res)\n",
        "  f.close()\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train_base.copy()\n",
        "X_test = X_test_base.copy()\n",
        "\n",
        "\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_db_iqOsJ-eo",
        "outputId": "5c86685f-ed71-4f7c-b321-770f3d2c456b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1217"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2LIVVFXGv8B7",
        "outputId": "2b3d082c-f122-4b56-ed8c-05c2d901ffc7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21617\tvalid-logloss:0.22258\n",
            "[600]\ttrain-logloss:0.20580\tvalid-logloss:0.21884\n",
            "[900]\ttrain-logloss:0.19848\tvalid-logloss:0.21766\n",
            "[1200]\ttrain-logloss:0.19204\tvalid-logloss:0.21716\n",
            "[1500]\ttrain-logloss:0.18597\tvalid-logloss:0.21690\n",
            "[1640]\ttrain-logloss:0.18326\tvalid-logloss:0.21689\n",
            "Rund no:  0 Metric :  0.792098599084659\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21617\tvalid-logloss:0.22252\n",
            "[600]\ttrain-logloss:0.20577\tvalid-logloss:0.21870\n",
            "[900]\ttrain-logloss:0.19844\tvalid-logloss:0.21757\n",
            "[1200]\ttrain-logloss:0.19192\tvalid-logloss:0.21695\n",
            "[1500]\ttrain-logloss:0.18588\tvalid-logloss:0.21674\n",
            "[1800]\ttrain-logloss:0.18015\tvalid-logloss:0.21658\n",
            "[1938]\ttrain-logloss:0.17763\tvalid-logloss:0.21660\n",
            "Rund no: 1 Metric : 0.7926531408705695 Max: 0.7926531408705695\n",
            "[0]\ttrain-logloss:0.66207\tvalid-logloss:0.66209\n",
            "[300]\ttrain-logloss:0.21622\tvalid-logloss:0.22291\n",
            "[600]\ttrain-logloss:0.20586\tvalid-logloss:0.21891\n",
            "[900]\ttrain-logloss:0.19847\tvalid-logloss:0.21766\n",
            "[1200]\ttrain-logloss:0.19206\tvalid-logloss:0.21716\n",
            "[1500]\ttrain-logloss:0.18596\tvalid-logloss:0.21696\n",
            "[1800]\ttrain-logloss:0.18020\tvalid-logloss:0.21678\n",
            "[2100]\ttrain-logloss:0.17475\tvalid-logloss:0.21675\n",
            "[2110]\ttrain-logloss:0.17457\tvalid-logloss:0.21673\n",
            "Rund no: 2 Metric : 0.7932302834166638 Max: 0.7932302834166638\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21615\tvalid-logloss:0.22260\n",
            "[600]\ttrain-logloss:0.20576\tvalid-logloss:0.21878\n",
            "[900]\ttrain-logloss:0.19840\tvalid-logloss:0.21764\n",
            "[1200]\ttrain-logloss:0.19196\tvalid-logloss:0.21728\n",
            "[1500]\ttrain-logloss:0.18591\tvalid-logloss:0.21707\n",
            "[1770]\ttrain-logloss:0.18075\tvalid-logloss:0.21691\n",
            "Rund no: 3 Metric : 0.7905996110330749 Max: 0.7932302834166638\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21611\tvalid-logloss:0.22255\n",
            "[600]\ttrain-logloss:0.20572\tvalid-logloss:0.21872\n",
            "[900]\ttrain-logloss:0.19841\tvalid-logloss:0.21763\n",
            "[1200]\ttrain-logloss:0.19194\tvalid-logloss:0.21723\n",
            "[1443]\ttrain-logloss:0.18704\tvalid-logloss:0.21721\n",
            "Rund no: 4 Metric : 0.7920402147039272 Max: 0.7932302834166638\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21606\tvalid-logloss:0.22259\n",
            "[600]\ttrain-logloss:0.20565\tvalid-logloss:0.21871\n",
            "[900]\ttrain-logloss:0.19829\tvalid-logloss:0.21761\n",
            "[1200]\ttrain-logloss:0.19184\tvalid-logloss:0.21719\n",
            "[1500]\ttrain-logloss:0.18574\tvalid-logloss:0.21707\n",
            "[1800]\ttrain-logloss:0.17996\tvalid-logloss:0.21695\n",
            "[1982]\ttrain-logloss:0.17667\tvalid-logloss:0.21693\n",
            "Rund no: 5 Metric : 0.7927658185815369 Max: 0.7932302834166638\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21611\tvalid-logloss:0.22253\n",
            "[600]\ttrain-logloss:0.20571\tvalid-logloss:0.21866\n",
            "[900]\ttrain-logloss:0.19839\tvalid-logloss:0.21760\n",
            "[1200]\ttrain-logloss:0.19190\tvalid-logloss:0.21713\n",
            "[1444]\ttrain-logloss:0.18699\tvalid-logloss:0.21703\n",
            "Rund no: 6 Metric : 0.7910812465939407 Max: 0.7932302834166638\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21611\tvalid-logloss:0.22281\n",
            "[600]\ttrain-logloss:0.20573\tvalid-logloss:0.21887\n",
            "[900]\ttrain-logloss:0.19840\tvalid-logloss:0.21773\n",
            "[1200]\ttrain-logloss:0.19189\tvalid-logloss:0.21734\n",
            "[1500]\ttrain-logloss:0.18580\tvalid-logloss:0.21716\n",
            "[1652]\ttrain-logloss:0.18288\tvalid-logloss:0.21716\n",
            "Rund no: 7 Metric : 0.7913837925207564 Max: 0.7932302834166638\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21617\tvalid-logloss:0.22257\n",
            "[600]\ttrain-logloss:0.20576\tvalid-logloss:0.21867\n",
            "[900]\ttrain-logloss:0.19838\tvalid-logloss:0.21753\n",
            "[1200]\ttrain-logloss:0.19191\tvalid-logloss:0.21712\n",
            "[1500]\ttrain-logloss:0.18580\tvalid-logloss:0.21685\n",
            "[1739]\ttrain-logloss:0.18125\tvalid-logloss:0.21671\n",
            "Rund no: 8 Metric : 0.7919621137062276 Max: 0.7932302834166638\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21612\tvalid-logloss:0.22259\n",
            "[600]\ttrain-logloss:0.20571\tvalid-logloss:0.21872\n",
            "[900]\ttrain-logloss:0.19838\tvalid-logloss:0.21765\n",
            "[1200]\ttrain-logloss:0.19186\tvalid-logloss:0.21723\n",
            "[1500]\ttrain-logloss:0.18574\tvalid-logloss:0.21704\n",
            "[1759]\ttrain-logloss:0.18075\tvalid-logloss:0.21712\n",
            "Rund no: 9 Metric : 0.7922090942988329 Max: 0.7932302834166638\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21613\tvalid-logloss:0.22271\n",
            "[600]\ttrain-logloss:0.20578\tvalid-logloss:0.21894\n",
            "[900]\ttrain-logloss:0.19843\tvalid-logloss:0.21784\n",
            "[1200]\ttrain-logloss:0.19196\tvalid-logloss:0.21731\n",
            "[1376]\ttrain-logloss:0.18834\tvalid-logloss:0.21727\n",
            "Rund no: 10 Metric : 0.7910564278378273 Max: 0.7932302834166638\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21612\tvalid-logloss:0.22258\n",
            "[600]\ttrain-logloss:0.20571\tvalid-logloss:0.21886\n",
            "[900]\ttrain-logloss:0.19836\tvalid-logloss:0.21770\n",
            "[1200]\ttrain-logloss:0.19190\tvalid-logloss:0.21721\n",
            "[1443]\ttrain-logloss:0.18691\tvalid-logloss:0.21708\n",
            "Rund no: 11 Metric : 0.7918306363385552 Max: 0.7932302834166638\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21611\tvalid-logloss:0.22251\n",
            "[600]\ttrain-logloss:0.20567\tvalid-logloss:0.21870\n",
            "[900]\ttrain-logloss:0.19837\tvalid-logloss:0.21754\n",
            "[1200]\ttrain-logloss:0.19188\tvalid-logloss:0.21716\n",
            "[1405]\ttrain-logloss:0.18771\tvalid-logloss:0.21709\n",
            "Rund no: 12 Metric : 0.7921380070759372 Max: 0.7932302834166638\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21612\tvalid-logloss:0.22258\n",
            "[600]\ttrain-logloss:0.20570\tvalid-logloss:0.21870\n",
            "[900]\ttrain-logloss:0.19840\tvalid-logloss:0.21765\n",
            "[1200]\ttrain-logloss:0.19188\tvalid-logloss:0.21734\n",
            "[1500]\ttrain-logloss:0.18579\tvalid-logloss:0.21714\n",
            "[1800]\ttrain-logloss:0.18011\tvalid-logloss:0.21697\n",
            "[2005]\ttrain-logloss:0.17637\tvalid-logloss:0.21692\n",
            "Rund no: 13 Metric : 0.7919255834912231 Max: 0.7932302834166638\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21613\tvalid-logloss:0.22266\n",
            "[600]\ttrain-logloss:0.20578\tvalid-logloss:0.21879\n",
            "[900]\ttrain-logloss:0.19838\tvalid-logloss:0.21764\n",
            "[1200]\ttrain-logloss:0.19190\tvalid-logloss:0.21716\n",
            "[1500]\ttrain-logloss:0.18584\tvalid-logloss:0.21701\n",
            "[1742]\ttrain-logloss:0.18123\tvalid-logloss:0.21698\n",
            "Rund no: 14 Metric : 0.7920621812049727 Max: 0.7932302834166638\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21610\tvalid-logloss:0.22252\n",
            "[600]\ttrain-logloss:0.20572\tvalid-logloss:0.21868\n",
            "[900]\ttrain-logloss:0.19838\tvalid-logloss:0.21753\n",
            "[1200]\ttrain-logloss:0.19193\tvalid-logloss:0.21715\n",
            "[1500]\ttrain-logloss:0.18591\tvalid-logloss:0.21690\n",
            "[1800]\ttrain-logloss:0.18013\tvalid-logloss:0.21666\n",
            "[1940]\ttrain-logloss:0.17757\tvalid-logloss:0.21667\n",
            "Rund no: 15 Metric : 0.792973949496246 Max: 0.7932302834166638\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21619\tvalid-logloss:0.22279\n",
            "[600]\ttrain-logloss:0.20585\tvalid-logloss:0.21886\n",
            "[900]\ttrain-logloss:0.19850\tvalid-logloss:0.21773\n",
            "[1200]\ttrain-logloss:0.19209\tvalid-logloss:0.21722\n",
            "[1268]\ttrain-logloss:0.19066\tvalid-logloss:0.21720\n",
            "Rund no: 16 Metric : 0.7915812071219697 Max: 0.7932302834166638\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21610\tvalid-logloss:0.22275\n",
            "[600]\ttrain-logloss:0.20574\tvalid-logloss:0.21885\n",
            "[900]\ttrain-logloss:0.19842\tvalid-logloss:0.21767\n",
            "[1200]\ttrain-logloss:0.19199\tvalid-logloss:0.21730\n",
            "[1426]\ttrain-logloss:0.18742\tvalid-logloss:0.21720\n",
            "Rund no: 17 Metric : 0.7911867979314793 Max: 0.7932302834166638\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21613\tvalid-logloss:0.22260\n",
            "[600]\ttrain-logloss:0.20569\tvalid-logloss:0.21876\n",
            "[900]\ttrain-logloss:0.19837\tvalid-logloss:0.21766\n",
            "[1200]\ttrain-logloss:0.19188\tvalid-logloss:0.21730\n",
            "[1373]\ttrain-logloss:0.18836\tvalid-logloss:0.21726\n",
            "Rund no: 18 Metric : 0.7920670799059498 Max: 0.7932302834166638\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21617\tvalid-logloss:0.22259\n",
            "[600]\ttrain-logloss:0.20578\tvalid-logloss:0.21879\n",
            "[900]\ttrain-logloss:0.19843\tvalid-logloss:0.21765\n",
            "[1200]\ttrain-logloss:0.19198\tvalid-logloss:0.21734\n",
            "[1500]\ttrain-logloss:0.18593\tvalid-logloss:0.21713\n",
            "[1743]\ttrain-logloss:0.18127\tvalid-logloss:0.21710\n",
            "Rund no: 19 Metric : 0.7919650652819603 Max: 0.7932302834166638\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21618\tvalid-logloss:0.22270\n",
            "[600]\ttrain-logloss:0.20574\tvalid-logloss:0.21883\n",
            "[900]\ttrain-logloss:0.19842\tvalid-logloss:0.21773\n",
            "[1200]\ttrain-logloss:0.19195\tvalid-logloss:0.21735\n",
            "[1500]\ttrain-logloss:0.18587\tvalid-logloss:0.21721\n",
            "[1800]\ttrain-logloss:0.18016\tvalid-logloss:0.21712\n",
            "[1829]\ttrain-logloss:0.17961\tvalid-logloss:0.21710\n",
            "Rund no: 20 Metric : 0.7919675752500627 Max: 0.7932302834166638\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21610\tvalid-logloss:0.22280\n",
            "[600]\ttrain-logloss:0.20572\tvalid-logloss:0.21884\n",
            "[900]\ttrain-logloss:0.19837\tvalid-logloss:0.21766\n",
            "[1200]\ttrain-logloss:0.19190\tvalid-logloss:0.21728\n",
            "[1443]\ttrain-logloss:0.18697\tvalid-logloss:0.21726\n",
            "Rund no: 21 Metric : 0.7921973450297728 Max: 0.7932302834166638\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21612\tvalid-logloss:0.22257\n",
            "[600]\ttrain-logloss:0.20565\tvalid-logloss:0.21883\n",
            "[900]\ttrain-logloss:0.19833\tvalid-logloss:0.21755\n",
            "[1200]\ttrain-logloss:0.19191\tvalid-logloss:0.21717\n",
            "[1500]\ttrain-logloss:0.18583\tvalid-logloss:0.21695\n",
            "[1743]\ttrain-logloss:0.18121\tvalid-logloss:0.21692\n",
            "Rund no: 22 Metric : 0.7922544674353846 Max: 0.7932302834166638\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21607\tvalid-logloss:0.22251\n",
            "[600]\ttrain-logloss:0.20569\tvalid-logloss:0.21864\n",
            "[900]\ttrain-logloss:0.19836\tvalid-logloss:0.21755\n",
            "[1200]\ttrain-logloss:0.19187\tvalid-logloss:0.21707\n",
            "[1443]\ttrain-logloss:0.18690\tvalid-logloss:0.21694\n",
            "Rund no: 23 Metric : 0.7917864902446321 Max: 0.7932302834166638\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21612\tvalid-logloss:0.22260\n",
            "[600]\ttrain-logloss:0.20575\tvalid-logloss:0.21868\n",
            "[900]\ttrain-logloss:0.19846\tvalid-logloss:0.21759\n",
            "[1200]\ttrain-logloss:0.19197\tvalid-logloss:0.21710\n",
            "[1375]\ttrain-logloss:0.18838\tvalid-logloss:0.21704\n",
            "Rund no: 24 Metric : 0.7914573648762102 Max: 0.7932302834166638\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21614\tvalid-logloss:0.22255\n",
            "[600]\ttrain-logloss:0.20578\tvalid-logloss:0.21880\n",
            "[900]\ttrain-logloss:0.19846\tvalid-logloss:0.21767\n",
            "[1200]\ttrain-logloss:0.19190\tvalid-logloss:0.21727\n",
            "[1500]\ttrain-logloss:0.18576\tvalid-logloss:0.21711\n",
            "[1738]\ttrain-logloss:0.18122\tvalid-logloss:0.21703\n",
            "Rund no: 25 Metric : 0.7910240707458611 Max: 0.7932302834166638\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21618\tvalid-logloss:0.22283\n",
            "[600]\ttrain-logloss:0.20578\tvalid-logloss:0.21898\n",
            "[900]\ttrain-logloss:0.19847\tvalid-logloss:0.21781\n",
            "[1200]\ttrain-logloss:0.19198\tvalid-logloss:0.21741\n",
            "[1227]\ttrain-logloss:0.19141\tvalid-logloss:0.21741\n",
            "Rund no: 26 Metric : 0.7921865312766734 Max: 0.7932302834166638\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21605\tvalid-logloss:0.22284\n",
            "[600]\ttrain-logloss:0.20567\tvalid-logloss:0.21887\n",
            "[900]\ttrain-logloss:0.19836\tvalid-logloss:0.21791\n",
            "[1200]\ttrain-logloss:0.19192\tvalid-logloss:0.21760\n",
            "[1372]\ttrain-logloss:0.18840\tvalid-logloss:0.21769\n",
            "Rund no: 27 Metric : 0.7921901868591477 Max: 0.7932302834166638\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21615\tvalid-logloss:0.22261\n",
            "[600]\ttrain-logloss:0.20575\tvalid-logloss:0.21883\n",
            "[900]\ttrain-logloss:0.19832\tvalid-logloss:0.21799\n",
            "[1200]\ttrain-logloss:0.19184\tvalid-logloss:0.21759\n",
            "[1500]\ttrain-logloss:0.18581\tvalid-logloss:0.21745\n",
            "[1623]\ttrain-logloss:0.18344\tvalid-logloss:0.21745\n",
            "Rund no: 28 Metric : 0.7920860591826311 Max: 0.7932302834166638\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21612\tvalid-logloss:0.22257\n",
            "[600]\ttrain-logloss:0.20569\tvalid-logloss:0.21878\n",
            "[900]\ttrain-logloss:0.19841\tvalid-logloss:0.21763\n",
            "[1200]\ttrain-logloss:0.19188\tvalid-logloss:0.21717\n",
            "[1500]\ttrain-logloss:0.18584\tvalid-logloss:0.21701\n",
            "[1754]\ttrain-logloss:0.18094\tvalid-logloss:0.21693\n",
            "Rund no: 29 Metric : 0.7922429055874536 Max: 0.7932302834166638\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21613\tvalid-logloss:0.22252\n",
            "[600]\ttrain-logloss:0.20578\tvalid-logloss:0.21869\n",
            "[900]\ttrain-logloss:0.19837\tvalid-logloss:0.21753\n",
            "[1200]\ttrain-logloss:0.19196\tvalid-logloss:0.21715\n",
            "[1444]\ttrain-logloss:0.18698\tvalid-logloss:0.21702\n",
            "Rund no: 30 Metric : 0.7916850874181581 Max: 0.7932302834166638\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21613\tvalid-logloss:0.22257\n",
            "[600]\ttrain-logloss:0.20576\tvalid-logloss:0.21878\n",
            "[900]\ttrain-logloss:0.19840\tvalid-logloss:0.21770\n",
            "[1200]\ttrain-logloss:0.19198\tvalid-logloss:0.21728\n",
            "[1411]\ttrain-logloss:0.18765\tvalid-logloss:0.21726\n",
            "Rund no: 31 Metric : 0.7918949754305236 Max: 0.7932302834166638\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21612\tvalid-logloss:0.22257\n",
            "[600]\ttrain-logloss:0.20573\tvalid-logloss:0.21871\n",
            "[900]\ttrain-logloss:0.19841\tvalid-logloss:0.21768\n",
            "[1200]\ttrain-logloss:0.19192\tvalid-logloss:0.21728\n",
            "[1500]\ttrain-logloss:0.18582\tvalid-logloss:0.21710\n",
            "[1607]\ttrain-logloss:0.18374\tvalid-logloss:0.21713\n",
            "Rund no: 32 Metric : 0.7917356869750641 Max: 0.7932302834166638\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21610\tvalid-logloss:0.22257\n",
            "[600]\ttrain-logloss:0.20578\tvalid-logloss:0.21883\n",
            "[900]\ttrain-logloss:0.19846\tvalid-logloss:0.21771\n",
            "[1200]\ttrain-logloss:0.19197\tvalid-logloss:0.21728\n",
            "[1372]\ttrain-logloss:0.18843\tvalid-logloss:0.21728\n",
            "Rund no: 33 Metric : 0.7915375874949462 Max: 0.7932302834166638\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21615\tvalid-logloss:0.22259\n",
            "[600]\ttrain-logloss:0.20579\tvalid-logloss:0.21883\n",
            "[900]\ttrain-logloss:0.19839\tvalid-logloss:0.21780\n",
            "[1200]\ttrain-logloss:0.19189\tvalid-logloss:0.21729\n",
            "[1448]\ttrain-logloss:0.18692\tvalid-logloss:0.21727\n",
            "Rund no: 34 Metric : 0.7925339848289565 Max: 0.7932302834166638\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21609\tvalid-logloss:0.22254\n",
            "[600]\ttrain-logloss:0.20570\tvalid-logloss:0.21875\n",
            "[900]\ttrain-logloss:0.19839\tvalid-logloss:0.21771\n",
            "[1200]\ttrain-logloss:0.19195\tvalid-logloss:0.21733\n",
            "[1500]\ttrain-logloss:0.18589\tvalid-logloss:0.21712\n",
            "[1652]\ttrain-logloss:0.18296\tvalid-logloss:0.21711\n",
            "Rund no: 35 Metric : 0.7916115457878619 Max: 0.7932302834166638\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21613\tvalid-logloss:0.22260\n",
            "[600]\ttrain-logloss:0.20571\tvalid-logloss:0.21883\n",
            "[900]\ttrain-logloss:0.19841\tvalid-logloss:0.21771\n",
            "[1200]\ttrain-logloss:0.19197\tvalid-logloss:0.21730\n",
            "[1500]\ttrain-logloss:0.18591\tvalid-logloss:0.21717\n",
            "[1762]\ttrain-logloss:0.18091\tvalid-logloss:0.21715\n",
            "Rund no: 36 Metric : 0.7926479731630907 Max: 0.7932302834166638\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21616\tvalid-logloss:0.22262\n",
            "[600]\ttrain-logloss:0.20574\tvalid-logloss:0.21869\n",
            "[900]\ttrain-logloss:0.19847\tvalid-logloss:0.21771\n",
            "[1200]\ttrain-logloss:0.19194\tvalid-logloss:0.21735\n",
            "[1500]\ttrain-logloss:0.18585\tvalid-logloss:0.21709\n",
            "[1767]\ttrain-logloss:0.18077\tvalid-logloss:0.21703\n",
            "Rund no: 37 Metric : 0.7931006210749973 Max: 0.7932302834166638\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21610\tvalid-logloss:0.22257\n",
            "[600]\ttrain-logloss:0.20567\tvalid-logloss:0.21863\n",
            "[900]\ttrain-logloss:0.19836\tvalid-logloss:0.21765\n",
            "[1200]\ttrain-logloss:0.19190\tvalid-logloss:0.21723\n",
            "[1500]\ttrain-logloss:0.18581\tvalid-logloss:0.21710\n",
            "[1720]\ttrain-logloss:0.18159\tvalid-logloss:0.21698\n",
            "Rund no: 38 Metric : 0.792545832287809 Max: 0.7932302834166638\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21612\tvalid-logloss:0.22258\n",
            "[600]\ttrain-logloss:0.20581\tvalid-logloss:0.21878\n",
            "[900]\ttrain-logloss:0.19847\tvalid-logloss:0.21769\n",
            "[1200]\ttrain-logloss:0.19196\tvalid-logloss:0.21719\n",
            "[1500]\ttrain-logloss:0.18587\tvalid-logloss:0.21702\n",
            "[1628]\ttrain-logloss:0.18345\tvalid-logloss:0.21699\n",
            "Rund no: 39 Metric : 0.7919262955074491 Max: 0.7932302834166638\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21608\tvalid-logloss:0.22262\n",
            "[600]\ttrain-logloss:0.20569\tvalid-logloss:0.21871\n",
            "[900]\ttrain-logloss:0.19834\tvalid-logloss:0.21765\n",
            "[1200]\ttrain-logloss:0.19190\tvalid-logloss:0.21729\n",
            "[1372]\ttrain-logloss:0.18837\tvalid-logloss:0.21736\n",
            "Rund no: 40 Metric : 0.7928081350911238 Max: 0.7932302834166638\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21612\tvalid-logloss:0.22260\n",
            "[600]\ttrain-logloss:0.20574\tvalid-logloss:0.21876\n",
            "[900]\ttrain-logloss:0.19842\tvalid-logloss:0.21770\n",
            "[1200]\ttrain-logloss:0.19196\tvalid-logloss:0.21725\n",
            "[1438]\ttrain-logloss:0.18712\tvalid-logloss:0.21722\n",
            "Rund no: 41 Metric : 0.7913777564136731 Max: 0.7932302834166638\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21613\tvalid-logloss:0.22257\n",
            "[600]\ttrain-logloss:0.20577\tvalid-logloss:0.21862\n",
            "[900]\ttrain-logloss:0.19847\tvalid-logloss:0.21759\n",
            "[1200]\ttrain-logloss:0.19192\tvalid-logloss:0.21717\n",
            "[1500]\ttrain-logloss:0.18587\tvalid-logloss:0.21697\n",
            "[1800]\ttrain-logloss:0.18017\tvalid-logloss:0.21689\n",
            "[2100]\ttrain-logloss:0.17470\tvalid-logloss:0.21682\n",
            "[2108]\ttrain-logloss:0.17456\tvalid-logloss:0.21682\n",
            "Rund no: 42 Metric : 0.7914813491762135 Max: 0.7932302834166638\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21613\tvalid-logloss:0.22263\n",
            "[600]\ttrain-logloss:0.20573\tvalid-logloss:0.21880\n",
            "[900]\ttrain-logloss:0.19843\tvalid-logloss:0.21764\n",
            "[1200]\ttrain-logloss:0.19197\tvalid-logloss:0.21721\n",
            "[1370]\ttrain-logloss:0.18847\tvalid-logloss:0.21718\n",
            "Rund no: 43 Metric : 0.7916751858306081 Max: 0.7932302834166638\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21612\tvalid-logloss:0.22259\n",
            "[600]\ttrain-logloss:0.20567\tvalid-logloss:0.21878\n",
            "[900]\ttrain-logloss:0.19838\tvalid-logloss:0.21769\n",
            "[1200]\ttrain-logloss:0.19190\tvalid-logloss:0.21733\n",
            "[1500]\ttrain-logloss:0.18578\tvalid-logloss:0.21715\n",
            "[1787]\ttrain-logloss:0.18030\tvalid-logloss:0.21704\n",
            "Rund no: 44 Metric : 0.7922064553989046 Max: 0.7932302834166638\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21610\tvalid-logloss:0.22255\n",
            "[600]\ttrain-logloss:0.20575\tvalid-logloss:0.21869\n",
            "[900]\ttrain-logloss:0.19848\tvalid-logloss:0.21764\n",
            "[1200]\ttrain-logloss:0.19200\tvalid-logloss:0.21723\n",
            "[1480]\ttrain-logloss:0.18629\tvalid-logloss:0.21717\n",
            "Rund no: 45 Metric : 0.7921334584650073 Max: 0.7932302834166638\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21615\tvalid-logloss:0.22255\n",
            "[600]\ttrain-logloss:0.20571\tvalid-logloss:0.21866\n",
            "[900]\ttrain-logloss:0.19846\tvalid-logloss:0.21765\n",
            "[1200]\ttrain-logloss:0.19200\tvalid-logloss:0.21721\n",
            "[1500]\ttrain-logloss:0.18592\tvalid-logloss:0.21708\n",
            "[1516]\ttrain-logloss:0.18560\tvalid-logloss:0.21707\n",
            "Rund no: 46 Metric : 0.7919756735322896 Max: 0.7932302834166638\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21612\tvalid-logloss:0.22258\n",
            "[600]\ttrain-logloss:0.20573\tvalid-logloss:0.21878\n",
            "[900]\ttrain-logloss:0.19842\tvalid-logloss:0.21761\n",
            "[1200]\ttrain-logloss:0.19194\tvalid-logloss:0.21723\n",
            "[1500]\ttrain-logloss:0.18591\tvalid-logloss:0.21705\n",
            "[1651]\ttrain-logloss:0.18298\tvalid-logloss:0.21702\n",
            "Rund no: 47 Metric : 0.7915951388461575 Max: 0.7932302834166638\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21612\tvalid-logloss:0.22256\n",
            "[600]\ttrain-logloss:0.20566\tvalid-logloss:0.21881\n",
            "[900]\ttrain-logloss:0.19840\tvalid-logloss:0.21767\n",
            "[1200]\ttrain-logloss:0.19191\tvalid-logloss:0.21722\n",
            "[1500]\ttrain-logloss:0.18589\tvalid-logloss:0.21706\n",
            "[1739]\ttrain-logloss:0.18128\tvalid-logloss:0.21700\n",
            "Rund no: 48 Metric : 0.7930458782450259 Max: 0.7932302834166638\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21615\tvalid-logloss:0.22263\n",
            "[600]\ttrain-logloss:0.20580\tvalid-logloss:0.21891\n",
            "[900]\ttrain-logloss:0.19845\tvalid-logloss:0.21774\n",
            "[1200]\ttrain-logloss:0.19205\tvalid-logloss:0.21730\n",
            "[1500]\ttrain-logloss:0.18595\tvalid-logloss:0.21721\n",
            "[1507]\ttrain-logloss:0.18581\tvalid-logloss:0.21720\n",
            "Rund no: 49 Metric : 0.7906156910303782 Max: 0.7932302834166638\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21612\tvalid-logloss:0.22258\n",
            "[600]\ttrain-logloss:0.20568\tvalid-logloss:0.21882\n",
            "[900]\ttrain-logloss:0.19836\tvalid-logloss:0.21783\n",
            "[1200]\ttrain-logloss:0.19191\tvalid-logloss:0.21744\n",
            "[1247]\ttrain-logloss:0.19090\tvalid-logloss:0.21740\n",
            "Rund no: 50 Metric : 0.7909121786289363 Max: 0.7932302834166638\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21612\tvalid-logloss:0.22258\n",
            "[600]\ttrain-logloss:0.20572\tvalid-logloss:0.21869\n",
            "[900]\ttrain-logloss:0.19831\tvalid-logloss:0.21751\n",
            "[1200]\ttrain-logloss:0.19186\tvalid-logloss:0.21713\n",
            "[1269]\ttrain-logloss:0.19045\tvalid-logloss:0.21713\n",
            "Rund no: 51 Metric : 0.7917277549327137 Max: 0.7932302834166638\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21619\tvalid-logloss:0.22268\n",
            "[600]\ttrain-logloss:0.20578\tvalid-logloss:0.21871\n",
            "[900]\ttrain-logloss:0.19843\tvalid-logloss:0.21758\n",
            "[1200]\ttrain-logloss:0.19191\tvalid-logloss:0.21724\n",
            "[1500]\ttrain-logloss:0.18588\tvalid-logloss:0.21702\n",
            "[1800]\ttrain-logloss:0.18018\tvalid-logloss:0.21684\n",
            "[1962]\ttrain-logloss:0.17719\tvalid-logloss:0.21682\n",
            "Rund no: 52 Metric : 0.7931806714901681 Max: 0.7932302834166638\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21617\tvalid-logloss:0.22252\n",
            "[600]\ttrain-logloss:0.20576\tvalid-logloss:0.21868\n",
            "[900]\ttrain-logloss:0.19838\tvalid-logloss:0.21764\n",
            "[1200]\ttrain-logloss:0.19196\tvalid-logloss:0.21722\n",
            "[1500]\ttrain-logloss:0.18588\tvalid-logloss:0.21693\n",
            "[1628]\ttrain-logloss:0.18340\tvalid-logloss:0.21697\n",
            "Rund no: 53 Metric : 0.7919298645467379 Max: 0.7932302834166638\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21608\tvalid-logloss:0.22259\n",
            "[600]\ttrain-logloss:0.20574\tvalid-logloss:0.21883\n",
            "[900]\ttrain-logloss:0.19844\tvalid-logloss:0.21772\n",
            "[1200]\ttrain-logloss:0.19200\tvalid-logloss:0.21739\n",
            "[1500]\ttrain-logloss:0.18587\tvalid-logloss:0.21720\n",
            "[1637]\ttrain-logloss:0.18322\tvalid-logloss:0.21721\n",
            "Rund no: 54 Metric : 0.790760018674398 Max: 0.7932302834166638\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21612\tvalid-logloss:0.22258\n",
            "[600]\ttrain-logloss:0.20575\tvalid-logloss:0.21881\n",
            "[900]\ttrain-logloss:0.19848\tvalid-logloss:0.21773\n",
            "[1200]\ttrain-logloss:0.19199\tvalid-logloss:0.21725\n",
            "[1443]\ttrain-logloss:0.18707\tvalid-logloss:0.21717\n",
            "Rund no: 55 Metric : 0.7918056133829 Max: 0.7932302834166638\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21612\tvalid-logloss:0.22257\n",
            "[600]\ttrain-logloss:0.20575\tvalid-logloss:0.21872\n",
            "[900]\ttrain-logloss:0.19837\tvalid-logloss:0.21764\n",
            "[1200]\ttrain-logloss:0.19195\tvalid-logloss:0.21724\n",
            "[1375]\ttrain-logloss:0.18844\tvalid-logloss:0.21721\n",
            "Rund no: 56 Metric : 0.7925632356781365 Max: 0.7932302834166638\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21612\tvalid-logloss:0.22258\n",
            "[600]\ttrain-logloss:0.20574\tvalid-logloss:0.21873\n",
            "[900]\ttrain-logloss:0.19838\tvalid-logloss:0.21772\n",
            "[1200]\ttrain-logloss:0.19184\tvalid-logloss:0.21727\n",
            "[1295]\ttrain-logloss:0.18993\tvalid-logloss:0.21728\n",
            "Rund no: 57 Metric : 0.7916537558593614 Max: 0.7932302834166638\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21612\tvalid-logloss:0.22260\n",
            "[600]\ttrain-logloss:0.20573\tvalid-logloss:0.21881\n",
            "[900]\ttrain-logloss:0.19844\tvalid-logloss:0.21770\n",
            "[1200]\ttrain-logloss:0.19195\tvalid-logloss:0.21725\n",
            "[1500]\ttrain-logloss:0.18583\tvalid-logloss:0.21700\n",
            "[1631]\ttrain-logloss:0.18328\tvalid-logloss:0.21699\n",
            "Rund no: 58 Metric : 0.7925527233898984 Max: 0.7932302834166638\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21610\tvalid-logloss:0.22255\n",
            "[600]\ttrain-logloss:0.20574\tvalid-logloss:0.21880\n",
            "[900]\ttrain-logloss:0.19846\tvalid-logloss:0.21767\n",
            "[1200]\ttrain-logloss:0.19198\tvalid-logloss:0.21729\n",
            "[1375]\ttrain-logloss:0.18841\tvalid-logloss:0.21724\n",
            "Rund no: 59 Metric : 0.7915045912789105 Max: 0.7932302834166638\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21613\tvalid-logloss:0.22259\n",
            "[600]\ttrain-logloss:0.20574\tvalid-logloss:0.21870\n",
            "[900]\ttrain-logloss:0.19839\tvalid-logloss:0.21752\n",
            "[1200]\ttrain-logloss:0.19191\tvalid-logloss:0.21718\n",
            "[1361]\ttrain-logloss:0.18861\tvalid-logloss:0.21726\n",
            "Rund no: 60 Metric : 0.7930851935401988 Max: 0.7932302834166638\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21612\tvalid-logloss:0.22268\n",
            "[600]\ttrain-logloss:0.20572\tvalid-logloss:0.21884\n",
            "[900]\ttrain-logloss:0.19839\tvalid-logloss:0.21775\n",
            "[1200]\ttrain-logloss:0.19199\tvalid-logloss:0.21725\n",
            "[1500]\ttrain-logloss:0.18590\tvalid-logloss:0.21702\n",
            "[1800]\ttrain-logloss:0.18012\tvalid-logloss:0.21681\n",
            "[2005]\ttrain-logloss:0.17636\tvalid-logloss:0.21691\n",
            "Rund no: 61 Metric : 0.792305114107553 Max: 0.7932302834166638\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21612\tvalid-logloss:0.22255\n",
            "[600]\ttrain-logloss:0.20573\tvalid-logloss:0.21877\n",
            "[900]\ttrain-logloss:0.19840\tvalid-logloss:0.21778\n",
            "[1200]\ttrain-logloss:0.19191\tvalid-logloss:0.21735\n",
            "[1500]\ttrain-logloss:0.18590\tvalid-logloss:0.21712\n",
            "[1800]\ttrain-logloss:0.18014\tvalid-logloss:0.21699\n",
            "[1948]\ttrain-logloss:0.17738\tvalid-logloss:0.21700\n",
            "Rund no: 62 Metric : 0.791794048325891 Max: 0.7932302834166638\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21620\tvalid-logloss:0.22271\n",
            "[600]\ttrain-logloss:0.20574\tvalid-logloss:0.21881\n",
            "[900]\ttrain-logloss:0.19844\tvalid-logloss:0.21770\n",
            "[1200]\ttrain-logloss:0.19202\tvalid-logloss:0.21722\n",
            "[1500]\ttrain-logloss:0.18598\tvalid-logloss:0.21698\n",
            "[1800]\ttrain-logloss:0.18031\tvalid-logloss:0.21675\n",
            "[2005]\ttrain-logloss:0.17658\tvalid-logloss:0.21668\n",
            "Rund no: 63 Metric : 0.7940104216604645 Max: 0.7940104216604645\n",
            "[0]\ttrain-logloss:0.66207\tvalid-logloss:0.66209\n",
            "[300]\ttrain-logloss:0.21623\tvalid-logloss:0.22259\n",
            "[600]\ttrain-logloss:0.20580\tvalid-logloss:0.21872\n",
            "[900]\ttrain-logloss:0.19843\tvalid-logloss:0.21752\n",
            "[1200]\ttrain-logloss:0.19190\tvalid-logloss:0.21704\n",
            "[1500]\ttrain-logloss:0.18584\tvalid-logloss:0.21676\n",
            "[1609]\ttrain-logloss:0.18372\tvalid-logloss:0.21677\n",
            "Rund no: 64 Metric : 0.7926650690415363 Max: 0.7940104216604645\n",
            "[0]\ttrain-logloss:0.66207\tvalid-logloss:0.66209\n",
            "[300]\ttrain-logloss:0.21619\tvalid-logloss:0.22251\n",
            "[600]\ttrain-logloss:0.20588\tvalid-logloss:0.21864\n",
            "[900]\ttrain-logloss:0.19841\tvalid-logloss:0.21738\n",
            "[1200]\ttrain-logloss:0.19190\tvalid-logloss:0.21685\n",
            "[1500]\ttrain-logloss:0.18584\tvalid-logloss:0.21649\n",
            "[1800]\ttrain-logloss:0.18005\tvalid-logloss:0.21636\n",
            "[1893]\ttrain-logloss:0.17834\tvalid-logloss:0.21637\n",
            "Rund no: 65 Metric : 0.7936716430735264 Max: 0.7940104216604645\n",
            "[0]\ttrain-logloss:0.66207\tvalid-logloss:0.66209\n",
            "[300]\ttrain-logloss:0.21619\tvalid-logloss:0.22247\n",
            "[600]\ttrain-logloss:0.20582\tvalid-logloss:0.21860\n",
            "[900]\ttrain-logloss:0.19834\tvalid-logloss:0.21754\n",
            "[1200]\ttrain-logloss:0.19187\tvalid-logloss:0.21701\n",
            "[1500]\ttrain-logloss:0.18574\tvalid-logloss:0.21668\n",
            "[1800]\ttrain-logloss:0.18000\tvalid-logloss:0.21654\n",
            "[1964]\ttrain-logloss:0.17702\tvalid-logloss:0.21657\n",
            "Rund no: 66 Metric : 0.7936009111862952 Max: 0.7940104216604645\n",
            "[0]\ttrain-logloss:0.66207\tvalid-logloss:0.66209\n",
            "[300]\ttrain-logloss:0.21622\tvalid-logloss:0.22262\n",
            "[600]\ttrain-logloss:0.20586\tvalid-logloss:0.21880\n",
            "[900]\ttrain-logloss:0.19846\tvalid-logloss:0.21769\n",
            "[1200]\ttrain-logloss:0.19200\tvalid-logloss:0.21717\n",
            "[1432]\ttrain-logloss:0.18724\tvalid-logloss:0.21710\n",
            "Rund no: 67 Metric : 0.7923958451707109 Max: 0.7940104216604645\n",
            "[0]\ttrain-logloss:0.66207\tvalid-logloss:0.66209\n",
            "[300]\ttrain-logloss:0.21622\tvalid-logloss:0.22261\n",
            "[600]\ttrain-logloss:0.20584\tvalid-logloss:0.21874\n",
            "[900]\ttrain-logloss:0.19839\tvalid-logloss:0.21762\n",
            "[1200]\ttrain-logloss:0.19196\tvalid-logloss:0.21713\n",
            "[1491]\ttrain-logloss:0.18601\tvalid-logloss:0.21694\n",
            "Rund no: 68 Metric : 0.7929604956554379 Max: 0.7940104216604645\n",
            "[0]\ttrain-logloss:0.66207\tvalid-logloss:0.66209\n",
            "[300]\ttrain-logloss:0.21626\tvalid-logloss:0.22272\n",
            "[600]\ttrain-logloss:0.20588\tvalid-logloss:0.21888\n",
            "[900]\ttrain-logloss:0.19848\tvalid-logloss:0.21774\n",
            "[1200]\ttrain-logloss:0.19198\tvalid-logloss:0.21724\n",
            "[1500]\ttrain-logloss:0.18584\tvalid-logloss:0.21693\n",
            "[1749]\ttrain-logloss:0.18114\tvalid-logloss:0.21690\n",
            "Rund no: 69 Metric : 0.7932171594319822 Max: 0.7940104216604645\n",
            "[0]\ttrain-logloss:0.66207\tvalid-logloss:0.66209\n",
            "[300]\ttrain-logloss:0.21612\tvalid-logloss:0.22258\n",
            "[600]\ttrain-logloss:0.20575\tvalid-logloss:0.21876\n",
            "[900]\ttrain-logloss:0.19837\tvalid-logloss:0.21777\n",
            "[1200]\ttrain-logloss:0.19191\tvalid-logloss:0.21737\n",
            "[1500]\ttrain-logloss:0.18578\tvalid-logloss:0.21715\n",
            "[1800]\ttrain-logloss:0.18004\tvalid-logloss:0.21709\n",
            "[1894]\ttrain-logloss:0.17831\tvalid-logloss:0.21713\n",
            "Rund no: 70 Metric : 0.7925908515076656 Max: 0.7940104216604645\n",
            "[0]\ttrain-logloss:0.66207\tvalid-logloss:0.66209\n",
            "[300]\ttrain-logloss:0.21619\tvalid-logloss:0.22251\n",
            "[600]\ttrain-logloss:0.20581\tvalid-logloss:0.21857\n",
            "[900]\ttrain-logloss:0.19831\tvalid-logloss:0.21746\n",
            "[1200]\ttrain-logloss:0.19190\tvalid-logloss:0.21708\n",
            "[1500]\ttrain-logloss:0.18584\tvalid-logloss:0.21681\n",
            "[1800]\ttrain-logloss:0.18011\tvalid-logloss:0.21663\n",
            "[1897]\ttrain-logloss:0.17832\tvalid-logloss:0.21664\n",
            "Rund no: 71 Metric : 0.7933452771654945 Max: 0.7940104216604645\n",
            "[0]\ttrain-logloss:0.66207\tvalid-logloss:0.66209\n",
            "[300]\ttrain-logloss:0.21617\tvalid-logloss:0.22253\n",
            "[600]\ttrain-logloss:0.20578\tvalid-logloss:0.21881\n",
            "[900]\ttrain-logloss:0.19836\tvalid-logloss:0.21772\n",
            "[1200]\ttrain-logloss:0.19187\tvalid-logloss:0.21731\n",
            "[1500]\ttrain-logloss:0.18576\tvalid-logloss:0.21692\n",
            "[1659]\ttrain-logloss:0.18276\tvalid-logloss:0.21693\n",
            "Rund no: 72 Metric : 0.7934796493759496 Max: 0.7940104216604645\n",
            "[0]\ttrain-logloss:0.66207\tvalid-logloss:0.66209\n",
            "[300]\ttrain-logloss:0.21618\tvalid-logloss:0.22268\n",
            "[600]\ttrain-logloss:0.20583\tvalid-logloss:0.21887\n",
            "[900]\ttrain-logloss:0.19840\tvalid-logloss:0.21773\n",
            "[1200]\ttrain-logloss:0.19195\tvalid-logloss:0.21714\n",
            "[1500]\ttrain-logloss:0.18578\tvalid-logloss:0.21679\n",
            "[1745]\ttrain-logloss:0.18106\tvalid-logloss:0.21673\n",
            "Rund no: 73 Metric : 0.7927469954477865 Max: 0.7940104216604645\n",
            "[0]\ttrain-logloss:0.66207\tvalid-logloss:0.66209\n",
            "[300]\ttrain-logloss:0.21615\tvalid-logloss:0.22251\n",
            "[600]\ttrain-logloss:0.20584\tvalid-logloss:0.21876\n",
            "[900]\ttrain-logloss:0.19836\tvalid-logloss:0.21759\n",
            "[1200]\ttrain-logloss:0.19192\tvalid-logloss:0.21709\n",
            "[1500]\ttrain-logloss:0.18578\tvalid-logloss:0.21686\n",
            "[1659]\ttrain-logloss:0.18276\tvalid-logloss:0.21682\n",
            "Rund no: 74 Metric : 0.7920970312646958 Max: 0.7940104216604645\n",
            "[0]\ttrain-logloss:0.66207\tvalid-logloss:0.66209\n",
            "[300]\ttrain-logloss:0.21624\tvalid-logloss:0.22256\n",
            "[600]\ttrain-logloss:0.20587\tvalid-logloss:0.21873\n",
            "[900]\ttrain-logloss:0.19850\tvalid-logloss:0.21757\n",
            "[1200]\ttrain-logloss:0.19205\tvalid-logloss:0.21707\n",
            "[1500]\ttrain-logloss:0.18595\tvalid-logloss:0.21683\n",
            "[1800]\ttrain-logloss:0.18024\tvalid-logloss:0.21672\n",
            "[1879]\ttrain-logloss:0.17880\tvalid-logloss:0.21674\n",
            "Rund no: 75 Metric : 0.7922077708317319 Max: 0.7940104216604645\n",
            "[0]\ttrain-logloss:0.66207\tvalid-logloss:0.66209\n",
            "[300]\ttrain-logloss:0.21622\tvalid-logloss:0.22261\n",
            "[600]\ttrain-logloss:0.20583\tvalid-logloss:0.21881\n",
            "[900]\ttrain-logloss:0.19837\tvalid-logloss:0.21757\n",
            "[1200]\ttrain-logloss:0.19198\tvalid-logloss:0.21703\n",
            "[1500]\ttrain-logloss:0.18587\tvalid-logloss:0.21677\n",
            "[1800]\ttrain-logloss:0.18017\tvalid-logloss:0.21666\n",
            "[2100]\ttrain-logloss:0.17475\tvalid-logloss:0.21660\n",
            "[2150]\ttrain-logloss:0.17389\tvalid-logloss:0.21661\n",
            "Rund no: 76 Metric : 0.7937289334353391 Max: 0.7940104216604645\n",
            "[0]\ttrain-logloss:0.66207\tvalid-logloss:0.66209\n",
            "[300]\ttrain-logloss:0.21622\tvalid-logloss:0.22261\n",
            "[600]\ttrain-logloss:0.20582\tvalid-logloss:0.21872\n",
            "[900]\ttrain-logloss:0.19838\tvalid-logloss:0.21764\n",
            "[1200]\ttrain-logloss:0.19190\tvalid-logloss:0.21712\n",
            "[1500]\ttrain-logloss:0.18583\tvalid-logloss:0.21683\n",
            "[1571]\ttrain-logloss:0.18446\tvalid-logloss:0.21684\n",
            "Rund no: 77 Metric : 0.7935083649323963 Max: 0.7940104216604645\n",
            "[0]\ttrain-logloss:0.66207\tvalid-logloss:0.66209\n",
            "[300]\ttrain-logloss:0.21622\tvalid-logloss:0.22261\n",
            "[600]\ttrain-logloss:0.20585\tvalid-logloss:0.21886\n",
            "[900]\ttrain-logloss:0.19845\tvalid-logloss:0.21764\n",
            "[1200]\ttrain-logloss:0.19204\tvalid-logloss:0.21724\n",
            "[1500]\ttrain-logloss:0.18586\tvalid-logloss:0.21691\n",
            "[1800]\ttrain-logloss:0.18013\tvalid-logloss:0.21676\n",
            "[2059]\ttrain-logloss:0.17545\tvalid-logloss:0.21679\n",
            "Rund no: 78 Metric : 0.7934335202260353 Max: 0.7940104216604645\n",
            "[0]\ttrain-logloss:0.66207\tvalid-logloss:0.66209\n",
            "[300]\ttrain-logloss:0.21616\tvalid-logloss:0.22252\n",
            "[600]\ttrain-logloss:0.20583\tvalid-logloss:0.21878\n",
            "[900]\ttrain-logloss:0.19841\tvalid-logloss:0.21752\n",
            "[1200]\ttrain-logloss:0.19191\tvalid-logloss:0.21707\n",
            "[1500]\ttrain-logloss:0.18580\tvalid-logloss:0.21671\n",
            "[1800]\ttrain-logloss:0.18007\tvalid-logloss:0.21659\n",
            "[1892]\ttrain-logloss:0.17838\tvalid-logloss:0.21664\n",
            "Rund no: 79 Metric : 0.7936624544511708 Max: 0.7940104216604645\n",
            "[0]\ttrain-logloss:0.66207\tvalid-logloss:0.66209\n",
            "[300]\ttrain-logloss:0.21618\tvalid-logloss:0.22259\n",
            "[600]\ttrain-logloss:0.20579\tvalid-logloss:0.21873\n",
            "[900]\ttrain-logloss:0.19842\tvalid-logloss:0.21763\n",
            "[1200]\ttrain-logloss:0.19193\tvalid-logloss:0.21705\n",
            "[1443]\ttrain-logloss:0.18696\tvalid-logloss:0.21697\n",
            "Rund no: 80 Metric : 0.7923456432226611 Max: 0.7940104216604645\n",
            "[0]\ttrain-logloss:0.66207\tvalid-logloss:0.66209\n",
            "[300]\ttrain-logloss:0.21613\tvalid-logloss:0.22252\n",
            "[600]\ttrain-logloss:0.20585\tvalid-logloss:0.21876\n",
            "[900]\ttrain-logloss:0.19837\tvalid-logloss:0.21752\n",
            "[1200]\ttrain-logloss:0.19190\tvalid-logloss:0.21708\n",
            "[1500]\ttrain-logloss:0.18576\tvalid-logloss:0.21690\n",
            "[1800]\ttrain-logloss:0.18004\tvalid-logloss:0.21673\n",
            "[2100]\ttrain-logloss:0.17466\tvalid-logloss:0.21676\n",
            "[2122]\ttrain-logloss:0.17429\tvalid-logloss:0.21679\n",
            "Rund no: 81 Metric : 0.7926429854447965 Max: 0.7940104216604645\n",
            "[0]\ttrain-logloss:0.66207\tvalid-logloss:0.66209\n",
            "[300]\ttrain-logloss:0.21619\tvalid-logloss:0.22263\n",
            "[600]\ttrain-logloss:0.20582\tvalid-logloss:0.21876\n",
            "[900]\ttrain-logloss:0.19844\tvalid-logloss:0.21754\n",
            "[1200]\ttrain-logloss:0.19196\tvalid-logloss:0.21707\n",
            "[1500]\ttrain-logloss:0.18585\tvalid-logloss:0.21679\n",
            "[1609]\ttrain-logloss:0.18371\tvalid-logloss:0.21681\n",
            "Rund no: 82 Metric : 0.7926141553084526 Max: 0.7940104216604645\n",
            "[0]\ttrain-logloss:0.66207\tvalid-logloss:0.66209\n",
            "[300]\ttrain-logloss:0.21626\tvalid-logloss:0.22258\n",
            "[600]\ttrain-logloss:0.20584\tvalid-logloss:0.21864\n",
            "[900]\ttrain-logloss:0.19846\tvalid-logloss:0.21744\n",
            "[1200]\ttrain-logloss:0.19199\tvalid-logloss:0.21696\n",
            "[1500]\ttrain-logloss:0.18587\tvalid-logloss:0.21667\n",
            "[1658]\ttrain-logloss:0.18285\tvalid-logloss:0.21663\n",
            "Rund no: 83 Metric : 0.7930988404112717 Max: 0.7940104216604645\n",
            "[0]\ttrain-logloss:0.66207\tvalid-logloss:0.66209\n",
            "[300]\ttrain-logloss:0.21611\tvalid-logloss:0.22253\n",
            "[600]\ttrain-logloss:0.20586\tvalid-logloss:0.21877\n",
            "[900]\ttrain-logloss:0.19839\tvalid-logloss:0.21752\n",
            "[1200]\ttrain-logloss:0.19189\tvalid-logloss:0.21697\n",
            "[1492]\ttrain-logloss:0.18594\tvalid-logloss:0.21685\n",
            "Rund no: 84 Metric : 0.792656760868938 Max: 0.7940104216604645\n",
            "[0]\ttrain-logloss:0.66207\tvalid-logloss:0.66209\n",
            "[300]\ttrain-logloss:0.21619\tvalid-logloss:0.22265\n",
            "[600]\ttrain-logloss:0.20578\tvalid-logloss:0.21882\n",
            "[900]\ttrain-logloss:0.19838\tvalid-logloss:0.21786\n",
            "[1200]\ttrain-logloss:0.19192\tvalid-logloss:0.21741\n",
            "[1500]\ttrain-logloss:0.18580\tvalid-logloss:0.21720\n",
            "[1765]\ttrain-logloss:0.18077\tvalid-logloss:0.21715\n",
            "Rund no: 85 Metric : 0.7920150366436252 Max: 0.7940104216604645\n",
            "[0]\ttrain-logloss:0.66207\tvalid-logloss:0.66209\n",
            "[300]\ttrain-logloss:0.21621\tvalid-logloss:0.22250\n",
            "[600]\ttrain-logloss:0.20584\tvalid-logloss:0.21866\n",
            "[900]\ttrain-logloss:0.19842\tvalid-logloss:0.21746\n",
            "[1200]\ttrain-logloss:0.19194\tvalid-logloss:0.21695\n",
            "[1500]\ttrain-logloss:0.18579\tvalid-logloss:0.21671\n",
            "[1800]\ttrain-logloss:0.18004\tvalid-logloss:0.21653\n",
            "[1891]\ttrain-logloss:0.17838\tvalid-logloss:0.21658\n",
            "Rund no: 86 Metric : 0.7935915936073239 Max: 0.7940104216604645\n",
            "[0]\ttrain-logloss:0.66207\tvalid-logloss:0.66209\n",
            "[300]\ttrain-logloss:0.21624\tvalid-logloss:0.22256\n",
            "[600]\ttrain-logloss:0.20581\tvalid-logloss:0.21868\n",
            "[900]\ttrain-logloss:0.19837\tvalid-logloss:0.21741\n",
            "[1200]\ttrain-logloss:0.19190\tvalid-logloss:0.21700\n",
            "[1500]\ttrain-logloss:0.18578\tvalid-logloss:0.21671\n",
            "[1653]\ttrain-logloss:0.18282\tvalid-logloss:0.21666\n",
            "Rund no: 87 Metric : 0.7931935480700258 Max: 0.7940104216604645\n",
            "[0]\ttrain-logloss:0.66207\tvalid-logloss:0.66209\n",
            "[300]\ttrain-logloss:0.21612\tvalid-logloss:0.22254\n",
            "[600]\ttrain-logloss:0.20580\tvalid-logloss:0.21879\n",
            "[900]\ttrain-logloss:0.19836\tvalid-logloss:0.21762\n",
            "[1200]\ttrain-logloss:0.19194\tvalid-logloss:0.21725\n",
            "[1500]\ttrain-logloss:0.18584\tvalid-logloss:0.21692\n",
            "[1752]\ttrain-logloss:0.18112\tvalid-logloss:0.21684\n",
            "Rund no: 88 Metric : 0.7930345263043448 Max: 0.7940104216604645\n",
            "[0]\ttrain-logloss:0.66207\tvalid-logloss:0.66209\n",
            "[300]\ttrain-logloss:0.21620\tvalid-logloss:0.22262\n",
            "[600]\ttrain-logloss:0.20584\tvalid-logloss:0.21869\n",
            "[900]\ttrain-logloss:0.19838\tvalid-logloss:0.21756\n",
            "[1200]\ttrain-logloss:0.19197\tvalid-logloss:0.21699\n",
            "[1500]\ttrain-logloss:0.18589\tvalid-logloss:0.21676\n",
            "[1800]\ttrain-logloss:0.18016\tvalid-logloss:0.21661\n",
            "[1942]\ttrain-logloss:0.17755\tvalid-logloss:0.21663\n",
            "Rund no: 89 Metric : 0.7938144199640923 Max: 0.7940104216604645\n",
            "[0]\ttrain-logloss:0.66207\tvalid-logloss:0.66209\n",
            "[300]\ttrain-logloss:0.21621\tvalid-logloss:0.22260\n",
            "[600]\ttrain-logloss:0.20586\tvalid-logloss:0.21875\n",
            "[900]\ttrain-logloss:0.19842\tvalid-logloss:0.21759\n",
            "[1200]\ttrain-logloss:0.19195\tvalid-logloss:0.21720\n",
            "[1500]\ttrain-logloss:0.18587\tvalid-logloss:0.21691\n",
            "[1637]\ttrain-logloss:0.18317\tvalid-logloss:0.21688\n",
            "Rund no: 90 Metric : 0.7924836675753213 Max: 0.7940104216604645\n",
            "[0]\ttrain-logloss:0.66207\tvalid-logloss:0.66209\n",
            "[300]\ttrain-logloss:0.21622\tvalid-logloss:0.22261\n",
            "[600]\ttrain-logloss:0.20581\tvalid-logloss:0.21885\n",
            "[900]\ttrain-logloss:0.19840\tvalid-logloss:0.21779\n",
            "[1200]\ttrain-logloss:0.19194\tvalid-logloss:0.21724\n",
            "[1500]\ttrain-logloss:0.18581\tvalid-logloss:0.21704\n",
            "[1800]\ttrain-logloss:0.18011\tvalid-logloss:0.21689\n",
            "[1869]\ttrain-logloss:0.17885\tvalid-logloss:0.21692\n",
            "Rund no: 91 Metric : 0.7914562815301409 Max: 0.7940104216604645\n",
            "[0]\ttrain-logloss:0.66207\tvalid-logloss:0.66209\n",
            "[300]\ttrain-logloss:0.21619\tvalid-logloss:0.22258\n",
            "[600]\ttrain-logloss:0.20586\tvalid-logloss:0.21876\n",
            "[900]\ttrain-logloss:0.19842\tvalid-logloss:0.21768\n",
            "[1200]\ttrain-logloss:0.19195\tvalid-logloss:0.21716\n",
            "[1500]\ttrain-logloss:0.18580\tvalid-logloss:0.21682\n",
            "[1800]\ttrain-logloss:0.18010\tvalid-logloss:0.21666\n",
            "[1906]\ttrain-logloss:0.17819\tvalid-logloss:0.21670\n",
            "Rund no: 92 Metric : 0.79310081603561 Max: 0.7940104216604645\n",
            "[0]\ttrain-logloss:0.66207\tvalid-logloss:0.66209\n",
            "[300]\ttrain-logloss:0.21618\tvalid-logloss:0.22260\n",
            "[600]\ttrain-logloss:0.20579\tvalid-logloss:0.21873\n",
            "[900]\ttrain-logloss:0.19828\tvalid-logloss:0.21754\n",
            "[1200]\ttrain-logloss:0.19182\tvalid-logloss:0.21702\n",
            "[1500]\ttrain-logloss:0.18569\tvalid-logloss:0.21676\n",
            "[1800]\ttrain-logloss:0.18000\tvalid-logloss:0.21663\n",
            "[2026]\ttrain-logloss:0.17586\tvalid-logloss:0.21667\n",
            "Rund no: 93 Metric : 0.7935622885486122 Max: 0.7940104216604645\n",
            "[0]\ttrain-logloss:0.66207\tvalid-logloss:0.66209\n",
            "[300]\ttrain-logloss:0.21618\tvalid-logloss:0.22264\n",
            "[600]\ttrain-logloss:0.20583\tvalid-logloss:0.21871\n",
            "[900]\ttrain-logloss:0.19836\tvalid-logloss:0.21778\n",
            "[933]\ttrain-logloss:0.19766\tvalid-logloss:0.21772\n",
            "Rund no: 94 Metric : 0.7917087322198513 Max: 0.7940104216604645\n",
            "[0]\ttrain-logloss:0.66207\tvalid-logloss:0.66209\n",
            "[300]\ttrain-logloss:0.21619\tvalid-logloss:0.22260\n",
            "[600]\ttrain-logloss:0.20582\tvalid-logloss:0.21876\n",
            "[900]\ttrain-logloss:0.19843\tvalid-logloss:0.21752\n",
            "[1200]\ttrain-logloss:0.19193\tvalid-logloss:0.21701\n",
            "[1500]\ttrain-logloss:0.18582\tvalid-logloss:0.21670\n",
            "[1800]\ttrain-logloss:0.18016\tvalid-logloss:0.21654\n",
            "[1895]\ttrain-logloss:0.17843\tvalid-logloss:0.21655\n",
            "Rund no: 95 Metric : 0.7951358214006115 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21627\tvalid-logloss:0.22265\n",
            "[600]\ttrain-logloss:0.20590\tvalid-logloss:0.21876\n",
            "[900]\ttrain-logloss:0.19863\tvalid-logloss:0.21768\n",
            "[1200]\ttrain-logloss:0.19205\tvalid-logloss:0.21730\n",
            "[1253]\ttrain-logloss:0.19095\tvalid-logloss:0.21726\n",
            "Rund no: 96 Metric : 0.7918002362054719 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21632\tvalid-logloss:0.22282\n",
            "[600]\ttrain-logloss:0.20590\tvalid-logloss:0.21894\n",
            "[900]\ttrain-logloss:0.19860\tvalid-logloss:0.21780\n",
            "[1200]\ttrain-logloss:0.19196\tvalid-logloss:0.21738\n",
            "[1500]\ttrain-logloss:0.18587\tvalid-logloss:0.21716\n",
            "[1799]\ttrain-logloss:0.18018\tvalid-logloss:0.21715\n",
            "Rund no: 97 Metric : 0.792787283089349 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21627\tvalid-logloss:0.22262\n",
            "[600]\ttrain-logloss:0.20597\tvalid-logloss:0.21864\n",
            "[900]\ttrain-logloss:0.19867\tvalid-logloss:0.21753\n",
            "[1200]\ttrain-logloss:0.19212\tvalid-logloss:0.21708\n",
            "[1241]\ttrain-logloss:0.19127\tvalid-logloss:0.21707\n",
            "Rund no: 98 Metric : 0.7925538433183291 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21628\tvalid-logloss:0.22263\n",
            "[600]\ttrain-logloss:0.20584\tvalid-logloss:0.21875\n",
            "[900]\ttrain-logloss:0.19859\tvalid-logloss:0.21762\n",
            "[1200]\ttrain-logloss:0.19206\tvalid-logloss:0.21740\n",
            "[1243]\ttrain-logloss:0.19116\tvalid-logloss:0.21737\n",
            "Rund no: 99 Metric : 0.7922178395174684 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21626\tvalid-logloss:0.22261\n",
            "[600]\ttrain-logloss:0.20589\tvalid-logloss:0.21880\n",
            "[900]\ttrain-logloss:0.19864\tvalid-logloss:0.21769\n",
            "[1200]\ttrain-logloss:0.19213\tvalid-logloss:0.21712\n",
            "[1500]\ttrain-logloss:0.18598\tvalid-logloss:0.21696\n",
            "[1740]\ttrain-logloss:0.18134\tvalid-logloss:0.21690\n",
            "Rund no: 100 Metric : 0.7923621561324499 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21627\tvalid-logloss:0.22268\n",
            "[600]\ttrain-logloss:0.20586\tvalid-logloss:0.21874\n",
            "[900]\ttrain-logloss:0.19855\tvalid-logloss:0.21767\n",
            "[1200]\ttrain-logloss:0.19201\tvalid-logloss:0.21724\n",
            "[1500]\ttrain-logloss:0.18596\tvalid-logloss:0.21702\n",
            "[1800]\ttrain-logloss:0.18024\tvalid-logloss:0.21685\n",
            "[1869]\ttrain-logloss:0.17899\tvalid-logloss:0.21684\n",
            "Rund no: 101 Metric : 0.7932301168718132 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21626\tvalid-logloss:0.22265\n",
            "[600]\ttrain-logloss:0.20591\tvalid-logloss:0.21892\n",
            "[900]\ttrain-logloss:0.19859\tvalid-logloss:0.21779\n",
            "[1200]\ttrain-logloss:0.19214\tvalid-logloss:0.21729\n",
            "[1248]\ttrain-logloss:0.19114\tvalid-logloss:0.21721\n",
            "Rund no: 102 Metric : 0.7928314283914193 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21628\tvalid-logloss:0.22280\n",
            "[600]\ttrain-logloss:0.20587\tvalid-logloss:0.21890\n",
            "[900]\ttrain-logloss:0.19856\tvalid-logloss:0.21764\n",
            "[1200]\ttrain-logloss:0.19203\tvalid-logloss:0.21709\n",
            "[1500]\ttrain-logloss:0.18597\tvalid-logloss:0.21682\n",
            "[1662]\ttrain-logloss:0.18276\tvalid-logloss:0.21681\n",
            "Rund no: 103 Metric : 0.7925882943826337 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21625\tvalid-logloss:0.22274\n",
            "[600]\ttrain-logloss:0.20591\tvalid-logloss:0.21896\n",
            "[900]\ttrain-logloss:0.19857\tvalid-logloss:0.21782\n",
            "[1200]\ttrain-logloss:0.19201\tvalid-logloss:0.21738\n",
            "[1500]\ttrain-logloss:0.18592\tvalid-logloss:0.21723\n",
            "[1800]\ttrain-logloss:0.18014\tvalid-logloss:0.21712\n",
            "[1919]\ttrain-logloss:0.17800\tvalid-logloss:0.21713\n",
            "Rund no: 104 Metric : 0.7921441244882066 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21626\tvalid-logloss:0.22261\n",
            "[600]\ttrain-logloss:0.20587\tvalid-logloss:0.21880\n",
            "[900]\ttrain-logloss:0.19859\tvalid-logloss:0.21770\n",
            "[1200]\ttrain-logloss:0.19200\tvalid-logloss:0.21722\n",
            "[1500]\ttrain-logloss:0.18592\tvalid-logloss:0.21696\n",
            "[1629]\ttrain-logloss:0.18340\tvalid-logloss:0.21698\n",
            "Rund no: 105 Metric : 0.7919159586563514 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21625\tvalid-logloss:0.22282\n",
            "[600]\ttrain-logloss:0.20589\tvalid-logloss:0.21896\n",
            "[900]\ttrain-logloss:0.19861\tvalid-logloss:0.21779\n",
            "[1200]\ttrain-logloss:0.19204\tvalid-logloss:0.21735\n",
            "[1500]\ttrain-logloss:0.18591\tvalid-logloss:0.21709\n",
            "[1653]\ttrain-logloss:0.18294\tvalid-logloss:0.21707\n",
            "Rund no: 106 Metric : 0.7928974454863864 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21626\tvalid-logloss:0.22277\n",
            "[600]\ttrain-logloss:0.20594\tvalid-logloss:0.21888\n",
            "[900]\ttrain-logloss:0.19861\tvalid-logloss:0.21772\n",
            "[1200]\ttrain-logloss:0.19205\tvalid-logloss:0.21721\n",
            "[1500]\ttrain-logloss:0.18597\tvalid-logloss:0.21694\n",
            "[1800]\ttrain-logloss:0.18024\tvalid-logloss:0.21686\n",
            "[1916]\ttrain-logloss:0.17817\tvalid-logloss:0.21692\n",
            "Rund no: 107 Metric : 0.7947968879911409 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21630\tvalid-logloss:0.22284\n",
            "[600]\ttrain-logloss:0.20590\tvalid-logloss:0.21895\n",
            "[900]\ttrain-logloss:0.19857\tvalid-logloss:0.21776\n",
            "[1200]\ttrain-logloss:0.19200\tvalid-logloss:0.21732\n",
            "[1242]\ttrain-logloss:0.19109\tvalid-logloss:0.21727\n",
            "Rund no: 108 Metric : 0.791768281861788 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21627\tvalid-logloss:0.22265\n",
            "[600]\ttrain-logloss:0.20588\tvalid-logloss:0.21876\n",
            "[900]\ttrain-logloss:0.19863\tvalid-logloss:0.21761\n",
            "[1200]\ttrain-logloss:0.19211\tvalid-logloss:0.21713\n",
            "[1500]\ttrain-logloss:0.18601\tvalid-logloss:0.21685\n",
            "[1653]\ttrain-logloss:0.18303\tvalid-logloss:0.21683\n",
            "Rund no: 109 Metric : 0.7925093500953692 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21624\tvalid-logloss:0.22279\n",
            "[600]\ttrain-logloss:0.20591\tvalid-logloss:0.21910\n",
            "[900]\ttrain-logloss:0.19857\tvalid-logloss:0.21794\n",
            "[1200]\ttrain-logloss:0.19205\tvalid-logloss:0.21768\n",
            "[1250]\ttrain-logloss:0.19101\tvalid-logloss:0.21758\n",
            "Rund no: 110 Metric : 0.7923430174299764 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21635\tvalid-logloss:0.22279\n",
            "[600]\ttrain-logloss:0.20589\tvalid-logloss:0.21885\n",
            "[900]\ttrain-logloss:0.19854\tvalid-logloss:0.21768\n",
            "[1200]\ttrain-logloss:0.19195\tvalid-logloss:0.21727\n",
            "[1500]\ttrain-logloss:0.18583\tvalid-logloss:0.21697\n",
            "[1659]\ttrain-logloss:0.18279\tvalid-logloss:0.21697\n",
            "Rund no: 111 Metric : 0.7923522025382792 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21624\tvalid-logloss:0.22266\n",
            "[600]\ttrain-logloss:0.20583\tvalid-logloss:0.21885\n",
            "[900]\ttrain-logloss:0.19864\tvalid-logloss:0.21772\n",
            "[1200]\ttrain-logloss:0.19209\tvalid-logloss:0.21719\n",
            "[1500]\ttrain-logloss:0.18604\tvalid-logloss:0.21697\n",
            "[1653]\ttrain-logloss:0.18305\tvalid-logloss:0.21694\n",
            "Rund no: 112 Metric : 0.7919428024290522 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21623\tvalid-logloss:0.22267\n",
            "[600]\ttrain-logloss:0.20588\tvalid-logloss:0.21884\n",
            "[900]\ttrain-logloss:0.19852\tvalid-logloss:0.21778\n",
            "[1200]\ttrain-logloss:0.19198\tvalid-logloss:0.21737\n",
            "[1500]\ttrain-logloss:0.18588\tvalid-logloss:0.21706\n",
            "[1745]\ttrain-logloss:0.18112\tvalid-logloss:0.21700\n",
            "Rund no: 113 Metric : 0.7940743136034668 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21620\tvalid-logloss:0.22265\n",
            "[600]\ttrain-logloss:0.20590\tvalid-logloss:0.21875\n",
            "[900]\ttrain-logloss:0.19862\tvalid-logloss:0.21766\n",
            "[1200]\ttrain-logloss:0.19206\tvalid-logloss:0.21708\n",
            "[1500]\ttrain-logloss:0.18601\tvalid-logloss:0.21682\n",
            "[1660]\ttrain-logloss:0.18290\tvalid-logloss:0.21681\n",
            "Rund no: 114 Metric : 0.7930844028500328 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21627\tvalid-logloss:0.22265\n",
            "[600]\ttrain-logloss:0.20586\tvalid-logloss:0.21868\n",
            "[900]\ttrain-logloss:0.19863\tvalid-logloss:0.21768\n",
            "[1200]\ttrain-logloss:0.19203\tvalid-logloss:0.21720\n",
            "[1500]\ttrain-logloss:0.18593\tvalid-logloss:0.21693\n",
            "[1656]\ttrain-logloss:0.18291\tvalid-logloss:0.21694\n",
            "Rund no: 115 Metric : 0.7933022689893461 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21629\tvalid-logloss:0.22277\n",
            "[600]\ttrain-logloss:0.20584\tvalid-logloss:0.21886\n",
            "[900]\ttrain-logloss:0.19853\tvalid-logloss:0.21769\n",
            "[1200]\ttrain-logloss:0.19199\tvalid-logloss:0.21720\n",
            "[1500]\ttrain-logloss:0.18586\tvalid-logloss:0.21696\n",
            "[1704]\ttrain-logloss:0.18190\tvalid-logloss:0.21692\n",
            "Rund no: 116 Metric : 0.7932554337452284 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21624\tvalid-logloss:0.22276\n",
            "[600]\ttrain-logloss:0.20588\tvalid-logloss:0.21885\n",
            "[900]\ttrain-logloss:0.19856\tvalid-logloss:0.21762\n",
            "[1200]\ttrain-logloss:0.19199\tvalid-logloss:0.21712\n",
            "[1500]\ttrain-logloss:0.18593\tvalid-logloss:0.21682\n",
            "[1722]\ttrain-logloss:0.18160\tvalid-logloss:0.21680\n",
            "Rund no: 117 Metric : 0.7929925031518561 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21625\tvalid-logloss:0.22259\n",
            "[600]\ttrain-logloss:0.20582\tvalid-logloss:0.21864\n",
            "[900]\ttrain-logloss:0.19850\tvalid-logloss:0.21750\n",
            "[1200]\ttrain-logloss:0.19194\tvalid-logloss:0.21724\n",
            "[1250]\ttrain-logloss:0.19087\tvalid-logloss:0.21714\n",
            "Rund no: 118 Metric : 0.7929008139804261 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21627\tvalid-logloss:0.22262\n",
            "[600]\ttrain-logloss:0.20585\tvalid-logloss:0.21873\n",
            "[900]\ttrain-logloss:0.19856\tvalid-logloss:0.21763\n",
            "[1200]\ttrain-logloss:0.19204\tvalid-logloss:0.21715\n",
            "[1500]\ttrain-logloss:0.18596\tvalid-logloss:0.21682\n",
            "[1800]\ttrain-logloss:0.18024\tvalid-logloss:0.21674\n",
            "[2091]\ttrain-logloss:0.17503\tvalid-logloss:0.21673\n",
            "Rund no: 119 Metric : 0.7933623358516322 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21625\tvalid-logloss:0.22266\n",
            "[600]\ttrain-logloss:0.20588\tvalid-logloss:0.21884\n",
            "[900]\ttrain-logloss:0.19859\tvalid-logloss:0.21767\n",
            "[1200]\ttrain-logloss:0.19198\tvalid-logloss:0.21723\n",
            "[1500]\ttrain-logloss:0.18589\tvalid-logloss:0.21699\n",
            "[1644]\ttrain-logloss:0.18305\tvalid-logloss:0.21701\n",
            "Rund no: 120 Metric : 0.7924660791225457 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21632\tvalid-logloss:0.22281\n",
            "[600]\ttrain-logloss:0.20594\tvalid-logloss:0.21890\n",
            "[900]\ttrain-logloss:0.19865\tvalid-logloss:0.21780\n",
            "[1200]\ttrain-logloss:0.19210\tvalid-logloss:0.21736\n",
            "[1238]\ttrain-logloss:0.19131\tvalid-logloss:0.21735\n",
            "Rund no: 121 Metric : 0.7927365776060258 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21626\tvalid-logloss:0.22267\n",
            "[600]\ttrain-logloss:0.20586\tvalid-logloss:0.21865\n",
            "[900]\ttrain-logloss:0.19859\tvalid-logloss:0.21757\n",
            "[1200]\ttrain-logloss:0.19206\tvalid-logloss:0.21712\n",
            "[1500]\ttrain-logloss:0.18591\tvalid-logloss:0.21695\n",
            "[1661]\ttrain-logloss:0.18277\tvalid-logloss:0.21692\n",
            "Rund no: 122 Metric : 0.7930114051242816 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21633\tvalid-logloss:0.22278\n",
            "[600]\ttrain-logloss:0.20592\tvalid-logloss:0.21884\n",
            "[900]\ttrain-logloss:0.19867\tvalid-logloss:0.21769\n",
            "[1200]\ttrain-logloss:0.19207\tvalid-logloss:0.21724\n",
            "[1243]\ttrain-logloss:0.19118\tvalid-logloss:0.21721\n",
            "Rund no: 123 Metric : 0.7921924413219894 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21630\tvalid-logloss:0.22285\n",
            "[600]\ttrain-logloss:0.20588\tvalid-logloss:0.21895\n",
            "[900]\ttrain-logloss:0.19861\tvalid-logloss:0.21787\n",
            "[1200]\ttrain-logloss:0.19205\tvalid-logloss:0.21732\n",
            "[1500]\ttrain-logloss:0.18592\tvalid-logloss:0.21714\n",
            "[1643]\ttrain-logloss:0.18314\tvalid-logloss:0.21711\n",
            "Rund no: 124 Metric : 0.7923065031089415 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21628\tvalid-logloss:0.22269\n",
            "[600]\ttrain-logloss:0.20586\tvalid-logloss:0.21872\n",
            "[900]\ttrain-logloss:0.19854\tvalid-logloss:0.21754\n",
            "[1200]\ttrain-logloss:0.19199\tvalid-logloss:0.21718\n",
            "[1244]\ttrain-logloss:0.19108\tvalid-logloss:0.21717\n",
            "Rund no: 125 Metric : 0.7920843856009865 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21628\tvalid-logloss:0.22279\n",
            "[600]\ttrain-logloss:0.20593\tvalid-logloss:0.21898\n",
            "[900]\ttrain-logloss:0.19859\tvalid-logloss:0.21778\n",
            "[1200]\ttrain-logloss:0.19198\tvalid-logloss:0.21727\n",
            "[1379]\ttrain-logloss:0.18828\tvalid-logloss:0.21732\n",
            "Rund no: 126 Metric : 0.7924793066259694 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21627\tvalid-logloss:0.22267\n",
            "[600]\ttrain-logloss:0.20586\tvalid-logloss:0.21866\n",
            "[900]\ttrain-logloss:0.19856\tvalid-logloss:0.21758\n",
            "[1200]\ttrain-logloss:0.19203\tvalid-logloss:0.21704\n",
            "[1500]\ttrain-logloss:0.18592\tvalid-logloss:0.21671\n",
            "[1653]\ttrain-logloss:0.18296\tvalid-logloss:0.21669\n",
            "Rund no: 127 Metric : 0.7924428530957228 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21625\tvalid-logloss:0.22260\n",
            "[600]\ttrain-logloss:0.20588\tvalid-logloss:0.21872\n",
            "[900]\ttrain-logloss:0.19854\tvalid-logloss:0.21762\n",
            "[1200]\ttrain-logloss:0.19195\tvalid-logloss:0.21711\n",
            "[1427]\ttrain-logloss:0.18734\tvalid-logloss:0.21702\n",
            "Rund no: 128 Metric : 0.7927702250379491 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21626\tvalid-logloss:0.22266\n",
            "[600]\ttrain-logloss:0.20587\tvalid-logloss:0.21880\n",
            "[900]\ttrain-logloss:0.19866\tvalid-logloss:0.21771\n",
            "[1200]\ttrain-logloss:0.19207\tvalid-logloss:0.21727\n",
            "[1446]\ttrain-logloss:0.18698\tvalid-logloss:0.21707\n",
            "Rund no: 129 Metric : 0.7926606299544106 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21627\tvalid-logloss:0.22265\n",
            "[600]\ttrain-logloss:0.20592\tvalid-logloss:0.21876\n",
            "[900]\ttrain-logloss:0.19855\tvalid-logloss:0.21771\n",
            "[1200]\ttrain-logloss:0.19202\tvalid-logloss:0.21749\n",
            "[1243]\ttrain-logloss:0.19110\tvalid-logloss:0.21738\n",
            "Rund no: 130 Metric : 0.791962516884483 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21623\tvalid-logloss:0.22257\n",
            "[600]\ttrain-logloss:0.20589\tvalid-logloss:0.21871\n",
            "[900]\ttrain-logloss:0.19850\tvalid-logloss:0.21757\n",
            "[1200]\ttrain-logloss:0.19196\tvalid-logloss:0.21711\n",
            "[1500]\ttrain-logloss:0.18585\tvalid-logloss:0.21686\n",
            "[1647]\ttrain-logloss:0.18299\tvalid-logloss:0.21684\n",
            "Rund no: 131 Metric : 0.792142205390417 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21629\tvalid-logloss:0.22281\n",
            "[600]\ttrain-logloss:0.20586\tvalid-logloss:0.21895\n",
            "[900]\ttrain-logloss:0.19855\tvalid-logloss:0.21778\n",
            "[1200]\ttrain-logloss:0.19202\tvalid-logloss:0.21734\n",
            "[1500]\ttrain-logloss:0.18590\tvalid-logloss:0.21706\n",
            "[1735]\ttrain-logloss:0.18138\tvalid-logloss:0.21702\n",
            "Rund no: 132 Metric : 0.7927410235224757 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21627\tvalid-logloss:0.22265\n",
            "[600]\ttrain-logloss:0.20584\tvalid-logloss:0.21863\n",
            "[900]\ttrain-logloss:0.19856\tvalid-logloss:0.21759\n",
            "[1200]\ttrain-logloss:0.19197\tvalid-logloss:0.21711\n",
            "[1500]\ttrain-logloss:0.18589\tvalid-logloss:0.21676\n",
            "[1800]\ttrain-logloss:0.18017\tvalid-logloss:0.21670\n",
            "[1822]\ttrain-logloss:0.17980\tvalid-logloss:0.21668\n",
            "Rund no: 133 Metric : 0.7942361229479449 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21633\tvalid-logloss:0.22291\n",
            "[600]\ttrain-logloss:0.20581\tvalid-logloss:0.21894\n",
            "[900]\ttrain-logloss:0.19854\tvalid-logloss:0.21772\n",
            "[1200]\ttrain-logloss:0.19202\tvalid-logloss:0.21724\n",
            "[1500]\ttrain-logloss:0.18588\tvalid-logloss:0.21706\n",
            "[1663]\ttrain-logloss:0.18272\tvalid-logloss:0.21708\n",
            "Rund no: 134 Metric : 0.7925558387882817 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21627\tvalid-logloss:0.22271\n",
            "[600]\ttrain-logloss:0.20589\tvalid-logloss:0.21888\n",
            "[900]\ttrain-logloss:0.19866\tvalid-logloss:0.21775\n",
            "[1200]\ttrain-logloss:0.19206\tvalid-logloss:0.21726\n",
            "[1394]\ttrain-logloss:0.18804\tvalid-logloss:0.21721\n",
            "Rund no: 135 Metric : 0.7917438510720548 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21625\tvalid-logloss:0.22268\n",
            "[600]\ttrain-logloss:0.20584\tvalid-logloss:0.21872\n",
            "[900]\ttrain-logloss:0.19854\tvalid-logloss:0.21749\n",
            "[1200]\ttrain-logloss:0.19200\tvalid-logloss:0.21702\n",
            "[1246]\ttrain-logloss:0.19104\tvalid-logloss:0.21702\n",
            "Rund no: 136 Metric : 0.7930913742590548 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21624\tvalid-logloss:0.22268\n",
            "[600]\ttrain-logloss:0.20583\tvalid-logloss:0.21881\n",
            "[900]\ttrain-logloss:0.19859\tvalid-logloss:0.21774\n",
            "[1200]\ttrain-logloss:0.19199\tvalid-logloss:0.21737\n",
            "[1246]\ttrain-logloss:0.19103\tvalid-logloss:0.21731\n",
            "Rund no: 137 Metric : 0.7922683875053463 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21623\tvalid-logloss:0.22275\n",
            "[600]\ttrain-logloss:0.20588\tvalid-logloss:0.21887\n",
            "[900]\ttrain-logloss:0.19859\tvalid-logloss:0.21771\n",
            "[1200]\ttrain-logloss:0.19207\tvalid-logloss:0.21729\n",
            "[1500]\ttrain-logloss:0.18600\tvalid-logloss:0.21696\n",
            "[1662]\ttrain-logloss:0.18282\tvalid-logloss:0.21696\n",
            "Rund no: 138 Metric : 0.793132613526206 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21627\tvalid-logloss:0.22262\n",
            "[600]\ttrain-logloss:0.20591\tvalid-logloss:0.21882\n",
            "[900]\ttrain-logloss:0.19864\tvalid-logloss:0.21767\n",
            "[1200]\ttrain-logloss:0.19202\tvalid-logloss:0.21715\n",
            "[1500]\ttrain-logloss:0.18593\tvalid-logloss:0.21695\n",
            "[1800]\ttrain-logloss:0.18019\tvalid-logloss:0.21673\n",
            "[2062]\ttrain-logloss:0.17546\tvalid-logloss:0.21667\n",
            "Rund no: 139 Metric : 0.7932400129656778 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21627\tvalid-logloss:0.22265\n",
            "[600]\ttrain-logloss:0.20589\tvalid-logloss:0.21875\n",
            "[900]\ttrain-logloss:0.19860\tvalid-logloss:0.21756\n",
            "[1200]\ttrain-logloss:0.19205\tvalid-logloss:0.21709\n",
            "[1500]\ttrain-logloss:0.18590\tvalid-logloss:0.21683\n",
            "[1654]\ttrain-logloss:0.18292\tvalid-logloss:0.21685\n",
            "Rund no: 140 Metric : 0.7924095674497388 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21628\tvalid-logloss:0.22266\n",
            "[600]\ttrain-logloss:0.20588\tvalid-logloss:0.21887\n",
            "[900]\ttrain-logloss:0.19854\tvalid-logloss:0.21768\n",
            "[1200]\ttrain-logloss:0.19199\tvalid-logloss:0.21710\n",
            "[1500]\ttrain-logloss:0.18583\tvalid-logloss:0.21683\n",
            "[1773]\ttrain-logloss:0.18058\tvalid-logloss:0.21688\n",
            "Rund no: 141 Metric : 0.7925006979611464 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21623\tvalid-logloss:0.22267\n",
            "[600]\ttrain-logloss:0.20586\tvalid-logloss:0.21883\n",
            "[900]\ttrain-logloss:0.19858\tvalid-logloss:0.21764\n",
            "[1200]\ttrain-logloss:0.19201\tvalid-logloss:0.21716\n",
            "[1500]\ttrain-logloss:0.18598\tvalid-logloss:0.21687\n",
            "[1661]\ttrain-logloss:0.18284\tvalid-logloss:0.21685\n",
            "Rund no: 142 Metric : 0.7934577440447418 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21624\tvalid-logloss:0.22278\n",
            "[600]\ttrain-logloss:0.20584\tvalid-logloss:0.21878\n",
            "[900]\ttrain-logloss:0.19855\tvalid-logloss:0.21761\n",
            "[1200]\ttrain-logloss:0.19196\tvalid-logloss:0.21714\n",
            "[1249]\ttrain-logloss:0.19093\tvalid-logloss:0.21709\n",
            "Rund no: 143 Metric : 0.7922700269463534 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21625\tvalid-logloss:0.22258\n",
            "[600]\ttrain-logloss:0.20581\tvalid-logloss:0.21865\n",
            "[900]\ttrain-logloss:0.19855\tvalid-logloss:0.21745\n",
            "[1200]\ttrain-logloss:0.19207\tvalid-logloss:0.21707\n",
            "[1500]\ttrain-logloss:0.18593\tvalid-logloss:0.21682\n",
            "[1718]\ttrain-logloss:0.18169\tvalid-logloss:0.21689\n",
            "Rund no: 144 Metric : 0.7925310371632039 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21626\tvalid-logloss:0.22282\n",
            "[600]\ttrain-logloss:0.20583\tvalid-logloss:0.21888\n",
            "[900]\ttrain-logloss:0.19854\tvalid-logloss:0.21778\n",
            "[1200]\ttrain-logloss:0.19193\tvalid-logloss:0.21730\n",
            "[1500]\ttrain-logloss:0.18588\tvalid-logloss:0.21701\n",
            "[1652]\ttrain-logloss:0.18293\tvalid-logloss:0.21696\n",
            "Rund no: 145 Metric : 0.7933584090442116 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21623\tvalid-logloss:0.22283\n",
            "[600]\ttrain-logloss:0.20581\tvalid-logloss:0.21889\n",
            "[900]\ttrain-logloss:0.19855\tvalid-logloss:0.21770\n",
            "[1200]\ttrain-logloss:0.19196\tvalid-logloss:0.21712\n",
            "[1387]\ttrain-logloss:0.18810\tvalid-logloss:0.21703\n",
            "Rund no: 146 Metric : 0.7927164616317584 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21624\tvalid-logloss:0.22270\n",
            "[600]\ttrain-logloss:0.20585\tvalid-logloss:0.21875\n",
            "[900]\ttrain-logloss:0.19857\tvalid-logloss:0.21761\n",
            "[1200]\ttrain-logloss:0.19201\tvalid-logloss:0.21714\n",
            "[1252]\ttrain-logloss:0.19092\tvalid-logloss:0.21706\n",
            "Rund no: 147 Metric : 0.7929833853510713 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21626\tvalid-logloss:0.22262\n",
            "[600]\ttrain-logloss:0.20590\tvalid-logloss:0.21869\n",
            "[900]\ttrain-logloss:0.19861\tvalid-logloss:0.21763\n",
            "[1200]\ttrain-logloss:0.19206\tvalid-logloss:0.21718\n",
            "[1500]\ttrain-logloss:0.18594\tvalid-logloss:0.21693\n",
            "[1660]\ttrain-logloss:0.18282\tvalid-logloss:0.21688\n",
            "Rund no: 148 Metric : 0.7922482850418693 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21627\tvalid-logloss:0.22265\n",
            "[600]\ttrain-logloss:0.20590\tvalid-logloss:0.21875\n",
            "[900]\ttrain-logloss:0.19861\tvalid-logloss:0.21759\n",
            "[1200]\ttrain-logloss:0.19199\tvalid-logloss:0.21704\n",
            "[1500]\ttrain-logloss:0.18592\tvalid-logloss:0.21680\n",
            "[1780]\ttrain-logloss:0.18053\tvalid-logloss:0.21673\n",
            "Rund no: 149 Metric : 0.7930953114191095 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21627\tvalid-logloss:0.22269\n",
            "[600]\ttrain-logloss:0.20587\tvalid-logloss:0.21877\n",
            "[900]\ttrain-logloss:0.19861\tvalid-logloss:0.21770\n",
            "[1200]\ttrain-logloss:0.19214\tvalid-logloss:0.21726\n",
            "[1500]\ttrain-logloss:0.18603\tvalid-logloss:0.21698\n",
            "[1681]\ttrain-logloss:0.18256\tvalid-logloss:0.21701\n",
            "Rund no: 150 Metric : 0.7937810891163158 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21627\tvalid-logloss:0.22267\n",
            "[600]\ttrain-logloss:0.20591\tvalid-logloss:0.21868\n",
            "[900]\ttrain-logloss:0.19859\tvalid-logloss:0.21760\n",
            "[1200]\ttrain-logloss:0.19199\tvalid-logloss:0.21714\n",
            "[1500]\ttrain-logloss:0.18595\tvalid-logloss:0.21686\n",
            "[1800]\ttrain-logloss:0.18019\tvalid-logloss:0.21675\n",
            "[2100]\ttrain-logloss:0.17480\tvalid-logloss:0.21670\n",
            "[2284]\ttrain-logloss:0.17165\tvalid-logloss:0.21668\n",
            "Rund no: 151 Metric : 0.7933450172805446 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21630\tvalid-logloss:0.22287\n",
            "[600]\ttrain-logloss:0.20586\tvalid-logloss:0.21891\n",
            "[900]\ttrain-logloss:0.19857\tvalid-logloss:0.21771\n",
            "[1200]\ttrain-logloss:0.19201\tvalid-logloss:0.21719\n",
            "[1500]\ttrain-logloss:0.18591\tvalid-logloss:0.21682\n",
            "[1609]\ttrain-logloss:0.18380\tvalid-logloss:0.21685\n",
            "Rund no: 152 Metric : 0.7911596585170736 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21626\tvalid-logloss:0.22274\n",
            "[600]\ttrain-logloss:0.20588\tvalid-logloss:0.21892\n",
            "[900]\ttrain-logloss:0.19858\tvalid-logloss:0.21776\n",
            "[1200]\ttrain-logloss:0.19201\tvalid-logloss:0.21730\n",
            "[1500]\ttrain-logloss:0.18593\tvalid-logloss:0.21704\n",
            "[1660]\ttrain-logloss:0.18285\tvalid-logloss:0.21699\n",
            "Rund no: 153 Metric : 0.7929335084094566 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21627\tvalid-logloss:0.22265\n",
            "[600]\ttrain-logloss:0.20588\tvalid-logloss:0.21878\n",
            "[900]\ttrain-logloss:0.19860\tvalid-logloss:0.21769\n",
            "[1200]\ttrain-logloss:0.19202\tvalid-logloss:0.21719\n",
            "[1500]\ttrain-logloss:0.18592\tvalid-logloss:0.21695\n",
            "[1625]\ttrain-logloss:0.18346\tvalid-logloss:0.21697\n",
            "Rund no: 154 Metric : 0.7925942898326415 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21624\tvalid-logloss:0.22268\n",
            "[600]\ttrain-logloss:0.20586\tvalid-logloss:0.21878\n",
            "[900]\ttrain-logloss:0.19856\tvalid-logloss:0.21758\n",
            "[1200]\ttrain-logloss:0.19197\tvalid-logloss:0.21711\n",
            "[1250]\ttrain-logloss:0.19087\tvalid-logloss:0.21707\n",
            "Rund no: 155 Metric : 0.7926684956213339 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21627\tvalid-logloss:0.22265\n",
            "[600]\ttrain-logloss:0.20589\tvalid-logloss:0.21874\n",
            "[900]\ttrain-logloss:0.19863\tvalid-logloss:0.21756\n",
            "[1200]\ttrain-logloss:0.19203\tvalid-logloss:0.21709\n",
            "[1500]\ttrain-logloss:0.18593\tvalid-logloss:0.21688\n",
            "[1745]\ttrain-logloss:0.18122\tvalid-logloss:0.21682\n",
            "Rund no: 156 Metric : 0.793654023285645 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21627\tvalid-logloss:0.22269\n",
            "[600]\ttrain-logloss:0.20590\tvalid-logloss:0.21880\n",
            "[900]\ttrain-logloss:0.19865\tvalid-logloss:0.21772\n",
            "[1200]\ttrain-logloss:0.19208\tvalid-logloss:0.21735\n",
            "[1247]\ttrain-logloss:0.19111\tvalid-logloss:0.21726\n",
            "Rund no: 157 Metric : 0.792347554451206 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21624\tvalid-logloss:0.22272\n",
            "[600]\ttrain-logloss:0.20585\tvalid-logloss:0.21876\n",
            "[900]\ttrain-logloss:0.19855\tvalid-logloss:0.21763\n",
            "[1200]\ttrain-logloss:0.19198\tvalid-logloss:0.21727\n",
            "[1500]\ttrain-logloss:0.18592\tvalid-logloss:0.21697\n",
            "[1800]\ttrain-logloss:0.18013\tvalid-logloss:0.21687\n",
            "[1858]\ttrain-logloss:0.17908\tvalid-logloss:0.21689\n",
            "Rund no: 158 Metric : 0.7931571597862612 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21621\tvalid-logloss:0.22275\n",
            "[600]\ttrain-logloss:0.20583\tvalid-logloss:0.21883\n",
            "[900]\ttrain-logloss:0.19851\tvalid-logloss:0.21771\n",
            "[1200]\ttrain-logloss:0.19198\tvalid-logloss:0.21720\n",
            "[1500]\ttrain-logloss:0.18590\tvalid-logloss:0.21691\n",
            "[1654]\ttrain-logloss:0.18292\tvalid-logloss:0.21690\n",
            "Rund no: 159 Metric : 0.7932406959314047 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21628\tvalid-logloss:0.22267\n",
            "[600]\ttrain-logloss:0.20589\tvalid-logloss:0.21867\n",
            "[900]\ttrain-logloss:0.19856\tvalid-logloss:0.21742\n",
            "[1200]\ttrain-logloss:0.19198\tvalid-logloss:0.21692\n",
            "[1500]\ttrain-logloss:0.18591\tvalid-logloss:0.21669\n",
            "[1735]\ttrain-logloss:0.18141\tvalid-logloss:0.21663\n",
            "Rund no: 160 Metric : 0.7936396914937085 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21622\tvalid-logloss:0.22281\n",
            "[600]\ttrain-logloss:0.20591\tvalid-logloss:0.21910\n",
            "[900]\ttrain-logloss:0.19862\tvalid-logloss:0.21791\n",
            "[1200]\ttrain-logloss:0.19202\tvalid-logloss:0.21738\n",
            "[1500]\ttrain-logloss:0.18596\tvalid-logloss:0.21720\n",
            "[1800]\ttrain-logloss:0.18023\tvalid-logloss:0.21716\n",
            "[2037]\ttrain-logloss:0.17594\tvalid-logloss:0.21716\n",
            "Rund no: 161 Metric : 0.7927206172278343 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21625\tvalid-logloss:0.22276\n",
            "[600]\ttrain-logloss:0.20587\tvalid-logloss:0.21887\n",
            "[900]\ttrain-logloss:0.19864\tvalid-logloss:0.21779\n",
            "[1200]\ttrain-logloss:0.19207\tvalid-logloss:0.21743\n",
            "[1245]\ttrain-logloss:0.19109\tvalid-logloss:0.21736\n",
            "Rund no: 162 Metric : 0.7912921160682636 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21622\tvalid-logloss:0.22274\n",
            "[600]\ttrain-logloss:0.20593\tvalid-logloss:0.21892\n",
            "[900]\ttrain-logloss:0.19867\tvalid-logloss:0.21779\n",
            "[1200]\ttrain-logloss:0.19206\tvalid-logloss:0.21741\n",
            "[1500]\ttrain-logloss:0.18596\tvalid-logloss:0.21713\n",
            "[1796]\ttrain-logloss:0.18025\tvalid-logloss:0.21705\n",
            "Rund no: 163 Metric : 0.7918812016069642 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21627\tvalid-logloss:0.22267\n",
            "[600]\ttrain-logloss:0.20589\tvalid-logloss:0.21867\n",
            "[900]\ttrain-logloss:0.19858\tvalid-logloss:0.21756\n",
            "[1200]\ttrain-logloss:0.19201\tvalid-logloss:0.21717\n",
            "[1239]\ttrain-logloss:0.19122\tvalid-logloss:0.21715\n",
            "Rund no: 164 Metric : 0.7929490193200286 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21631\tvalid-logloss:0.22279\n",
            "[600]\ttrain-logloss:0.20594\tvalid-logloss:0.21894\n",
            "[900]\ttrain-logloss:0.19859\tvalid-logloss:0.21779\n",
            "[1200]\ttrain-logloss:0.19208\tvalid-logloss:0.21729\n",
            "[1500]\ttrain-logloss:0.18599\tvalid-logloss:0.21702\n",
            "[1800]\ttrain-logloss:0.18025\tvalid-logloss:0.21710\n",
            "[1828]\ttrain-logloss:0.17976\tvalid-logloss:0.21711\n",
            "Rund no: 165 Metric : 0.7917103626699957 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21624\tvalid-logloss:0.22278\n",
            "[600]\ttrain-logloss:0.20586\tvalid-logloss:0.21881\n",
            "[900]\ttrain-logloss:0.19851\tvalid-logloss:0.21752\n",
            "[1200]\ttrain-logloss:0.19195\tvalid-logloss:0.21702\n",
            "[1500]\ttrain-logloss:0.18587\tvalid-logloss:0.21673\n",
            "[1655]\ttrain-logloss:0.18289\tvalid-logloss:0.21674\n",
            "Rund no: 166 Metric : 0.7924135850152981 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21627\tvalid-logloss:0.22263\n",
            "[600]\ttrain-logloss:0.20583\tvalid-logloss:0.21864\n",
            "[900]\ttrain-logloss:0.19852\tvalid-logloss:0.21753\n",
            "[1200]\ttrain-logloss:0.19193\tvalid-logloss:0.21733\n",
            "[1244]\ttrain-logloss:0.19100\tvalid-logloss:0.21727\n",
            "Rund no: 167 Metric : 0.7926247718656203 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21626\tvalid-logloss:0.22261\n",
            "[600]\ttrain-logloss:0.20586\tvalid-logloss:0.21871\n",
            "[900]\ttrain-logloss:0.19854\tvalid-logloss:0.21769\n",
            "[1200]\ttrain-logloss:0.19200\tvalid-logloss:0.21738\n",
            "[1243]\ttrain-logloss:0.19109\tvalid-logloss:0.21731\n",
            "Rund no: 168 Metric : 0.7924310100168526 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21628\tvalid-logloss:0.22269\n",
            "[600]\ttrain-logloss:0.20587\tvalid-logloss:0.21878\n",
            "[900]\ttrain-logloss:0.19856\tvalid-logloss:0.21753\n",
            "[1200]\ttrain-logloss:0.19206\tvalid-logloss:0.21696\n",
            "[1500]\ttrain-logloss:0.18599\tvalid-logloss:0.21663\n",
            "[1655]\ttrain-logloss:0.18304\tvalid-logloss:0.21665\n",
            "Rund no: 169 Metric : 0.7921902626118134 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21630\tvalid-logloss:0.22281\n",
            "[600]\ttrain-logloss:0.20595\tvalid-logloss:0.21893\n",
            "[900]\ttrain-logloss:0.19858\tvalid-logloss:0.21775\n",
            "[1200]\ttrain-logloss:0.19201\tvalid-logloss:0.21721\n",
            "[1500]\ttrain-logloss:0.18598\tvalid-logloss:0.21708\n",
            "[1671]\ttrain-logloss:0.18263\tvalid-logloss:0.21702\n",
            "Rund no: 170 Metric : 0.7916120182853846 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21630\tvalid-logloss:0.22276\n",
            "[600]\ttrain-logloss:0.20588\tvalid-logloss:0.21885\n",
            "[900]\ttrain-logloss:0.19861\tvalid-logloss:0.21775\n",
            "[1200]\ttrain-logloss:0.19207\tvalid-logloss:0.21743\n",
            "[1244]\ttrain-logloss:0.19114\tvalid-logloss:0.21737\n",
            "Rund no: 171 Metric : 0.7918922216133146 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21627\tvalid-logloss:0.22274\n",
            "[600]\ttrain-logloss:0.20588\tvalid-logloss:0.21892\n",
            "[900]\ttrain-logloss:0.19859\tvalid-logloss:0.21780\n",
            "[1200]\ttrain-logloss:0.19204\tvalid-logloss:0.21728\n",
            "[1500]\ttrain-logloss:0.18603\tvalid-logloss:0.21710\n",
            "[1642]\ttrain-logloss:0.18324\tvalid-logloss:0.21713\n",
            "Rund no: 172 Metric : 0.792517836666119 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21623\tvalid-logloss:0.22283\n",
            "[600]\ttrain-logloss:0.20588\tvalid-logloss:0.21880\n",
            "[900]\ttrain-logloss:0.19862\tvalid-logloss:0.21767\n",
            "[1200]\ttrain-logloss:0.19203\tvalid-logloss:0.21723\n",
            "[1500]\ttrain-logloss:0.18597\tvalid-logloss:0.21704\n",
            "[1662]\ttrain-logloss:0.18279\tvalid-logloss:0.21704\n",
            "Rund no: 173 Metric : 0.790394032359661 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21630\tvalid-logloss:0.22282\n",
            "[600]\ttrain-logloss:0.20588\tvalid-logloss:0.21888\n",
            "[900]\ttrain-logloss:0.19866\tvalid-logloss:0.21778\n",
            "[1200]\ttrain-logloss:0.19209\tvalid-logloss:0.21731\n",
            "[1500]\ttrain-logloss:0.18596\tvalid-logloss:0.21712\n",
            "[1776]\ttrain-logloss:0.18067\tvalid-logloss:0.21706\n",
            "Rund no: 174 Metric : 0.7931953360499557 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21628\tvalid-logloss:0.22277\n",
            "[600]\ttrain-logloss:0.20584\tvalid-logloss:0.21882\n",
            "[900]\ttrain-logloss:0.19860\tvalid-logloss:0.21772\n",
            "[1200]\ttrain-logloss:0.19207\tvalid-logloss:0.21745\n",
            "[1241]\ttrain-logloss:0.19123\tvalid-logloss:0.21741\n",
            "Rund no: 175 Metric : 0.792439827648385 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21626\tvalid-logloss:0.22273\n",
            "[600]\ttrain-logloss:0.20592\tvalid-logloss:0.21890\n",
            "[900]\ttrain-logloss:0.19859\tvalid-logloss:0.21765\n",
            "[1200]\ttrain-logloss:0.19191\tvalid-logloss:0.21712\n",
            "[1249]\ttrain-logloss:0.19089\tvalid-logloss:0.21709\n",
            "Rund no: 176 Metric : 0.7922598738544733 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21627\tvalid-logloss:0.22275\n",
            "[600]\ttrain-logloss:0.20589\tvalid-logloss:0.21885\n",
            "[900]\ttrain-logloss:0.19859\tvalid-logloss:0.21772\n",
            "[1200]\ttrain-logloss:0.19199\tvalid-logloss:0.21718\n",
            "[1500]\ttrain-logloss:0.18596\tvalid-logloss:0.21691\n",
            "[1661]\ttrain-logloss:0.18282\tvalid-logloss:0.21693\n",
            "Rund no: 177 Metric : 0.7928770603237135 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21620\tvalid-logloss:0.22265\n",
            "[600]\ttrain-logloss:0.20592\tvalid-logloss:0.21883\n",
            "[900]\ttrain-logloss:0.19860\tvalid-logloss:0.21765\n",
            "[1200]\ttrain-logloss:0.19206\tvalid-logloss:0.21720\n",
            "[1500]\ttrain-logloss:0.18595\tvalid-logloss:0.21686\n",
            "[1735]\ttrain-logloss:0.18138\tvalid-logloss:0.21681\n",
            "Rund no: 178 Metric : 0.7941459274087124 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21621\tvalid-logloss:0.22258\n",
            "[600]\ttrain-logloss:0.20594\tvalid-logloss:0.21872\n",
            "[900]\ttrain-logloss:0.19856\tvalid-logloss:0.21757\n",
            "[1200]\ttrain-logloss:0.19199\tvalid-logloss:0.21710\n",
            "[1500]\ttrain-logloss:0.18593\tvalid-logloss:0.21686\n",
            "[1800]\ttrain-logloss:0.18016\tvalid-logloss:0.21676\n",
            "[2086]\ttrain-logloss:0.17502\tvalid-logloss:0.21674\n",
            "Rund no: 179 Metric : 0.79267871781846 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21627\tvalid-logloss:0.22264\n",
            "[600]\ttrain-logloss:0.20593\tvalid-logloss:0.21882\n",
            "[900]\ttrain-logloss:0.19856\tvalid-logloss:0.21758\n",
            "[1200]\ttrain-logloss:0.19195\tvalid-logloss:0.21703\n",
            "[1500]\ttrain-logloss:0.18585\tvalid-logloss:0.21676\n",
            "[1721]\ttrain-logloss:0.18159\tvalid-logloss:0.21672\n",
            "Rund no: 180 Metric : 0.7928688939004499 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21625\tvalid-logloss:0.22276\n",
            "[600]\ttrain-logloss:0.20590\tvalid-logloss:0.21880\n",
            "[900]\ttrain-logloss:0.19857\tvalid-logloss:0.21761\n",
            "[1200]\ttrain-logloss:0.19200\tvalid-logloss:0.21713\n",
            "[1500]\ttrain-logloss:0.18594\tvalid-logloss:0.21685\n",
            "[1660]\ttrain-logloss:0.18281\tvalid-logloss:0.21686\n",
            "Rund no: 181 Metric : 0.7936425204307747 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21627\tvalid-logloss:0.22265\n",
            "[600]\ttrain-logloss:0.20588\tvalid-logloss:0.21885\n",
            "[900]\ttrain-logloss:0.19853\tvalid-logloss:0.21768\n",
            "[1200]\ttrain-logloss:0.19204\tvalid-logloss:0.21722\n",
            "[1500]\ttrain-logloss:0.18595\tvalid-logloss:0.21706\n",
            "[1680]\ttrain-logloss:0.18242\tvalid-logloss:0.21712\n",
            "Rund no: 182 Metric : 0.7930596481261956 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21623\tvalid-logloss:0.22268\n",
            "[600]\ttrain-logloss:0.20583\tvalid-logloss:0.21875\n",
            "[900]\ttrain-logloss:0.19857\tvalid-logloss:0.21765\n",
            "[1200]\ttrain-logloss:0.19198\tvalid-logloss:0.21740\n",
            "[1241]\ttrain-logloss:0.19111\tvalid-logloss:0.21735\n",
            "Rund no: 183 Metric : 0.7919911186697633 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21625\tvalid-logloss:0.22265\n",
            "[600]\ttrain-logloss:0.20594\tvalid-logloss:0.21876\n",
            "[900]\ttrain-logloss:0.19863\tvalid-logloss:0.21769\n",
            "[1200]\ttrain-logloss:0.19210\tvalid-logloss:0.21731\n",
            "[1260]\ttrain-logloss:0.19085\tvalid-logloss:0.21726\n",
            "Rund no: 184 Metric : 0.7919327301478611 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21623\tvalid-logloss:0.22264\n",
            "[600]\ttrain-logloss:0.20580\tvalid-logloss:0.21859\n",
            "[900]\ttrain-logloss:0.19857\tvalid-logloss:0.21752\n",
            "[1200]\ttrain-logloss:0.19205\tvalid-logloss:0.21710\n",
            "[1500]\ttrain-logloss:0.18601\tvalid-logloss:0.21683\n",
            "[1660]\ttrain-logloss:0.18286\tvalid-logloss:0.21685\n",
            "Rund no: 185 Metric : 0.7930444412379496 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21626\tvalid-logloss:0.22260\n",
            "[600]\ttrain-logloss:0.20587\tvalid-logloss:0.21861\n",
            "[900]\ttrain-logloss:0.19859\tvalid-logloss:0.21756\n",
            "[1200]\ttrain-logloss:0.19200\tvalid-logloss:0.21710\n",
            "[1500]\ttrain-logloss:0.18586\tvalid-logloss:0.21680\n",
            "[1651]\ttrain-logloss:0.18292\tvalid-logloss:0.21680\n",
            "Rund no: 186 Metric : 0.7930071095765987 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21627\tvalid-logloss:0.22272\n",
            "[600]\ttrain-logloss:0.20584\tvalid-logloss:0.21891\n",
            "[900]\ttrain-logloss:0.19863\tvalid-logloss:0.21785\n",
            "[1200]\ttrain-logloss:0.19202\tvalid-logloss:0.21738\n",
            "[1500]\ttrain-logloss:0.18593\tvalid-logloss:0.21706\n",
            "[1661]\ttrain-logloss:0.18278\tvalid-logloss:0.21706\n",
            "Rund no: 187 Metric : 0.792190882864026 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21627\tvalid-logloss:0.22273\n",
            "[600]\ttrain-logloss:0.20592\tvalid-logloss:0.21884\n",
            "[900]\ttrain-logloss:0.19862\tvalid-logloss:0.21771\n",
            "[1200]\ttrain-logloss:0.19202\tvalid-logloss:0.21716\n",
            "[1500]\ttrain-logloss:0.18590\tvalid-logloss:0.21699\n",
            "[1800]\ttrain-logloss:0.18010\tvalid-logloss:0.21694\n",
            "[1830]\ttrain-logloss:0.17958\tvalid-logloss:0.21696\n",
            "Rund no: 188 Metric : 0.7920226850623068 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21626\tvalid-logloss:0.22269\n",
            "[600]\ttrain-logloss:0.20589\tvalid-logloss:0.21880\n",
            "[900]\ttrain-logloss:0.19861\tvalid-logloss:0.21768\n",
            "[1200]\ttrain-logloss:0.19207\tvalid-logloss:0.21710\n",
            "[1500]\ttrain-logloss:0.18600\tvalid-logloss:0.21688\n",
            "[1800]\ttrain-logloss:0.18024\tvalid-logloss:0.21682\n",
            "[1835]\ttrain-logloss:0.17964\tvalid-logloss:0.21679\n",
            "Rund no: 189 Metric : 0.7917692625964181 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21625\tvalid-logloss:0.22275\n",
            "[600]\ttrain-logloss:0.20579\tvalid-logloss:0.21886\n",
            "[900]\ttrain-logloss:0.19857\tvalid-logloss:0.21777\n",
            "[1200]\ttrain-logloss:0.19200\tvalid-logloss:0.21729\n",
            "[1500]\ttrain-logloss:0.18595\tvalid-logloss:0.21703\n",
            "[1800]\ttrain-logloss:0.18014\tvalid-logloss:0.21697\n",
            "[1972]\ttrain-logloss:0.17702\tvalid-logloss:0.21698\n",
            "Rund no: 190 Metric : 0.7924505965708286 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21623\tvalid-logloss:0.22271\n",
            "[600]\ttrain-logloss:0.20584\tvalid-logloss:0.21879\n",
            "[900]\ttrain-logloss:0.19855\tvalid-logloss:0.21770\n",
            "[1200]\ttrain-logloss:0.19202\tvalid-logloss:0.21714\n",
            "[1500]\ttrain-logloss:0.18589\tvalid-logloss:0.21692\n",
            "[1652]\ttrain-logloss:0.18293\tvalid-logloss:0.21697\n",
            "Rund no: 191 Metric : 0.7917241291849717 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21629\tvalid-logloss:0.22274\n",
            "[600]\ttrain-logloss:0.20586\tvalid-logloss:0.21882\n",
            "[900]\ttrain-logloss:0.19865\tvalid-logloss:0.21775\n",
            "[1200]\ttrain-logloss:0.19203\tvalid-logloss:0.21718\n",
            "[1428]\ttrain-logloss:0.18730\tvalid-logloss:0.21707\n",
            "Rund no: 192 Metric : 0.7922181117747151 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21627\tvalid-logloss:0.22265\n",
            "[600]\ttrain-logloss:0.20592\tvalid-logloss:0.21875\n",
            "[900]\ttrain-logloss:0.19861\tvalid-logloss:0.21764\n",
            "[1200]\ttrain-logloss:0.19206\tvalid-logloss:0.21731\n",
            "[1244]\ttrain-logloss:0.19114\tvalid-logloss:0.21723\n",
            "Rund no: 193 Metric : 0.7920198466570489 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21624\tvalid-logloss:0.22265\n",
            "[600]\ttrain-logloss:0.20591\tvalid-logloss:0.21879\n",
            "[900]\ttrain-logloss:0.19861\tvalid-logloss:0.21766\n",
            "[1200]\ttrain-logloss:0.19203\tvalid-logloss:0.21723\n",
            "[1500]\ttrain-logloss:0.18602\tvalid-logloss:0.21704\n",
            "[1661]\ttrain-logloss:0.18289\tvalid-logloss:0.21698\n",
            "Rund no: 194 Metric : 0.7934582422113297 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21626\tvalid-logloss:0.22278\n",
            "[600]\ttrain-logloss:0.20589\tvalid-logloss:0.21895\n",
            "[900]\ttrain-logloss:0.19860\tvalid-logloss:0.21773\n",
            "[1200]\ttrain-logloss:0.19208\tvalid-logloss:0.21731\n",
            "[1251]\ttrain-logloss:0.19098\tvalid-logloss:0.21726\n",
            "Rund no: 195 Metric : 0.7935719498258996 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21623\tvalid-logloss:0.22268\n",
            "[600]\ttrain-logloss:0.20588\tvalid-logloss:0.21874\n",
            "[900]\ttrain-logloss:0.19858\tvalid-logloss:0.21763\n",
            "[1200]\ttrain-logloss:0.19200\tvalid-logloss:0.21716\n",
            "[1500]\ttrain-logloss:0.18592\tvalid-logloss:0.21686\n",
            "[1800]\ttrain-logloss:0.18017\tvalid-logloss:0.21673\n",
            "[1971]\ttrain-logloss:0.17707\tvalid-logloss:0.21674\n",
            "Rund no: 196 Metric : 0.793425186020855 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21626\tvalid-logloss:0.22265\n",
            "[600]\ttrain-logloss:0.20585\tvalid-logloss:0.21868\n",
            "[900]\ttrain-logloss:0.19856\tvalid-logloss:0.21757\n",
            "[1200]\ttrain-logloss:0.19202\tvalid-logloss:0.21713\n",
            "[1500]\ttrain-logloss:0.18598\tvalid-logloss:0.21687\n",
            "[1660]\ttrain-logloss:0.18283\tvalid-logloss:0.21687\n",
            "Rund no: 197 Metric : 0.7937596555400639 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21630\tvalid-logloss:0.22278\n",
            "[600]\ttrain-logloss:0.20597\tvalid-logloss:0.21900\n",
            "[900]\ttrain-logloss:0.19864\tvalid-logloss:0.21787\n",
            "[1200]\ttrain-logloss:0.19207\tvalid-logloss:0.21733\n",
            "[1500]\ttrain-logloss:0.18598\tvalid-logloss:0.21709\n",
            "[1733]\ttrain-logloss:0.18145\tvalid-logloss:0.21700\n",
            "Rund no: 198 Metric : 0.7926111171081318 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21624\tvalid-logloss:0.22265\n",
            "[600]\ttrain-logloss:0.20587\tvalid-logloss:0.21878\n",
            "[900]\ttrain-logloss:0.19853\tvalid-logloss:0.21762\n",
            "[1200]\ttrain-logloss:0.19205\tvalid-logloss:0.21709\n",
            "[1500]\ttrain-logloss:0.18592\tvalid-logloss:0.21674\n",
            "[1660]\ttrain-logloss:0.18280\tvalid-logloss:0.21674\n",
            "Rund no: 199 Metric : 0.7928170542522148 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21627\tvalid-logloss:0.22265\n",
            "[600]\ttrain-logloss:0.20589\tvalid-logloss:0.21877\n",
            "[900]\ttrain-logloss:0.19859\tvalid-logloss:0.21768\n",
            "[1200]\ttrain-logloss:0.19205\tvalid-logloss:0.21717\n",
            "[1500]\ttrain-logloss:0.18600\tvalid-logloss:0.21698\n",
            "[1660]\ttrain-logloss:0.18291\tvalid-logloss:0.21698\n",
            "Rund no: 200 Metric : 0.7934748404933996 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21622\tvalid-logloss:0.22274\n",
            "[600]\ttrain-logloss:0.20576\tvalid-logloss:0.21879\n",
            "[900]\ttrain-logloss:0.19850\tvalid-logloss:0.21773\n",
            "[1200]\ttrain-logloss:0.19189\tvalid-logloss:0.21720\n",
            "[1500]\ttrain-logloss:0.18585\tvalid-logloss:0.21694\n",
            "[1649]\ttrain-logloss:0.18297\tvalid-logloss:0.21693\n",
            "Rund no: 201 Metric : 0.7936435251938571 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21627\tvalid-logloss:0.22270\n",
            "[600]\ttrain-logloss:0.20590\tvalid-logloss:0.21896\n",
            "[900]\ttrain-logloss:0.19861\tvalid-logloss:0.21773\n",
            "[1200]\ttrain-logloss:0.19212\tvalid-logloss:0.21734\n",
            "[1250]\ttrain-logloss:0.19106\tvalid-logloss:0.21732\n",
            "Rund no: 202 Metric : 0.7921275214966841 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21627\tvalid-logloss:0.22265\n",
            "[600]\ttrain-logloss:0.20591\tvalid-logloss:0.21872\n",
            "[900]\ttrain-logloss:0.19864\tvalid-logloss:0.21758\n",
            "[1200]\ttrain-logloss:0.19203\tvalid-logloss:0.21708\n",
            "[1500]\ttrain-logloss:0.18592\tvalid-logloss:0.21676\n",
            "[1644]\ttrain-logloss:0.18315\tvalid-logloss:0.21676\n",
            "Rund no: 203 Metric : 0.7916343591434478 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21625\tvalid-logloss:0.22260\n",
            "[600]\ttrain-logloss:0.20587\tvalid-logloss:0.21868\n",
            "[900]\ttrain-logloss:0.19855\tvalid-logloss:0.21756\n",
            "[1200]\ttrain-logloss:0.19198\tvalid-logloss:0.21714\n",
            "[1246]\ttrain-logloss:0.19099\tvalid-logloss:0.21709\n",
            "Rund no: 204 Metric : 0.7934087901898856 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21628\tvalid-logloss:0.22267\n",
            "[600]\ttrain-logloss:0.20595\tvalid-logloss:0.21883\n",
            "[900]\ttrain-logloss:0.19865\tvalid-logloss:0.21784\n",
            "[1200]\ttrain-logloss:0.19201\tvalid-logloss:0.21724\n",
            "[1500]\ttrain-logloss:0.18593\tvalid-logloss:0.21697\n",
            "[1613]\ttrain-logloss:0.18371\tvalid-logloss:0.21698\n",
            "Rund no: 205 Metric : 0.7925540275227603 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21623\tvalid-logloss:0.22267\n",
            "[600]\ttrain-logloss:0.20588\tvalid-logloss:0.21866\n",
            "[900]\ttrain-logloss:0.19855\tvalid-logloss:0.21759\n",
            "[1200]\ttrain-logloss:0.19205\tvalid-logloss:0.21727\n",
            "[1241]\ttrain-logloss:0.19119\tvalid-logloss:0.21724\n",
            "Rund no: 206 Metric : 0.7919839247331271 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21625\tvalid-logloss:0.22270\n",
            "[600]\ttrain-logloss:0.20582\tvalid-logloss:0.21878\n",
            "[900]\ttrain-logloss:0.19859\tvalid-logloss:0.21762\n",
            "[1200]\ttrain-logloss:0.19200\tvalid-logloss:0.21709\n",
            "[1500]\ttrain-logloss:0.18595\tvalid-logloss:0.21686\n",
            "[1661]\ttrain-logloss:0.18279\tvalid-logloss:0.21685\n",
            "Rund no: 207 Metric : 0.793294168776773 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21626\tvalid-logloss:0.22270\n",
            "[600]\ttrain-logloss:0.20592\tvalid-logloss:0.21892\n",
            "[900]\ttrain-logloss:0.19861\tvalid-logloss:0.21778\n",
            "[1200]\ttrain-logloss:0.19208\tvalid-logloss:0.21734\n",
            "[1500]\ttrain-logloss:0.18599\tvalid-logloss:0.21714\n",
            "[1800]\ttrain-logloss:0.18014\tvalid-logloss:0.21706\n",
            "[1831]\ttrain-logloss:0.17960\tvalid-logloss:0.21705\n",
            "Rund no: 208 Metric : 0.7924111627288739 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21621\tvalid-logloss:0.22266\n",
            "[600]\ttrain-logloss:0.20588\tvalid-logloss:0.21872\n",
            "[900]\ttrain-logloss:0.19855\tvalid-logloss:0.21757\n",
            "[1200]\ttrain-logloss:0.19201\tvalid-logloss:0.21714\n",
            "[1500]\ttrain-logloss:0.18593\tvalid-logloss:0.21698\n",
            "[1770]\ttrain-logloss:0.18077\tvalid-logloss:0.21692\n",
            "Rund no: 209 Metric : 0.7935723185489925 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21625\tvalid-logloss:0.22276\n",
            "[600]\ttrain-logloss:0.20592\tvalid-logloss:0.21888\n",
            "[900]\ttrain-logloss:0.19864\tvalid-logloss:0.21775\n",
            "[1200]\ttrain-logloss:0.19207\tvalid-logloss:0.21734\n",
            "[1500]\ttrain-logloss:0.18601\tvalid-logloss:0.21698\n",
            "[1800]\ttrain-logloss:0.18024\tvalid-logloss:0.21699\n",
            "[1807]\ttrain-logloss:0.18013\tvalid-logloss:0.21698\n",
            "Rund no: 210 Metric : 0.7919402788423309 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21625\tvalid-logloss:0.22261\n",
            "[600]\ttrain-logloss:0.20589\tvalid-logloss:0.21868\n",
            "[900]\ttrain-logloss:0.19865\tvalid-logloss:0.21752\n",
            "[1200]\ttrain-logloss:0.19205\tvalid-logloss:0.21704\n",
            "[1500]\ttrain-logloss:0.18598\tvalid-logloss:0.21679\n",
            "[1717]\ttrain-logloss:0.18172\tvalid-logloss:0.21668\n",
            "Rund no: 211 Metric : 0.793000173090811 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21627\tvalid-logloss:0.22265\n",
            "[600]\ttrain-logloss:0.20589\tvalid-logloss:0.21868\n",
            "[900]\ttrain-logloss:0.19864\tvalid-logloss:0.21760\n",
            "[1200]\ttrain-logloss:0.19203\tvalid-logloss:0.21715\n",
            "[1500]\ttrain-logloss:0.18593\tvalid-logloss:0.21682\n",
            "[1661]\ttrain-logloss:0.18278\tvalid-logloss:0.21684\n",
            "Rund no: 212 Metric : 0.7933467590525134 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21627\tvalid-logloss:0.22265\n",
            "[600]\ttrain-logloss:0.20586\tvalid-logloss:0.21876\n",
            "[900]\ttrain-logloss:0.19849\tvalid-logloss:0.21759\n",
            "[1200]\ttrain-logloss:0.19194\tvalid-logloss:0.21721\n",
            "[1500]\ttrain-logloss:0.18579\tvalid-logloss:0.21694\n",
            "[1661]\ttrain-logloss:0.18270\tvalid-logloss:0.21688\n",
            "Rund no: 213 Metric : 0.7928262731961822 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21626\tvalid-logloss:0.22263\n",
            "[600]\ttrain-logloss:0.20582\tvalid-logloss:0.21868\n",
            "[900]\ttrain-logloss:0.19860\tvalid-logloss:0.21758\n",
            "[1200]\ttrain-logloss:0.19206\tvalid-logloss:0.21716\n",
            "[1500]\ttrain-logloss:0.18602\tvalid-logloss:0.21690\n",
            "[1660]\ttrain-logloss:0.18290\tvalid-logloss:0.21689\n",
            "Rund no: 214 Metric : 0.7921413149515433 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21622\tvalid-logloss:0.22264\n",
            "[600]\ttrain-logloss:0.20582\tvalid-logloss:0.21874\n",
            "[900]\ttrain-logloss:0.19849\tvalid-logloss:0.21766\n",
            "[1200]\ttrain-logloss:0.19193\tvalid-logloss:0.21716\n",
            "[1429]\ttrain-logloss:0.18722\tvalid-logloss:0.21697\n",
            "Rund no: 215 Metric : 0.7922650350131054 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21622\tvalid-logloss:0.22273\n",
            "[600]\ttrain-logloss:0.20591\tvalid-logloss:0.21882\n",
            "[900]\ttrain-logloss:0.19859\tvalid-logloss:0.21765\n",
            "[1200]\ttrain-logloss:0.19207\tvalid-logloss:0.21740\n",
            "[1246]\ttrain-logloss:0.19111\tvalid-logloss:0.21731\n",
            "Rund no: 216 Metric : 0.7918628564399257 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21624\tvalid-logloss:0.22276\n",
            "[600]\ttrain-logloss:0.20586\tvalid-logloss:0.21889\n",
            "[900]\ttrain-logloss:0.19864\tvalid-logloss:0.21786\n",
            "[1200]\ttrain-logloss:0.19202\tvalid-logloss:0.21724\n",
            "[1500]\ttrain-logloss:0.18599\tvalid-logloss:0.21700\n",
            "[1619]\ttrain-logloss:0.18366\tvalid-logloss:0.21701\n",
            "Rund no: 217 Metric : 0.7922283322726854 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21620\tvalid-logloss:0.22264\n",
            "[600]\ttrain-logloss:0.20590\tvalid-logloss:0.21874\n",
            "[900]\ttrain-logloss:0.19861\tvalid-logloss:0.21761\n",
            "[1200]\ttrain-logloss:0.19199\tvalid-logloss:0.21698\n",
            "[1500]\ttrain-logloss:0.18591\tvalid-logloss:0.21670\n",
            "[1723]\ttrain-logloss:0.18166\tvalid-logloss:0.21670\n",
            "Rund no: 218 Metric : 0.7932698328691794 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21626\tvalid-logloss:0.22262\n",
            "[600]\ttrain-logloss:0.20587\tvalid-logloss:0.21871\n",
            "[900]\ttrain-logloss:0.19862\tvalid-logloss:0.21754\n",
            "[1200]\ttrain-logloss:0.19203\tvalid-logloss:0.21705\n",
            "[1500]\ttrain-logloss:0.18588\tvalid-logloss:0.21678\n",
            "[1752]\ttrain-logloss:0.18105\tvalid-logloss:0.21672\n",
            "Rund no: 219 Metric : 0.7924251901763405 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21630\tvalid-logloss:0.22281\n",
            "[600]\ttrain-logloss:0.20593\tvalid-logloss:0.21893\n",
            "[900]\ttrain-logloss:0.19860\tvalid-logloss:0.21786\n",
            "[1200]\ttrain-logloss:0.19208\tvalid-logloss:0.21732\n",
            "[1500]\ttrain-logloss:0.18597\tvalid-logloss:0.21711\n",
            "[1800]\ttrain-logloss:0.18019\tvalid-logloss:0.21699\n",
            "[1923]\ttrain-logloss:0.17799\tvalid-logloss:0.21709\n",
            "Rund no: 220 Metric : 0.7928873127931638 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21625\tvalid-logloss:0.22282\n",
            "[600]\ttrain-logloss:0.20591\tvalid-logloss:0.21900\n",
            "[900]\ttrain-logloss:0.19860\tvalid-logloss:0.21782\n",
            "[1200]\ttrain-logloss:0.19206\tvalid-logloss:0.21744\n",
            "[1500]\ttrain-logloss:0.18595\tvalid-logloss:0.21724\n",
            "[1553]\ttrain-logloss:0.18488\tvalid-logloss:0.21716\n",
            "Rund no: 221 Metric : 0.7928745763220293 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21625\tvalid-logloss:0.22263\n",
            "[600]\ttrain-logloss:0.20588\tvalid-logloss:0.21874\n",
            "[900]\ttrain-logloss:0.19855\tvalid-logloss:0.21761\n",
            "[1200]\ttrain-logloss:0.19199\tvalid-logloss:0.21707\n",
            "[1500]\ttrain-logloss:0.18582\tvalid-logloss:0.21682\n",
            "[1628]\ttrain-logloss:0.18336\tvalid-logloss:0.21683\n",
            "Rund no: 222 Metric : 0.7939672703652967 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21625\tvalid-logloss:0.22277\n",
            "[600]\ttrain-logloss:0.20586\tvalid-logloss:0.21891\n",
            "[900]\ttrain-logloss:0.19859\tvalid-logloss:0.21769\n",
            "[1200]\ttrain-logloss:0.19205\tvalid-logloss:0.21720\n",
            "[1500]\ttrain-logloss:0.18594\tvalid-logloss:0.21700\n",
            "[1609]\ttrain-logloss:0.18379\tvalid-logloss:0.21705\n",
            "Rund no: 223 Metric : 0.7930926712652384 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21626\tvalid-logloss:0.22272\n",
            "[600]\ttrain-logloss:0.20586\tvalid-logloss:0.21910\n",
            "[900]\ttrain-logloss:0.19860\tvalid-logloss:0.21832\n",
            "[1200]\ttrain-logloss:0.19209\tvalid-logloss:0.21804\n",
            "[1243]\ttrain-logloss:0.19119\tvalid-logloss:0.21797\n",
            "Rund no: 224 Metric : 0.792561574807809 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21623\tvalid-logloss:0.22291\n",
            "[600]\ttrain-logloss:0.20589\tvalid-logloss:0.21900\n",
            "[900]\ttrain-logloss:0.19862\tvalid-logloss:0.21792\n",
            "[1200]\ttrain-logloss:0.19205\tvalid-logloss:0.21750\n",
            "[1500]\ttrain-logloss:0.18598\tvalid-logloss:0.21725\n",
            "[1661]\ttrain-logloss:0.18281\tvalid-logloss:0.21731\n",
            "Rund no: 225 Metric : 0.7910488773115836 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21621\tvalid-logloss:0.22266\n",
            "[600]\ttrain-logloss:0.20582\tvalid-logloss:0.21876\n",
            "[900]\ttrain-logloss:0.19855\tvalid-logloss:0.21762\n",
            "[1200]\ttrain-logloss:0.19197\tvalid-logloss:0.21713\n",
            "[1500]\ttrain-logloss:0.18588\tvalid-logloss:0.21685\n",
            "[1611]\ttrain-logloss:0.18371\tvalid-logloss:0.21694\n",
            "Rund no: 226 Metric : 0.7919676083183703 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21630\tvalid-logloss:0.22279\n",
            "[600]\ttrain-logloss:0.20588\tvalid-logloss:0.21898\n",
            "[900]\ttrain-logloss:0.19860\tvalid-logloss:0.21779\n",
            "[1200]\ttrain-logloss:0.19199\tvalid-logloss:0.21716\n",
            "[1500]\ttrain-logloss:0.18589\tvalid-logloss:0.21688\n",
            "[1800]\ttrain-logloss:0.18009\tvalid-logloss:0.21681\n",
            "[1833]\ttrain-logloss:0.17951\tvalid-logloss:0.21682\n",
            "Rund no: 227 Metric : 0.7928298963202971 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21625\tvalid-logloss:0.22274\n",
            "[600]\ttrain-logloss:0.20582\tvalid-logloss:0.21874\n",
            "[900]\ttrain-logloss:0.19850\tvalid-logloss:0.21751\n",
            "[1200]\ttrain-logloss:0.19196\tvalid-logloss:0.21705\n",
            "[1500]\ttrain-logloss:0.18590\tvalid-logloss:0.21687\n",
            "[1626]\ttrain-logloss:0.18345\tvalid-logloss:0.21688\n",
            "Rund no: 228 Metric : 0.7928834656731785 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21618\tvalid-logloss:0.22273\n",
            "[600]\ttrain-logloss:0.20575\tvalid-logloss:0.21875\n",
            "[900]\ttrain-logloss:0.19850\tvalid-logloss:0.21765\n",
            "[1200]\ttrain-logloss:0.19196\tvalid-logloss:0.21715\n",
            "[1424]\ttrain-logloss:0.18741\tvalid-logloss:0.21718\n",
            "Rund no: 229 Metric : 0.7913813567804484 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21620\tvalid-logloss:0.22254\n",
            "[600]\ttrain-logloss:0.20580\tvalid-logloss:0.21874\n",
            "[900]\ttrain-logloss:0.19848\tvalid-logloss:0.21762\n",
            "[1200]\ttrain-logloss:0.19198\tvalid-logloss:0.21710\n",
            "[1500]\ttrain-logloss:0.18588\tvalid-logloss:0.21686\n",
            "[1800]\ttrain-logloss:0.18015\tvalid-logloss:0.21674\n",
            "[1968]\ttrain-logloss:0.17715\tvalid-logloss:0.21671\n",
            "Rund no: 230 Metric : 0.79428918155554 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21624\tvalid-logloss:0.22259\n",
            "[600]\ttrain-logloss:0.20594\tvalid-logloss:0.21870\n",
            "[900]\ttrain-logloss:0.19858\tvalid-logloss:0.21749\n",
            "[1200]\ttrain-logloss:0.19200\tvalid-logloss:0.21697\n",
            "[1500]\ttrain-logloss:0.18590\tvalid-logloss:0.21662\n",
            "[1661]\ttrain-logloss:0.18281\tvalid-logloss:0.21657\n",
            "Rund no: 231 Metric : 0.7937469935769085 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21627\tvalid-logloss:0.22261\n",
            "[600]\ttrain-logloss:0.20588\tvalid-logloss:0.21874\n",
            "[900]\ttrain-logloss:0.19859\tvalid-logloss:0.21763\n",
            "[1200]\ttrain-logloss:0.19201\tvalid-logloss:0.21719\n",
            "[1500]\ttrain-logloss:0.18593\tvalid-logloss:0.21701\n",
            "[1655]\ttrain-logloss:0.18290\tvalid-logloss:0.21702\n",
            "Rund no: 232 Metric : 0.7916858376990232 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21621\tvalid-logloss:0.22265\n",
            "[600]\ttrain-logloss:0.20590\tvalid-logloss:0.21881\n",
            "[900]\ttrain-logloss:0.19858\tvalid-logloss:0.21767\n",
            "[1200]\ttrain-logloss:0.19201\tvalid-logloss:0.21726\n",
            "[1500]\ttrain-logloss:0.18591\tvalid-logloss:0.21693\n",
            "[1800]\ttrain-logloss:0.18008\tvalid-logloss:0.21686\n",
            "[1960]\ttrain-logloss:0.17720\tvalid-logloss:0.21684\n",
            "Rund no: 233 Metric : 0.7936915824152531 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21633\tvalid-logloss:0.22289\n",
            "[600]\ttrain-logloss:0.20592\tvalid-logloss:0.21895\n",
            "[900]\ttrain-logloss:0.19863\tvalid-logloss:0.21783\n",
            "[1200]\ttrain-logloss:0.19210\tvalid-logloss:0.21726\n",
            "[1500]\ttrain-logloss:0.18599\tvalid-logloss:0.21703\n",
            "[1800]\ttrain-logloss:0.18021\tvalid-logloss:0.21688\n",
            "[1906]\ttrain-logloss:0.17832\tvalid-logloss:0.21687\n",
            "Rund no: 234 Metric : 0.7929337371640667 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21623\tvalid-logloss:0.22268\n",
            "[600]\ttrain-logloss:0.20589\tvalid-logloss:0.21891\n",
            "[900]\ttrain-logloss:0.19855\tvalid-logloss:0.21771\n",
            "[1200]\ttrain-logloss:0.19201\tvalid-logloss:0.21717\n",
            "[1500]\ttrain-logloss:0.18590\tvalid-logloss:0.21690\n",
            "[1651]\ttrain-logloss:0.18292\tvalid-logloss:0.21688\n",
            "Rund no: 235 Metric : 0.7924950551662713 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21620\tvalid-logloss:0.22263\n",
            "[600]\ttrain-logloss:0.20590\tvalid-logloss:0.21870\n",
            "[900]\ttrain-logloss:0.19856\tvalid-logloss:0.21750\n",
            "[1200]\ttrain-logloss:0.19197\tvalid-logloss:0.21693\n",
            "[1500]\ttrain-logloss:0.18593\tvalid-logloss:0.21661\n",
            "[1783]\ttrain-logloss:0.18044\tvalid-logloss:0.21654\n",
            "Rund no: 236 Metric : 0.7940460466887392 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21631\tvalid-logloss:0.22270\n",
            "[600]\ttrain-logloss:0.20596\tvalid-logloss:0.21882\n",
            "[900]\ttrain-logloss:0.19871\tvalid-logloss:0.21772\n",
            "[1200]\ttrain-logloss:0.19210\tvalid-logloss:0.21716\n",
            "[1500]\ttrain-logloss:0.18600\tvalid-logloss:0.21690\n",
            "[1800]\ttrain-logloss:0.18024\tvalid-logloss:0.21682\n",
            "[1834]\ttrain-logloss:0.17964\tvalid-logloss:0.21680\n",
            "Rund no: 237 Metric : 0.7923812070887185 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21627\tvalid-logloss:0.22266\n",
            "[600]\ttrain-logloss:0.20588\tvalid-logloss:0.21870\n",
            "[900]\ttrain-logloss:0.19861\tvalid-logloss:0.21759\n",
            "[1200]\ttrain-logloss:0.19201\tvalid-logloss:0.21715\n",
            "[1242]\ttrain-logloss:0.19110\tvalid-logloss:0.21709\n",
            "Rund no: 238 Metric : 0.792246082642555 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21625\tvalid-logloss:0.22266\n",
            "[600]\ttrain-logloss:0.20585\tvalid-logloss:0.21878\n",
            "[900]\ttrain-logloss:0.19861\tvalid-logloss:0.21768\n",
            "[1200]\ttrain-logloss:0.19203\tvalid-logloss:0.21735\n",
            "[1247]\ttrain-logloss:0.19103\tvalid-logloss:0.21727\n",
            "Rund no: 239 Metric : 0.7920190460935086 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21619\tvalid-logloss:0.22276\n",
            "[600]\ttrain-logloss:0.20584\tvalid-logloss:0.21896\n",
            "[900]\ttrain-logloss:0.19861\tvalid-logloss:0.21790\n",
            "[1200]\ttrain-logloss:0.19196\tvalid-logloss:0.21748\n",
            "[1500]\ttrain-logloss:0.18581\tvalid-logloss:0.21726\n",
            "[1745]\ttrain-logloss:0.18113\tvalid-logloss:0.21721\n",
            "Rund no: 240 Metric : 0.7934605346185959 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21633\tvalid-logloss:0.22264\n",
            "[600]\ttrain-logloss:0.20590\tvalid-logloss:0.21877\n",
            "[900]\ttrain-logloss:0.19855\tvalid-logloss:0.21758\n",
            "[1200]\ttrain-logloss:0.19198\tvalid-logloss:0.21701\n",
            "[1500]\ttrain-logloss:0.18588\tvalid-logloss:0.21673\n",
            "[1753]\ttrain-logloss:0.18095\tvalid-logloss:0.21671\n",
            "Rund no: 241 Metric : 0.7927987930785175 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21625\tvalid-logloss:0.22271\n",
            "[600]\ttrain-logloss:0.20587\tvalid-logloss:0.21886\n",
            "[900]\ttrain-logloss:0.19864\tvalid-logloss:0.21774\n",
            "[1200]\ttrain-logloss:0.19203\tvalid-logloss:0.21719\n",
            "[1500]\ttrain-logloss:0.18594\tvalid-logloss:0.21693\n",
            "[1658]\ttrain-logloss:0.18286\tvalid-logloss:0.21692\n",
            "Rund no: 242 Metric : 0.7933486641526333 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21627\tvalid-logloss:0.22274\n",
            "[600]\ttrain-logloss:0.20589\tvalid-logloss:0.21890\n",
            "[900]\ttrain-logloss:0.19857\tvalid-logloss:0.21772\n",
            "[1200]\ttrain-logloss:0.19197\tvalid-logloss:0.21717\n",
            "[1500]\ttrain-logloss:0.18583\tvalid-logloss:0.21689\n",
            "[1662]\ttrain-logloss:0.18268\tvalid-logloss:0.21686\n",
            "Rund no: 243 Metric : 0.7917957031094618 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21634\tvalid-logloss:0.22285\n",
            "[600]\ttrain-logloss:0.20589\tvalid-logloss:0.21887\n",
            "[900]\ttrain-logloss:0.19859\tvalid-logloss:0.21769\n",
            "[1200]\ttrain-logloss:0.19202\tvalid-logloss:0.21720\n",
            "[1500]\ttrain-logloss:0.18591\tvalid-logloss:0.21696\n",
            "[1652]\ttrain-logloss:0.18297\tvalid-logloss:0.21695\n",
            "Rund no: 244 Metric : 0.7927844918562603 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21627\tvalid-logloss:0.22269\n",
            "[600]\ttrain-logloss:0.20592\tvalid-logloss:0.21873\n",
            "[900]\ttrain-logloss:0.19863\tvalid-logloss:0.21762\n",
            "[1200]\ttrain-logloss:0.19200\tvalid-logloss:0.21710\n",
            "[1500]\ttrain-logloss:0.18588\tvalid-logloss:0.21690\n",
            "[1651]\ttrain-logloss:0.18295\tvalid-logloss:0.21683\n",
            "Rund no: 245 Metric : 0.7932068307058169 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21627\tvalid-logloss:0.22283\n",
            "[600]\ttrain-logloss:0.20587\tvalid-logloss:0.21889\n",
            "[900]\ttrain-logloss:0.19848\tvalid-logloss:0.21766\n",
            "[1200]\ttrain-logloss:0.19192\tvalid-logloss:0.21716\n",
            "[1500]\ttrain-logloss:0.18586\tvalid-logloss:0.21689\n",
            "[1661]\ttrain-logloss:0.18270\tvalid-logloss:0.21687\n",
            "Rund no: 246 Metric : 0.7920687712626246 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21622\tvalid-logloss:0.22279\n",
            "[600]\ttrain-logloss:0.20584\tvalid-logloss:0.21891\n",
            "[900]\ttrain-logloss:0.19853\tvalid-logloss:0.21775\n",
            "[1200]\ttrain-logloss:0.19195\tvalid-logloss:0.21738\n",
            "[1251]\ttrain-logloss:0.19087\tvalid-logloss:0.21732\n",
            "Rund no: 247 Metric : 0.7919942425304635 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21626\tvalid-logloss:0.22276\n",
            "[600]\ttrain-logloss:0.20585\tvalid-logloss:0.21879\n",
            "[900]\ttrain-logloss:0.19859\tvalid-logloss:0.21772\n",
            "[1200]\ttrain-logloss:0.19205\tvalid-logloss:0.21725\n",
            "[1500]\ttrain-logloss:0.18594\tvalid-logloss:0.21697\n",
            "[1655]\ttrain-logloss:0.18294\tvalid-logloss:0.21696\n",
            "Rund no: 248 Metric : 0.7924682651902979 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21623\tvalid-logloss:0.22265\n",
            "[600]\ttrain-logloss:0.20585\tvalid-logloss:0.21876\n",
            "[900]\ttrain-logloss:0.19859\tvalid-logloss:0.21758\n",
            "[1200]\ttrain-logloss:0.19205\tvalid-logloss:0.21719\n",
            "[1500]\ttrain-logloss:0.18599\tvalid-logloss:0.21687\n",
            "[1662]\ttrain-logloss:0.18284\tvalid-logloss:0.21688\n",
            "Rund no: 249 Metric : 0.7938172566132886 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21623\tvalid-logloss:0.22277\n",
            "[600]\ttrain-logloss:0.20590\tvalid-logloss:0.21899\n",
            "[900]\ttrain-logloss:0.19854\tvalid-logloss:0.21784\n",
            "[1200]\ttrain-logloss:0.19193\tvalid-logloss:0.21737\n",
            "[1500]\ttrain-logloss:0.18588\tvalid-logloss:0.21711\n",
            "[1651]\ttrain-logloss:0.18293\tvalid-logloss:0.21713\n",
            "Rund no: 250 Metric : 0.7927343334525148 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21630\tvalid-logloss:0.22268\n",
            "[600]\ttrain-logloss:0.20584\tvalid-logloss:0.21871\n",
            "[900]\ttrain-logloss:0.19859\tvalid-logloss:0.21760\n",
            "[1200]\ttrain-logloss:0.19202\tvalid-logloss:0.21713\n",
            "[1395]\ttrain-logloss:0.18802\tvalid-logloss:0.21699\n",
            "Rund no: 251 Metric : 0.7918623932134501 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21627\tvalid-logloss:0.22272\n",
            "[600]\ttrain-logloss:0.20587\tvalid-logloss:0.21883\n",
            "[900]\ttrain-logloss:0.19851\tvalid-logloss:0.21768\n",
            "[1200]\ttrain-logloss:0.19196\tvalid-logloss:0.21724\n",
            "[1500]\ttrain-logloss:0.18585\tvalid-logloss:0.21701\n",
            "[1653]\ttrain-logloss:0.18289\tvalid-logloss:0.21699\n",
            "Rund no: 252 Metric : 0.792122568809454 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21627\tvalid-logloss:0.22265\n",
            "[600]\ttrain-logloss:0.20591\tvalid-logloss:0.21875\n",
            "[900]\ttrain-logloss:0.19856\tvalid-logloss:0.21764\n",
            "[1200]\ttrain-logloss:0.19198\tvalid-logloss:0.21712\n",
            "[1500]\ttrain-logloss:0.18585\tvalid-logloss:0.21695\n",
            "[1734]\ttrain-logloss:0.18135\tvalid-logloss:0.21690\n",
            "Rund no: 253 Metric : 0.7934577762057471 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21627\tvalid-logloss:0.22278\n",
            "[600]\ttrain-logloss:0.20587\tvalid-logloss:0.21882\n",
            "[900]\ttrain-logloss:0.19862\tvalid-logloss:0.21768\n",
            "[1200]\ttrain-logloss:0.19204\tvalid-logloss:0.21722\n",
            "[1500]\ttrain-logloss:0.18595\tvalid-logloss:0.21696\n",
            "[1762]\ttrain-logloss:0.18094\tvalid-logloss:0.21690\n",
            "Rund no: 254 Metric : 0.7929395519313156 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21628\tvalid-logloss:0.22272\n",
            "[600]\ttrain-logloss:0.20590\tvalid-logloss:0.21877\n",
            "[900]\ttrain-logloss:0.19855\tvalid-logloss:0.21765\n",
            "[1200]\ttrain-logloss:0.19198\tvalid-logloss:0.21730\n",
            "[1245]\ttrain-logloss:0.19104\tvalid-logloss:0.21724\n",
            "Rund no: 255 Metric : 0.7912135904725374 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21627\tvalid-logloss:0.22265\n",
            "[600]\ttrain-logloss:0.20587\tvalid-logloss:0.21874\n",
            "[900]\ttrain-logloss:0.19859\tvalid-logloss:0.21763\n",
            "[1200]\ttrain-logloss:0.19196\tvalid-logloss:0.21713\n",
            "[1500]\ttrain-logloss:0.18590\tvalid-logloss:0.21696\n",
            "[1799]\ttrain-logloss:0.18020\tvalid-logloss:0.21691\n",
            "Rund no: 256 Metric : 0.7924080834676378 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21625\tvalid-logloss:0.22271\n",
            "[600]\ttrain-logloss:0.20586\tvalid-logloss:0.21886\n",
            "[900]\ttrain-logloss:0.19857\tvalid-logloss:0.21780\n",
            "[1200]\ttrain-logloss:0.19199\tvalid-logloss:0.21733\n",
            "[1500]\ttrain-logloss:0.18591\tvalid-logloss:0.21704\n",
            "[1654]\ttrain-logloss:0.18295\tvalid-logloss:0.21705\n",
            "Rund no: 257 Metric : 0.7913095308571297 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21620\tvalid-logloss:0.22262\n",
            "[600]\ttrain-logloss:0.20586\tvalid-logloss:0.21879\n",
            "[900]\ttrain-logloss:0.19853\tvalid-logloss:0.21762\n",
            "[1200]\ttrain-logloss:0.19197\tvalid-logloss:0.21711\n",
            "[1500]\ttrain-logloss:0.18592\tvalid-logloss:0.21700\n",
            "[1648]\ttrain-logloss:0.18303\tvalid-logloss:0.21700\n",
            "Rund no: 258 Metric : 0.7922520213024133 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21627\tvalid-logloss:0.22267\n",
            "[600]\ttrain-logloss:0.20589\tvalid-logloss:0.21874\n",
            "[900]\ttrain-logloss:0.19858\tvalid-logloss:0.21746\n",
            "[1200]\ttrain-logloss:0.19204\tvalid-logloss:0.21691\n",
            "[1500]\ttrain-logloss:0.18593\tvalid-logloss:0.21668\n",
            "[1640]\ttrain-logloss:0.18320\tvalid-logloss:0.21664\n",
            "Rund no: 259 Metric : 0.7934079982041107 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21620\tvalid-logloss:0.22256\n",
            "[600]\ttrain-logloss:0.20588\tvalid-logloss:0.21873\n",
            "[900]\ttrain-logloss:0.19857\tvalid-logloss:0.21759\n",
            "[1200]\ttrain-logloss:0.19200\tvalid-logloss:0.21723\n",
            "[1500]\ttrain-logloss:0.18592\tvalid-logloss:0.21684\n",
            "[1746]\ttrain-logloss:0.18115\tvalid-logloss:0.21675\n",
            "Rund no: 260 Metric : 0.7931675137114886 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21624\tvalid-logloss:0.22264\n",
            "[600]\ttrain-logloss:0.20584\tvalid-logloss:0.21874\n",
            "[900]\ttrain-logloss:0.19859\tvalid-logloss:0.21771\n",
            "[1200]\ttrain-logloss:0.19206\tvalid-logloss:0.21720\n",
            "[1500]\ttrain-logloss:0.18599\tvalid-logloss:0.21701\n",
            "[1507]\ttrain-logloss:0.18585\tvalid-logloss:0.21701\n",
            "Rund no: 261 Metric : 0.792825660838005 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21623\tvalid-logloss:0.22266\n",
            "[600]\ttrain-logloss:0.20581\tvalid-logloss:0.21875\n",
            "[900]\ttrain-logloss:0.19855\tvalid-logloss:0.21761\n",
            "[1200]\ttrain-logloss:0.19191\tvalid-logloss:0.21706\n",
            "[1500]\ttrain-logloss:0.18582\tvalid-logloss:0.21689\n",
            "[1800]\ttrain-logloss:0.18007\tvalid-logloss:0.21676\n",
            "[2098]\ttrain-logloss:0.17469\tvalid-logloss:0.21669\n",
            "Rund no: 262 Metric : 0.7929990575268295 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21625\tvalid-logloss:0.22274\n",
            "[600]\ttrain-logloss:0.20581\tvalid-logloss:0.21884\n",
            "[900]\ttrain-logloss:0.19859\tvalid-logloss:0.21775\n",
            "[1200]\ttrain-logloss:0.19205\tvalid-logloss:0.21718\n",
            "[1500]\ttrain-logloss:0.18596\tvalid-logloss:0.21688\n",
            "[1647]\ttrain-logloss:0.18318\tvalid-logloss:0.21682\n",
            "Rund no: 263 Metric : 0.7928391819863312 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21624\tvalid-logloss:0.22278\n",
            "[600]\ttrain-logloss:0.20590\tvalid-logloss:0.21897\n",
            "[900]\ttrain-logloss:0.19855\tvalid-logloss:0.21793\n",
            "[1200]\ttrain-logloss:0.19194\tvalid-logloss:0.21752\n",
            "[1500]\ttrain-logloss:0.18586\tvalid-logloss:0.21729\n",
            "[1639]\ttrain-logloss:0.18315\tvalid-logloss:0.21732\n",
            "Rund no: 264 Metric : 0.791510059322307 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21627\tvalid-logloss:0.22262\n",
            "[600]\ttrain-logloss:0.20584\tvalid-logloss:0.21868\n",
            "[900]\ttrain-logloss:0.19862\tvalid-logloss:0.21750\n",
            "[1200]\ttrain-logloss:0.19202\tvalid-logloss:0.21703\n",
            "[1500]\ttrain-logloss:0.18598\tvalid-logloss:0.21675\n",
            "[1786]\ttrain-logloss:0.18048\tvalid-logloss:0.21668\n",
            "Rund no: 265 Metric : 0.7929440591178134 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21627\tvalid-logloss:0.22265\n",
            "[600]\ttrain-logloss:0.20586\tvalid-logloss:0.21881\n",
            "[900]\ttrain-logloss:0.19852\tvalid-logloss:0.21759\n",
            "[1200]\ttrain-logloss:0.19197\tvalid-logloss:0.21712\n",
            "[1500]\ttrain-logloss:0.18581\tvalid-logloss:0.21680\n",
            "[1734]\ttrain-logloss:0.18129\tvalid-logloss:0.21673\n",
            "Rund no: 266 Metric : 0.7945463889392752 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21628\tvalid-logloss:0.22265\n",
            "[600]\ttrain-logloss:0.20588\tvalid-logloss:0.21875\n",
            "[900]\ttrain-logloss:0.19858\tvalid-logloss:0.21765\n",
            "[1200]\ttrain-logloss:0.19201\tvalid-logloss:0.21715\n",
            "[1500]\ttrain-logloss:0.18591\tvalid-logloss:0.21691\n",
            "[1800]\ttrain-logloss:0.18013\tvalid-logloss:0.21686\n",
            "[1820]\ttrain-logloss:0.17979\tvalid-logloss:0.21685\n",
            "Rund no: 267 Metric : 0.7930762351235403 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21627\tvalid-logloss:0.22265\n",
            "[600]\ttrain-logloss:0.20588\tvalid-logloss:0.21862\n",
            "[900]\ttrain-logloss:0.19856\tvalid-logloss:0.21745\n",
            "[1200]\ttrain-logloss:0.19207\tvalid-logloss:0.21697\n",
            "[1500]\ttrain-logloss:0.18592\tvalid-logloss:0.21678\n",
            "[1660]\ttrain-logloss:0.18280\tvalid-logloss:0.21676\n",
            "Rund no: 268 Metric : 0.793439346524442 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21624\tvalid-logloss:0.22275\n",
            "[600]\ttrain-logloss:0.20586\tvalid-logloss:0.21894\n",
            "[900]\ttrain-logloss:0.19853\tvalid-logloss:0.21784\n",
            "[1200]\ttrain-logloss:0.19195\tvalid-logloss:0.21735\n",
            "[1244]\ttrain-logloss:0.19104\tvalid-logloss:0.21730\n",
            "Rund no: 269 Metric : 0.7918716791106744 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21621\tvalid-logloss:0.22276\n",
            "[600]\ttrain-logloss:0.20582\tvalid-logloss:0.21891\n",
            "[900]\ttrain-logloss:0.19853\tvalid-logloss:0.21783\n",
            "[1200]\ttrain-logloss:0.19200\tvalid-logloss:0.21738\n",
            "[1500]\ttrain-logloss:0.18593\tvalid-logloss:0.21710\n",
            "[1662]\ttrain-logloss:0.18277\tvalid-logloss:0.21704\n",
            "Rund no: 270 Metric : 0.7923487903444579 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21626\tvalid-logloss:0.22270\n",
            "[600]\ttrain-logloss:0.20597\tvalid-logloss:0.21890\n",
            "[900]\ttrain-logloss:0.19859\tvalid-logloss:0.21778\n",
            "[1200]\ttrain-logloss:0.19198\tvalid-logloss:0.21744\n",
            "[1245]\ttrain-logloss:0.19104\tvalid-logloss:0.21734\n",
            "Rund no: 271 Metric : 0.7923677865474095 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21627\tvalid-logloss:0.22264\n",
            "[600]\ttrain-logloss:0.20584\tvalid-logloss:0.21872\n",
            "[900]\ttrain-logloss:0.19852\tvalid-logloss:0.21754\n",
            "[1200]\ttrain-logloss:0.19196\tvalid-logloss:0.21705\n",
            "[1500]\ttrain-logloss:0.18591\tvalid-logloss:0.21677\n",
            "[1800]\ttrain-logloss:0.18010\tvalid-logloss:0.21664\n",
            "[2056]\ttrain-logloss:0.17556\tvalid-logloss:0.21670\n",
            "Rund no: 272 Metric : 0.7930805622712738 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21626\tvalid-logloss:0.22277\n",
            "[600]\ttrain-logloss:0.20588\tvalid-logloss:0.21883\n",
            "[900]\ttrain-logloss:0.19854\tvalid-logloss:0.21761\n",
            "[1200]\ttrain-logloss:0.19196\tvalid-logloss:0.21722\n",
            "[1249]\ttrain-logloss:0.19094\tvalid-logloss:0.21719\n",
            "Rund no: 273 Metric : 0.7925524977534155 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21622\tvalid-logloss:0.22265\n",
            "[600]\ttrain-logloss:0.20583\tvalid-logloss:0.21879\n",
            "[900]\ttrain-logloss:0.19854\tvalid-logloss:0.21771\n",
            "[1200]\ttrain-logloss:0.19198\tvalid-logloss:0.21717\n",
            "[1500]\ttrain-logloss:0.18591\tvalid-logloss:0.21695\n",
            "[1800]\ttrain-logloss:0.18014\tvalid-logloss:0.21685\n",
            "Rund no: 274 Metric : 0.7933301401915176 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21620\tvalid-logloss:0.22261\n",
            "[600]\ttrain-logloss:0.20584\tvalid-logloss:0.21870\n",
            "[900]\ttrain-logloss:0.19857\tvalid-logloss:0.21767\n",
            "[1200]\ttrain-logloss:0.19203\tvalid-logloss:0.21727\n",
            "[1246]\ttrain-logloss:0.19107\tvalid-logloss:0.21718\n",
            "Rund no: 275 Metric : 0.7940704070868745 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21629\tvalid-logloss:0.22275\n",
            "[600]\ttrain-logloss:0.20588\tvalid-logloss:0.21884\n",
            "[900]\ttrain-logloss:0.19859\tvalid-logloss:0.21797\n",
            "[980]\ttrain-logloss:0.19676\tvalid-logloss:0.21778\n",
            "Rund no: 276 Metric : 0.7914214875689235 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21627\tvalid-logloss:0.22265\n",
            "[600]\ttrain-logloss:0.20587\tvalid-logloss:0.21879\n",
            "[900]\ttrain-logloss:0.19856\tvalid-logloss:0.21766\n",
            "[1200]\ttrain-logloss:0.19193\tvalid-logloss:0.21707\n",
            "[1385]\ttrain-logloss:0.18814\tvalid-logloss:0.21701\n",
            "Rund no: 277 Metric : 0.7914559557735203 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21627\tvalid-logloss:0.22265\n",
            "[600]\ttrain-logloss:0.20590\tvalid-logloss:0.21875\n",
            "[900]\ttrain-logloss:0.19862\tvalid-logloss:0.21767\n",
            "[1200]\ttrain-logloss:0.19202\tvalid-logloss:0.21712\n",
            "[1500]\ttrain-logloss:0.18593\tvalid-logloss:0.21691\n",
            "[1661]\ttrain-logloss:0.18282\tvalid-logloss:0.21688\n",
            "Rund no: 278 Metric : 0.7920212740292694 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21623\tvalid-logloss:0.22267\n",
            "[600]\ttrain-logloss:0.20586\tvalid-logloss:0.21877\n",
            "[900]\ttrain-logloss:0.19856\tvalid-logloss:0.21765\n",
            "[1200]\ttrain-logloss:0.19206\tvalid-logloss:0.21721\n",
            "[1500]\ttrain-logloss:0.18594\tvalid-logloss:0.21692\n",
            "[1610]\ttrain-logloss:0.18383\tvalid-logloss:0.21690\n",
            "Rund no: 279 Metric : 0.7930578649221747 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21630\tvalid-logloss:0.22275\n",
            "[600]\ttrain-logloss:0.20590\tvalid-logloss:0.21889\n",
            "[900]\ttrain-logloss:0.19867\tvalid-logloss:0.21778\n",
            "[1200]\ttrain-logloss:0.19210\tvalid-logloss:0.21734\n",
            "[1500]\ttrain-logloss:0.18597\tvalid-logloss:0.21704\n",
            "[1744]\ttrain-logloss:0.18130\tvalid-logloss:0.21704\n",
            "Rund no: 280 Metric : 0.7919736252145763 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21625\tvalid-logloss:0.22262\n",
            "[600]\ttrain-logloss:0.20588\tvalid-logloss:0.21868\n",
            "[900]\ttrain-logloss:0.19856\tvalid-logloss:0.21754\n",
            "[1200]\ttrain-logloss:0.19200\tvalid-logloss:0.21711\n",
            "[1500]\ttrain-logloss:0.18591\tvalid-logloss:0.21687\n",
            "[1800]\ttrain-logloss:0.18012\tvalid-logloss:0.21676\n",
            "[2083]\ttrain-logloss:0.17504\tvalid-logloss:0.21671\n",
            "Rund no: 281 Metric : 0.7939157682929376 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21627\tvalid-logloss:0.22265\n",
            "[600]\ttrain-logloss:0.20591\tvalid-logloss:0.21876\n",
            "[900]\ttrain-logloss:0.19863\tvalid-logloss:0.21759\n",
            "[1200]\ttrain-logloss:0.19201\tvalid-logloss:0.21718\n",
            "[1246]\ttrain-logloss:0.19105\tvalid-logloss:0.21714\n",
            "Rund no: 282 Metric : 0.7917922730820677 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21627\tvalid-logloss:0.22265\n",
            "[600]\ttrain-logloss:0.20590\tvalid-logloss:0.21876\n",
            "[900]\ttrain-logloss:0.19870\tvalid-logloss:0.21771\n",
            "[1200]\ttrain-logloss:0.19211\tvalid-logloss:0.21723\n",
            "[1500]\ttrain-logloss:0.18601\tvalid-logloss:0.21696\n",
            "[1623]\ttrain-logloss:0.18360\tvalid-logloss:0.21710\n",
            "Rund no: 283 Metric : 0.791896087258517 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21627\tvalid-logloss:0.22268\n",
            "[600]\ttrain-logloss:0.20592\tvalid-logloss:0.21885\n",
            "[900]\ttrain-logloss:0.19864\tvalid-logloss:0.21762\n",
            "[1200]\ttrain-logloss:0.19205\tvalid-logloss:0.21710\n",
            "[1500]\ttrain-logloss:0.18599\tvalid-logloss:0.21683\n",
            "[1800]\ttrain-logloss:0.18022\tvalid-logloss:0.21670\n",
            "[1946]\ttrain-logloss:0.17760\tvalid-logloss:0.21673\n",
            "Rund no: 284 Metric : 0.79338377066495 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21626\tvalid-logloss:0.22281\n",
            "[600]\ttrain-logloss:0.20588\tvalid-logloss:0.21887\n",
            "[900]\ttrain-logloss:0.19864\tvalid-logloss:0.21768\n",
            "[1200]\ttrain-logloss:0.19213\tvalid-logloss:0.21711\n",
            "[1500]\ttrain-logloss:0.18605\tvalid-logloss:0.21696\n",
            "[1503]\ttrain-logloss:0.18598\tvalid-logloss:0.21695\n",
            "Rund no: 285 Metric : 0.7926358743477684 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21625\tvalid-logloss:0.22291\n",
            "[600]\ttrain-logloss:0.20583\tvalid-logloss:0.21889\n",
            "[900]\ttrain-logloss:0.19852\tvalid-logloss:0.21775\n",
            "[1200]\ttrain-logloss:0.19198\tvalid-logloss:0.21728\n",
            "[1500]\ttrain-logloss:0.18590\tvalid-logloss:0.21698\n",
            "[1662]\ttrain-logloss:0.18277\tvalid-logloss:0.21705\n",
            "Rund no: 286 Metric : 0.7928016246884968 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21626\tvalid-logloss:0.22265\n",
            "[600]\ttrain-logloss:0.20590\tvalid-logloss:0.21873\n",
            "[900]\ttrain-logloss:0.19865\tvalid-logloss:0.21767\n",
            "[1200]\ttrain-logloss:0.19205\tvalid-logloss:0.21719\n",
            "[1500]\ttrain-logloss:0.18595\tvalid-logloss:0.21701\n",
            "[1800]\ttrain-logloss:0.18020\tvalid-logloss:0.21691\n",
            "[1837]\ttrain-logloss:0.17955\tvalid-logloss:0.21691\n",
            "Rund no: 287 Metric : 0.7927853378111185 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21619\tvalid-logloss:0.22257\n",
            "[600]\ttrain-logloss:0.20580\tvalid-logloss:0.21881\n",
            "[900]\ttrain-logloss:0.19851\tvalid-logloss:0.21769\n",
            "[1200]\ttrain-logloss:0.19200\tvalid-logloss:0.21729\n",
            "[1500]\ttrain-logloss:0.18592\tvalid-logloss:0.21701\n",
            "[1800]\ttrain-logloss:0.18013\tvalid-logloss:0.21693\n",
            "[2068]\ttrain-logloss:0.17532\tvalid-logloss:0.21686\n",
            "Rund no: 288 Metric : 0.7943920096515327 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21625\tvalid-logloss:0.22265\n",
            "[600]\ttrain-logloss:0.20587\tvalid-logloss:0.21872\n",
            "[900]\ttrain-logloss:0.19858\tvalid-logloss:0.21759\n",
            "[1200]\ttrain-logloss:0.19196\tvalid-logloss:0.21713\n",
            "[1250]\ttrain-logloss:0.19093\tvalid-logloss:0.21703\n",
            "Rund no: 289 Metric : 0.792398275021406 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21625\tvalid-logloss:0.22266\n",
            "[600]\ttrain-logloss:0.20590\tvalid-logloss:0.21886\n",
            "[900]\ttrain-logloss:0.19863\tvalid-logloss:0.21771\n",
            "[1200]\ttrain-logloss:0.19209\tvalid-logloss:0.21724\n",
            "[1500]\ttrain-logloss:0.18591\tvalid-logloss:0.21694\n",
            "[1623]\ttrain-logloss:0.18353\tvalid-logloss:0.21693\n",
            "Rund no: 290 Metric : 0.7921817850735917 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21627\tvalid-logloss:0.22267\n",
            "[600]\ttrain-logloss:0.20583\tvalid-logloss:0.21872\n",
            "[900]\ttrain-logloss:0.19863\tvalid-logloss:0.21762\n",
            "[1200]\ttrain-logloss:0.19198\tvalid-logloss:0.21713\n",
            "[1500]\ttrain-logloss:0.18587\tvalid-logloss:0.21688\n",
            "[1661]\ttrain-logloss:0.18273\tvalid-logloss:0.21684\n",
            "Rund no: 291 Metric : 0.7916571223397213 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21626\tvalid-logloss:0.22283\n",
            "[600]\ttrain-logloss:0.20586\tvalid-logloss:0.21892\n",
            "[900]\ttrain-logloss:0.19857\tvalid-logloss:0.21774\n",
            "[1200]\ttrain-logloss:0.19200\tvalid-logloss:0.21736\n",
            "[1353]\ttrain-logloss:0.18880\tvalid-logloss:0.21733\n",
            "Rund no: 292 Metric : 0.7906444781509634 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21624\tvalid-logloss:0.22276\n",
            "[600]\ttrain-logloss:0.20589\tvalid-logloss:0.21898\n",
            "[900]\ttrain-logloss:0.19863\tvalid-logloss:0.21788\n",
            "[1200]\ttrain-logloss:0.19208\tvalid-logloss:0.21746\n",
            "[1500]\ttrain-logloss:0.18602\tvalid-logloss:0.21719\n",
            "[1605]\ttrain-logloss:0.18399\tvalid-logloss:0.21737\n",
            "Rund no: 293 Metric : 0.7928856420739576 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21627\tvalid-logloss:0.22266\n",
            "[600]\ttrain-logloss:0.20587\tvalid-logloss:0.21885\n",
            "[900]\ttrain-logloss:0.19856\tvalid-logloss:0.21782\n",
            "[1200]\ttrain-logloss:0.19200\tvalid-logloss:0.21725\n",
            "[1442]\ttrain-logloss:0.18711\tvalid-logloss:0.21717\n",
            "Rund no: 294 Metric : 0.7929611069584548 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21622\tvalid-logloss:0.22260\n",
            "[600]\ttrain-logloss:0.20593\tvalid-logloss:0.21868\n",
            "[900]\ttrain-logloss:0.19861\tvalid-logloss:0.21756\n",
            "[1200]\ttrain-logloss:0.19202\tvalid-logloss:0.21713\n",
            "[1500]\ttrain-logloss:0.18593\tvalid-logloss:0.21689\n",
            "[1627]\ttrain-logloss:0.18348\tvalid-logloss:0.21695\n",
            "Rund no: 295 Metric : 0.7926616252228753 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21622\tvalid-logloss:0.22271\n",
            "[600]\ttrain-logloss:0.20584\tvalid-logloss:0.21876\n",
            "[900]\ttrain-logloss:0.19855\tvalid-logloss:0.21771\n",
            "[1200]\ttrain-logloss:0.19197\tvalid-logloss:0.21718\n",
            "[1500]\ttrain-logloss:0.18590\tvalid-logloss:0.21682\n",
            "[1672]\ttrain-logloss:0.18258\tvalid-logloss:0.21681\n",
            "Rund no: 296 Metric : 0.7923675745940715 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21624\tvalid-logloss:0.22259\n",
            "[600]\ttrain-logloss:0.20588\tvalid-logloss:0.21868\n",
            "[900]\ttrain-logloss:0.19862\tvalid-logloss:0.21757\n",
            "[1200]\ttrain-logloss:0.19203\tvalid-logloss:0.21716\n",
            "[1500]\ttrain-logloss:0.18597\tvalid-logloss:0.21702\n",
            "[1800]\ttrain-logloss:0.18018\tvalid-logloss:0.21696\n",
            "[1817]\ttrain-logloss:0.17988\tvalid-logloss:0.21698\n",
            "Rund no: 297 Metric : 0.7927028481908733 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21620\tvalid-logloss:0.22259\n",
            "[600]\ttrain-logloss:0.20584\tvalid-logloss:0.21880\n",
            "[900]\ttrain-logloss:0.19855\tvalid-logloss:0.21766\n",
            "[1200]\ttrain-logloss:0.19205\tvalid-logloss:0.21721\n",
            "[1500]\ttrain-logloss:0.18596\tvalid-logloss:0.21688\n",
            "[1661]\ttrain-logloss:0.18286\tvalid-logloss:0.21684\n",
            "Rund no: 298 Metric : 0.7930299721504428 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21626\tvalid-logloss:0.22268\n",
            "[600]\ttrain-logloss:0.20592\tvalid-logloss:0.21882\n",
            "[900]\ttrain-logloss:0.19858\tvalid-logloss:0.21764\n",
            "[1200]\ttrain-logloss:0.19201\tvalid-logloss:0.21718\n",
            "[1243]\ttrain-logloss:0.19110\tvalid-logloss:0.21712\n",
            "Rund no: 299 Metric : 0.7922428488713806 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21626\tvalid-logloss:0.22269\n",
            "[600]\ttrain-logloss:0.20589\tvalid-logloss:0.21873\n",
            "[900]\ttrain-logloss:0.19864\tvalid-logloss:0.21774\n",
            "[1200]\ttrain-logloss:0.19202\tvalid-logloss:0.21724\n",
            "[1247]\ttrain-logloss:0.19103\tvalid-logloss:0.21721\n",
            "Rund no: 300 Metric : 0.7924169062293391 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21627\tvalid-logloss:0.22265\n",
            "[600]\ttrain-logloss:0.20587\tvalid-logloss:0.21872\n",
            "[900]\ttrain-logloss:0.19857\tvalid-logloss:0.21759\n",
            "[1200]\ttrain-logloss:0.19201\tvalid-logloss:0.21715\n",
            "[1500]\ttrain-logloss:0.18591\tvalid-logloss:0.21695\n",
            "[1800]\ttrain-logloss:0.18011\tvalid-logloss:0.21684\n",
            "[1828]\ttrain-logloss:0.17960\tvalid-logloss:0.21682\n",
            "Rund no: 301 Metric : 0.7924015476102609 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21626\tvalid-logloss:0.22268\n",
            "[600]\ttrain-logloss:0.20593\tvalid-logloss:0.21876\n",
            "[900]\ttrain-logloss:0.19865\tvalid-logloss:0.21751\n",
            "[1200]\ttrain-logloss:0.19213\tvalid-logloss:0.21712\n",
            "[1249]\ttrain-logloss:0.19110\tvalid-logloss:0.21709\n",
            "Rund no: 302 Metric : 0.7933423860851256 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21626\tvalid-logloss:0.22260\n",
            "[600]\ttrain-logloss:0.20585\tvalid-logloss:0.21869\n",
            "[900]\ttrain-logloss:0.19861\tvalid-logloss:0.21759\n",
            "[1200]\ttrain-logloss:0.19206\tvalid-logloss:0.21703\n",
            "[1423]\ttrain-logloss:0.18747\tvalid-logloss:0.21698\n",
            "Rund no: 303 Metric : 0.7924971957841631 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21624\tvalid-logloss:0.22274\n",
            "[600]\ttrain-logloss:0.20591\tvalid-logloss:0.21893\n",
            "[900]\ttrain-logloss:0.19854\tvalid-logloss:0.21772\n",
            "[1200]\ttrain-logloss:0.19195\tvalid-logloss:0.21723\n",
            "[1500]\ttrain-logloss:0.18586\tvalid-logloss:0.21699\n",
            "[1662]\ttrain-logloss:0.18271\tvalid-logloss:0.21699\n",
            "Rund no: 304 Metric : 0.7920727548201646 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21627\tvalid-logloss:0.22265\n",
            "[600]\ttrain-logloss:0.20591\tvalid-logloss:0.21876\n",
            "[900]\ttrain-logloss:0.19865\tvalid-logloss:0.21768\n",
            "[1200]\ttrain-logloss:0.19207\tvalid-logloss:0.21719\n",
            "[1500]\ttrain-logloss:0.18594\tvalid-logloss:0.21692\n",
            "[1800]\ttrain-logloss:0.18016\tvalid-logloss:0.21680\n",
            "[1965]\ttrain-logloss:0.17719\tvalid-logloss:0.21678\n",
            "Rund no: 305 Metric : 0.7925704967896723 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21629\tvalid-logloss:0.22270\n",
            "[600]\ttrain-logloss:0.20591\tvalid-logloss:0.21886\n",
            "[900]\ttrain-logloss:0.19857\tvalid-logloss:0.21761\n",
            "[1200]\ttrain-logloss:0.19199\tvalid-logloss:0.21708\n",
            "[1500]\ttrain-logloss:0.18588\tvalid-logloss:0.21684\n",
            "[1734]\ttrain-logloss:0.18137\tvalid-logloss:0.21677\n",
            "Rund no: 306 Metric : 0.7927023250809112 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21627\tvalid-logloss:0.22285\n",
            "[600]\ttrain-logloss:0.20583\tvalid-logloss:0.21890\n",
            "[900]\ttrain-logloss:0.19855\tvalid-logloss:0.21783\n",
            "[1200]\ttrain-logloss:0.19200\tvalid-logloss:0.21726\n",
            "[1500]\ttrain-logloss:0.18587\tvalid-logloss:0.21692\n",
            "[1660]\ttrain-logloss:0.18272\tvalid-logloss:0.21693\n",
            "Rund no: 307 Metric : 0.7925607927694842 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21627\tvalid-logloss:0.22290\n",
            "[600]\ttrain-logloss:0.20594\tvalid-logloss:0.21896\n",
            "[900]\ttrain-logloss:0.19864\tvalid-logloss:0.21774\n",
            "[1200]\ttrain-logloss:0.19197\tvalid-logloss:0.21715\n",
            "[1428]\ttrain-logloss:0.18733\tvalid-logloss:0.21706\n",
            "Rund no: 308 Metric : 0.7912421880104537 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21619\tvalid-logloss:0.22264\n",
            "[600]\ttrain-logloss:0.20580\tvalid-logloss:0.21865\n",
            "[900]\ttrain-logloss:0.19857\tvalid-logloss:0.21753\n",
            "[1200]\ttrain-logloss:0.19203\tvalid-logloss:0.21701\n",
            "[1500]\ttrain-logloss:0.18589\tvalid-logloss:0.21678\n",
            "[1660]\ttrain-logloss:0.18277\tvalid-logloss:0.21673\n",
            "Rund no: 309 Metric : 0.7937363595251893 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21627\tvalid-logloss:0.22265\n",
            "[600]\ttrain-logloss:0.20585\tvalid-logloss:0.21870\n",
            "[900]\ttrain-logloss:0.19859\tvalid-logloss:0.21765\n",
            "[1200]\ttrain-logloss:0.19199\tvalid-logloss:0.21710\n",
            "[1500]\ttrain-logloss:0.18592\tvalid-logloss:0.21681\n",
            "[1654]\ttrain-logloss:0.18292\tvalid-logloss:0.21678\n",
            "Rund no: 310 Metric : 0.7936926470125347 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21627\tvalid-logloss:0.22265\n",
            "[600]\ttrain-logloss:0.20588\tvalid-logloss:0.21873\n",
            "[900]\ttrain-logloss:0.19861\tvalid-logloss:0.21753\n",
            "[1200]\ttrain-logloss:0.19205\tvalid-logloss:0.21701\n",
            "[1500]\ttrain-logloss:0.18596\tvalid-logloss:0.21679\n",
            "[1721]\ttrain-logloss:0.18163\tvalid-logloss:0.21675\n",
            "Rund no: 311 Metric : 0.7919553991381051 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21628\tvalid-logloss:0.22278\n",
            "[600]\ttrain-logloss:0.20587\tvalid-logloss:0.21888\n",
            "[900]\ttrain-logloss:0.19856\tvalid-logloss:0.21765\n",
            "[1200]\ttrain-logloss:0.19202\tvalid-logloss:0.21720\n",
            "[1500]\ttrain-logloss:0.18595\tvalid-logloss:0.21698\n",
            "[1800]\ttrain-logloss:0.18021\tvalid-logloss:0.21691\n",
            "[1801]\ttrain-logloss:0.18020\tvalid-logloss:0.21691\n",
            "Rund no: 312 Metric : 0.7931143246961904 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21620\tvalid-logloss:0.22272\n",
            "[600]\ttrain-logloss:0.20581\tvalid-logloss:0.21873\n",
            "[900]\ttrain-logloss:0.19856\tvalid-logloss:0.21757\n",
            "[1200]\ttrain-logloss:0.19198\tvalid-logloss:0.21698\n",
            "[1500]\ttrain-logloss:0.18598\tvalid-logloss:0.21674\n",
            "[1581]\ttrain-logloss:0.18438\tvalid-logloss:0.21673\n",
            "Rund no: 313 Metric : 0.7923206096924382 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21622\tvalid-logloss:0.22266\n",
            "[600]\ttrain-logloss:0.20589\tvalid-logloss:0.21889\n",
            "[900]\ttrain-logloss:0.19864\tvalid-logloss:0.21774\n",
            "[1200]\ttrain-logloss:0.19198\tvalid-logloss:0.21726\n",
            "[1500]\ttrain-logloss:0.18582\tvalid-logloss:0.21701\n",
            "[1626]\ttrain-logloss:0.18337\tvalid-logloss:0.21701\n",
            "Rund no: 314 Metric : 0.7928089445790707 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21626\tvalid-logloss:0.22270\n",
            "[600]\ttrain-logloss:0.20585\tvalid-logloss:0.21885\n",
            "[900]\ttrain-logloss:0.19855\tvalid-logloss:0.21764\n",
            "[1200]\ttrain-logloss:0.19203\tvalid-logloss:0.21722\n",
            "[1500]\ttrain-logloss:0.18593\tvalid-logloss:0.21700\n",
            "[1660]\ttrain-logloss:0.18280\tvalid-logloss:0.21698\n",
            "Rund no: 315 Metric : 0.792366047596212 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21626\tvalid-logloss:0.22269\n",
            "[600]\ttrain-logloss:0.20585\tvalid-logloss:0.21881\n",
            "[900]\ttrain-logloss:0.19854\tvalid-logloss:0.21772\n",
            "[1200]\ttrain-logloss:0.19199\tvalid-logloss:0.21721\n",
            "[1500]\ttrain-logloss:0.18589\tvalid-logloss:0.21692\n",
            "[1662]\ttrain-logloss:0.18273\tvalid-logloss:0.21688\n",
            "Rund no: 316 Metric : 0.7929003660965142 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21622\tvalid-logloss:0.22263\n",
            "[600]\ttrain-logloss:0.20585\tvalid-logloss:0.21871\n",
            "[900]\ttrain-logloss:0.19862\tvalid-logloss:0.21766\n",
            "[1200]\ttrain-logloss:0.19208\tvalid-logloss:0.21726\n",
            "[1500]\ttrain-logloss:0.18597\tvalid-logloss:0.21703\n",
            "[1661]\ttrain-logloss:0.18282\tvalid-logloss:0.21707\n",
            "Rund no: 317 Metric : 0.7916965210351636 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21621\tvalid-logloss:0.22261\n",
            "[600]\ttrain-logloss:0.20588\tvalid-logloss:0.21878\n",
            "[900]\ttrain-logloss:0.19864\tvalid-logloss:0.21765\n",
            "[1200]\ttrain-logloss:0.19210\tvalid-logloss:0.21721\n",
            "[1500]\ttrain-logloss:0.18598\tvalid-logloss:0.21685\n",
            "[1652]\ttrain-logloss:0.18303\tvalid-logloss:0.21684\n",
            "Rund no: 318 Metric : 0.7931955685250198 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21624\tvalid-logloss:0.22268\n",
            "[600]\ttrain-logloss:0.20593\tvalid-logloss:0.21870\n",
            "[900]\ttrain-logloss:0.19865\tvalid-logloss:0.21755\n",
            "[1200]\ttrain-logloss:0.19209\tvalid-logloss:0.21710\n",
            "[1500]\ttrain-logloss:0.18600\tvalid-logloss:0.21689\n",
            "[1689]\ttrain-logloss:0.18235\tvalid-logloss:0.21685\n",
            "Rund no: 319 Metric : 0.7937286309891004 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21619\tvalid-logloss:0.22289\n",
            "[600]\ttrain-logloss:0.20590\tvalid-logloss:0.21901\n",
            "[900]\ttrain-logloss:0.19859\tvalid-logloss:0.21790\n",
            "[1200]\ttrain-logloss:0.19204\tvalid-logloss:0.21735\n",
            "[1500]\ttrain-logloss:0.18601\tvalid-logloss:0.21702\n",
            "[1800]\ttrain-logloss:0.18020\tvalid-logloss:0.21699\n",
            "[1816]\ttrain-logloss:0.17994\tvalid-logloss:0.21700\n",
            "Rund no: 320 Metric : 0.7938256284314935 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21620\tvalid-logloss:0.22262\n",
            "[600]\ttrain-logloss:0.20582\tvalid-logloss:0.21876\n",
            "[900]\ttrain-logloss:0.19858\tvalid-logloss:0.21767\n",
            "[1200]\ttrain-logloss:0.19198\tvalid-logloss:0.21718\n",
            "[1500]\ttrain-logloss:0.18590\tvalid-logloss:0.21698\n",
            "[1701]\ttrain-logloss:0.18199\tvalid-logloss:0.21691\n",
            "Rund no: 321 Metric : 0.7933519210939506 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21623\tvalid-logloss:0.22265\n",
            "[600]\ttrain-logloss:0.20587\tvalid-logloss:0.21880\n",
            "[900]\ttrain-logloss:0.19856\tvalid-logloss:0.21768\n",
            "[1200]\ttrain-logloss:0.19200\tvalid-logloss:0.21729\n",
            "[1241]\ttrain-logloss:0.19114\tvalid-logloss:0.21720\n",
            "Rund no: 322 Metric : 0.7924109986088692 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21629\tvalid-logloss:0.22273\n",
            "[600]\ttrain-logloss:0.20582\tvalid-logloss:0.21885\n",
            "[900]\ttrain-logloss:0.19848\tvalid-logloss:0.21766\n",
            "[1200]\ttrain-logloss:0.19193\tvalid-logloss:0.21726\n",
            "[1243]\ttrain-logloss:0.19103\tvalid-logloss:0.21721\n",
            "Rund no: 323 Metric : 0.7930190899437117 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21625\tvalid-logloss:0.22274\n",
            "[600]\ttrain-logloss:0.20591\tvalid-logloss:0.21890\n",
            "[900]\ttrain-logloss:0.19860\tvalid-logloss:0.21781\n",
            "[1200]\ttrain-logloss:0.19202\tvalid-logloss:0.21724\n",
            "[1500]\ttrain-logloss:0.18597\tvalid-logloss:0.21699\n",
            "[1660]\ttrain-logloss:0.18288\tvalid-logloss:0.21698\n",
            "Rund no: 324 Metric : 0.7929176200237408 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21625\tvalid-logloss:0.22263\n",
            "[600]\ttrain-logloss:0.20588\tvalid-logloss:0.21866\n",
            "[900]\ttrain-logloss:0.19859\tvalid-logloss:0.21753\n",
            "[1200]\ttrain-logloss:0.19194\tvalid-logloss:0.21705\n",
            "[1500]\ttrain-logloss:0.18590\tvalid-logloss:0.21683\n",
            "[1661]\ttrain-logloss:0.18278\tvalid-logloss:0.21688\n",
            "Rund no: 325 Metric : 0.7920030071647405 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21624\tvalid-logloss:0.22270\n",
            "[600]\ttrain-logloss:0.20587\tvalid-logloss:0.21882\n",
            "[900]\ttrain-logloss:0.19860\tvalid-logloss:0.21765\n",
            "[1200]\ttrain-logloss:0.19205\tvalid-logloss:0.21713\n",
            "[1500]\ttrain-logloss:0.18602\tvalid-logloss:0.21683\n",
            "[1717]\ttrain-logloss:0.18184\tvalid-logloss:0.21684\n",
            "Rund no: 326 Metric : 0.7922704747469329 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21625\tvalid-logloss:0.22271\n",
            "[600]\ttrain-logloss:0.20589\tvalid-logloss:0.21885\n",
            "[900]\ttrain-logloss:0.19857\tvalid-logloss:0.21773\n",
            "[1200]\ttrain-logloss:0.19203\tvalid-logloss:0.21732\n",
            "[1500]\ttrain-logloss:0.18596\tvalid-logloss:0.21709\n",
            "[1670]\ttrain-logloss:0.18264\tvalid-logloss:0.21709\n",
            "Rund no: 327 Metric : 0.7928490769757476 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21628\tvalid-logloss:0.22284\n",
            "[600]\ttrain-logloss:0.20595\tvalid-logloss:0.21897\n",
            "[900]\ttrain-logloss:0.19867\tvalid-logloss:0.21790\n",
            "[1200]\ttrain-logloss:0.19208\tvalid-logloss:0.21735\n",
            "[1361]\ttrain-logloss:0.18876\tvalid-logloss:0.21730\n",
            "Rund no: 328 Metric : 0.7921565836460022 Max: 0.7951358214006115\n",
            "[0]\ttrain-logloss:0.66280\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.21627\tvalid-logloss:0.22265\n",
            "[600]\ttrain-logloss:0.20587\tvalid-logloss:0.21878\n",
            "[900]\ttrain-logloss:0.19861\tvalid-logloss:0.21768\n",
            "[1200]\ttrain-logloss:0.19202\tvalid-logloss:0.21723\n",
            "[1420]\ttrain-logloss:0.18752\tvalid-logloss:0.21713\n",
            "Rund no: 329 Metric : 0.7923673312811308 Max: 0.7951358214006115\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "\n",
        "thresh = 0.7922\n",
        "results = pd.DataFrame({'feature':[], 'result':[]})\n",
        "acc_hist = []\n",
        "\n",
        "\n",
        "\n",
        "for i, (m,k) in enumerate(features_select):\n",
        "  X_train[f'{m}_{k}'] = X_train[m]*X_train[k]\n",
        "  X_test[f'{m}_{k}'] = X_test[m]*X_train[k]\n",
        "\n",
        "\n",
        "  dtrain = xgb.DMatrix(data=X_train, label=y_train)\n",
        "  dvalid = xgb.DMatrix(data=X_test, label=y_test)\n",
        "\n",
        "  model = xgb.train(xgb_parms, \n",
        "                      dtrain=dtrain,\n",
        "                      evals=[(dtrain,'train'),(dvalid,'valid')],\n",
        "                      num_boost_round=9999,\n",
        "                      early_stopping_rounds=100,\n",
        "                      verbose_eval=300) \n",
        "          #model.save_model(f'/content/drive/MyDrive/Amex/parquet/XGB v2/XGB_{i}.xgb')\n",
        "\n",
        "  oof_preds = model.predict(dvalid)\n",
        "  acc = amex_metric_mod(y_test.iloc[:,0].values, oof_preds)\n",
        "\n",
        "  if i > 0: print('Rund no:',i, 'Metric :' ,acc, 'Max:' , max(max(acc_hist), acc))\n",
        "  else: print('Rund no: ',i, 'Metric : ' ,acc)\n",
        "\n",
        "  results = results.append({'feature': f'{m}_{k}', 'result': acc}, ignore_index = True)\n",
        "\n",
        "  del dtrain, dvalid, model\n",
        "  _ = gc.collect\n",
        "\n",
        "\n",
        "  if i ==0: \n",
        "    if acc <= thresh:\n",
        "      X_train = X_train_base.copy()\n",
        "      X_test = X_test_base.copy()\n",
        "      keep = 'no'\n",
        "    else: keep = 'yes'\n",
        "  elif i != 0:\n",
        "    if acc <= max(acc_hist):\n",
        "      X_train = X_train.drop([f'{m}_{k}'], axis =1)\n",
        "      X_test = X_test.drop([f'{m}_{k}'], axis =1)\n",
        "      keep = 'no'\n",
        "    else: keep = 'yes'\n",
        "\n",
        "  acc_hist.append(acc)\n",
        "  res = [f'{m}_{k}',m,k, acc, keep ]\n",
        "\n",
        "  write_results(res)\n",
        "\n",
        "  del keep, res\n",
        "\n",
        "\n",
        "\n",
        "      \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n3Msg6i2X0Ns"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res_final = pd.read_csv('/content/drive/MyDrive/Amex/parquet/XGB v2/results.csv')"
      ],
      "metadata": {
        "id": "SoTTzzRwC7Pr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res_final = res_final[res_final['keep']=='yes']"
      ],
      "metadata": {
        "id": "jUi-a4KTFVCB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res_final"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "QEj5TSwCIIiU",
        "outputId": "52105fbe-ae80-422b-e4a9-52c20ce5a32a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                feature         F1         F2    result keep\n",
              "1   S_26_mean_B_14_mean  S_26_mean  B_14_mean  0.792653  yes\n",
              "2   S_26_mean_B_13_mean  S_26_mean  B_13_mean  0.793230  yes\n",
              "63   B_26_mean_B_3_mean  B_26_mean   B_3_mean  0.794010  yes\n",
              "95  R_27_mean_D_48_mean  R_27_mean  D_48_mean  0.795136  yes"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2ded8bac-458b-4223-a30f-a1a74991f898\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature</th>\n",
              "      <th>F1</th>\n",
              "      <th>F2</th>\n",
              "      <th>result</th>\n",
              "      <th>keep</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>S_26_mean_B_14_mean</td>\n",
              "      <td>S_26_mean</td>\n",
              "      <td>B_14_mean</td>\n",
              "      <td>0.792653</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>S_26_mean_B_13_mean</td>\n",
              "      <td>S_26_mean</td>\n",
              "      <td>B_13_mean</td>\n",
              "      <td>0.793230</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>B_26_mean_B_3_mean</td>\n",
              "      <td>B_26_mean</td>\n",
              "      <td>B_3_mean</td>\n",
              "      <td>0.794010</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>R_27_mean_D_48_mean</td>\n",
              "      <td>R_27_mean</td>\n",
              "      <td>D_48_mean</td>\n",
              "      <td>0.795136</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2ded8bac-458b-4223-a30f-a1a74991f898')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2ded8bac-458b-4223-a30f-a1a74991f898 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2ded8bac-458b-4223-a30f-a1a74991f898');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "col_added = list(zip(res_final.loc[:,'F1'], res_final.loc[:,'F2']))\n",
        "col_added"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "epRmw1I6ILWi",
        "outputId": "3c4d752d-ac48-4a84-a19e-ca752c70da4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('S_26_mean', 'B_14_mean'),\n",
              " ('S_26_mean', 'B_13_mean'),\n",
              " ('B_26_mean', 'B_3_mean'),\n",
              " ('R_27_mean', 'D_48_mean')]"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "col_ad = []\n",
        "\n",
        "for m,k in col_added:\n",
        "  train[f'{m}_{k}']= train[m]*train[k] \n",
        "  col_ad = col_ad + [f'{m}_{k}']"
      ],
      "metadata": {
        "id": "EpyLSeq2ILS5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "id": "W0nL-G8MSVMl",
        "outputId": "82587af4-b096-4591-80bb-26360665abb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-119-0c1cdefd54ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'X_test' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "col_ad =pd.Index(col_ad)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQCbJhYUOrsg",
        "outputId": "9e67d624-8bfc-42f5-c469-74f5e2385988"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['S_26_mean_B_14_mean', 'S_26_mean_B_13_mean', 'B_26_mean_B_3_mean',\n",
              "       'R_27_mean_D_48_mean'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "FEATURES = FEATURES.append(col_ad)\n",
        "FEATURES"
      ],
      "metadata": {
        "id": "iX3i1WrgO_2-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del X_train, X_train_base, X_test, X_test_base, y_train, y_test\n",
        "_ = gc.collect"
      ],
      "metadata": {
        "id": "xQj9-CmPFtIO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pry4EU1SIfK8"
      },
      "outputs": [],
      "source": [
        "# NEEDED WITH DeviceQuantileDMatrix BELOW\n",
        "class IterLoadForDMatrix(xgb.core.DataIter):\n",
        "    def __init__(self, df=None, features=None, target=None, batch_size=256*1024):\n",
        "        self.features = features\n",
        "        self.target = target\n",
        "        self.df = df\n",
        "        self.it = 0 # set iterator to 0\n",
        "        self.batch_size = batch_size\n",
        "        self.batches = int( np.ceil( len(df) / self.batch_size ) )\n",
        "        super().__init__()\n",
        "\n",
        "    def reset(self):\n",
        "        '''Reset the iterator'''\n",
        "        self.it = 0\n",
        "\n",
        "    def next(self, input_data):\n",
        "        '''Yield next batch of data.'''\n",
        "        if self.it == self.batches:\n",
        "            return 0 # Return 0 when there's no more batch.\n",
        "        \n",
        "        a = self.it * self.batch_size\n",
        "        b = min( (self.it + 1) * self.batch_size, len(self.df) )\n",
        "        dt = cudf.DataFrame(self.df.iloc[a:b])\n",
        "        input_data(data=dt[self.features], label=dt[self.target]) #, weight=dt['weight'])\n",
        "        self.it += 1\n",
        "        return 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TnZKA9EO-76N",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "outputId": "2a7b2990-bd4b-461b-ab61-f2b6f2634faf"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-120-953c8026e652>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mskf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFOLDS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSEED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m for fold,(train_idx, valid_idx) in enumerate(skf.split(\n\u001b[0;32m----> 9\u001b[0;31m             train, train.target )):\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# TRAIN WITH SUBSAMPLE OF TRAIN FOLD DATA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
          ]
        }
      ],
      "source": [
        "importances = []\n",
        "oof = []\n",
        "#train = train.to_pandas() # free GPU memory\n",
        "TRAIN_SUBSAMPLE = 1.0\n",
        "gc.collect()\n",
        "\n",
        "skf = KFold(n_splits=FOLDS, shuffle=True, random_state=SEED)\n",
        "for fold,(train_idx, valid_idx) in enumerate(skf.split(\n",
        "            train, train.target )):\n",
        "    \n",
        "    # TRAIN WITH SUBSAMPLE OF TRAIN FOLD DATA\n",
        "    if TRAIN_SUBSAMPLE<1.0:\n",
        "        np.random.seed(SEED)\n",
        "        train_idx = np.random.choice(train_idx, \n",
        "                       int(len(train_idx)*TRAIN_SUBSAMPLE), replace=False)\n",
        "        np.random.seed(None)\n",
        "    \n",
        "    print('#'*25)\n",
        "    print('### Fold',fold+1)\n",
        "    print('### Train size',len(train_idx),'Valid size',len(valid_idx))\n",
        "    print(f'### Training with {int(TRAIN_SUBSAMPLE*100)}% fold data...')\n",
        "    print('#'*25)\n",
        "    \n",
        "    # TRAIN, VALID, TEST FOR FOLD K\n",
        "    Xy_train = IterLoadForDMatrix(train.loc[train_idx], FEATURES, 'target')\n",
        "    X_valid = train.loc[valid_idx, FEATURES]\n",
        "    y_valid = train.loc[valid_idx, 'target']\n",
        "    \n",
        "    dtrain = xgb.DeviceQuantileDMatrix(Xy_train, max_bin=256)\n",
        "    dvalid = xgb.DMatrix(data=X_valid, label=y_valid)\n",
        "    \n",
        "    # TRAIN MODEL FOLD K\n",
        "    model = xgb.train(xgb_parms, \n",
        "                dtrain=dtrain,\n",
        "                evals=[(dtrain,'train'),(dvalid,'valid')],\n",
        "                num_boost_round=9999,\n",
        "                early_stopping_rounds=100,\n",
        "                verbose_eval=100) \n",
        "    model.save_model(f'/content/drive/MyDrive/Amex/parquet/XGB v2/XGB_v{VER}_fold{fold}.xgb')\n",
        "    \n",
        "    # GET FEATURE IMPORTANCE FOR FOLD K\n",
        "    dd = model.get_score(importance_type='weight')\n",
        "    df = pd.DataFrame({'feature':dd.keys(),f'importance_{fold}':dd.values()})\n",
        "    importances.append(df)\n",
        "            \n",
        "    # INFER OOF FOLD K\n",
        "    oof_preds = model.predict(dvalid)\n",
        "    acc = amex_metric_mod(y_valid.values, oof_preds)\n",
        "    print('Kaggle Metric =',acc,'\\n')\n",
        "    \n",
        "    # SAVE OOF\n",
        "    df = train.loc[valid_idx, ['customer_ID','target'] ].copy()\n",
        "    df['oof_pred'] = oof_preds\n",
        "    oof.append( df )\n",
        "    \n",
        "    del dtrain, Xy_train, dd, df\n",
        "    del X_valid, y_valid, dvalid, model\n",
        "    _ = gc.collect()\n",
        "    \n",
        "print('#'*25)\n",
        "oof = pd.concat(oof,axis=0,ignore_index=True).set_index('customer_ID')\n",
        "acc = amex_metric_mod(oof.target.values, oof.oof_pred.values)\n",
        "print('OVERALL CV Kaggle Metric =',acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nbmXCE7yN59I"
      },
      "outputs": [],
      "source": [
        "# #train model again with full set\n",
        "\n",
        "# Xy_train = IterLoadForDMatrix(train, FEATURES, 'target')\n",
        "# dtrain = xgb.DeviceQuantileDMatrix(Xy_train, max_bin=256)\n",
        "# # TRAIN MODEL\n",
        "# model = xgb.train(xgb_parms, \n",
        "#                 dtrain=dtrain,\n",
        "#                 evals=[(dtrain,'train'),(dtrain,'train')],\n",
        "#                 num_boost_round=1200,\n",
        "#                 early_stopping_rounds=100,\n",
        "#                 verbose_eval=100\n",
        "#                 )\n",
        "# model.save_model(f'XGB_full.xgb')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2fY06mhh-73M"
      },
      "outputs": [],
      "source": [
        "# CLEAN RAM\n",
        "del train\n",
        "_ = gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7sW60y39kqZt"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tkn5B21Tp0OA"
      },
      "source": [
        "# Save OOF Preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "69sI09-OYv-i",
        "outputId": "e93e7c87-fcc9-446d-d55c-f72779c44a8b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                         customer_ID  target  oof_pred\n",
              "0  20eac26171c3d251c55fc78204e59fab1c15fc2bc96d0c...       1  0.694981\n",
              "1  aea50fdf9b974ccec95fa177c3225a0f913483b457de6e...       0  0.000489\n",
              "2  32cd2d41aef737b69089882754395925c96eaee1f4a859...       0  0.002206\n",
              "3  8daa6d5dc2655a8a437531e6b8b96829113cdfe9bf6cae...       0  0.020012\n",
              "4  0ceba351a3851202542feb49d7385bcef32f6037fc57c7...       1  0.866356"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a7c2b20e-7f89-46f8-b328-c067ede1884c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>customer_ID</th>\n",
              "      <th>target</th>\n",
              "      <th>oof_pred</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20eac26171c3d251c55fc78204e59fab1c15fc2bc96d0c...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.694981</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>aea50fdf9b974ccec95fa177c3225a0f913483b457de6e...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000489</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>32cd2d41aef737b69089882754395925c96eaee1f4a859...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.002206</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8daa6d5dc2655a8a437531e6b8b96829113cdfe9bf6cae...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.020012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0ceba351a3851202542feb49d7385bcef32f6037fc57c7...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.866356</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a7c2b20e-7f89-46f8-b328-c067ede1884c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a7c2b20e-7f89-46f8-b328-c067ede1884c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a7c2b20e-7f89-46f8-b328-c067ede1884c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ],
      "source": [
        "oof_xgb = pd.read_parquet(TRAIN_PATH, columns=['customer_ID']).drop_duplicates()\n",
        "oof_xgb['customer_ID_hash'] = oof_xgb['customer_ID'].apply(lambda x: int(x[-16:],16) ).astype('int64')\n",
        "oof_xgb = oof_xgb.set_index('customer_ID_hash')\n",
        "oof_xgb = oof_xgb.merge(oof, left_index=True, right_index=True)\n",
        "oof_xgb = oof_xgb.sort_index().reset_index(drop=True)\n",
        "oof_xgb.to_csv(f'oof_xgb_v{VER}.csv',index=False)\n",
        "oof_xgb.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "dZUhtbYQYv00",
        "outputId": "ea2125eb-a66a-4bac-81e6-c2cae1bb562d"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEICAYAAABBBrPDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAbwUlEQVR4nO3df5RfdX3n8eeriVC3gAlkZCOJBjW6jbRGmGKq1UVRCLRLsLU07NEEyxIt4NbVWlF7DizKOVBXPbKLuEFyCB7lhyBLVkMhi1haa5BBkF9KGUJokgYykABqKhB87R/3M3oZv3Pnm/nOfCeTeT3O+Z653/f9fO79fIYwr7k/vndkm4iIiOH8xkQPICIi9mwJioiIaJSgiIiIRgmKiIholKCIiIhGCYqIiGiUoIiYYJKOkrS59v4+SUeNYjtvkfTAmA4uggRFTFKSTpF0j6Sdkh6VdLGkGUPaLJC0RtJTkn4i6RZJb6qtnyfJkn5ae/1wmP2dI+m50uZJSf8k6ffHY262X2f7OyO1K2N/da3fP9h+7XiMKaa2BEVMOpI+AlwAfBR4CbAIeAWwTtI+pc2rgO8C9wCHAi8DrgNuavEDfobt/crr9Q27vsr2fkAP8I/ANySpxfimdTTBiD1MgiImFUkHAP8d+KDtv7P9nO2NwEnAPOA9pek5wPdsf9L2dts/sX0h8BWqkBk1288Bq4F/Dxwk6bJyRLNW0s+At0l6maRrJQ1IeljSf63N4cWlzw5J9wO/N2SOGyW9oyxPk/QJSQ+Vo6I7JM2VdGtp/sNylPNnLU5h/bak75QjoPsknVBbd5mkiyR9q2z3thKuqPJ5SdskPV2O3A7r5HsWk1uCIiabNwG/CXyjXrT9U2At8M5Seifw9Rb9rwbeLOnFox2ApH2BU4BNth8v5f8MnAfsD/wT8H+BHwKHAEcDH5J0bGl7NvCq8joWWN6wuw8DJwPHAwcAfw7stP3Wsv715UjoqiFjfFEZw03AS4EPAl+VVD81tZQqdGcC/WX8AMcAbwVeQ3XEdhLwxEjfl9h7JShispkFPG57V4t1W8v6wXZbh2nzG8CBtdrj5bfuJyX9VcO+T5L0JLAJOAJ4V23d9ba/a/sXwO8APbbPtf2s7Q3AJVQ/mKH6wXteOdLZBFzYsM//AvyN7Qdc+aHtdn5oLwL2A84vY/g28E2q0Bl0ne3vl+/lV4GFpf4cVeD9B0C2f2S71fcypojpEz2AiN30ODBL0vQWYTG7rB9sN7tF/9nAL4AdVL9pA8waJniGutr2e4ZZt6m2/ArgZSVUBk0D/qEsv2xI+0ca9jkXeKiNsQ31Mqojnl8M2c8htfeP1pZ3UgULtr8t6X8BFwGvkPQN4K9sPz2KccReIEcUMdl8D3gG+ON6UdJ+wHHAzaX0/4A/bdH/JKprFzvHeFz1xzBvAh62PaP22t/28WX9VqoAGPTyhu1uojpFtbv+FZgrqf7/+MuBLe10tn2h7SOABVSnoD46ijHEXiJBEZOK7aeozqv/T0mLJb1I0jyqaw+bqS5WU9q8SdJ5kg6UtL+kDwLLgI+N8zC/D/xE0sfKhetpkg6TNHjR+mrg45JmSppDdf1gOF8GPiVpfrnI/LuSDirrHgNeOUy/26iOEv66fI+OAv4TcOVIg5f0e5LeWK5z/Az4OdVRWExRCYqYdGz/LfAJ4H8AT1P9UNwEHG37mdLmQeAPgNcDG6l+i/8T4Fjb3x3n8T0P/BHVOf+HqU6DfZnqwjBUIfZIWXcTvwq3Vj5HFSw3Uc31UmDwQvw5wOpybeWkIWN4lioYjiv7/yKwzPaP25jCAVTXVHaUcT4BfKaNfrGXUv5wUURENMkRRURENEpQREREowRFREQ0SlBERESjve4Dd7NmzfK8efMmehgREZPKHXfc8bjtnlbrRgwKSXOBy4GDqT5UtNL2FyQdCFxF9SC2jcBJtneUp2l+gerZNDuBU2z/oGxrOfA3ZdOftr261I8ALqO67W8t8Je2Pdw+msY7b948+vr6RppWRETUSBr2CQHtnHraBXzE9gKq58ecIWkBcBZws+35VJ+GPau0Pw6YX14rgIvLIA6kehjaG4EjgbMlzSx9LgZOq/VbXOrD7SMiIrpkxKCwvXXwiMD2T4AfUT0vZgnVo5YpX08sy0uAy8sDzNYDMyTNpnpK5rryILQdwDpgcVl3gO31rj7UcfmQbbXaR0REdMluXcwuj0p4A9UnYQ+uPVHyUapTU1CFSP2BZ5tLram+uUWdhn0MHdcKSX2S+gYGBnZnShERMYK2g6I8dO1a4ENDnyJZjgTG9SPeTfuwvdJ2r+3enp6W12IiImKU2gqK8nCwa4Gv2h78gzGPldNGlK/bSn0LL3wy5pxSa6rPaVFv2kdERHTJiEFR7mK6FPiR7c/VVq3hV3+Zazlwfa2+rDzpchHwVDl9dCNwTHli5kyqv6J1Y1n3tKRFZV/Lhmyr1T4iIqJL2vkcxZuB9wL3SLqr1D4BnA9cLelUqidMDj69ci3VrbH9VLfHvg/A9nZJnwJuL+3Otb29LJ/Or26PvaG8aNhHRER0yV739Nje3l7ncxQREbtH0h22e1utyyM8IiKi0V73CI9OzDvrW79c3nj+H07gSCIi9hw5ooiIiEYJioiIaJSgiIiIRgmKiIholKCIiIhGCYqIiGiUoIiIiEYJioiIaJSgiIiIRgmKiIholKCIiIhGCYqIiGiUoIiIiEYJioiIaJSgiIiIRgmKiIhoNGJQSFolaZuke2u1qyTdVV4bB/+WtqR5kv6ttu5LtT5HSLpHUr+kCyWp1A+UtE7Sg+XrzFJXadcv6W5Jh4/99CMiYiTtHFFcBiyuF2z/me2FthcC1wLfqK1+aHCd7Q/U6hcDpwHzy2twm2cBN9ueD9xc3gMcV2u7ovSPiIguGzEobN8KbG+1rhwVnARc0bQNSbOBA2yvt23gcuDEsnoJsLosrx5Sv9yV9cCMsp2IiOiiTq9RvAV4zPaDtdqhku6U9PeS3lJqhwCba202lxrAwba3luVHgYNrfTYN0+cFJK2Q1Cepb2BgoIPpRETEUJ0Gxcm88GhiK/By228APgx8TdIB7W6sHG14dwdhe6XtXtu9PT09u9s9IiIaTB9tR0nTgT8Gjhis2X4GeKYs3yHpIeA1wBZgTq37nFIDeEzSbNtby6mlbaW+BZg7TJ+IiOiSTo4o3gH82PYvTylJ6pE0rSy/kupC9IZyaulpSYvKdY1lwPWl2xpgeVlePqS+rNz9tAh4qnaKKiIiuqSd22OvAL4HvFbSZkmnllVL+fWL2G8F7i63y14DfMD24IXw04EvA/3AQ8ANpX4+8E5JD1KFz/mlvhbYUNpfUvpHRESXjXjqyfbJw9RPaVG7lup22Vbt+4DDWtSfAI5uUTdwxkjji4iI8ZVPZkdERKMERURENEpQREREowRFREQ0SlBERESjBEVERDRKUERERKMERURENEpQREREowRFREQ0SlBERESjBEVERDRKUERERKMERURENEpQREREowRFREQ0SlBERESjBEVERDRq529mr5K0TdK9tdo5krZIuqu8jq+t+7ikfkkPSDq2Vl9cav2SzqrVD5V0W6lfJWmfUt+3vO8v6+eN1aQjIqJ97RxRXAYsblH/vO2F5bUWQNICYCnwutLni5KmSZoGXAQcBywATi5tAS4o23o1sAM4tdRPBXaU+udLu4iI6LIRg8L2rcD2Nre3BLjS9jO2Hwb6gSPLq9/2BtvPAlcCSyQJeDtwTem/Gjixtq3VZfka4OjSPiIiuqiTaxRnSrq7nJqaWWqHAJtqbTaX2nD1g4Anbe8aUn/Btsr6p0r7XyNphaQ+SX0DAwMdTCkiIoYabVBcDLwKWAhsBT47ZiMaBdsrbffa7u3p6ZnIoURE7HVGFRS2H7P9vO1fAJdQnVoC2ALMrTWdU2rD1Z8AZkiaPqT+gm2V9S8p7SMiootGFRSSZtfevgsYvCNqDbC03LF0KDAf+D5wOzC/3OG0D9UF7zW2DdwCvLv0Xw5cX9vW8rL8buDbpX1ERHTR9JEaSLoCOAqYJWkzcDZwlKSFgIGNwPsBbN8n6WrgfmAXcIbt58t2zgRuBKYBq2zfV3bxMeBKSZ8G7gQuLfVLga9I6qe6mL6049lGRMRuGzEobJ/conxpi9pg+/OA81rU1wJrW9Q38KtTV/X6z4E/HWl8ERExvvLJ7IiIaJSgiIiIRgmKiIholKCIiIhGCYqIiGiUoIiIiEYJioiIaJSgiIiIRgmKiIholKCIiIhGCYqIiGiUoIiIiEYJioiIaJSgiIiIRgmKiIholKCIiIhGCYqIiGg0YlBIWiVpm6R7a7XPSPqxpLslXSdpRqnPk/Rvku4qry/V+hwh6R5J/ZIulKRSP1DSOkkPlq8zS12lXX/Zz+FjP/2IiBhJO0cUlwGLh9TWAYfZ/l3gn4GP19Y9ZHtheX2gVr8YOA2YX16D2zwLuNn2fODm8h7guFrbFaV/RER02YhBYftWYPuQ2k22d5W364E5TduQNBs4wPZ62wYuB04sq5cAq8vy6iH1y11ZD8wo24mIiC4ai2sUfw7cUHt/qKQ7Jf29pLeU2iHA5lqbzaUGcLDtrWX5UeDgWp9Nw/R5AUkrJPVJ6hsYGOhgKhERMVRHQSHpk8Au4KultBV4ue03AB8GvibpgHa3V442vLvjsL3Sdq/t3p6ent3tHhERDaaPtqOkU4A/Ao4uP+Cx/QzwTFm+Q9JDwGuALbzw9NScUgN4TNJs21vLqaVtpb4FmDtMn4iI6JJRHVFIWgz8NXCC7Z21eo+kaWX5lVQXojeUU0tPS1pU7nZaBlxfuq0Blpfl5UPqy8rdT4uAp2qnqCIioktGPKKQdAVwFDBL0mbgbKq7nPYF1pW7XNeXO5zeCpwr6TngF8AHbA9eCD+d6g6qF1Nd0xi8rnE+cLWkU4FHgJNKfS1wPNAP7ATe18lEIyJidEYMCtsntyhfOkzba4Frh1nXBxzWov4EcHSLuoEzRhpfRESMr3wyOyIiGiUoIiKiUYIiIiIaJSgiIqJRgiIiIholKCIiolGCIiIiGiUoIiKiUYIiIiIaJSgiIqJRgiIiIholKCIiolGCIiIiGiUoIiKiUYIiIiIaJSgiIqJRgiIiIholKCIiolFbQSFplaRtku6t1Q6UtE7Sg+XrzFKXpAsl9Uu6W9LhtT7LS/sHJS2v1Y+QdE/pc6HKH+Iebh8REdE97R5RXAYsHlI7C7jZ9nzg5vIe4DhgfnmtAC6G6oc+cDbwRuBI4OzaD/6LgdNq/RaPsI+IiOiStoLC9q3A9iHlJcDqsrwaOLFWv9yV9cAMSbOBY4F1trfb3gGsAxaXdQfYXm/bwOVDttVqHxER0SWdXKM42PbWsvwocHBZPgTYVGu3udSa6ptb1Jv28QKSVkjqk9Q3MDAwyulEREQrY3IxuxwJeCy2NZp92F5pu9d2b09Pz3gOIyJiyukkKB4rp40oX7eV+hZgbq3dnFJrqs9pUW/aR0REdEknQbEGGLxzaTlwfa2+rNz9tAh4qpw+uhE4RtLMchH7GODGsu5pSYvK3U7Lhmyr1T4iIqJLprfTSNIVwFHALEmbqe5eOh+4WtKpwCPASaX5WuB4oB/YCbwPwPZ2SZ8Cbi/tzrU9eIH8dKo7q14M3FBeNOwjIiK6pK2gsH3yMKuObtHWwBnDbGcVsKpFvQ84rEX9iVb7iIiI7sknsyMiolGCIiIiGiUoIiKiUYIiIiIaJSgiIqJRgiIiIholKCIiolGCIiIiGiUoIiKiUYIiIiIaJSgiIqJRgiIiIholKCIiolGCIiIiGiUoIiKiUYIiIiIaJSgiIqJRgiIiIhqNOigkvVbSXbXX05I+JOkcSVtq9eNrfT4uqV/SA5KOrdUXl1q/pLNq9UMl3VbqV0naZ/RTjYiI0Rh1UNh+wPZC2wuBI4CdwHVl9ecH19leCyBpAbAUeB2wGPiipGmSpgEXAccBC4CTS1uAC8q2Xg3sAE4d7XgjImJ0xurU09HAQ7YfaWizBLjS9jO2Hwb6gSPLq9/2BtvPAlcCSyQJeDtwTem/GjhxjMYbERFtGqugWApcUXt/pqS7Ja2SNLPUDgE21dpsLrXh6gcBT9reNaT+ayStkNQnqW9gYKDz2URExC91HBTlusEJwNdL6WLgVcBCYCvw2U73MRLbK2332u7t6ekZ791FREwp08dgG8cBP7D9GMDgVwBJlwDfLG+3AHNr/eaUGsPUnwBmSJpejirq7SMiokvG4tTTydROO0maXVv3LuDesrwGWCppX0mHAvOB7wO3A/PLHU77UJ3GWmPbwC3Au0v/5cD1YzDeiIjYDR0dUUj6LeCdwPtr5b+VtBAwsHFwne37JF0N3A/sAs6w/XzZzpnAjcA0YJXt+8q2PgZcKenTwJ3ApZ2MNyIidl9HQWH7Z1QXneu19za0Pw84r0V9LbC2RX0D1V1RERExQfLJ7IiIaJSgiIiIRgmKiIholKCIiIhGCYqIiGiUoIiIiEYJioiIaJSgiIiIRgmKiIholKCIiIhGCYqIiGiUoIiIiEYJioiIaJSgiIiIRgmKiIholKCIiIhGCYqIiGjUcVBI2ijpHkl3SeortQMlrZP0YPk6s9Ql6UJJ/ZLulnR4bTvLS/sHJS2v1Y8o2+8vfdXpmCMion1jdUTxNtsLbfeW92cBN9ueD9xc3gMcB8wvrxXAxVAFC3A28EaqP3169mC4lDan1fotHqMxR0REG8br1NMSYHVZXg2cWKtf7sp6YIak2cCxwDrb223vANYBi8u6A2yvt23g8tq2IiKiC8YiKAzcJOkOSStK7WDbW8vyo8DBZfkQYFOt7+ZSa6pvblF/AUkrJPVJ6hsYGOh0PhERUTN9DLbxB7a3SHopsE7Sj+srbVuSx2A/w7K9ElgJ0NvbO677ioiYajo+orC9pXzdBlxHdY3hsXLaiPJ1W2m+BZhb6z6n1Jrqc1rUIyKiSzoKCkm/JWn/wWXgGOBeYA0weOfScuD6srwGWFbufloEPFVOUd0IHCNpZrmIfQxwY1n3tKRF5W6nZbVtRUREF3R66ulg4Lpyx+p04Gu2/07S7cDVkk4FHgFOKu3XAscD/cBO4H0AtrdL+hRwe2l3ru3tZfl04DLgxcAN5RUREV3SUVDY3gC8vkX9CeDoFnUDZwyzrVXAqhb1PuCwTsYZERGjl09mR0REowRFREQ0SlBERESjBEVERDRKUERERKMERURENEpQREREowRFREQ0SlBERESjBEVERDRKUERERKMERURENEpQREREowRFREQ0SlBERESjBEVERDRKUERERKNO/xTqXmveWd/65fLG8/9wAkcSETGxRn1EIWmupFsk3S/pPkl/WernSNoi6a7yOr7W5+OS+iU9IOnYWn1xqfVLOqtWP1TSbaV+laR9RjveiIgYnU5OPe0CPmJ7AbAIOEPSgrLu87YXltdagLJuKfA6YDHwRUnTJE0DLgKOAxYAJ9e2c0HZ1quBHcCpHYw3IiJGYdRBYXur7R+U5Z8APwIOaeiyBLjS9jO2Hwb6gSPLq9/2BtvPAlcCSyQJeDtwTem/GjhxtOONiIjRGZOL2ZLmAW8AbiulMyXdLWmVpJmldgiwqdZtc6kNVz8IeNL2riH1VvtfIalPUt/AwMAYzCgiIgZ1HBSS9gOuBT5k+2ngYuBVwEJgK/DZTvcxEtsrbffa7u3p6Rnv3UVETCkd3fUk6UVUIfFV298AsP1Ybf0lwDfL2y3A3Fr3OaXGMPUngBmSppejinr7iIjokk7uehJwKfAj25+r1WfXmr0LuLcsrwGWStpX0qHAfOD7wO3A/HKH0z5UF7zX2DZwC/Du0n85cP1oxxsREaPTyRHFm4H3AvdIuqvUPkF119JCwMBG4P0Atu+TdDVwP9UdU2fYfh5A0pnAjcA0YJXt+8r2PgZcKenTwJ1UwRQREV006qCw/Y+AWqxa29DnPOC8FvW1rfrZ3kB1V1REREyQPMIjIiIaJSgiIqJRgiIiIholKCIiolGCIiIiGuUx423II8cjYipLUERETGLd+EU2p54iIqJRgiIiIholKCIiolGuUeymXNiOiKkmRxQREdEoQREREY1y6qkD9dNQkFNREbF3SlBEREwyQ39JHW8JijGUC90RsTdKUIyT4RI/ARIR7ej2UUOTBEWXJUAipqY96Qf/7trjg0LSYuALVH9P+8u2z5/gIY2LTv4RJWQi2jeZf2BPlD06KCRNAy4C3glsBm6XtMb2/RM7sj1L/uFHxHja0z9HcSTQb3uD7WeBK4ElEzymiIgpZY8+ogAOATbV3m8G3ji0kaQVwIry9qeSHhjl/mYBj4+y72SVOU8NmfMUoAs6mvMrhluxpwdFW2yvBFZ2uh1JfbZ7x2BIk0bmPDVkzlPDeM15Tz/1tAWYW3s/p9QiIqJL9vSguB2YL+lQSfsAS4E1EzymiIgpZY8+9WR7l6QzgRupbo9dZfu+cdxlx6evJqHMeWrInKeGcZmzbI/HdiMiYi+xp596ioiICZagiIiIRlMyKCQtlvSApH5JZ7VYv6+kq8r62yTN6/4ox1Ybc/6wpPsl3S3pZknD3lM9WYw051q7P5FkSZP+Vsp25izppPLf+j5JX+v2GMdaG/+2Xy7pFkl3ln/fx0/EOMeKpFWStkm6d5j1knRh+X7cLenwjndqe0q9qC6KPwS8EtgH+CGwYEib04EvleWlwFUTPe4uzPltwL8ry38xFeZc2u0P3AqsB3onetxd+O88H7gTmFnev3Six92FOa8E/qIsLwA2TvS4O5zzW4HDgXuHWX88cAMgYBFwW6f7nIpHFO08FmQJsLosXwMcLUldHONYG3HOtm+xvbO8XU/1mZXJrN3Hv3wKuAD4eTcHN07amfNpwEW2dwDY3tblMY61duZs4ICy/BLgX7s4vjFn+1Zge0OTJcDlrqwHZkia3ck+p2JQtHosyCHDtbG9C3gKOKgroxsf7cy57lSq30gmsxHnXA7J59reW56q2M5/59cAr5H0XUnry9OZJ7N25nwO8B5Jm4G1wAe7M7QJs7v/v49oj/4cRXSfpPcAvcB/nOixjCdJvwF8DjhlgofSbdOpTj8dRXXUeKuk37H95ISOanydDFxm+7OSfh/4iqTDbP9iogc2WUzFI4p2HgvyyzaSplMdrj7RldGNj7YehSLpHcAngRNsP9OlsY2Xkea8P3AY8B1JG6nO5a6Z5Be02/nvvBlYY/s52w8D/0wVHJNVO3M+FbgawPb3gN+kemDg3mrMH300FYOinceCrAGWl+V3A992uUo0SY04Z0lvAP43VUhM9vPWMMKcbT9le5btebbnUV2XOcF238QMd0y082/7/1AdTSBpFtWpqA3dHOQYa2fO/wIcDSDpt6mCYqCro+yuNcCycvfTIuAp21s72eCUO/XkYR4LIulcoM/2GuBSqsPTfqqLRksnbsSda3POnwH2A75ertv/i+0TJmzQHWpzznuVNud8I3CMpPuB54GP2p60R8ttzvkjwCWS/hvVhe1TJvMvfpKuoAr7WeW6y9nAiwBsf4nqOszxQD+wE3hfx/ucxN+viIjogql46ikiInZDgiIiIholKCIiolGCIiIiGiUoIiKiUYIiIiIaJSgiIqLR/wekMoYITF+gPgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# PLOT OOF PREDICTIONS\n",
        "plt.hist(oof_xgb.oof_pred.values, bins=100)\n",
        "plt.title('OOF Predictions')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ttbu6b88p0OA"
      },
      "outputs": [],
      "source": [
        "# CLEAR VRAM, RAM FOR INFERENCE BELOW\n",
        "del oof_xgb, oof\n",
        "_ = gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_S5V_ZCp0OA"
      },
      "source": [
        "# Feature Importance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jNrw2WYOV7zt"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df = importances[0].copy()\n",
        "for k in range(1,FOLDS): df = df.merge(importances[k], on='feature', how='left')\n",
        "df['importance'] = df.iloc[:,1:].mean(axis=1)\n",
        "df = df.sort_values('importance',ascending=False)\n",
        "df.to_csv(f'xgb_feature_importance_v{VER}.csv',index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "QXCr0VOyV8bZ",
        "outputId": "bac1cc64-f96d-4a60-c2a4-801d2a810020"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "NUM_FEATURES = 20\n",
        "plt.figure(figsize=(10,5*NUM_FEATURES//10))\n",
        "plt.barh(np.arange(NUM_FEATURES,0,-1), df.importance.values[:NUM_FEATURES])\n",
        "plt.yticks(np.arange(NUM_FEATURES,0,-1), df.feature.values[:NUM_FEATURES])\n",
        "plt.title(f'XGB Feature Importance - Top {NUM_FEATURES}')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NnTqDaIp0OB"
      },
      "source": [
        "# Process and Feature Engineer Test Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DBnfSzhIeECa"
      },
      "outputs": [],
      "source": [
        "_ = gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mLEPOC2ap0OB",
        "outputId": "760dbbcf-0a25-4489-bb24-cbf86397bd2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading test data...\n",
            "shape of data: (11363762, 2)\n",
            "We will process test data as 4 separate parts.\n",
            "There will be 231155 customers in each part (except the last part).\n",
            "Below are number of rows in each part:\n",
            "[2841209, 2839857, 2842105, 2840591]\n"
          ]
        }
      ],
      "source": [
        "# CALCULATE SIZE OF EACH SEPARATE TEST PART\n",
        "def get_rows(customers, test, NUM_PARTS = 4, verbose = ''):\n",
        "    chunk = len(customers)//NUM_PARTS\n",
        "    if verbose != '':\n",
        "        print(f'We will process {verbose} data as {NUM_PARTS} separate parts.')\n",
        "        print(f'There will be {chunk} customers in each part (except the last part).')\n",
        "        print('Below are number of rows in each part:')\n",
        "    rows = []\n",
        "\n",
        "    for k in range(NUM_PARTS):\n",
        "        if k==NUM_PARTS-1: cc = customers[k*chunk:]\n",
        "        else: cc = customers[k*chunk:(k+1)*chunk]\n",
        "        s = test.loc[test.customer_ID.isin(cc)].shape[0]\n",
        "        rows.append(s)\n",
        "    if verbose != '': print( rows )\n",
        "    return rows,chunk\n",
        "\n",
        "# COMPUTE SIZE OF 4 PARTS FOR TEST DATA\n",
        "NUM_PARTS = 4\n",
        "TEST_PATH = 'test.parquet'\n",
        "\n",
        "print(f'Reading test data...')\n",
        "test = read_file(path = TEST_PATH, usecols = ['customer_ID','S_2'])\n",
        "test = handle_na(test,NAN_VALUE)\n",
        "customers = test[['customer_ID']].drop_duplicates().sort_index().values.flatten()\n",
        "rows,num_cust = get_rows(customers, test[['customer_ID']], NUM_PARTS = NUM_PARTS, verbose = 'test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bJeJFYqQpdzT"
      },
      "outputs": [],
      "source": [
        "os.chdir('/content/drive/MyDrive/Amex/parquet/')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOK1diNsp0OB"
      },
      "source": [
        "# Infer Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9OGciocgp0OC",
        "outputId": "63fe6f6d-756e-4638-9a35-0a2dee7ac5b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Reading test data...\n",
            "shape of data: (11363762, 190)\n",
            "=> Test part 1 has shape (2841209, 190)\n",
            "shape after engineering (231155, 1114)\n",
            "\n",
            "Reading test data...\n",
            "shape of data: (11363762, 190)\n",
            "=> Test part 2 has shape (2839857, 190)\n",
            "shape after engineering (231155, 1114)\n",
            "\n",
            "Reading test data...\n",
            "shape of data: (11363762, 190)\n",
            "=> Test part 3 has shape (2842105, 190)\n",
            "shape after engineering (231155, 1114)\n",
            "\n",
            "Reading test data...\n",
            "shape of data: (11363762, 190)\n",
            "=> Test part 4 has shape (2840591, 190)\n",
            "shape after engineering (231156, 1114)\n"
          ]
        }
      ],
      "source": [
        "# INFER TEST DATA IN PARTS\n",
        "skip_rows = 0\n",
        "skip_cust = 0\n",
        "test_preds = []\n",
        "\n",
        "for k in range(NUM_PARTS):\n",
        "    \n",
        "    # READ PART OF TEST DATA\n",
        "    print(f'\\nReading test data...')\n",
        "    test = read_file(path = TEST_PATH)\n",
        "    test = test.iloc[skip_rows:skip_rows+rows[k]]\n",
        "    skip_rows += rows[k]\n",
        "    print(f'=> Test part {k+1} has shape', test.shape )\n",
        "    \n",
        "    # PROCESS AND FEATURE ENGINEER PART OF TEST DATA\n",
        "    test = process_and_feature_engineer(test,cat_features, num_features, growth)\n",
        "    for m,k in col_added:\n",
        "      test[f'{m}_{k}']= test[m]*test[k] \n",
        "    if k==NUM_PARTS-1: test = test.loc[customers[skip_cust:]]\n",
        "    else: test = test.loc[customers[skip_cust:skip_cust+num_cust]]\n",
        "    skip_cust += num_cust\n",
        "    \n",
        "    # TEST DATA FOR XGB\n",
        "    X_test = test[FEATURES]\n",
        "    dtest = xgb.DMatrix(data=X_test)\n",
        "    del test \n",
        "    del X_test\n",
        "    gc.collect()\n",
        "\n",
        "    # INFER XGB MODELS ON TEST DATA\n",
        "    model = xgb.Booster()\n",
        "    model.load_model(f'XGB_v{VER}_fold0.xgb')\n",
        "    #model.load_model('XGB_full.xgb')\n",
        "    preds = model.predict(dtest)\n",
        "    for f in range(1,FOLDS):\n",
        "        model.load_model(f'XGB_v{VER}_fold{fold}.xgb')\n",
        "        #model.load_model(f'XGB_full.xgb')\n",
        "        preds += model.predict(dtest)\n",
        "    preds /= FOLDS\n",
        "    test_preds.append(preds)\n",
        "\n",
        "    # CLEAN MEMORY\n",
        "    del dtest, model\n",
        "    _ = gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgvQnNhip0OC"
      },
      "source": [
        "# Create Submission CSV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "id": "XmDkNfhrp0OC",
        "outputId": "f1062d85-485b-4d04-fd96-8ab9340e7a97"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-154-8c6867ac9a70>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# WRITE SUBMISSION FILE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#test_preds = np.concatenate(test_preds).to_numpy()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustomers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'prediction'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_preds\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0msub\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Amex/parquet/sample_submission.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'customer_ID'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msub\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'customer_ID_hash'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msub\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'customer_ID'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhex_to_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'int64'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    612\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m             \u001b[0;31m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 614\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmanager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    615\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m     return arrays_to_mgr(\n\u001b[0;32m--> 465\u001b[0;31m         \u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsolidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    466\u001b[0m     )\n\u001b[1;32m    467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, arr_names, index, columns, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_extract_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;31m# don't force copy because getting jammed in an ndarray anyway\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mensure_index\u001b[0;34m(index_like, copy)\u001b[0m\n\u001b[1;32m   6334\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6336\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, data, dtype, copy, name, tupleize_cols, **kwargs)\u001b[0m\n\u001b[1;32m    474\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_scalar_data_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__array__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mcupy/_core/core.pyx\u001b[0m in \u001b[0;36mcupy._core.core.ndarray.__array__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Implicit conversion to a NumPy array is not allowed. Please use `.get()` to construct a NumPy array explicitly."
          ]
        }
      ],
      "source": [
        "# WRITE SUBMISSION FILE\n",
        "#test_preds = np.concatenate(test_preds).to_numpy()\n",
        "test = pd.DataFrame(index=customers,data={'prediction':[test_preds]})\n",
        "sub = pd.read_csv('/content/drive/MyDrive/Amex/parquet/sample_submission.csv')[['customer_ID']]\n",
        "sub['customer_ID_hash'] = sub['customer_ID'].str[-16:].str.hex_to_int().astype('int64')\n",
        "sub = sub.set_index('customer_ID_hash')\n",
        "sub = sub.merge(test['prediction'], left_index=True, right_index=True, how='left')\n",
        "sub = sub.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "feR6CECRp0OC"
      },
      "outputs": [],
      "source": [
        "sub.to_csv(f'/content/drive/My Drive/Amex/parquet/XGB Baseline/submission.csv',index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "lZwCEYdKp0OC",
        "outputId": "4d2277e3-8ba0-449b-eb2b-0144b6737813"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# PLOT PREDICTIONS\n",
        "plt.hist(sub.to_pandas().prediction, bins=100)\n",
        "plt.title('Test Predictions')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrtP9j0mxhCM"
      },
      "source": [
        "Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P9FSILOswW2E"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from xgboost import plot_importance\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jqOO1fQuxlMl"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, \n",
        "                                                    y, \n",
        "                                                    test_size = 0.2, \n",
        "                                                    random_state=100,\n",
        "                                                    stratify=y)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "Amex XGBoost fin.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}