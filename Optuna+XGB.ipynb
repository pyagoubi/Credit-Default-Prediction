{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "notebook24500585f0.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pyagoubi/kaggle-American-Default-competition/blob/main/Optuna%2BXGB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pynvml"
      ],
      "metadata": {
        "id": "JpiHdOzpItYq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6209ce74-81f5-4ce6-967f-fa8ca29cf8de"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pynvml\n",
            "  Downloading pynvml-11.4.1-py3-none-any.whl (46 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 46 kB 2.1 MB/s \n",
            "\u001b[?25hInstalling collected packages: pynvml\n",
            "Successfully installed pynvml-11.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/rapidsai/rapidsai-csp-utils.git\n",
        "!python rapidsai-csp-utils/colab/env-check.py"
      ],
      "metadata": {
        "id": "93jraPg5ItVz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!bash rapidsai-csp-utils/colab/update_gcc.sh\n",
        "import os\n",
        "os._exit(00)"
      ],
      "metadata": {
        "id": "rrK8Fk6HItSc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This will install CondaColab.  This will restart your kernel one last time.  Run this cell by itself and only run the next cell once you see the session crash.\n",
        "import condacolab\n",
        "condacolab.install()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJ30xrtVItPK",
        "outputId": "648d6203-52e7-4f0d-90a4-332e03e602e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚è¨ Downloading https://github.com/jaimergp/miniforge/releases/latest/download/Mambaforge-colab-Linux-x86_64.sh...\n",
            "üì¶ Installing...\n",
            "üìå Adjusting configuration...\n",
            "ü©π Patching environment...\n",
            "‚è≤ Done in 0:00:22\n",
            "üîÅ Restarting kernel...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# you can now run the rest of the cells as normal\n",
        "import condacolab\n",
        "condacolab.check()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nbtk8dTYItMI",
        "outputId": "477744d4-c499-47c4-946d-372af2e6fbfe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ú®üç∞‚ú® Everything looks OK!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Installing RAPIDS is now 'python rapidsai-csp-utils/colab/install_rapids.py <release> <packages>'\n",
        "# The <release> options are 'stable' and 'nightly'.  Leaving it blank or adding any other words will default to stable.\n",
        "!python rapidsai-csp-utils/colab/install_rapids.py stable\n",
        "import os\n",
        "os.environ['NUMBAPRO_NVVM'] = '/usr/local/cuda/nvvm/lib64/libnvvm.so'\n",
        "os.environ['NUMBAPRO_LIBDEVICE'] = '/usr/local/cuda/nvvm/libdevice/'\n",
        "os.environ['CONDA_PREFIX'] = '/usr/local'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNQ2SZDcItJM",
        "outputId": "d16b8bdb-dded-4e5e-9406-145b93a0f724"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: cffi 1.14.5\n",
            "Uninstalling cffi-1.14.5:\n",
            "  Successfully uninstalled cffi-1.14.5\n",
            "Found existing installation: cryptography 3.4.5\n",
            "Uninstalling cryptography-3.4.5:\n",
            "  Successfully uninstalled cryptography-3.4.5\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting cffi==1.15.0\n",
            "  Downloading cffi-1.15.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (427 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/site-packages (from cffi==1.15.0) (2.20)\n",
            "Installing collected packages: cffi\n",
            "Successfully installed cffi-1.15.0\n",
            "Installing RAPIDS Stable 21.12\n",
            "Starting the RAPIDS install on Colab.  This will take about 15 minutes.\n",
            "Collecting package metadata (current_repodata.json): ...working... done\n",
            "Solving environment: ...working... WARNING conda.core.solve:_add_specs(611): pinned spec cudatoolkit=11.1 conflicts with explicit specs.  Overriding pinned spec.\n",
            "failed with initial frozen solve. Retrying with flexible solve.\n",
            "Solving environment: ...working... WARNING conda.core.solve:_add_specs(611): pinned spec cudatoolkit=11.1 conflicts with explicit specs.  Overriding pinned spec.\n",
            "failed with repodata from current_repodata.json, will retry with next repodata source.\n",
            "Collecting package metadata (repodata.json): ...working... done\n",
            "Solving environment: ...working... WARNING conda.core.solve:_add_specs(611): pinned spec cudatoolkit=11.1 conflicts with explicit specs.  Overriding pinned spec.\n",
            "done\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - cudatoolkit=11.2\n",
            "    - dask-sql\n",
            "    - gcsfs\n",
            "    - llvmlite\n",
            "    - openssl\n",
            "    - python=3.7\n",
            "    - rapids=21.12\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    abseil-cpp-20210324.2      |       h9c3ff4c_0        1010 KB  conda-forge\n",
            "    aiohttp-3.8.1              |   py37h540881e_1         561 KB  conda-forge\n",
            "    aiosignal-1.2.0            |     pyhd8ed1ab_0          12 KB  conda-forge\n",
            "    alsa-lib-1.2.3.2           |       h166bdaf_0         554 KB  conda-forge\n",
            "    anyio-3.6.1                |   py37h89c1867_0         153 KB  conda-forge\n",
            "    appdirs-1.4.4              |     pyh9f0ad1d_0          13 KB  conda-forge\n",
            "    argon2-cffi-21.3.0         |     pyhd8ed1ab_0          15 KB  conda-forge\n",
            "    argon2-cffi-bindings-21.2.0|   py37h540881e_2          34 KB  conda-forge\n",
            "    arrow-cpp-5.0.0            |py37hc2523e2_2_cuda        23.3 MB  conda-forge\n",
            "    arrow-cpp-proc-3.0.0       |             cuda          24 KB  conda-forge\n",
            "    asgiref-3.5.2              |     pyhd8ed1ab_0          22 KB  conda-forge\n",
            "    async-timeout-4.0.2        |     pyhd8ed1ab_0           9 KB  conda-forge\n",
            "    asynctest-0.13.0           |             py_0          24 KB  conda-forge\n",
            "    attrs-21.4.0               |     pyhd8ed1ab_0          49 KB  conda-forge\n",
            "    aws-c-cal-0.5.11           |       h95a6274_0          37 KB  conda-forge\n",
            "    aws-c-common-0.6.2         |       h7f98852_0         168 KB  conda-forge\n",
            "    aws-c-event-stream-0.2.7   |      h3541f99_13          47 KB  conda-forge\n",
            "    aws-c-io-0.10.5            |       hfb6a706_0         121 KB  conda-forge\n",
            "    aws-checksums-0.1.11       |       ha31a3da_7          50 KB  conda-forge\n",
            "    aws-sdk-cpp-1.8.186        |       hb4091e7_3         4.6 MB  conda-forge\n",
            "    backcall-0.2.0             |     pyh9f0ad1d_0          13 KB  conda-forge\n",
            "    backports-1.0              |             py_2           4 KB  conda-forge\n",
            "    backports.functools_lru_cache-1.6.4|     pyhd8ed1ab_0           9 KB  conda-forge\n",
            "    backports.zoneinfo-0.2.1   |   py37h540881e_5          47 KB  conda-forge\n",
            "    beautifulsoup4-4.11.1      |     pyha770c72_0          96 KB  conda-forge\n",
            "    bleach-5.0.1               |     pyhd8ed1ab_0         124 KB  conda-forge\n",
            "    blinker-1.4                |             py_1          13 KB  conda-forge\n",
            "    blosc-1.21.1               |       h83bc5f7_3          47 KB  conda-forge\n",
            "    bokeh-2.4.0                |   py37h89c1867_0        13.5 MB  conda-forge\n",
            "    boost-1.74.0               |   py37h796e4cb_5         342 KB  conda-forge\n",
            "    boost-cpp-1.74.0           |       h312852a_4        16.3 MB  conda-forge\n",
            "    brotli-1.0.9               |       h166bdaf_7          18 KB  conda-forge\n",
            "    brotli-bin-1.0.9           |       h166bdaf_7          19 KB  conda-forge\n",
            "    brunsli-0.1                |       h9c3ff4c_0         200 KB  conda-forge\n",
            "    c-blosc2-2.1.1             |       h7a311fb_2         248 KB  conda-forge\n",
            "    ca-certificates-2022.6.15  |       ha878542_0         149 KB  conda-forge\n",
            "    cachetools-5.0.0           |     pyhd8ed1ab_0          12 KB  conda-forge\n",
            "    cairo-1.16.0               |    h6cf1ce9_1008         1.5 MB  conda-forge\n",
            "    certifi-2022.6.15          |   py37h89c1867_0         155 KB  conda-forge\n",
            "    cfitsio-3.470              |       hb418390_7         1.3 MB  conda-forge\n",
            "    charls-2.2.0               |       h9c3ff4c_0         138 KB  conda-forge\n",
            "    charset-normalizer-2.1.0   |     pyhd8ed1ab_0          35 KB  conda-forge\n",
            "    click-8.1.3                |   py37h89c1867_0         145 KB  conda-forge\n",
            "    click-plugins-1.1.1        |             py_0           9 KB  conda-forge\n",
            "    cligj-0.7.2                |     pyhd8ed1ab_1          10 KB  conda-forge\n",
            "    cloudpickle-2.1.0          |     pyhd8ed1ab_0          25 KB  conda-forge\n",
            "    colorcet-3.0.0             |     pyhd8ed1ab_0         1.5 MB  conda-forge\n",
            "    conda-4.12.0               |   py37h89c1867_0         1.0 MB  conda-forge\n",
            "    cucim-21.12.00             |cuda_11_py37_g6d1f082_0         3.2 MB  rapidsai\n",
            "    cudatoolkit-11.2.72        |       h2bc3f7f_0       933.4 MB  nvidia\n",
            "    cudf-21.12.02              |cuda_11_py37_g06540b9b37_0        12.6 MB  rapidsai\n",
            "    cudf_kafka-21.12.02        |py37_g06540b9b37_0         1.8 MB  rapidsai\n",
            "    cugraph-21.12.00           |cuda11_py37_g3a43e9d0_0         7.2 MB  rapidsai\n",
            "    cuml-21.12.00              |cuda11_py37_g04c4927f3_0         9.4 MB  rapidsai\n",
            "    cupy-9.6.0                 |   py37h07c33ac_0        51.5 MB  conda-forge\n",
            "    curl-7.78.0                |       hea6ffbf_0         148 KB  conda-forge\n",
            "    cusignal-21.12.00          |  py37_g2bf865c_0         1.1 MB  rapidsai\n",
            "    cuspatial-21.12.00         |  py37_gab6748f_0        15.9 MB  rapidsai\n",
            "    custreamz-21.12.02         |py37_g06540b9b37_0          32 KB  rapidsai\n",
            "    cuxfilter-21.12.00         |  py37_g2e0fb5a_0         137 KB  rapidsai\n",
            "    cycler-0.11.0              |     pyhd8ed1ab_0          10 KB  conda-forge\n",
            "    cyrus-sasl-2.1.27          |       h230043b_5         228 KB  conda-forge\n",
            "    cytoolz-0.11.2             |   py37h540881e_2         382 KB  conda-forge\n",
            "    dask-2021.11.2             |     pyhd8ed1ab_0           5 KB  conda-forge\n",
            "    dask-core-2021.11.2        |     pyhd8ed1ab_0         783 KB  conda-forge\n",
            "    dask-cuda-21.12.00         |           py37_0         123 KB  rapidsai\n",
            "    dask-cudf-21.12.02         |cuda_11_py37_g06540b9b37_0         112 KB  rapidsai\n",
            "    dask-sql-2022.1.0          |   py37h89c1867_0        19.7 MB  conda-forge\n",
            "    datashader-0.11.1          |     pyh9f0ad1d_0        14.0 MB  conda-forge\n",
            "    datashape-0.5.4            |             py_1          49 KB  conda-forge\n",
            "    debugpy-1.6.0              |   py37hd23a5d3_0         2.0 MB  conda-forge\n",
            "    decorator-5.1.1            |     pyhd8ed1ab_0          12 KB  conda-forge\n",
            "    defusedxml-0.7.1           |     pyhd8ed1ab_0          23 KB  conda-forge\n",
            "    distributed-2021.11.2      |   py37h89c1867_0         1.1 MB  conda-forge\n",
            "    dlpack-0.5                 |       h9c3ff4c_0          12 KB  conda-forge\n",
            "    entrypoints-0.4            |     pyhd8ed1ab_0           9 KB  conda-forge\n",
            "    expat-2.4.8                |       h27087fc_0         187 KB  conda-forge\n",
            "    faiss-proc-1.0.0           |             cuda          24 KB  rapidsai\n",
            "    fastapi-0.78.0             |     pyhd8ed1ab_0          44 KB  conda-forge\n",
            "    fastavro-1.5.2             |   py37h540881e_0         461 KB  conda-forge\n",
            "    fastrlock-0.8              |   py37hd23a5d3_2          31 KB  conda-forge\n",
            "    fiona-1.8.20               |   py37hb7e2723_2         1.1 MB  conda-forge\n",
            "    flit-core-3.7.1            |     pyhd8ed1ab_0          44 KB  conda-forge\n",
            "    font-ttf-dejavu-sans-mono-2.37|       hab24e00_0         388 KB  conda-forge\n",
            "    font-ttf-inconsolata-3.000 |       h77eed37_0          94 KB  conda-forge\n",
            "    font-ttf-source-code-pro-2.038|       h77eed37_0         684 KB  conda-forge\n",
            "    font-ttf-ubuntu-0.83       |       hab24e00_0         1.9 MB  conda-forge\n",
            "    fontconfig-2.14.0          |       h8e229c2_0         305 KB  conda-forge\n",
            "    fonts-conda-ecosystem-1    |                0           4 KB  conda-forge\n",
            "    fonts-conda-forge-1        |                0           4 KB  conda-forge\n",
            "    freetype-2.10.4            |       h0708190_1         890 KB  conda-forge\n",
            "    freexl-1.0.6               |       h7f98852_0          48 KB  conda-forge\n",
            "    frozenlist-1.3.0           |   py37h540881e_1          43 KB  conda-forge\n",
            "    fsspec-2022.5.0            |     pyhd8ed1ab_0          96 KB  conda-forge\n",
            "    gcsfs-2022.5.0             |     pyhd8ed1ab_0          25 KB  conda-forge\n",
            "    gdal-3.3.2                 |   py37hd5a0ba4_3         1.7 MB  conda-forge\n",
            "    geopandas-0.9.0            |     pyhd8ed1ab_1           5 KB  conda-forge\n",
            "    geopandas-base-0.9.0       |     pyhd8ed1ab_1         950 KB  conda-forge\n",
            "    geos-3.9.1                 |       h9c3ff4c_2         1.1 MB  conda-forge\n",
            "    geotiff-1.7.0              |       h08e826d_2         296 KB  conda-forge\n",
            "    gettext-0.19.8.1           |    h0b5b191_1005         3.6 MB  conda-forge\n",
            "    gflags-2.2.2               |    he1b5a44_1004         114 KB  conda-forge\n",
            "    giflib-5.2.1               |       h36c2ea0_2          77 KB  conda-forge\n",
            "    glog-0.5.0                 |       h48cff8f_0         104 KB  conda-forge\n",
            "    google-api-core-2.8.2      |     pyhd8ed1ab_0          70 KB  conda-forge\n",
            "    google-auth-2.9.0          |     pyh6c4a22f_0          90 KB  conda-forge\n",
            "    google-auth-oauthlib-0.5.2 |     pyhd8ed1ab_0          20 KB  conda-forge\n",
            "    google-cloud-core-2.3.1    |     pyhd8ed1ab_0          27 KB  conda-forge\n",
            "    google-cloud-storage-2.4.0 |     pyh6c4a22f_0          74 KB  conda-forge\n",
            "    google-crc32c-1.1.2        |   py37h5d4fa31_3          24 KB  conda-forge\n",
            "    google-resumable-media-2.3.3|     pyhd8ed1ab_0          42 KB  conda-forge\n",
            "    googleapis-common-protos-1.56.3|   py37h89c1867_0         122 KB  conda-forge\n",
            "    graphite2-1.3.13           |    h58526e2_1001         102 KB  conda-forge\n",
            "    grpc-cpp-1.39.0            |       hf1f433d_2         3.6 MB  conda-forge\n",
            "    grpcio-1.38.1              |   py37hb27c1af_0         2.2 MB  conda-forge\n",
            "    h11-0.13.0                 |     pyhd8ed1ab_1          46 KB  conda-forge\n",
            "    harfbuzz-2.9.1             |       h83ec7ef_1         2.0 MB  conda-forge\n",
            "    hdf4-4.2.15                |       h10796ff_3         950 KB  conda-forge\n",
            "    hdf5-1.12.1                |nompi_h2750804_100         3.5 MB  conda-forge\n",
            "    heapdict-1.0.1             |             py_0           7 KB  conda-forge\n",
            "    imagecodecs-2021.8.26      |   py37hfe5a812_1         7.2 MB  conda-forge\n",
            "    imageio-2.13.1             |     pyhd8ed1ab_0         3.1 MB  conda-forge\n",
            "    importlib-metadata-4.11.4  |   py37h89c1867_0          33 KB  conda-forge\n",
            "    importlib_metadata-4.11.4  |       hd8ed1ab_0           4 KB  conda-forge\n",
            "    importlib_resources-5.8.0  |     pyhd8ed1ab_0          22 KB  conda-forge\n",
            "    ipykernel-6.14.0           |   py37h25bab4e_0         185 KB  conda-forge\n",
            "    ipython-7.33.0             |   py37h89c1867_0         1.1 MB  conda-forge\n",
            "    ipython_genutils-0.2.0     |             py_1          21 KB  conda-forge\n",
            "    ipywidgets-7.7.1           |     pyhd8ed1ab_0         103 KB  conda-forge\n",
            "    jbig-2.1                   |    h7f98852_2003          43 KB  conda-forge\n",
            "    jedi-0.18.1                |   py37h89c1867_1        1008 KB  conda-forge\n",
            "    jinja2-3.1.2               |     pyhd8ed1ab_1          99 KB  conda-forge\n",
            "    joblib-1.1.0               |     pyhd8ed1ab_0         210 KB  conda-forge\n",
            "    jpeg-9e                    |       h166bdaf_2         269 KB  conda-forge\n",
            "    jpype1-1.4.0               |   py37h7cecad7_0         495 KB  conda-forge\n",
            "    json-c-0.15                |       h98cffda_0         274 KB  conda-forge\n",
            "    jsonschema-4.6.1           |     pyhd8ed1ab_0          63 KB  conda-forge\n",
            "    jupyter-server-proxy-3.2.1 |     pyhd8ed1ab_0          29 KB  conda-forge\n",
            "    jupyter_client-7.3.4       |     pyhd8ed1ab_0          91 KB  conda-forge\n",
            "    jupyter_core-4.10.0        |   py37h89c1867_0          81 KB  conda-forge\n",
            "    jupyter_server-1.18.0      |     pyhd8ed1ab_1         241 KB  conda-forge\n",
            "    jupyterlab_pygments-0.2.2  |     pyhd8ed1ab_0          17 KB  conda-forge\n",
            "    jupyterlab_widgets-1.1.1   |     pyhd8ed1ab_0         133 KB  conda-forge\n",
            "    jxrlib-1.1                 |       h7f98852_2         235 KB  conda-forge\n",
            "    kealib-1.4.15              |       hfe1a663_0         188 KB  conda-forge\n",
            "    keyutils-1.6.1             |       h166bdaf_0         115 KB  conda-forge\n",
            "    kiwisolver-1.4.3           |   py37h7cecad7_0          73 KB  conda-forge\n",
            "    krb5-1.19.3                |       h3790be6_0         1.4 MB  conda-forge\n",
            "    lcms2-2.12                 |       hddcbb42_0         443 KB  conda-forge\n",
            "    lerc-3.0                   |       h9c3ff4c_0         216 KB  conda-forge\n",
            "    libaec-1.0.6               |       h9c3ff4c_0          45 KB  conda-forge\n",
            "    libarchive-3.5.2           |       hccf745f_1         1.6 MB  conda-forge\n",
            "    libblas-3.9.0              |15_linux64_openblas          12 KB  conda-forge\n",
            "    libbrotlicommon-1.0.9      |       h166bdaf_7          65 KB  conda-forge\n",
            "    libbrotlidec-1.0.9         |       h166bdaf_7          33 KB  conda-forge\n",
            "    libbrotlienc-1.0.9         |       h166bdaf_7         287 KB  conda-forge\n",
            "    libcblas-3.9.0             |15_linux64_openblas          12 KB  conda-forge\n",
            "    libcrc32c-1.1.2            |       h9c3ff4c_0          20 KB  conda-forge\n",
            "    libcucim-21.12.00          |cuda11_g6d1f082_0         2.8 MB  rapidsai\n",
            "    libcudf-21.12.02           |cuda11_g06540b9b37_0       288.2 MB  rapidsai\n",
            "    libcudf_kafka-21.12.02     |    g06540b9b37_0         126 KB  rapidsai\n",
            "    libcugraph-21.12.00        |cuda11_g3a43e9d0_0       259.4 MB  rapidsai\n",
            "    libcuml-21.12.00           |cuda11_g04c4927f3_0       222.9 MB  rapidsai\n",
            "    libcumlprims-21.12.00      |cuda11_g0a7f19f_0         3.7 MB  nvidia\n",
            "    libcurl-7.78.0             |       h2574ce0_0         335 KB  conda-forge\n",
            "    libcusolver-11.3.5.50      |       hcab339c_0        89.2 MB  nvidia\n",
            "    libcuspatial-21.12.00      |cuda11_gab6748f_0         6.4 MB  rapidsai\n",
            "    libdap4-3.20.6             |       hd7c4107_2        11.3 MB  conda-forge\n",
            "    libdeflate-1.8             |       h7f98852_0          67 KB  conda-forge\n",
            "    libevent-2.1.10            |       h9b69904_4         1.1 MB  conda-forge\n",
            "    libfaiss-1.7.0             |cuda112h5bea7ad_8_cuda        98.5 MB  conda-forge\n",
            "    libgcc-ng-12.1.0           |      h8d9b700_16         940 KB  conda-forge\n",
            "    libgcrypt-1.10.1           |       h166bdaf_0         703 KB  conda-forge\n",
            "    libgdal-3.3.2              |       h6acdded_3        13.1 MB  conda-forge\n",
            "    libgfortran-ng-12.1.0      |      h69a702a_16          23 KB  conda-forge\n",
            "    libgfortran5-12.1.0        |      hdcd56e2_16         1.8 MB  conda-forge\n",
            "    libglib-2.68.4             |       h3e27bee_0         3.0 MB  conda-forge\n",
            "    libgomp-12.1.0             |      h8d9b700_16         459 KB  conda-forge\n",
            "    libgpg-error-1.45          |       hc0c96e0_0         286 KB  conda-forge\n",
            "    libgsasl-1.10.0            |       h5b4c23d_0         179 KB  conda-forge\n",
            "    libhwloc-2.3.0             |       h5e5b7d1_1         2.7 MB  conda-forge\n",
            "    libkml-1.3.0               |    h238a007_1014         591 KB  conda-forge\n",
            "    liblapack-3.9.0            |15_linux64_openblas          12 KB  conda-forge\n",
            "    libllvm11-11.1.0           |       hf817b99_3        29.1 MB  conda-forge\n",
            "    libnetcdf-4.8.1            |nompi_hb3fd0d9_101         1.5 MB  conda-forge\n",
            "    libnsl-2.0.0               |       h7f98852_0          31 KB  conda-forge\n",
            "    libntlm-1.4                |    h7f98852_1002          32 KB  conda-forge\n",
            "    libopenblas-0.3.20         |pthreads_h78a6416_0        10.1 MB  conda-forge\n",
            "    libpng-1.6.37              |       h21135ba_2         306 KB  conda-forge\n",
            "    libpq-13.5                 |       hd57d9b9_1         2.8 MB  conda-forge\n",
            "    libprotobuf-3.16.0         |       h780b84a_0         2.5 MB  conda-forge\n",
            "    librdkafka-1.6.1           |       hc49e61c_1        12.6 MB  conda-forge\n",
            "    librmm-21.12.00            |cuda11_g957ad04_0         688 KB  rapidsai\n",
            "    librttopo-1.1.0            |       h1185371_6         235 KB  conda-forge\n",
            "    libsodium-1.0.18           |       h36c2ea0_1         366 KB  conda-forge\n",
            "    libspatialindex-1.9.3      |       h9c3ff4c_4         4.6 MB  conda-forge\n",
            "    libspatialite-5.0.1        |       h5cf074c_8         4.4 MB  conda-forge\n",
            "    libstdcxx-ng-12.1.0        |      ha89aaad_16         4.3 MB  conda-forge\n",
            "    libthrift-0.14.2           |       he6d91bd_1         4.5 MB  conda-forge\n",
            "    libtiff-4.3.0              |       h6f004c6_2         614 KB  conda-forge\n",
            "    libutf8proc-2.7.0          |       h7f98852_0          98 KB  conda-forge\n",
            "    libuuid-2.32.1             |    h7f98852_1000          28 KB  conda-forge\n",
            "    libuv-1.42.0               |       h7f98852_0         1.0 MB  conda-forge\n",
            "    libwebp-1.2.2              |       h3452ae3_0          85 KB  conda-forge\n",
            "    libwebp-base-1.2.2         |       h7f98852_1         824 KB  conda-forge\n",
            "    libxcb-1.13                |    h7f98852_1004         391 KB  conda-forge\n",
            "    libxgboost-1.5.0dev.rapidsai21.12|       cuda11.2_0       128.2 MB  rapidsai\n",
            "    libxml2-2.9.12             |       h72842e0_0         772 KB  conda-forge\n",
            "    libzip-1.9.2               |       hc869a4a_0          97 KB  conda-forge\n",
            "    libzlib-1.2.12             |       h166bdaf_1          63 KB  conda-forge\n",
            "    libzopfli-1.0.3            |       h9c3ff4c_0         164 KB  conda-forge\n",
            "    llvmlite-0.38.1            |   py37h0761922_0         2.3 MB  conda-forge\n",
            "    locket-1.0.0               |     pyhd8ed1ab_0           8 KB  conda-forge\n",
            "    mapclassify-2.4.3          |     pyhd8ed1ab_0          36 KB  conda-forge\n",
            "    markdown-3.3.7             |     pyhd8ed1ab_0          67 KB  conda-forge\n",
            "    markupsafe-2.1.1           |   py37h540881e_1          22 KB  conda-forge\n",
            "    matplotlib-base-3.4.3      |   py37h1058ff1_0         7.2 MB  conda-forge\n",
            "    matplotlib-inline-0.1.3    |     pyhd8ed1ab_0          11 KB  conda-forge\n",
            "    mistune-0.8.4              |py37h5e8e339_1005          54 KB  conda-forge\n",
            "    msgpack-python-1.0.4       |   py37h7cecad7_0          90 KB  conda-forge\n",
            "    multidict-6.0.2            |   py37h540881e_1          49 KB  conda-forge\n",
            "    multipledispatch-0.6.0     |             py_0          12 KB  conda-forge\n",
            "    munch-2.5.0                |             py_0          12 KB  conda-forge\n",
            "    nbclient-0.6.5             |     pyhd8ed1ab_0          65 KB  conda-forge\n",
            "    nbconvert-6.5.0            |     pyhd8ed1ab_0           6 KB  conda-forge\n",
            "    nbconvert-core-6.5.0       |     pyhd8ed1ab_0         425 KB  conda-forge\n",
            "    nbconvert-pandoc-6.5.0     |     pyhd8ed1ab_0           4 KB  conda-forge\n",
            "    nbformat-5.4.0             |     pyhd8ed1ab_0         104 KB  conda-forge\n",
            "    nccl-2.12.12.1             |       h0800d71_0       135.3 MB  conda-forge\n",
            "    nest-asyncio-1.5.5         |     pyhd8ed1ab_0           9 KB  conda-forge\n",
            "    networkx-2.7.1             |     pyhd8ed1ab_0         1.5 MB  conda-forge\n",
            "    nodejs-14.17.4             |       h92b4a50_0        15.8 MB  conda-forge\n",
            "    notebook-6.4.12            |     pyha770c72_0         6.3 MB  conda-forge\n",
            "    numba-0.55.2               |   py37h43839f2_0         3.8 MB  conda-forge\n",
            "    numpy-1.21.6               |   py37h976b520_0         6.1 MB  conda-forge\n",
            "    nvtx-0.2.3                 |   py37h5e8e339_1          55 KB  conda-forge\n",
            "    oauthlib-3.2.0             |     pyhd8ed1ab_0          90 KB  conda-forge\n",
            "    olefile-0.46               |     pyh9f0ad1d_1          32 KB  conda-forge\n",
            "    openjdk-11.0.9.1           |       h5cc2fde_1       173.5 MB  conda-forge\n",
            "    openjpeg-2.4.0             |       hb52868f_1         444 KB  conda-forge\n",
            "    openssl-1.1.1p             |       h166bdaf_0         2.1 MB  conda-forge\n",
            "    orc-1.6.9                  |       h58a87f1_0         746 KB  conda-forge\n",
            "    packaging-21.3             |     pyhd8ed1ab_0          36 KB  conda-forge\n",
            "    pandas-1.3.5               |   py37he8f5f7f_0        12.7 MB  conda-forge\n",
            "    pandoc-2.18                |       ha770c72_0        12.5 MB  conda-forge\n",
            "    pandocfilters-1.5.0        |     pyhd8ed1ab_0          11 KB  conda-forge\n",
            "    panel-0.12.4               |     pyhd8ed1ab_0         9.8 MB  conda-forge\n",
            "    param-1.12.2               |     pyh6c4a22f_0          72 KB  conda-forge\n",
            "    parquet-cpp-1.5.1          |                2           3 KB  conda-forge\n",
            "    parso-0.8.3                |     pyhd8ed1ab_0          69 KB  conda-forge\n",
            "    partd-1.2.0                |     pyhd8ed1ab_0          18 KB  conda-forge\n",
            "    pcre-8.45                  |       h9c3ff4c_0         253 KB  conda-forge\n",
            "    pexpect-4.8.0              |     pyh9f0ad1d_2          47 KB  conda-forge\n",
            "    pickle5-0.0.12             |   py37h5e8e339_0         173 KB  conda-forge\n",
            "    pickleshare-0.7.5          |          py_1003           9 KB  conda-forge\n",
            "    pillow-8.3.1               |   py37h0f21c89_0         692 KB  conda-forge\n",
            "    pixman-0.40.0              |       h36c2ea0_0         627 KB  conda-forge\n",
            "    pooch-1.6.0                |     pyhd8ed1ab_0          44 KB  conda-forge\n",
            "    poppler-21.09.0            |       h0e1ea10_1        16.8 MB  conda-forge\n",
            "    poppler-data-0.4.11        |       hd8ed1ab_0         3.6 MB  conda-forge\n",
            "    postgresql-13.5            |       h2510834_1         5.3 MB  conda-forge\n",
            "    proj-8.1.0                 |       h277dcde_1         2.9 MB  conda-forge\n",
            "    prometheus_client-0.14.1   |     pyhd8ed1ab_0          49 KB  conda-forge\n",
            "    prompt-toolkit-3.0.30      |     pyha770c72_0         254 KB  conda-forge\n",
            "    protobuf-3.16.0            |   py37hcd2ae1e_0         342 KB  conda-forge\n",
            "    psutil-5.9.1               |   py37h540881e_0         344 KB  conda-forge\n",
            "    pthread-stubs-0.4          |    h36c2ea0_1001           5 KB  conda-forge\n",
            "    ptxcompiler-0.2.0          |   py37hcfeb250_0         5.6 MB  rapidsai\n",
            "    ptyprocess-0.7.0           |     pyhd3deb0d_0          16 KB  conda-forge\n",
            "    py-xgboost-1.5.0dev.rapidsai21.12|   cuda11.2py37_0         159 KB  rapidsai\n",
            "    pyarrow-5.0.0              |py37hf0016df_2_cuda         2.9 MB  conda-forge\n",
            "    pyasn1-0.4.8               |             py_0          53 KB  conda-forge\n",
            "    pyasn1-modules-0.2.7       |             py_0          60 KB  conda-forge\n",
            "    pyct-0.4.6                 |             py_0           3 KB  conda-forge\n",
            "    pyct-core-0.4.6            |             py_0          13 KB  conda-forge\n",
            "    pydantic-1.9.1             |   py37h540881e_0         2.2 MB  conda-forge\n",
            "    pydeck-0.5.0               |     pyh9f0ad1d_0         3.6 MB  conda-forge\n",
            "    pyee-8.1.0                 |     pyhd8ed1ab_0          14 KB  conda-forge\n",
            "    pygments-2.12.0            |     pyhd8ed1ab_0         817 KB  conda-forge\n",
            "    pyjwt-2.4.0                |     pyhd8ed1ab_0          19 KB  conda-forge\n",
            "    pynvml-11.4.1              |     pyhd8ed1ab_0          40 KB  conda-forge\n",
            "    pyparsing-3.0.9            |     pyhd8ed1ab_0          79 KB  conda-forge\n",
            "    pyppeteer-1.0.2            |     pyhd8ed1ab_0          63 KB  conda-forge\n",
            "    pyproj-3.1.0               |   py37hdf91f24_4         523 KB  conda-forge\n",
            "    pyrsistent-0.18.1          |   py37h540881e_1          91 KB  conda-forge\n",
            "    python-confluent-kafka-1.6.0|   py37h5e8e339_1         125 KB  conda-forge\n",
            "    python-dateutil-2.8.2      |     pyhd8ed1ab_0         240 KB  conda-forge\n",
            "    python-fastjsonschema-2.15.3|     pyhd8ed1ab_0         243 KB  conda-forge\n",
            "    python-tzdata-2022.1       |     pyhd8ed1ab_0         151 KB  conda-forge\n",
            "    python_abi-3.7             |          2_cp37m           4 KB  conda-forge\n",
            "    pytz-2022.1                |     pyhd8ed1ab_0         242 KB  conda-forge\n",
            "    pytz-deprecation-shim-0.1.0.post0|   py37h89c1867_2          22 KB  conda-forge\n",
            "    pyu2f-0.1.5                |     pyhd8ed1ab_0          31 KB  conda-forge\n",
            "    pyviz_comms-2.2.0          |     pyhd8ed1ab_0          31 KB  conda-forge\n",
            "    pywavelets-1.3.0           |   py37hda87dfa_1         4.4 MB  conda-forge\n",
            "    pyyaml-6.0                 |   py37h540881e_4         178 KB  conda-forge\n",
            "    pyzmq-23.2.0               |   py37h0c0c2a8_0         474 KB  conda-forge\n",
            "    rapids-21.12.00            |cuda11.2_py37_gc46440c_94           5 KB  rapidsai\n",
            "    rapids-xgboost-21.12.00    |cuda11.2_py37_gc46440c_94           5 KB  rapidsai\n",
            "    re2-2021.08.01             |       h9c3ff4c_0         220 KB  conda-forge\n",
            "    readline-8.1               |       h46c0cb4_0         295 KB  conda-forge\n",
            "    requests-oauthlib-1.3.1    |     pyhd8ed1ab_0          22 KB  conda-forge\n",
            "    rmm-21.12.00               |cuda11_py37_g957ad04_0_has_cma         943 KB  rapidsai\n",
            "    rsa-4.8                    |     pyhd8ed1ab_0          31 KB  conda-forge\n",
            "    rtree-1.0.0                |   py37h0b55af0_1          49 KB  conda-forge\n",
            "    s2n-1.0.10                 |       h9b69904_0         442 KB  conda-forge\n",
            "    scikit-image-0.18.1        |   py37hdc94413_0        11.5 MB  conda-forge\n",
            "    scikit-learn-1.0.2         |   py37hf9e9bfc_0         7.8 MB  conda-forge\n",
            "    scipy-1.7.3                |   py37hf2a6cf1_0        21.8 MB  conda-forge\n",
            "    send2trash-1.8.0           |     pyhd8ed1ab_0          17 KB  conda-forge\n",
            "    setuptools-59.8.0          |   py37h89c1867_1         1.0 MB  conda-forge\n",
            "    shapely-1.8.0              |   py37h48c49eb_0         367 KB  conda-forge\n",
            "    simpervisor-0.4            |     pyhd8ed1ab_0           9 KB  conda-forge\n",
            "    snappy-1.1.9               |       hbd366e4_1          35 KB  conda-forge\n",
            "    sniffio-1.2.0              |   py37h89c1867_3          15 KB  conda-forge\n",
            "    sortedcontainers-2.4.0     |     pyhd8ed1ab_0          26 KB  conda-forge\n",
            "    soupsieve-2.3.1            |     pyhd8ed1ab_0          33 KB  conda-forge\n",
            "    spdlog-1.8.5               |       h4bd325d_1         352 KB  conda-forge\n",
            "    sqlite-3.37.0              |       h9cd32fc_0         1.5 MB  conda-forge\n",
            "    starlette-0.19.1           |     pyhd8ed1ab_0          47 KB  conda-forge\n",
            "    streamz-0.6.3              |     pyh6c4a22f_0          61 KB  conda-forge\n",
            "    tabulate-0.8.10            |     pyhd8ed1ab_0          29 KB  conda-forge\n",
            "    tblib-1.7.0                |     pyhd8ed1ab_0          15 KB  conda-forge\n",
            "    terminado-0.15.0           |   py37h89c1867_0          28 KB  conda-forge\n",
            "    threadpoolctl-3.1.0        |     pyh8a188c0_0          18 KB  conda-forge\n",
            "    tifffile-2021.11.2         |     pyhd8ed1ab_0         139 KB  conda-forge\n",
            "    tiledb-2.3.4               |       he87e0bf_0         4.1 MB  conda-forge\n",
            "    tinycss2-1.1.1             |     pyhd8ed1ab_0          23 KB  conda-forge\n",
            "    toolz-0.11.2               |     pyhd8ed1ab_0          48 KB  conda-forge\n",
            "    tornado-6.1                |   py37h540881e_3         646 KB  conda-forge\n",
            "    traitlets-5.3.0            |     pyhd8ed1ab_0          85 KB  conda-forge\n",
            "    treelite-2.1.0             |   py37h4b3d254_0         1.4 MB  conda-forge\n",
            "    typing-extensions-4.2.0    |       hd8ed1ab_1           8 KB  conda-forge\n",
            "    typing_extensions-4.2.0    |     pyha770c72_1          27 KB  conda-forge\n",
            "    tzcode-2022a               |       h166bdaf_0          69 KB  conda-forge\n",
            "    tzdata-2022a               |       h191b570_0         121 KB  conda-forge\n",
            "    tzlocal-4.2                |   py37h89c1867_1          31 KB  conda-forge\n",
            "    ucx-1.11.2+gef2bbcf        |       cuda11.2_0        11.9 MB  rapidsai\n",
            "    ucx-proc-1.0.0             |              gpu           9 KB  rapidsai\n",
            "    ucx-py-0.23.0              |  py37_gef2bbcf_0         353 KB  rapidsai\n",
            "    uvicorn-0.17.6             |   py37h89c1867_1          78 KB  conda-forge\n",
            "    wcwidth-0.2.5              |     pyh9f0ad1d_2          33 KB  conda-forge\n",
            "    webencodings-0.5.1         |             py_1          12 KB  conda-forge\n",
            "    websocket-client-1.3.3     |     pyhd8ed1ab_0          41 KB  conda-forge\n",
            "    websockets-10.3            |   py37h540881e_0         122 KB  conda-forge\n",
            "    widgetsnbextension-3.6.1   |     pyha770c72_0         1.2 MB  conda-forge\n",
            "    xarray-0.20.2              |     pyhd8ed1ab_0         628 KB  conda-forge\n",
            "    xerces-c-3.2.3             |       h9d8b166_3         1.8 MB  conda-forge\n",
            "    xgboost-1.5.0dev.rapidsai21.12|   cuda11.2py37_0          17 KB  rapidsai\n",
            "    xorg-fixesproto-5.0        |    h7f98852_1002           9 KB  conda-forge\n",
            "    xorg-inputproto-2.3.2      |    h7f98852_1002          19 KB  conda-forge\n",
            "    xorg-kbproto-1.0.7         |    h7f98852_1002          27 KB  conda-forge\n",
            "    xorg-libice-1.0.10         |       h7f98852_0          58 KB  conda-forge\n",
            "    xorg-libsm-1.2.3           |    hd9c2040_1000          26 KB  conda-forge\n",
            "    xorg-libx11-1.7.2          |       h7f98852_0         941 KB  conda-forge\n",
            "    xorg-libxau-1.0.9          |       h7f98852_0          13 KB  conda-forge\n",
            "    xorg-libxdmcp-1.1.3        |       h7f98852_0          19 KB  conda-forge\n",
            "    xorg-libxext-1.3.4         |       h7f98852_1          54 KB  conda-forge\n",
            "    xorg-libxfixes-5.0.3       |    h7f98852_1004          18 KB  conda-forge\n",
            "    xorg-libxi-1.7.10          |       h7f98852_0          46 KB  conda-forge\n",
            "    xorg-libxrender-0.9.10     |    h7f98852_1003          32 KB  conda-forge\n",
            "    xorg-libxtst-1.2.3         |    h7f98852_1002          31 KB  conda-forge\n",
            "    xorg-recordproto-1.14.2    |    h7f98852_1002           8 KB  conda-forge\n",
            "    xorg-renderproto-0.11.1    |    h7f98852_1002           9 KB  conda-forge\n",
            "    xorg-xextproto-7.3.0       |    h7f98852_1002          28 KB  conda-forge\n",
            "    xorg-xproto-7.0.31         |    h7f98852_1007          73 KB  conda-forge\n",
            "    yarl-1.7.2                 |   py37h540881e_2         132 KB  conda-forge\n",
            "    zeromq-4.3.4               |       h9c3ff4c_1         351 KB  conda-forge\n",
            "    zfp-0.5.5                  |       h9c3ff4c_8         190 KB  conda-forge\n",
            "    zict-2.2.0                 |     pyhd8ed1ab_0          20 KB  conda-forge\n",
            "    zipp-3.8.0                 |     pyhd8ed1ab_0          12 KB  conda-forge\n",
            "    zlib-1.2.12                |       h166bdaf_1          91 KB  conda-forge\n",
            "    zlib-ng-2.0.6              |       h166bdaf_0          96 KB  conda-forge\n",
            "    zstd-1.5.2                 |       h8a70e8d_2         448 KB  conda-forge\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:        2.86 GB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  abseil-cpp         conda-forge/linux-64::abseil-cpp-20210324.2-h9c3ff4c_0\n",
            "  aiohttp            conda-forge/linux-64::aiohttp-3.8.1-py37h540881e_1\n",
            "  aiosignal          conda-forge/noarch::aiosignal-1.2.0-pyhd8ed1ab_0\n",
            "  alsa-lib           conda-forge/linux-64::alsa-lib-1.2.3.2-h166bdaf_0\n",
            "  anyio              conda-forge/linux-64::anyio-3.6.1-py37h89c1867_0\n",
            "  appdirs            conda-forge/noarch::appdirs-1.4.4-pyh9f0ad1d_0\n",
            "  argon2-cffi        conda-forge/noarch::argon2-cffi-21.3.0-pyhd8ed1ab_0\n",
            "  argon2-cffi-bindi~ conda-forge/linux-64::argon2-cffi-bindings-21.2.0-py37h540881e_2\n",
            "  arrow-cpp          conda-forge/linux-64::arrow-cpp-5.0.0-py37hc2523e2_2_cuda\n",
            "  arrow-cpp-proc     conda-forge/linux-64::arrow-cpp-proc-3.0.0-cuda\n",
            "  asgiref            conda-forge/noarch::asgiref-3.5.2-pyhd8ed1ab_0\n",
            "  async-timeout      conda-forge/noarch::async-timeout-4.0.2-pyhd8ed1ab_0\n",
            "  asynctest          conda-forge/noarch::asynctest-0.13.0-py_0\n",
            "  attrs              conda-forge/noarch::attrs-21.4.0-pyhd8ed1ab_0\n",
            "  aws-c-cal          conda-forge/linux-64::aws-c-cal-0.5.11-h95a6274_0\n",
            "  aws-c-common       conda-forge/linux-64::aws-c-common-0.6.2-h7f98852_0\n",
            "  aws-c-event-stream conda-forge/linux-64::aws-c-event-stream-0.2.7-h3541f99_13\n",
            "  aws-c-io           conda-forge/linux-64::aws-c-io-0.10.5-hfb6a706_0\n",
            "  aws-checksums      conda-forge/linux-64::aws-checksums-0.1.11-ha31a3da_7\n",
            "  aws-sdk-cpp        conda-forge/linux-64::aws-sdk-cpp-1.8.186-hb4091e7_3\n",
            "  backcall           conda-forge/noarch::backcall-0.2.0-pyh9f0ad1d_0\n",
            "  backports          conda-forge/noarch::backports-1.0-py_2\n",
            "  backports.functoo~ conda-forge/noarch::backports.functools_lru_cache-1.6.4-pyhd8ed1ab_0\n",
            "  backports.zoneinfo conda-forge/linux-64::backports.zoneinfo-0.2.1-py37h540881e_5\n",
            "  beautifulsoup4     conda-forge/noarch::beautifulsoup4-4.11.1-pyha770c72_0\n",
            "  bleach             conda-forge/noarch::bleach-5.0.1-pyhd8ed1ab_0\n",
            "  blinker            conda-forge/noarch::blinker-1.4-py_1\n",
            "  blosc              conda-forge/linux-64::blosc-1.21.1-h83bc5f7_3\n",
            "  bokeh              conda-forge/linux-64::bokeh-2.4.0-py37h89c1867_0\n",
            "  boost              conda-forge/linux-64::boost-1.74.0-py37h796e4cb_5\n",
            "  boost-cpp          conda-forge/linux-64::boost-cpp-1.74.0-h312852a_4\n",
            "  brotli             conda-forge/linux-64::brotli-1.0.9-h166bdaf_7\n",
            "  brotli-bin         conda-forge/linux-64::brotli-bin-1.0.9-h166bdaf_7\n",
            "  brunsli            conda-forge/linux-64::brunsli-0.1-h9c3ff4c_0\n",
            "  c-blosc2           conda-forge/linux-64::c-blosc2-2.1.1-h7a311fb_2\n",
            "  cachetools         conda-forge/noarch::cachetools-5.0.0-pyhd8ed1ab_0\n",
            "  cairo              conda-forge/linux-64::cairo-1.16.0-h6cf1ce9_1008\n",
            "  cfitsio            conda-forge/linux-64::cfitsio-3.470-hb418390_7\n",
            "  charls             conda-forge/linux-64::charls-2.2.0-h9c3ff4c_0\n",
            "  charset-normalizer conda-forge/noarch::charset-normalizer-2.1.0-pyhd8ed1ab_0\n",
            "  click              conda-forge/linux-64::click-8.1.3-py37h89c1867_0\n",
            "  click-plugins      conda-forge/noarch::click-plugins-1.1.1-py_0\n",
            "  cligj              conda-forge/noarch::cligj-0.7.2-pyhd8ed1ab_1\n",
            "  cloudpickle        conda-forge/noarch::cloudpickle-2.1.0-pyhd8ed1ab_0\n",
            "  colorcet           conda-forge/noarch::colorcet-3.0.0-pyhd8ed1ab_0\n",
            "  cucim              rapidsai/linux-64::cucim-21.12.00-cuda_11_py37_g6d1f082_0\n",
            "  cudatoolkit        nvidia/linux-64::cudatoolkit-11.2.72-h2bc3f7f_0\n",
            "  cudf               rapidsai/linux-64::cudf-21.12.02-cuda_11_py37_g06540b9b37_0\n",
            "  cudf_kafka         rapidsai/linux-64::cudf_kafka-21.12.02-py37_g06540b9b37_0\n",
            "  cugraph            rapidsai/linux-64::cugraph-21.12.00-cuda11_py37_g3a43e9d0_0\n",
            "  cuml               rapidsai/linux-64::cuml-21.12.00-cuda11_py37_g04c4927f3_0\n",
            "  cupy               conda-forge/linux-64::cupy-9.6.0-py37h07c33ac_0\n",
            "  curl               conda-forge/linux-64::curl-7.78.0-hea6ffbf_0\n",
            "  cusignal           rapidsai/noarch::cusignal-21.12.00-py37_g2bf865c_0\n",
            "  cuspatial          rapidsai/linux-64::cuspatial-21.12.00-py37_gab6748f_0\n",
            "  custreamz          rapidsai/linux-64::custreamz-21.12.02-py37_g06540b9b37_0\n",
            "  cuxfilter          rapidsai/linux-64::cuxfilter-21.12.00-py37_g2e0fb5a_0\n",
            "  cycler             conda-forge/noarch::cycler-0.11.0-pyhd8ed1ab_0\n",
            "  cyrus-sasl         conda-forge/linux-64::cyrus-sasl-2.1.27-h230043b_5\n",
            "  cytoolz            conda-forge/linux-64::cytoolz-0.11.2-py37h540881e_2\n",
            "  dask               conda-forge/noarch::dask-2021.11.2-pyhd8ed1ab_0\n",
            "  dask-core          conda-forge/noarch::dask-core-2021.11.2-pyhd8ed1ab_0\n",
            "  dask-cuda          rapidsai/linux-64::dask-cuda-21.12.00-py37_0\n",
            "  dask-cudf          rapidsai/linux-64::dask-cudf-21.12.02-cuda_11_py37_g06540b9b37_0\n",
            "  dask-sql           conda-forge/linux-64::dask-sql-2022.1.0-py37h89c1867_0\n",
            "  datashader         conda-forge/noarch::datashader-0.11.1-pyh9f0ad1d_0\n",
            "  datashape          conda-forge/noarch::datashape-0.5.4-py_1\n",
            "  debugpy            conda-forge/linux-64::debugpy-1.6.0-py37hd23a5d3_0\n",
            "  decorator          conda-forge/noarch::decorator-5.1.1-pyhd8ed1ab_0\n",
            "  defusedxml         conda-forge/noarch::defusedxml-0.7.1-pyhd8ed1ab_0\n",
            "  distributed        conda-forge/linux-64::distributed-2021.11.2-py37h89c1867_0\n",
            "  dlpack             conda-forge/linux-64::dlpack-0.5-h9c3ff4c_0\n",
            "  entrypoints        conda-forge/noarch::entrypoints-0.4-pyhd8ed1ab_0\n",
            "  expat              conda-forge/linux-64::expat-2.4.8-h27087fc_0\n",
            "  faiss-proc         rapidsai/linux-64::faiss-proc-1.0.0-cuda\n",
            "  fastapi            conda-forge/noarch::fastapi-0.78.0-pyhd8ed1ab_0\n",
            "  fastavro           conda-forge/linux-64::fastavro-1.5.2-py37h540881e_0\n",
            "  fastrlock          conda-forge/linux-64::fastrlock-0.8-py37hd23a5d3_2\n",
            "  fiona              conda-forge/linux-64::fiona-1.8.20-py37hb7e2723_2\n",
            "  flit-core          conda-forge/noarch::flit-core-3.7.1-pyhd8ed1ab_0\n",
            "  font-ttf-dejavu-s~ conda-forge/noarch::font-ttf-dejavu-sans-mono-2.37-hab24e00_0\n",
            "  font-ttf-inconsol~ conda-forge/noarch::font-ttf-inconsolata-3.000-h77eed37_0\n",
            "  font-ttf-source-c~ conda-forge/noarch::font-ttf-source-code-pro-2.038-h77eed37_0\n",
            "  font-ttf-ubuntu    conda-forge/noarch::font-ttf-ubuntu-0.83-hab24e00_0\n",
            "  fontconfig         conda-forge/linux-64::fontconfig-2.14.0-h8e229c2_0\n",
            "  fonts-conda-ecosy~ conda-forge/noarch::fonts-conda-ecosystem-1-0\n",
            "  fonts-conda-forge  conda-forge/noarch::fonts-conda-forge-1-0\n",
            "  freetype           conda-forge/linux-64::freetype-2.10.4-h0708190_1\n",
            "  freexl             conda-forge/linux-64::freexl-1.0.6-h7f98852_0\n",
            "  frozenlist         conda-forge/linux-64::frozenlist-1.3.0-py37h540881e_1\n",
            "  fsspec             conda-forge/noarch::fsspec-2022.5.0-pyhd8ed1ab_0\n",
            "  gcsfs              conda-forge/noarch::gcsfs-2022.5.0-pyhd8ed1ab_0\n",
            "  gdal               conda-forge/linux-64::gdal-3.3.2-py37hd5a0ba4_3\n",
            "  geopandas          conda-forge/noarch::geopandas-0.9.0-pyhd8ed1ab_1\n",
            "  geopandas-base     conda-forge/noarch::geopandas-base-0.9.0-pyhd8ed1ab_1\n",
            "  geos               conda-forge/linux-64::geos-3.9.1-h9c3ff4c_2\n",
            "  geotiff            conda-forge/linux-64::geotiff-1.7.0-h08e826d_2\n",
            "  gettext            conda-forge/linux-64::gettext-0.19.8.1-h0b5b191_1005\n",
            "  gflags             conda-forge/linux-64::gflags-2.2.2-he1b5a44_1004\n",
            "  giflib             conda-forge/linux-64::giflib-5.2.1-h36c2ea0_2\n",
            "  glog               conda-forge/linux-64::glog-0.5.0-h48cff8f_0\n",
            "  google-api-core    conda-forge/noarch::google-api-core-2.8.2-pyhd8ed1ab_0\n",
            "  google-auth        conda-forge/noarch::google-auth-2.9.0-pyh6c4a22f_0\n",
            "  google-auth-oauth~ conda-forge/noarch::google-auth-oauthlib-0.5.2-pyhd8ed1ab_0\n",
            "  google-cloud-core  conda-forge/noarch::google-cloud-core-2.3.1-pyhd8ed1ab_0\n",
            "  google-cloud-stor~ conda-forge/noarch::google-cloud-storage-2.4.0-pyh6c4a22f_0\n",
            "  google-crc32c      conda-forge/linux-64::google-crc32c-1.1.2-py37h5d4fa31_3\n",
            "  google-resumable-~ conda-forge/noarch::google-resumable-media-2.3.3-pyhd8ed1ab_0\n",
            "  googleapis-common~ conda-forge/linux-64::googleapis-common-protos-1.56.3-py37h89c1867_0\n",
            "  graphite2          conda-forge/linux-64::graphite2-1.3.13-h58526e2_1001\n",
            "  grpc-cpp           conda-forge/linux-64::grpc-cpp-1.39.0-hf1f433d_2\n",
            "  grpcio             conda-forge/linux-64::grpcio-1.38.1-py37hb27c1af_0\n",
            "  h11                conda-forge/noarch::h11-0.13.0-pyhd8ed1ab_1\n",
            "  harfbuzz           conda-forge/linux-64::harfbuzz-2.9.1-h83ec7ef_1\n",
            "  hdf4               conda-forge/linux-64::hdf4-4.2.15-h10796ff_3\n",
            "  hdf5               conda-forge/linux-64::hdf5-1.12.1-nompi_h2750804_100\n",
            "  heapdict           conda-forge/noarch::heapdict-1.0.1-py_0\n",
            "  imagecodecs        conda-forge/linux-64::imagecodecs-2021.8.26-py37hfe5a812_1\n",
            "  imageio            conda-forge/noarch::imageio-2.13.1-pyhd8ed1ab_0\n",
            "  importlib-metadata conda-forge/linux-64::importlib-metadata-4.11.4-py37h89c1867_0\n",
            "  importlib_metadata conda-forge/noarch::importlib_metadata-4.11.4-hd8ed1ab_0\n",
            "  importlib_resourc~ conda-forge/noarch::importlib_resources-5.8.0-pyhd8ed1ab_0\n",
            "  ipykernel          conda-forge/linux-64::ipykernel-6.14.0-py37h25bab4e_0\n",
            "  ipython            conda-forge/linux-64::ipython-7.33.0-py37h89c1867_0\n",
            "  ipython_genutils   conda-forge/noarch::ipython_genutils-0.2.0-py_1\n",
            "  ipywidgets         conda-forge/noarch::ipywidgets-7.7.1-pyhd8ed1ab_0\n",
            "  jbig               conda-forge/linux-64::jbig-2.1-h7f98852_2003\n",
            "  jedi               conda-forge/linux-64::jedi-0.18.1-py37h89c1867_1\n",
            "  jinja2             conda-forge/noarch::jinja2-3.1.2-pyhd8ed1ab_1\n",
            "  joblib             conda-forge/noarch::joblib-1.1.0-pyhd8ed1ab_0\n",
            "  jpeg               conda-forge/linux-64::jpeg-9e-h166bdaf_2\n",
            "  jpype1             conda-forge/linux-64::jpype1-1.4.0-py37h7cecad7_0\n",
            "  json-c             conda-forge/linux-64::json-c-0.15-h98cffda_0\n",
            "  jsonschema         conda-forge/noarch::jsonschema-4.6.1-pyhd8ed1ab_0\n",
            "  jupyter-server-pr~ conda-forge/noarch::jupyter-server-proxy-3.2.1-pyhd8ed1ab_0\n",
            "  jupyter_client     conda-forge/noarch::jupyter_client-7.3.4-pyhd8ed1ab_0\n",
            "  jupyter_core       conda-forge/linux-64::jupyter_core-4.10.0-py37h89c1867_0\n",
            "  jupyter_server     conda-forge/noarch::jupyter_server-1.18.0-pyhd8ed1ab_1\n",
            "  jupyterlab_pygmen~ conda-forge/noarch::jupyterlab_pygments-0.2.2-pyhd8ed1ab_0\n",
            "  jupyterlab_widgets conda-forge/noarch::jupyterlab_widgets-1.1.1-pyhd8ed1ab_0\n",
            "  jxrlib             conda-forge/linux-64::jxrlib-1.1-h7f98852_2\n",
            "  kealib             conda-forge/linux-64::kealib-1.4.15-hfe1a663_0\n",
            "  keyutils           conda-forge/linux-64::keyutils-1.6.1-h166bdaf_0\n",
            "  kiwisolver         conda-forge/linux-64::kiwisolver-1.4.3-py37h7cecad7_0\n",
            "  lcms2              conda-forge/linux-64::lcms2-2.12-hddcbb42_0\n",
            "  lerc               conda-forge/linux-64::lerc-3.0-h9c3ff4c_0\n",
            "  libaec             conda-forge/linux-64::libaec-1.0.6-h9c3ff4c_0\n",
            "  libblas            conda-forge/linux-64::libblas-3.9.0-15_linux64_openblas\n",
            "  libbrotlicommon    conda-forge/linux-64::libbrotlicommon-1.0.9-h166bdaf_7\n",
            "  libbrotlidec       conda-forge/linux-64::libbrotlidec-1.0.9-h166bdaf_7\n",
            "  libbrotlienc       conda-forge/linux-64::libbrotlienc-1.0.9-h166bdaf_7\n",
            "  libcblas           conda-forge/linux-64::libcblas-3.9.0-15_linux64_openblas\n",
            "  libcrc32c          conda-forge/linux-64::libcrc32c-1.1.2-h9c3ff4c_0\n",
            "  libcucim           rapidsai/linux-64::libcucim-21.12.00-cuda11_g6d1f082_0\n",
            "  libcudf            rapidsai/linux-64::libcudf-21.12.02-cuda11_g06540b9b37_0\n",
            "  libcudf_kafka      rapidsai/linux-64::libcudf_kafka-21.12.02-g06540b9b37_0\n",
            "  libcugraph         rapidsai/linux-64::libcugraph-21.12.00-cuda11_g3a43e9d0_0\n",
            "  libcuml            rapidsai/linux-64::libcuml-21.12.00-cuda11_g04c4927f3_0\n",
            "  libcumlprims       nvidia/linux-64::libcumlprims-21.12.00-cuda11_g0a7f19f_0\n",
            "  libcusolver        nvidia/linux-64::libcusolver-11.3.5.50-hcab339c_0\n",
            "  libcuspatial       rapidsai/linux-64::libcuspatial-21.12.00-cuda11_gab6748f_0\n",
            "  libdap4            conda-forge/linux-64::libdap4-3.20.6-hd7c4107_2\n",
            "  libdeflate         conda-forge/linux-64::libdeflate-1.8-h7f98852_0\n",
            "  libevent           conda-forge/linux-64::libevent-2.1.10-h9b69904_4\n",
            "  libfaiss           conda-forge/linux-64::libfaiss-1.7.0-cuda112h5bea7ad_8_cuda\n",
            "  libgcrypt          conda-forge/linux-64::libgcrypt-1.10.1-h166bdaf_0\n",
            "  libgdal            conda-forge/linux-64::libgdal-3.3.2-h6acdded_3\n",
            "  libgfortran-ng     conda-forge/linux-64::libgfortran-ng-12.1.0-h69a702a_16\n",
            "  libgfortran5       conda-forge/linux-64::libgfortran5-12.1.0-hdcd56e2_16\n",
            "  libglib            conda-forge/linux-64::libglib-2.68.4-h3e27bee_0\n",
            "  libgpg-error       conda-forge/linux-64::libgpg-error-1.45-hc0c96e0_0\n",
            "  libgsasl           conda-forge/linux-64::libgsasl-1.10.0-h5b4c23d_0\n",
            "  libhwloc           conda-forge/linux-64::libhwloc-2.3.0-h5e5b7d1_1\n",
            "  libkml             conda-forge/linux-64::libkml-1.3.0-h238a007_1014\n",
            "  liblapack          conda-forge/linux-64::liblapack-3.9.0-15_linux64_openblas\n",
            "  libllvm11          conda-forge/linux-64::libllvm11-11.1.0-hf817b99_3\n",
            "  libnetcdf          conda-forge/linux-64::libnetcdf-4.8.1-nompi_hb3fd0d9_101\n",
            "  libnsl             conda-forge/linux-64::libnsl-2.0.0-h7f98852_0\n",
            "  libntlm            conda-forge/linux-64::libntlm-1.4-h7f98852_1002\n",
            "  libopenblas        conda-forge/linux-64::libopenblas-0.3.20-pthreads_h78a6416_0\n",
            "  libpng             conda-forge/linux-64::libpng-1.6.37-h21135ba_2\n",
            "  libpq              conda-forge/linux-64::libpq-13.5-hd57d9b9_1\n",
            "  libprotobuf        conda-forge/linux-64::libprotobuf-3.16.0-h780b84a_0\n",
            "  librdkafka         conda-forge/linux-64::librdkafka-1.6.1-hc49e61c_1\n",
            "  librmm             rapidsai/linux-64::librmm-21.12.00-cuda11_g957ad04_0\n",
            "  librttopo          conda-forge/linux-64::librttopo-1.1.0-h1185371_6\n",
            "  libsodium          conda-forge/linux-64::libsodium-1.0.18-h36c2ea0_1\n",
            "  libspatialindex    conda-forge/linux-64::libspatialindex-1.9.3-h9c3ff4c_4\n",
            "  libspatialite      conda-forge/linux-64::libspatialite-5.0.1-h5cf074c_8\n",
            "  libthrift          conda-forge/linux-64::libthrift-0.14.2-he6d91bd_1\n",
            "  libtiff            conda-forge/linux-64::libtiff-4.3.0-h6f004c6_2\n",
            "  libutf8proc        conda-forge/linux-64::libutf8proc-2.7.0-h7f98852_0\n",
            "  libuuid            conda-forge/linux-64::libuuid-2.32.1-h7f98852_1000\n",
            "  libuv              conda-forge/linux-64::libuv-1.42.0-h7f98852_0\n",
            "  libwebp            conda-forge/linux-64::libwebp-1.2.2-h3452ae3_0\n",
            "  libwebp-base       conda-forge/linux-64::libwebp-base-1.2.2-h7f98852_1\n",
            "  libxcb             conda-forge/linux-64::libxcb-1.13-h7f98852_1004\n",
            "  libxgboost         rapidsai/linux-64::libxgboost-1.5.0dev.rapidsai21.12-cuda11.2_0\n",
            "  libzip             conda-forge/linux-64::libzip-1.9.2-hc869a4a_0\n",
            "  libzlib            conda-forge/linux-64::libzlib-1.2.12-h166bdaf_1\n",
            "  libzopfli          conda-forge/linux-64::libzopfli-1.0.3-h9c3ff4c_0\n",
            "  llvmlite           conda-forge/linux-64::llvmlite-0.38.1-py37h0761922_0\n",
            "  locket             conda-forge/noarch::locket-1.0.0-pyhd8ed1ab_0\n",
            "  mapclassify        conda-forge/noarch::mapclassify-2.4.3-pyhd8ed1ab_0\n",
            "  markdown           conda-forge/noarch::markdown-3.3.7-pyhd8ed1ab_0\n",
            "  markupsafe         conda-forge/linux-64::markupsafe-2.1.1-py37h540881e_1\n",
            "  matplotlib-base    conda-forge/linux-64::matplotlib-base-3.4.3-py37h1058ff1_0\n",
            "  matplotlib-inline  conda-forge/noarch::matplotlib-inline-0.1.3-pyhd8ed1ab_0\n",
            "  mistune            conda-forge/linux-64::mistune-0.8.4-py37h5e8e339_1005\n",
            "  msgpack-python     conda-forge/linux-64::msgpack-python-1.0.4-py37h7cecad7_0\n",
            "  multidict          conda-forge/linux-64::multidict-6.0.2-py37h540881e_1\n",
            "  multipledispatch   conda-forge/noarch::multipledispatch-0.6.0-py_0\n",
            "  munch              conda-forge/noarch::munch-2.5.0-py_0\n",
            "  nbclient           conda-forge/noarch::nbclient-0.6.5-pyhd8ed1ab_0\n",
            "  nbconvert          conda-forge/noarch::nbconvert-6.5.0-pyhd8ed1ab_0\n",
            "  nbconvert-core     conda-forge/noarch::nbconvert-core-6.5.0-pyhd8ed1ab_0\n",
            "  nbconvert-pandoc   conda-forge/noarch::nbconvert-pandoc-6.5.0-pyhd8ed1ab_0\n",
            "  nbformat           conda-forge/noarch::nbformat-5.4.0-pyhd8ed1ab_0\n",
            "  nccl               conda-forge/linux-64::nccl-2.12.12.1-h0800d71_0\n",
            "  nest-asyncio       conda-forge/noarch::nest-asyncio-1.5.5-pyhd8ed1ab_0\n",
            "  networkx           conda-forge/noarch::networkx-2.7.1-pyhd8ed1ab_0\n",
            "  nodejs             conda-forge/linux-64::nodejs-14.17.4-h92b4a50_0\n",
            "  notebook           conda-forge/noarch::notebook-6.4.12-pyha770c72_0\n",
            "  numba              conda-forge/linux-64::numba-0.55.2-py37h43839f2_0\n",
            "  numpy              conda-forge/linux-64::numpy-1.21.6-py37h976b520_0\n",
            "  nvtx               conda-forge/linux-64::nvtx-0.2.3-py37h5e8e339_1\n",
            "  oauthlib           conda-forge/noarch::oauthlib-3.2.0-pyhd8ed1ab_0\n",
            "  olefile            conda-forge/noarch::olefile-0.46-pyh9f0ad1d_1\n",
            "  openjdk            conda-forge/linux-64::openjdk-11.0.9.1-h5cc2fde_1\n",
            "  openjpeg           conda-forge/linux-64::openjpeg-2.4.0-hb52868f_1\n",
            "  orc                conda-forge/linux-64::orc-1.6.9-h58a87f1_0\n",
            "  packaging          conda-forge/noarch::packaging-21.3-pyhd8ed1ab_0\n",
            "  pandas             conda-forge/linux-64::pandas-1.3.5-py37he8f5f7f_0\n",
            "  pandoc             conda-forge/linux-64::pandoc-2.18-ha770c72_0\n",
            "  pandocfilters      conda-forge/noarch::pandocfilters-1.5.0-pyhd8ed1ab_0\n",
            "  panel              conda-forge/noarch::panel-0.12.4-pyhd8ed1ab_0\n",
            "  param              conda-forge/noarch::param-1.12.2-pyh6c4a22f_0\n",
            "  parquet-cpp        conda-forge/noarch::parquet-cpp-1.5.1-2\n",
            "  parso              conda-forge/noarch::parso-0.8.3-pyhd8ed1ab_0\n",
            "  partd              conda-forge/noarch::partd-1.2.0-pyhd8ed1ab_0\n",
            "  pcre               conda-forge/linux-64::pcre-8.45-h9c3ff4c_0\n",
            "  pexpect            conda-forge/noarch::pexpect-4.8.0-pyh9f0ad1d_2\n",
            "  pickle5            conda-forge/linux-64::pickle5-0.0.12-py37h5e8e339_0\n",
            "  pickleshare        conda-forge/noarch::pickleshare-0.7.5-py_1003\n",
            "  pillow             conda-forge/linux-64::pillow-8.3.1-py37h0f21c89_0\n",
            "  pixman             conda-forge/linux-64::pixman-0.40.0-h36c2ea0_0\n",
            "  pooch              conda-forge/noarch::pooch-1.6.0-pyhd8ed1ab_0\n",
            "  poppler            conda-forge/linux-64::poppler-21.09.0-h0e1ea10_1\n",
            "  poppler-data       conda-forge/noarch::poppler-data-0.4.11-hd8ed1ab_0\n",
            "  postgresql         conda-forge/linux-64::postgresql-13.5-h2510834_1\n",
            "  proj               conda-forge/linux-64::proj-8.1.0-h277dcde_1\n",
            "  prometheus_client  conda-forge/noarch::prometheus_client-0.14.1-pyhd8ed1ab_0\n",
            "  prompt-toolkit     conda-forge/noarch::prompt-toolkit-3.0.30-pyha770c72_0\n",
            "  protobuf           conda-forge/linux-64::protobuf-3.16.0-py37hcd2ae1e_0\n",
            "  psutil             conda-forge/linux-64::psutil-5.9.1-py37h540881e_0\n",
            "  pthread-stubs      conda-forge/linux-64::pthread-stubs-0.4-h36c2ea0_1001\n",
            "  ptxcompiler        rapidsai/linux-64::ptxcompiler-0.2.0-py37hcfeb250_0\n",
            "  ptyprocess         conda-forge/noarch::ptyprocess-0.7.0-pyhd3deb0d_0\n",
            "  py-xgboost         rapidsai/linux-64::py-xgboost-1.5.0dev.rapidsai21.12-cuda11.2py37_0\n",
            "  pyarrow            conda-forge/linux-64::pyarrow-5.0.0-py37hf0016df_2_cuda\n",
            "  pyasn1             conda-forge/noarch::pyasn1-0.4.8-py_0\n",
            "  pyasn1-modules     conda-forge/noarch::pyasn1-modules-0.2.7-py_0\n",
            "  pyct               conda-forge/noarch::pyct-0.4.6-py_0\n",
            "  pyct-core          conda-forge/noarch::pyct-core-0.4.6-py_0\n",
            "  pydantic           conda-forge/linux-64::pydantic-1.9.1-py37h540881e_0\n",
            "  pydeck             conda-forge/noarch::pydeck-0.5.0-pyh9f0ad1d_0\n",
            "  pyee               conda-forge/noarch::pyee-8.1.0-pyhd8ed1ab_0\n",
            "  pygments           conda-forge/noarch::pygments-2.12.0-pyhd8ed1ab_0\n",
            "  pyjwt              conda-forge/noarch::pyjwt-2.4.0-pyhd8ed1ab_0\n",
            "  pynvml             conda-forge/noarch::pynvml-11.4.1-pyhd8ed1ab_0\n",
            "  pyparsing          conda-forge/noarch::pyparsing-3.0.9-pyhd8ed1ab_0\n",
            "  pyppeteer          conda-forge/noarch::pyppeteer-1.0.2-pyhd8ed1ab_0\n",
            "  pyproj             conda-forge/linux-64::pyproj-3.1.0-py37hdf91f24_4\n",
            "  pyrsistent         conda-forge/linux-64::pyrsistent-0.18.1-py37h540881e_1\n",
            "  python-confluent-~ conda-forge/linux-64::python-confluent-kafka-1.6.0-py37h5e8e339_1\n",
            "  python-dateutil    conda-forge/noarch::python-dateutil-2.8.2-pyhd8ed1ab_0\n",
            "  python-fastjsonsc~ conda-forge/noarch::python-fastjsonschema-2.15.3-pyhd8ed1ab_0\n",
            "  python-tzdata      conda-forge/noarch::python-tzdata-2022.1-pyhd8ed1ab_0\n",
            "  pytz               conda-forge/noarch::pytz-2022.1-pyhd8ed1ab_0\n",
            "  pytz-deprecation-~ conda-forge/linux-64::pytz-deprecation-shim-0.1.0.post0-py37h89c1867_2\n",
            "  pyu2f              conda-forge/noarch::pyu2f-0.1.5-pyhd8ed1ab_0\n",
            "  pyviz_comms        conda-forge/noarch::pyviz_comms-2.2.0-pyhd8ed1ab_0\n",
            "  pywavelets         conda-forge/linux-64::pywavelets-1.3.0-py37hda87dfa_1\n",
            "  pyyaml             conda-forge/linux-64::pyyaml-6.0-py37h540881e_4\n",
            "  pyzmq              conda-forge/linux-64::pyzmq-23.2.0-py37h0c0c2a8_0\n",
            "  rapids             rapidsai/linux-64::rapids-21.12.00-cuda11.2_py37_gc46440c_94\n",
            "  rapids-xgboost     rapidsai/linux-64::rapids-xgboost-21.12.00-cuda11.2_py37_gc46440c_94\n",
            "  re2                conda-forge/linux-64::re2-2021.08.01-h9c3ff4c_0\n",
            "  requests-oauthlib  conda-forge/noarch::requests-oauthlib-1.3.1-pyhd8ed1ab_0\n",
            "  rmm                rapidsai/linux-64::rmm-21.12.00-cuda11_py37_g957ad04_0_has_cma\n",
            "  rsa                conda-forge/noarch::rsa-4.8-pyhd8ed1ab_0\n",
            "  rtree              conda-forge/linux-64::rtree-1.0.0-py37h0b55af0_1\n",
            "  s2n                conda-forge/linux-64::s2n-1.0.10-h9b69904_0\n",
            "  scikit-image       conda-forge/linux-64::scikit-image-0.18.1-py37hdc94413_0\n",
            "  scikit-learn       conda-forge/linux-64::scikit-learn-1.0.2-py37hf9e9bfc_0\n",
            "  scipy              conda-forge/linux-64::scipy-1.7.3-py37hf2a6cf1_0\n",
            "  send2trash         conda-forge/noarch::send2trash-1.8.0-pyhd8ed1ab_0\n",
            "  shapely            conda-forge/linux-64::shapely-1.8.0-py37h48c49eb_0\n",
            "  simpervisor        conda-forge/noarch::simpervisor-0.4-pyhd8ed1ab_0\n",
            "  snappy             conda-forge/linux-64::snappy-1.1.9-hbd366e4_1\n",
            "  sniffio            conda-forge/linux-64::sniffio-1.2.0-py37h89c1867_3\n",
            "  sortedcontainers   conda-forge/noarch::sortedcontainers-2.4.0-pyhd8ed1ab_0\n",
            "  soupsieve          conda-forge/noarch::soupsieve-2.3.1-pyhd8ed1ab_0\n",
            "  spdlog             conda-forge/linux-64::spdlog-1.8.5-h4bd325d_1\n",
            "  starlette          conda-forge/noarch::starlette-0.19.1-pyhd8ed1ab_0\n",
            "  streamz            conda-forge/noarch::streamz-0.6.3-pyh6c4a22f_0\n",
            "  tabulate           conda-forge/noarch::tabulate-0.8.10-pyhd8ed1ab_0\n",
            "  tblib              conda-forge/noarch::tblib-1.7.0-pyhd8ed1ab_0\n",
            "  terminado          conda-forge/linux-64::terminado-0.15.0-py37h89c1867_0\n",
            "  threadpoolctl      conda-forge/noarch::threadpoolctl-3.1.0-pyh8a188c0_0\n",
            "  tifffile           conda-forge/noarch::tifffile-2021.11.2-pyhd8ed1ab_0\n",
            "  tiledb             conda-forge/linux-64::tiledb-2.3.4-he87e0bf_0\n",
            "  tinycss2           conda-forge/noarch::tinycss2-1.1.1-pyhd8ed1ab_0\n",
            "  toolz              conda-forge/noarch::toolz-0.11.2-pyhd8ed1ab_0\n",
            "  tornado            conda-forge/linux-64::tornado-6.1-py37h540881e_3\n",
            "  traitlets          conda-forge/noarch::traitlets-5.3.0-pyhd8ed1ab_0\n",
            "  treelite           conda-forge/linux-64::treelite-2.1.0-py37h4b3d254_0\n",
            "  typing-extensions  conda-forge/noarch::typing-extensions-4.2.0-hd8ed1ab_1\n",
            "  typing_extensions  conda-forge/noarch::typing_extensions-4.2.0-pyha770c72_1\n",
            "  tzcode             conda-forge/linux-64::tzcode-2022a-h166bdaf_0\n",
            "  tzdata             conda-forge/noarch::tzdata-2022a-h191b570_0\n",
            "  tzlocal            conda-forge/linux-64::tzlocal-4.2-py37h89c1867_1\n",
            "  ucx                rapidsai/linux-64::ucx-1.11.2+gef2bbcf-cuda11.2_0\n",
            "  ucx-proc           rapidsai/linux-64::ucx-proc-1.0.0-gpu\n",
            "  ucx-py             rapidsai/linux-64::ucx-py-0.23.0-py37_gef2bbcf_0\n",
            "  uvicorn            conda-forge/linux-64::uvicorn-0.17.6-py37h89c1867_1\n",
            "  wcwidth            conda-forge/noarch::wcwidth-0.2.5-pyh9f0ad1d_2\n",
            "  webencodings       conda-forge/noarch::webencodings-0.5.1-py_1\n",
            "  websocket-client   conda-forge/noarch::websocket-client-1.3.3-pyhd8ed1ab_0\n",
            "  websockets         conda-forge/linux-64::websockets-10.3-py37h540881e_0\n",
            "  widgetsnbextension conda-forge/noarch::widgetsnbextension-3.6.1-pyha770c72_0\n",
            "  xarray             conda-forge/noarch::xarray-0.20.2-pyhd8ed1ab_0\n",
            "  xerces-c           conda-forge/linux-64::xerces-c-3.2.3-h9d8b166_3\n",
            "  xgboost            rapidsai/linux-64::xgboost-1.5.0dev.rapidsai21.12-cuda11.2py37_0\n",
            "  xorg-fixesproto    conda-forge/linux-64::xorg-fixesproto-5.0-h7f98852_1002\n",
            "  xorg-inputproto    conda-forge/linux-64::xorg-inputproto-2.3.2-h7f98852_1002\n",
            "  xorg-kbproto       conda-forge/linux-64::xorg-kbproto-1.0.7-h7f98852_1002\n",
            "  xorg-libice        conda-forge/linux-64::xorg-libice-1.0.10-h7f98852_0\n",
            "  xorg-libsm         conda-forge/linux-64::xorg-libsm-1.2.3-hd9c2040_1000\n",
            "  xorg-libx11        conda-forge/linux-64::xorg-libx11-1.7.2-h7f98852_0\n",
            "  xorg-libxau        conda-forge/linux-64::xorg-libxau-1.0.9-h7f98852_0\n",
            "  xorg-libxdmcp      conda-forge/linux-64::xorg-libxdmcp-1.1.3-h7f98852_0\n",
            "  xorg-libxext       conda-forge/linux-64::xorg-libxext-1.3.4-h7f98852_1\n",
            "  xorg-libxfixes     conda-forge/linux-64::xorg-libxfixes-5.0.3-h7f98852_1004\n",
            "  xorg-libxi         conda-forge/linux-64::xorg-libxi-1.7.10-h7f98852_0\n",
            "  xorg-libxrender    conda-forge/linux-64::xorg-libxrender-0.9.10-h7f98852_1003\n",
            "  xorg-libxtst       conda-forge/linux-64::xorg-libxtst-1.2.3-h7f98852_1002\n",
            "  xorg-recordproto   conda-forge/linux-64::xorg-recordproto-1.14.2-h7f98852_1002\n",
            "  xorg-renderproto   conda-forge/linux-64::xorg-renderproto-0.11.1-h7f98852_1002\n",
            "  xorg-xextproto     conda-forge/linux-64::xorg-xextproto-7.3.0-h7f98852_1002\n",
            "  xorg-xproto        conda-forge/linux-64::xorg-xproto-7.0.31-h7f98852_1007\n",
            "  yarl               conda-forge/linux-64::yarl-1.7.2-py37h540881e_2\n",
            "  zeromq             conda-forge/linux-64::zeromq-4.3.4-h9c3ff4c_1\n",
            "  zfp                conda-forge/linux-64::zfp-0.5.5-h9c3ff4c_8\n",
            "  zict               conda-forge/noarch::zict-2.2.0-pyhd8ed1ab_0\n",
            "  zipp               conda-forge/noarch::zipp-3.8.0-pyhd8ed1ab_0\n",
            "  zlib-ng            conda-forge/linux-64::zlib-ng-2.0.6-h166bdaf_0\n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "  ca-certificates                      2020.12.5-ha878542_0 --> 2022.6.15-ha878542_0\n",
            "  certifi                          2020.12.5-py37h89c1867_1 --> 2022.6.15-py37h89c1867_0\n",
            "  conda                                4.9.2-py37h89c1867_0 --> 4.12.0-py37h89c1867_0\n",
            "  krb5                                    1.17.2-h926e7f8_0 --> 1.19.3-h3790be6_0\n",
            "  libarchive                               3.5.1-h3f442fb_1 --> 3.5.2-hccf745f_1\n",
            "  libcurl                                 7.75.0-hc4aaa36_0 --> 7.78.0-h2574ce0_0\n",
            "  libgcc-ng                               9.3.0-h2828fa1_18 --> 12.1.0-h8d9b700_16\n",
            "  libgomp                                 9.3.0-h2828fa1_18 --> 12.1.0-h8d9b700_16\n",
            "  libstdcxx-ng                            9.3.0-h6de172a_18 --> 12.1.0-ha89aaad_16\n",
            "  libxml2                                 2.9.10-h72842e0_3 --> 2.9.12-h72842e0_0\n",
            "  openssl                                 1.1.1j-h7f98852_0 --> 1.1.1p-h166bdaf_0\n",
            "  python_abi                                    3.7-1_cp37m --> 3.7-2_cp37m\n",
            "  readline                                   8.0-he28a2e2_2 --> 8.1-h46c0cb4_0\n",
            "  setuptools                          49.6.0-py37h89c1867_3 --> 59.8.0-py37h89c1867_1\n",
            "  sqlite                                  3.34.0-h74cdb3f_0 --> 3.37.0-h9cd32fc_0\n",
            "  zlib                                 1.2.11-h516909a_1010 --> 1.2.12-h166bdaf_1\n",
            "  zstd                                     1.4.9-ha95c52a_0 --> 1.5.2-h8a70e8d_2\n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "\n",
            "libtiff-4.3.0        | 614 KB    |            |   0%\n",
            "libtiff-4.3.0        | 614 KB    | ##8        |  29%\n",
            "libtiff-4.3.0        | 614 KB    | ########## | 100%\n",
            "libtiff-4.3.0        | 614 KB    | ########## | 100%\n",
            "\n",
            "xorg-fixesproto-5.0  | 9 KB      |            |   0%\n",
            "xorg-fixesproto-5.0  | 9 KB      | ########## | 100%\n",
            "\n",
            "aiohttp-3.8.1        | 561 KB    |            |   0%\n",
            "aiohttp-3.8.1        | 561 KB    | ########## | 100%\n",
            "aiohttp-3.8.1        | 561 KB    | ########## | 100%\n",
            "\n",
            "harfbuzz-2.9.1       | 2.0 MB    |            |   0%\n",
            "harfbuzz-2.9.1       | 2.0 MB    | ########## | 100%\n",
            "harfbuzz-2.9.1       | 2.0 MB    | ########## | 100%\n",
            "\n",
            "psutil-5.9.1         | 344 KB    |            |   0%\n",
            "psutil-5.9.1         | 344 KB    | ########## | 100%\n",
            "psutil-5.9.1         | 344 KB    | ########## | 100%\n",
            "\n",
            "jxrlib-1.1           | 235 KB    |            |   0%\n",
            "jxrlib-1.1           | 235 KB    | ########## | 100%\n",
            "\n",
            "font-ttf-inconsolata | 94 KB     |            |   0%\n",
            "font-ttf-inconsolata | 94 KB     | ########## | 100%\n",
            "\n",
            "libgcrypt-1.10.1     | 703 KB    |            |   0%\n",
            "libgcrypt-1.10.1     | 703 KB    | ########## | 100%\n",
            "libgcrypt-1.10.1     | 703 KB    | ########## | 100%\n",
            "\n",
            "tifffile-2021.11.2   | 139 KB    |            |   0%\n",
            "tifffile-2021.11.2   | 139 KB    | ########## | 100%\n",
            "\n",
            "beautifulsoup4-4.11. | 96 KB     |            |   0%\n",
            "beautifulsoup4-4.11. | 96 KB     | ########## | 100%\n",
            "\n",
            "sortedcontainers-2.4 | 26 KB     |            |   0%\n",
            "sortedcontainers-2.4 | 26 KB     | ########## | 100%\n",
            "\n",
            "libntlm-1.4          | 32 KB     |            |   0%\n",
            "libntlm-1.4          | 32 KB     | ########## | 100%\n",
            "\n",
            "libnsl-2.0.0         | 31 KB     |            |   0%\n",
            "libnsl-2.0.0         | 31 KB     | ########## | 100%\n",
            "\n",
            "pywavelets-1.3.0     | 4.4 MB    |            |   0%\n",
            "pywavelets-1.3.0     | 4.4 MB    | ########## | 100%\n",
            "pywavelets-1.3.0     | 4.4 MB    | ########## | 100%\n",
            "\n",
            "jupyter_core-4.10.0  | 81 KB     |            |   0%\n",
            "jupyter_core-4.10.0  | 81 KB     | ########## | 100%\n",
            "\n",
            "libspatialindex-1.9. | 4.6 MB    |            |   0%\n",
            "libspatialindex-1.9. | 4.6 MB    | ########## | 100%\n",
            "libspatialindex-1.9. | 4.6 MB    | ########## | 100%\n",
            "\n",
            "prompt-toolkit-3.0.3 | 254 KB    |            |   0%\n",
            "prompt-toolkit-3.0.3 | 254 KB    | ########## | 100%\n",
            "prompt-toolkit-3.0.3 | 254 KB    | ########## | 100%\n",
            "\n",
            "xerces-c-3.2.3       | 1.8 MB    |            |   0%\n",
            "xerces-c-3.2.3       | 1.8 MB    | ########## | 100%\n",
            "xerces-c-3.2.3       | 1.8 MB    | ########## | 100%\n",
            "\n",
            "zfp-0.5.5            | 190 KB    |            |   0%\n",
            "zfp-0.5.5            | 190 KB    | ########## | 100%\n",
            "\n",
            "curl-7.78.0          | 148 KB    |            |   0%\n",
            "curl-7.78.0          | 148 KB    | ########## | 100%\n",
            "\n",
            "librdkafka-1.6.1     | 12.6 MB   |            |   0%\n",
            "librdkafka-1.6.1     | 12.6 MB   | ######5    |  66%\n",
            "librdkafka-1.6.1     | 12.6 MB   | ########## | 100%\n",
            "librdkafka-1.6.1     | 12.6 MB   | ########## | 100%\n",
            "\n",
            "websockets-10.3      | 122 KB    |            |   0%\n",
            "websockets-10.3      | 122 KB    | ########## | 100%\n",
            "\n",
            "geopandas-base-0.9.0 | 950 KB    |            |   0%\n",
            "geopandas-base-0.9.0 | 950 KB    | ########## | 100%\n",
            "geopandas-base-0.9.0 | 950 KB    | ########## | 100%\n",
            "\n",
            "libpq-13.5           | 2.8 MB    |            |   0%\n",
            "libpq-13.5           | 2.8 MB    | #######1   |  71%\n",
            "libpq-13.5           | 2.8 MB    | ########## | 100%\n",
            "libpq-13.5           | 2.8 MB    | ########## | 100%\n",
            "\n",
            "brotli-bin-1.0.9     | 19 KB     |            |   0%\n",
            "brotli-bin-1.0.9     | 19 KB     | ########## | 100%\n",
            "\n",
            "libzlib-1.2.12       | 63 KB     |            |   0%\n",
            "libzlib-1.2.12       | 63 KB     | ########## | 100%\n",
            "\n",
            "re2-2021.08.01       | 220 KB    |            |   0%\n",
            "re2-2021.08.01       | 220 KB    | ########## | 100%\n",
            "\n",
            "jupyterlab_widgets-1 | 133 KB    |            |   0%\n",
            "jupyterlab_widgets-1 | 133 KB    | ########## | 100%\n",
            "\n",
            "async-timeout-4.0.2  | 9 KB      |            |   0%\n",
            "async-timeout-4.0.2  | 9 KB      | ########## | 100%\n",
            "\n",
            "mistune-0.8.4        | 54 KB     |            |   0%\n",
            "mistune-0.8.4        | 54 KB     | ########## | 100%\n",
            "\n",
            "click-8.1.3          | 145 KB    |            |   0%\n",
            "click-8.1.3          | 145 KB    | ########## | 100%\n",
            "\n",
            "font-ttf-dejavu-sans | 388 KB    |            |   0%\n",
            "font-ttf-dejavu-sans | 388 KB    | ########## | 100%\n",
            "\n",
            "grpc-cpp-1.39.0      | 3.6 MB    |            |   0%\n",
            "grpc-cpp-1.39.0      | 3.6 MB    | ########## | 100%\n",
            "grpc-cpp-1.39.0      | 3.6 MB    | ########## | 100%\n",
            "\n",
            "libllvm11-11.1.0     | 29.1 MB   |            |   0%\n",
            "libllvm11-11.1.0     | 29.1 MB   | #7         |  17%\n",
            "libllvm11-11.1.0     | 29.1 MB   | ##2        |  22%\n",
            "libllvm11-11.1.0     | 29.1 MB   | ##6        |  27%\n",
            "libllvm11-11.1.0     | 29.1 MB   | ###        |  30%\n",
            "libllvm11-11.1.0     | 29.1 MB   | ###4       |  34%\n",
            "libllvm11-11.1.0     | 29.1 MB   | ###7       |  37%\n",
            "libllvm11-11.1.0     | 29.1 MB   | ####       |  41%\n",
            "libllvm11-11.1.0     | 29.1 MB   | ####3      |  44%\n",
            "libllvm11-11.1.0     | 29.1 MB   | ####6      |  47%\n",
            "libllvm11-11.1.0     | 29.1 MB   | ####9      |  50%\n",
            "libllvm11-11.1.0     | 29.1 MB   | #####2     |  53%\n",
            "libllvm11-11.1.0     | 29.1 MB   | #####5     |  56%\n",
            "libllvm11-11.1.0     | 29.1 MB   | #####8     |  58%\n",
            "libllvm11-11.1.0     | 29.1 MB   | ######1    |  61%\n",
            "libllvm11-11.1.0     | 29.1 MB   | ######4    |  64%\n",
            "libllvm11-11.1.0     | 29.1 MB   | ######6    |  67%\n",
            "libllvm11-11.1.0     | 29.1 MB   | ######9    |  70%\n",
            "libllvm11-11.1.0     | 29.1 MB   | #######2   |  73%\n",
            "libllvm11-11.1.0     | 29.1 MB   | #######5   |  76%\n",
            "libllvm11-11.1.0     | 29.1 MB   | #######8   |  78%\n",
            "libllvm11-11.1.0     | 29.1 MB   | ########1  |  81%\n",
            "libllvm11-11.1.0     | 29.1 MB   | ########4  |  84%\n",
            "libllvm11-11.1.0     | 29.1 MB   | ########6  |  87%\n",
            "libllvm11-11.1.0     | 29.1 MB   | ########9  |  90%\n",
            "libllvm11-11.1.0     | 29.1 MB   | #########2 |  93%\n",
            "libllvm11-11.1.0     | 29.1 MB   | #########5 |  96%\n",
            "libllvm11-11.1.0     | 29.1 MB   | #########8 |  98%\n",
            "libllvm11-11.1.0     | 29.1 MB   | ########## | 100%\n",
            "\n",
            "google-auth-2.9.0    | 90 KB     |            |   0%\n",
            "google-auth-2.9.0    | 90 KB     | #7         |  18%\n",
            "google-auth-2.9.0    | 90 KB     | ########## | 100%\n",
            "\n",
            "widgetsnbextension-3 | 1.2 MB    |            |   0%\n",
            "widgetsnbextension-3 | 1.2 MB    | ########## | 100%\n",
            "widgetsnbextension-3 | 1.2 MB    | ########## | 100%\n",
            "\n",
            "openjdk-11.0.9.1     | 173.5 MB  |            |   0%\n",
            "openjdk-11.0.9.1     | 173.5 MB  | 3          |   3%\n",
            "openjdk-11.0.9.1     | 173.5 MB  | #          |  11%\n",
            "openjdk-11.0.9.1     | 173.5 MB  | #7         |  18%\n",
            "openjdk-11.0.9.1     | 173.5 MB  | ##4        |  25%\n",
            "openjdk-11.0.9.1     | 173.5 MB  | ###2       |  32%\n",
            "openjdk-11.0.9.1     | 173.5 MB  | ###9       |  39%\n",
            "openjdk-11.0.9.1     | 173.5 MB  | ####6      |  47%\n",
            "openjdk-11.0.9.1     | 173.5 MB  | #####4     |  54%\n",
            "openjdk-11.0.9.1     | 173.5 MB  | ######     |  61%\n",
            "openjdk-11.0.9.1     | 173.5 MB  | ######7    |  68%\n",
            "openjdk-11.0.9.1     | 173.5 MB  | #######5   |  75%\n",
            "openjdk-11.0.9.1     | 173.5 MB  | ########1  |  82%\n",
            "openjdk-11.0.9.1     | 173.5 MB  | ########8  |  89%\n",
            "openjdk-11.0.9.1     | 173.5 MB  | #########5 |  95%\n",
            "openjdk-11.0.9.1     | 173.5 MB  | ########## | 100%\n",
            "\n",
            "shapely-1.8.0        | 367 KB    |            |   0%\n",
            "shapely-1.8.0        | 367 KB    | ########## | 100%\n",
            "shapely-1.8.0        | 367 KB    | ########## | 100%\n",
            "\n",
            "llvmlite-0.38.1      | 2.3 MB    |            |   0%\n",
            "llvmlite-0.38.1      | 2.3 MB    | ########## | 100%\n",
            "llvmlite-0.38.1      | 2.3 MB    | ########## | 100%\n",
            "\n",
            "libgdal-3.3.2        | 13.1 MB   |            |   0%\n",
            "libgdal-3.3.2        | 13.1 MB   | #####6     |  56%\n",
            "libgdal-3.3.2        | 13.1 MB   | ########## | 100%\n",
            "libgdal-3.3.2        | 13.1 MB   | ########## | 100%\n",
            "\n",
            "cuxfilter-21.12.00   | 137 KB    |            |   0%\n",
            "cuxfilter-21.12.00   | 137 KB    | #1         |  12%\n",
            "cuxfilter-21.12.00   | 137 KB    | ####6      |  47%\n",
            "cuxfilter-21.12.00   | 137 KB    | ########## | 100%\n",
            "cuxfilter-21.12.00   | 137 KB    | ########## | 100%\n",
            "\n",
            "jsonschema-4.6.1     | 63 KB     |            |   0%\n",
            "jsonschema-4.6.1     | 63 KB     | ########## | 100%\n",
            "\n",
            "google-resumable-med | 42 KB     |            |   0%\n",
            "google-resumable-med | 42 KB     | ########## | 100%\n",
            "\n",
            "libthrift-0.14.2     | 4.5 MB    |            |   0%\n",
            "libthrift-0.14.2     | 4.5 MB    | ########## | 100%\n",
            "libthrift-0.14.2     | 4.5 MB    | ########## | 100%\n",
            "\n",
            "xgboost-1.5.0dev.rap | 17 KB     |            |   0%\n",
            "xgboost-1.5.0dev.rap | 17 KB     | #########2 |  93%\n",
            "xgboost-1.5.0dev.rap | 17 KB     | ########## | 100%\n",
            "\n",
            "pynvml-11.4.1        | 40 KB     |            |   0%\n",
            "pynvml-11.4.1        | 40 KB     | ########## | 100%\n",
            "\n",
            "giflib-5.2.1         | 77 KB     |            |   0%\n",
            "giflib-5.2.1         | 77 KB     | ########## | 100%\n",
            "\n",
            "jupyter_client-7.3.4 | 91 KB     |            |   0%\n",
            "jupyter_client-7.3.4 | 91 KB     | ########## | 100%\n",
            "\n",
            "libgcc-ng-12.1.0     | 940 KB    |            |   0%\n",
            "libgcc-ng-12.1.0     | 940 KB    | ########## | 100%\n",
            "libgcc-ng-12.1.0     | 940 KB    | ########## | 100%\n",
            "\n",
            "google-auth-oauthlib | 20 KB     |            |   0%\n",
            "google-auth-oauthlib | 20 KB     | ########## | 100%\n",
            "\n",
            "tzlocal-4.2          | 31 KB     |            |   0%\n",
            "tzlocal-4.2          | 31 KB     | ########## | 100%\n",
            "\n",
            "fastrlock-0.8        | 31 KB     |            |   0%\n",
            "fastrlock-0.8        | 31 KB     | ########## | 100%\n",
            "\n",
            "scikit-learn-1.0.2   | 7.8 MB    |            |   0%\n",
            "scikit-learn-1.0.2   | 7.8 MB    | ########## | 100%\n",
            "scikit-learn-1.0.2   | 7.8 MB    | ########## | 100%\n",
            "\n",
            "lcms2-2.12           | 443 KB    |            |   0%\n",
            "lcms2-2.12           | 443 KB    | ########## | 100%\n",
            "\n",
            "datashader-0.11.1    | 14.0 MB   |            |   0%\n",
            "datashader-0.11.1    | 14.0 MB   | #5         |  16%\n",
            "datashader-0.11.1    | 14.0 MB   | #########7 |  98%\n",
            "datashader-0.11.1    | 14.0 MB   | ########## | 100%\n",
            "\n",
            "liblapack-3.9.0      | 12 KB     |            |   0%\n",
            "liblapack-3.9.0      | 12 KB     | ########## | 100%\n",
            "\n",
            "backports.functools_ | 9 KB      |            |   0%\n",
            "backports.functools_ | 9 KB      | ########## | 100%\n",
            "\n",
            "libstdcxx-ng-12.1.0  | 4.3 MB    |            |   0%\n",
            "libstdcxx-ng-12.1.0  | 4.3 MB    | ####3      |  44%\n",
            "libstdcxx-ng-12.1.0  | 4.3 MB    | ######3    |  63%\n",
            "libstdcxx-ng-12.1.0  | 4.3 MB    | ########2  |  82%\n",
            "libstdcxx-ng-12.1.0  | 4.3 MB    | ########## | 100%\n",
            "libstdcxx-ng-12.1.0  | 4.3 MB    | ########## | 100%\n",
            "\n",
            "python-dateutil-2.8. | 240 KB    |            |   0%\n",
            "python-dateutil-2.8. | 240 KB    | ########## | 100%\n",
            "\n",
            "sqlite-3.37.0        | 1.5 MB    |            |   0%\n",
            "sqlite-3.37.0        | 1.5 MB    | ########## | 100%\n",
            "sqlite-3.37.0        | 1.5 MB    | ########## | 100%\n",
            "\n",
            "traitlets-5.3.0      | 85 KB     |            |   0%\n",
            "traitlets-5.3.0      | 85 KB     | ########## | 100%\n",
            "\n",
            "rtree-1.0.0          | 49 KB     |            |   0%\n",
            "rtree-1.0.0          | 49 KB     | ########## | 100%\n",
            "\n",
            "libpng-1.6.37        | 306 KB    |            |   0%\n",
            "libpng-1.6.37        | 306 KB    | ########## | 100%\n",
            "\n",
            "rapids-21.12.00      | 5 KB      |            |   0%\n",
            "rapids-21.12.00      | 5 KB      | ########## | 100%\n",
            "rapids-21.12.00      | 5 KB      | ########## | 100%\n",
            "\n",
            "importlib_resources- | 22 KB     |            |   0%\n",
            "importlib_resources- | 22 KB     | ########## | 100%\n",
            "\n",
            "parquet-cpp-1.5.1    | 3 KB      |            |   0%\n",
            "parquet-cpp-1.5.1    | 3 KB      | ########## | 100%\n",
            "\n",
            "cupy-9.6.0           | 51.5 MB   |            |   0%\n",
            "cupy-9.6.0           | 51.5 MB   | 7          |   7%\n",
            "cupy-9.6.0           | 51.5 MB   | ##1        |  21%\n",
            "cupy-9.6.0           | 51.5 MB   | ###7       |  37%\n",
            "cupy-9.6.0           | 51.5 MB   | ######1    |  62%\n",
            "cupy-9.6.0           | 51.5 MB   | #######9   |  79%\n",
            "cupy-9.6.0           | 51.5 MB   | #########8 |  98%\n",
            "cupy-9.6.0           | 51.5 MB   | ########## | 100%\n",
            "\n",
            "libfaiss-1.7.0       | 98.5 MB   |            |   0%\n",
            "libfaiss-1.7.0       | 98.5 MB   | 1          |   2%\n",
            "libfaiss-1.7.0       | 98.5 MB   | 2          |   2%\n",
            "libfaiss-1.7.0       | 98.5 MB   | 3          |   3%\n",
            "libfaiss-1.7.0       | 98.5 MB   | 4          |   4%\n",
            "libfaiss-1.7.0       | 98.5 MB   | 5          |   5%\n",
            "libfaiss-1.7.0       | 98.5 MB   | 5          |   6%\n",
            "libfaiss-1.7.0       | 98.5 MB   | 6          |   7%\n",
            "libfaiss-1.7.0       | 98.5 MB   | 7          |   8%\n",
            "libfaiss-1.7.0       | 98.5 MB   | 8          |   8%\n",
            "libfaiss-1.7.0       | 98.5 MB   | 9          |   9%\n",
            "libfaiss-1.7.0       | 98.5 MB   | #          |  10%\n",
            "libfaiss-1.7.0       | 98.5 MB   | #          |  11%\n",
            "libfaiss-1.7.0       | 98.5 MB   | #1         |  12%\n",
            "libfaiss-1.7.0       | 98.5 MB   | #2         |  13%\n",
            "libfaiss-1.7.0       | 98.5 MB   | #3         |  13%\n",
            "libfaiss-1.7.0       | 98.5 MB   | #4         |  14%\n",
            "libfaiss-1.7.0       | 98.5 MB   | #5         |  15%\n",
            "libfaiss-1.7.0       | 98.5 MB   | #6         |  16%\n",
            "libfaiss-1.7.0       | 98.5 MB   | #6         |  17%\n",
            "libfaiss-1.7.0       | 98.5 MB   | #7         |  18%\n",
            "libfaiss-1.7.0       | 98.5 MB   | #8         |  19%\n",
            "libfaiss-1.7.0       | 98.5 MB   | #9         |  19%\n",
            "libfaiss-1.7.0       | 98.5 MB   | ##         |  20%\n",
            "libfaiss-1.7.0       | 98.5 MB   | ##1        |  21%\n",
            "libfaiss-1.7.0       | 98.5 MB   | ##2        |  22%\n",
            "libfaiss-1.7.0       | 98.5 MB   | ##2        |  23%\n",
            "libfaiss-1.7.0       | 98.5 MB   | ##5        |  26%\n",
            "libfaiss-1.7.0       | 98.5 MB   | ##6        |  27%\n",
            "libfaiss-1.7.0       | 98.5 MB   | ##7        |  28%\n",
            "libfaiss-1.7.0       | 98.5 MB   | ##9        |  29%\n",
            "libfaiss-1.7.0       | 98.5 MB   | ##9        |  30%\n",
            "libfaiss-1.7.0       | 98.5 MB   | ###        |  31%\n",
            "libfaiss-1.7.0       | 98.5 MB   | ###1       |  32%\n",
            "libfaiss-1.7.0       | 98.5 MB   | ###2       |  33%\n",
            "libfaiss-1.7.0       | 98.5 MB   | ####2      |  42%\n",
            "libfaiss-1.7.0       | 98.5 MB   | ####9      |  50%\n",
            "libfaiss-1.7.0       | 98.5 MB   | #####4     |  54%\n",
            "libfaiss-1.7.0       | 98.5 MB   | #####7     |  58%\n",
            "libfaiss-1.7.0       | 98.5 MB   | #######    |  70%\n",
            "libfaiss-1.7.0       | 98.5 MB   | ########3  |  83%\n",
            "libfaiss-1.7.0       | 98.5 MB   | #########6 |  96%\n",
            "libfaiss-1.7.0       | 98.5 MB   | ########## | 100%\n",
            "\n",
            "pyasn1-modules-0.2.7 | 60 KB     |            |   0%\n",
            "pyasn1-modules-0.2.7 | 60 KB     | ########## | 100%\n",
            "\n",
            "zlib-ng-2.0.6        | 96 KB     |            |   0%\n",
            "zlib-ng-2.0.6        | 96 KB     | ####9      |  50%\n",
            "zlib-ng-2.0.6        | 96 KB     | ########## | 100%\n",
            "\n",
            "libgomp-12.1.0       | 459 KB    |            |   0%\n",
            "libgomp-12.1.0       | 459 KB    | ########## | 100%\n",
            "\n",
            "multipledispatch-0.6 | 12 KB     |            |   0%\n",
            "multipledispatch-0.6 | 12 KB     | ########## | 100%\n",
            "\n",
            "pexpect-4.8.0        | 47 KB     |            |   0%\n",
            "pexpect-4.8.0        | 47 KB     | ########## | 100%\n",
            "\n",
            "dask-2021.11.2       | 5 KB      |            |   0%\n",
            "dask-2021.11.2       | 5 KB      | ########## | 100%\n",
            "\n",
            "nccl-2.12.12.1       | 135.3 MB  |            |   0%\n",
            "nccl-2.12.12.1       | 135.3 MB  | 4          |   4%\n",
            "nccl-2.12.12.1       | 135.3 MB  | #3         |  14%\n",
            "nccl-2.12.12.1       | 135.3 MB  | ##2        |  23%\n",
            "nccl-2.12.12.1       | 135.3 MB  | ###1       |  32%\n",
            "nccl-2.12.12.1       | 135.3 MB  | ####       |  41%\n",
            "nccl-2.12.12.1       | 135.3 MB  | ####9      |  50%\n",
            "nccl-2.12.12.1       | 135.3 MB  | #####8     |  59%\n",
            "nccl-2.12.12.1       | 135.3 MB  | ######7    |  68%\n",
            "nccl-2.12.12.1       | 135.3 MB  | #######6   |  77%\n",
            "nccl-2.12.12.1       | 135.3 MB  | ########5  |  85%\n",
            "nccl-2.12.12.1       | 135.3 MB  | #########3 |  94%\n",
            "nccl-2.12.12.1       | 135.3 MB  | ########## | 100%\n",
            "\n",
            "pyct-core-0.4.6      | 13 KB     |            |   0%\n",
            "pyct-core-0.4.6      | 13 KB     | ########## | 100%\n",
            "\n",
            "jbig-2.1             | 43 KB     |            |   0%\n",
            "jbig-2.1             | 43 KB     | ########## | 100%\n",
            "\n",
            "cuspatial-21.12.00   | 15.9 MB   |            |   0%\n",
            "cuspatial-21.12.00   | 15.9 MB   |            |   0%\n",
            "cuspatial-21.12.00   | 15.9 MB   |            |   0%\n",
            "cuspatial-21.12.00   | 15.9 MB   | 1          |   2%\n",
            "cuspatial-21.12.00   | 15.9 MB   | 6          |   7%\n",
            "cuspatial-21.12.00   | 15.9 MB   | ##8        |  28%\n",
            "cuspatial-21.12.00   | 15.9 MB   | #####4     |  54%\n",
            "cuspatial-21.12.00   | 15.9 MB   | ########1  |  82%\n",
            "cuspatial-21.12.00   | 15.9 MB   | ########## | 100%\n",
            "cuspatial-21.12.00   | 15.9 MB   | ########## | 100%\n",
            "\n",
            "jinja2-3.1.2         | 99 KB     |            |   0%\n",
            "jinja2-3.1.2         | 99 KB     | ########## | 100%\n",
            "\n",
            "ca-certificates-2022 | 149 KB    |            |   0%\n",
            "ca-certificates-2022 | 149 KB    | ########## | 100%\n",
            "\n",
            "libgfortran-ng-12.1. | 23 KB     |            |   0%\n",
            "libgfortran-ng-12.1. | 23 KB     | ########## | 100%\n",
            "\n",
            "parso-0.8.3          | 69 KB     |            |   0%\n",
            "parso-0.8.3          | 69 KB     | ########## | 100%\n",
            "\n",
            "libnetcdf-4.8.1      | 1.5 MB    |            |   0%\n",
            "libnetcdf-4.8.1      | 1.5 MB    | ########## | 100%\n",
            "libnetcdf-4.8.1      | 1.5 MB    | ########## | 100%\n",
            "\n",
            "flit-core-3.7.1      | 44 KB     |            |   0%\n",
            "flit-core-3.7.1      | 44 KB     | ########## | 100%\n",
            "\n",
            "libhwloc-2.3.0       | 2.7 MB    |            |   0%\n",
            "libhwloc-2.3.0       | 2.7 MB    | ########## | 100%\n",
            "libhwloc-2.3.0       | 2.7 MB    | ########## | 100%\n",
            "\n",
            "zict-2.2.0           | 20 KB     |            |   0%\n",
            "zict-2.2.0           | 20 KB     | ########## | 100%\n",
            "\n",
            "libspatialite-5.0.1  | 4.4 MB    |            |   0%\n",
            "libspatialite-5.0.1  | 4.4 MB    | ###8       |  38%\n",
            "libspatialite-5.0.1  | 4.4 MB    | #####6     |  56%\n",
            "libspatialite-5.0.1  | 4.4 MB    | #######5   |  76%\n",
            "libspatialite-5.0.1  | 4.4 MB    | #########3 |  94%\n",
            "libspatialite-5.0.1  | 4.4 MB    | ########## | 100%\n",
            "\n",
            "libsodium-1.0.18     | 366 KB    |            |   0%\n",
            "libsodium-1.0.18     | 366 KB    | ########## | 100%\n",
            "\n",
            "geopandas-0.9.0      | 5 KB      |            |   0%\n",
            "geopandas-0.9.0      | 5 KB      | ########## | 100%\n",
            "\n",
            "ipykernel-6.14.0     | 185 KB    |            |   0%\n",
            "ipykernel-6.14.0     | 185 KB    | ########## | 100%\n",
            "\n",
            "pytz-deprecation-shi | 22 KB     |            |   0%\n",
            "pytz-deprecation-shi | 22 KB     | ########## | 100%\n",
            "\n",
            "proj-8.1.0           | 2.9 MB    |            |   0%\n",
            "proj-8.1.0           | 2.9 MB    | ########## | 100%\n",
            "proj-8.1.0           | 2.9 MB    | ########## | 100%\n",
            "\n",
            "click-plugins-1.1.1  | 9 KB      |            |   0%\n",
            "click-plugins-1.1.1  | 9 KB      | ########## | 100%\n",
            "\n",
            "tzdata-2022a         | 121 KB    |            |   0%\n",
            "tzdata-2022a         | 121 KB    | ########## | 100%\n",
            "\n",
            "packaging-21.3       | 36 KB     |            |   0%\n",
            "packaging-21.3       | 36 KB     | ########## | 100%\n",
            "\n",
            "xorg-libxfixes-5.0.3 | 18 KB     |            |   0%\n",
            "xorg-libxfixes-5.0.3 | 18 KB     | ########## | 100%\n",
            "\n",
            "pooch-1.6.0          | 44 KB     |            |   0%\n",
            "pooch-1.6.0          | 44 KB     | ########## | 100%\n",
            "\n",
            "libcblas-3.9.0       | 12 KB     |            |   0%\n",
            "libcblas-3.9.0       | 12 KB     | ########## | 100%\n",
            "\n",
            "libopenblas-0.3.20   | 10.1 MB   |            |   0%\n",
            "libopenblas-0.3.20   | 10.1 MB   | ####7      |  47%\n",
            "libopenblas-0.3.20   | 10.1 MB   | ########## | 100%\n",
            "libopenblas-0.3.20   | 10.1 MB   | ########## | 100%\n",
            "\n",
            "xorg-xproto-7.0.31   | 73 KB     |            |   0%\n",
            "xorg-xproto-7.0.31   | 73 KB     | ########## | 100%\n",
            "\n",
            "threadpoolctl-3.1.0  | 18 KB     |            |   0%\n",
            "threadpoolctl-3.1.0  | 18 KB     | ########## | 100%\n",
            "\n",
            "poppler-21.09.0      | 16.8 MB   |            |   0%\n",
            "poppler-21.09.0      | 16.8 MB   | ###6       |  36%\n",
            "poppler-21.09.0      | 16.8 MB   | #####3     |  54%\n",
            "poppler-21.09.0      | 16.8 MB   | ######6    |  66%\n",
            "poppler-21.09.0      | 16.8 MB   | #######6   |  77%\n",
            "poppler-21.09.0      | 16.8 MB   | ########## | 100%\n",
            "poppler-21.09.0      | 16.8 MB   | ########## | 100%\n",
            "\n",
            "jpype1-1.4.0         | 495 KB    |            |   0%\n",
            "jpype1-1.4.0         | 495 KB    | ########## | 100%\n",
            "jpype1-1.4.0         | 495 KB    | ########## | 100%\n",
            "\n",
            "libcuspatial-21.12.0 | 6.4 MB    |            |   0%\n",
            "libcuspatial-21.12.0 | 6.4 MB    |            |   0%\n",
            "libcuspatial-21.12.0 | 6.4 MB    |            |   1%\n",
            "libcuspatial-21.12.0 | 6.4 MB    | 4          |   4%\n",
            "libcuspatial-21.12.0 | 6.4 MB    | #7         |  18%\n",
            "libcuspatial-21.12.0 | 6.4 MB    | #######2   |  73%\n",
            "libcuspatial-21.12.0 | 6.4 MB    | ########## | 100%\n",
            "libcuspatial-21.12.0 | 6.4 MB    | ########## | 100%\n",
            "\n",
            "uvicorn-0.17.6       | 78 KB     |            |   0%\n",
            "uvicorn-0.17.6       | 78 KB     | ########## | 100%\n",
            "\n",
            "partd-1.2.0          | 18 KB     |            |   0%\n",
            "partd-1.2.0          | 18 KB     | ########## | 100%\n",
            "\n",
            "hdf5-1.12.1          | 3.5 MB    |            |   0%\n",
            "hdf5-1.12.1          | 3.5 MB    | ########## | 100%\n",
            "hdf5-1.12.1          | 3.5 MB    | ########## | 100%\n",
            "\n",
            "libcuml-21.12.00     | 222.9 MB  |            |   0%\n",
            "libcuml-21.12.00     | 222.9 MB  |            |   0%\n",
            "libcuml-21.12.00     | 222.9 MB  | 2          |   2%\n",
            "libcuml-21.12.00     | 222.9 MB  | 4          |   4%\n",
            "libcuml-21.12.00     | 222.9 MB  | 6          |   7%\n",
            "libcuml-21.12.00     | 222.9 MB  | 9          |   9%\n",
            "libcuml-21.12.00     | 222.9 MB  | #1         |  11%\n",
            "libcuml-21.12.00     | 222.9 MB  | #4         |  14%\n",
            "libcuml-21.12.00     | 222.9 MB  | #6         |  16%\n",
            "libcuml-21.12.00     | 222.9 MB  | #8         |  19%\n",
            "libcuml-21.12.00     | 222.9 MB  | ##1        |  21%\n",
            "libcuml-21.12.00     | 222.9 MB  | ##3        |  24%\n",
            "libcuml-21.12.00     | 222.9 MB  | ##6        |  26%\n",
            "libcuml-21.12.00     | 222.9 MB  | ##8        |  29%\n",
            "libcuml-21.12.00     | 222.9 MB  | ###1       |  31%\n",
            "libcuml-21.12.00     | 222.9 MB  | ###3       |  34%\n",
            "libcuml-21.12.00     | 222.9 MB  | ###6       |  36%\n",
            "libcuml-21.12.00     | 222.9 MB  | ###8       |  39%\n",
            "libcuml-21.12.00     | 222.9 MB  | ####1      |  41%\n",
            "libcuml-21.12.00     | 222.9 MB  | ####3      |  43%\n",
            "libcuml-21.12.00     | 222.9 MB  | ####4      |  45%\n",
            "libcuml-21.12.00     | 222.9 MB  | ####7      |  47%\n",
            "libcuml-21.12.00     | 222.9 MB  | ####9      |  49%\n",
            "libcuml-21.12.00     | 222.9 MB  | #####1     |  51%\n",
            "libcuml-21.12.00     | 222.9 MB  | #####3     |  53%\n",
            "libcuml-21.12.00     | 222.9 MB  | #####5     |  56%\n",
            "libcuml-21.12.00     | 222.9 MB  | #####7     |  58%\n",
            "libcuml-21.12.00     | 222.9 MB  | #####9     |  60%\n",
            "libcuml-21.12.00     | 222.9 MB  | ######1    |  62%\n",
            "libcuml-21.12.00     | 222.9 MB  | ######3    |  64%\n",
            "libcuml-21.12.00     | 222.9 MB  | ######5    |  66%\n",
            "libcuml-21.12.00     | 222.9 MB  | ######8    |  68%\n",
            "libcuml-21.12.00     | 222.9 MB  | #######    |  70%\n",
            "libcuml-21.12.00     | 222.9 MB  | #######2   |  72%\n",
            "libcuml-21.12.00     | 222.9 MB  | #######4   |  74%\n",
            "libcuml-21.12.00     | 222.9 MB  | #######6   |  77%\n",
            "libcuml-21.12.00     | 222.9 MB  | #######9   |  79%\n",
            "libcuml-21.12.00     | 222.9 MB  | ########1  |  81%\n",
            "libcuml-21.12.00     | 222.9 MB  | ########3  |  83%\n",
            "libcuml-21.12.00     | 222.9 MB  | ########5  |  86%\n",
            "libcuml-21.12.00     | 222.9 MB  | ########8  |  88%\n",
            "libcuml-21.12.00     | 222.9 MB  | #########  |  90%\n",
            "libcuml-21.12.00     | 222.9 MB  | #########2 |  92%\n",
            "libcuml-21.12.00     | 222.9 MB  | #########4 |  95%\n",
            "libcuml-21.12.00     | 222.9 MB  | #########7 |  97%\n",
            "libcuml-21.12.00     | 222.9 MB  | #########9 | 100%\n",
            "libcuml-21.12.00     | 222.9 MB  | ########## | 100%\n",
            "\n",
            "pyproj-3.1.0         | 523 KB    |            |   0%\n",
            "pyproj-3.1.0         | 523 KB    | ########## | 100%\n",
            "pyproj-3.1.0         | 523 KB    | ########## | 100%\n",
            "\n",
            "gettext-0.19.8.1     | 3.6 MB    |            |   0%\n",
            "gettext-0.19.8.1     | 3.6 MB    | ########## | 100%\n",
            "gettext-0.19.8.1     | 3.6 MB    | ########## | 100%\n",
            "\n",
            "sniffio-1.2.0        | 15 KB     |            |   0%\n",
            "sniffio-1.2.0        | 15 KB     | ########## | 100%\n",
            "\n",
            "nbconvert-core-6.5.0 | 425 KB    |            |   0%\n",
            "nbconvert-core-6.5.0 | 425 KB    | ########## | 100%\n",
            "nbconvert-core-6.5.0 | 425 KB    | ########## | 100%\n",
            "\n",
            "pthread-stubs-0.4    | 5 KB      |            |   0%\n",
            "pthread-stubs-0.4    | 5 KB      | ########## | 100%\n",
            "\n",
            "python_abi-3.7       | 4 KB      |            |   0%\n",
            "python_abi-3.7       | 4 KB      | ########## | 100%\n",
            "python_abi-3.7       | 4 KB      | ########## | 100%\n",
            "\n",
            "numpy-1.21.6         | 6.1 MB    |            |   0%\n",
            "numpy-1.21.6         | 6.1 MB    | ########## | 100%\n",
            "numpy-1.21.6         | 6.1 MB    | ########## | 100%\n",
            "\n",
            "fiona-1.8.20         | 1.1 MB    |            |   0%\n",
            "fiona-1.8.20         | 1.1 MB    | ########## | 100%\n",
            "fiona-1.8.20         | 1.1 MB    | ########## | 100%\n",
            "\n",
            "blinker-1.4          | 13 KB     |            |   0%\n",
            "blinker-1.4          | 13 KB     | ########## | 100%\n",
            "\n",
            "custreamz-21.12.02   | 32 KB     |            |   0%\n",
            "custreamz-21.12.02   | 32 KB     | ####9      |  50%\n",
            "custreamz-21.12.02   | 32 KB     | ########## | 100%\n",
            "\n",
            "panel-0.12.4         | 9.8 MB    |            |   0%\n",
            "panel-0.12.4         | 9.8 MB    | ########8  |  88%\n",
            "panel-0.12.4         | 9.8 MB    | ########## | 100%\n",
            "\n",
            "soupsieve-2.3.1      | 33 KB     |            |   0%\n",
            "soupsieve-2.3.1      | 33 KB     | ########## | 100%\n",
            "\n",
            "starlette-0.19.1     | 47 KB     |            |   0%\n",
            "starlette-0.19.1     | 47 KB     | ########## | 100%\n",
            "\n",
            "pandas-1.3.5         | 12.7 MB   |            |   0%\n",
            "pandas-1.3.5         | 12.7 MB   | ###7       |  38%\n",
            "pandas-1.3.5         | 12.7 MB   | ########## | 100%\n",
            "pandas-1.3.5         | 12.7 MB   | ########## | 100%\n",
            "\n",
            "jupyter-server-proxy | 29 KB     |            |   0%\n",
            "jupyter-server-proxy | 29 KB     | ########## | 100%\n",
            "\n",
            "wcwidth-0.2.5        | 33 KB     |            |   0%\n",
            "wcwidth-0.2.5        | 33 KB     | ########## | 100%\n",
            "\n",
            "gdal-3.3.2           | 1.7 MB    |            |   0%\n",
            "gdal-3.3.2           | 1.7 MB    | ########## | 100%\n",
            "gdal-3.3.2           | 1.7 MB    | ########## | 100%\n",
            "\n",
            "libcusolver-11.3.5.5 | 89.2 MB   |            |   0%\n",
            "libcusolver-11.3.5.5 | 89.2 MB   | ########## | 100%\n",
            "libcusolver-11.3.5.5 | 89.2 MB   | ########## | 100%\n",
            "\n",
            "notebook-6.4.12      | 6.3 MB    |            |   0%\n",
            "notebook-6.4.12      | 6.3 MB    | ##3        |  24%\n",
            "notebook-6.4.12      | 6.3 MB    | ###7       |  37%\n",
            "notebook-6.4.12      | 6.3 MB    | #####      |  50%\n",
            "notebook-6.4.12      | 6.3 MB    | ######4    |  64%\n",
            "notebook-6.4.12      | 6.3 MB    | #######7   |  77%\n",
            "notebook-6.4.12      | 6.3 MB    | #########  |  91%\n",
            "notebook-6.4.12      | 6.3 MB    | ########## | 100%\n",
            "\n",
            "joblib-1.1.0         | 210 KB    |            |   0%\n",
            "joblib-1.1.0         | 210 KB    | ########## | 100%\n",
            "\n",
            "googleapis-common-pr | 122 KB    |            |   0%\n",
            "googleapis-common-pr | 122 KB    | ########## | 100%\n",
            "googleapis-common-pr | 122 KB    | ########## | 100%\n",
            "\n",
            "scikit-image-0.18.1  | 11.5 MB   |            |   0%\n",
            "scikit-image-0.18.1  | 11.5 MB   | ######5    |  65%\n",
            "scikit-image-0.18.1  | 11.5 MB   | ########## | 100%\n",
            "scikit-image-0.18.1  | 11.5 MB   | ########## | 100%\n",
            "\n",
            "setuptools-59.8.0    | 1.0 MB    |            |   0%\n",
            "setuptools-59.8.0    | 1.0 MB    | ########## | 100%\n",
            "setuptools-59.8.0    | 1.0 MB    | ########## | 100%\n",
            "\n",
            "cudf_kafka-21.12.02  | 1.8 MB    |            |   0%\n",
            "cudf_kafka-21.12.02  | 1.8 MB    |            |   1%\n",
            "cudf_kafka-21.12.02  | 1.8 MB    | 6          |   6%\n",
            "cudf_kafka-21.12.02  | 1.8 MB    | ###        |  31%\n",
            "cudf_kafka-21.12.02  | 1.8 MB    | ########## | 100%\n",
            "cudf_kafka-21.12.02  | 1.8 MB    | ########## | 100%\n",
            "\n",
            "python-confluent-kaf | 125 KB    |            |   0%\n",
            "python-confluent-kaf | 125 KB    | ########## | 100%\n",
            "\n",
            "xorg-libxrender-0.9. | 32 KB     |            |   0%\n",
            "xorg-libxrender-0.9. | 32 KB     | ########## | 100%\n",
            "\n",
            "libgsasl-1.10.0      | 179 KB    |            |   0%\n",
            "libgsasl-1.10.0      | 179 KB    | ########## | 100%\n",
            "\n",
            "tiledb-2.3.4         | 4.1 MB    |            |   0%\n",
            "tiledb-2.3.4         | 4.1 MB    | ########## | 100%\n",
            "tiledb-2.3.4         | 4.1 MB    | ########## | 100%\n",
            "\n",
            "olefile-0.46         | 32 KB     |            |   0%\n",
            "olefile-0.46         | 32 KB     | ########## | 100%\n",
            "\n",
            "libcurl-7.78.0       | 335 KB    |            |   0%\n",
            "libcurl-7.78.0       | 335 KB    | ########## | 100%\n",
            "libcurl-7.78.0       | 335 KB    | ########## | 100%\n",
            "\n",
            "bleach-5.0.1         | 124 KB    |            |   0%\n",
            "bleach-5.0.1         | 124 KB    | ########## | 100%\n",
            "\n",
            "xorg-libxext-1.3.4   | 54 KB     |            |   0%\n",
            "xorg-libxext-1.3.4   | 54 KB     | ########## | 100%\n",
            "\n",
            "google-cloud-core-2. | 27 KB     |            |   0%\n",
            "google-cloud-core-2. | 27 KB     | ########## | 100%\n",
            "\n",
            "graphite2-1.3.13     | 102 KB    |            |   0%\n",
            "graphite2-1.3.13     | 102 KB    | ########## | 100%\n",
            "\n",
            "libwebp-base-1.2.2   | 824 KB    |            |   0%\n",
            "libwebp-base-1.2.2   | 824 KB    | ########## | 100%\n",
            "libwebp-base-1.2.2   | 824 KB    | ########## | 100%\n",
            "\n",
            "rapids-xgboost-21.12 | 5 KB      |            |   0%\n",
            "rapids-xgboost-21.12 | 5 KB      | ########## | 100%\n",
            "rapids-xgboost-21.12 | 5 KB      | ########## | 100%\n",
            "\n",
            "pixman-0.40.0        | 627 KB    |            |   0%\n",
            "pixman-0.40.0        | 627 KB    | ########## | 100%\n",
            "pixman-0.40.0        | 627 KB    | ########## | 100%\n",
            "\n",
            "rsa-4.8              | 31 KB     |            |   0%\n",
            "rsa-4.8              | 31 KB     | ########## | 100%\n",
            "\n",
            "python-fastjsonschem | 243 KB    |            |   0%\n",
            "python-fastjsonschem | 243 KB    | ########## | 100%\n",
            "python-fastjsonschem | 243 KB    | ########## | 100%\n",
            "\n",
            "pyarrow-5.0.0        | 2.9 MB    |            |   0%\n",
            "pyarrow-5.0.0        | 2.9 MB    | ########## | 100%\n",
            "pyarrow-5.0.0        | 2.9 MB    | ########## | 100%\n",
            "\n",
            "argon2-cffi-bindings | 34 KB     |            |   0%\n",
            "argon2-cffi-bindings | 34 KB     | ########## | 100%\n",
            "\n",
            "readline-8.1         | 295 KB    |            |   0%\n",
            "readline-8.1         | 295 KB    | ########## | 100%\n",
            "\n",
            "pyppeteer-1.0.2      | 63 KB     |            |   0%\n",
            "pyppeteer-1.0.2      | 63 KB     | ########## | 100%\n",
            "\n",
            "aws-checksums-0.1.11 | 50 KB     |            |   0%\n",
            "aws-checksums-0.1.11 | 50 KB     | ########## | 100%\n",
            "\n",
            "toolz-0.11.2         | 48 KB     |            |   0%\n",
            "toolz-0.11.2         | 48 KB     | ########## | 100%\n",
            "\n",
            "libglib-2.68.4       | 3.0 MB    |            |   0%\n",
            "libglib-2.68.4       | 3.0 MB    | ########4  |  85%\n",
            "libglib-2.68.4       | 3.0 MB    | ########## | 100%\n",
            "\n",
            "cligj-0.7.2          | 10 KB     |            |   0%\n",
            "cligj-0.7.2          | 10 KB     | ########## | 100%\n",
            "\n",
            "msgpack-python-1.0.4 | 90 KB     |            |   0%\n",
            "msgpack-python-1.0.4 | 90 KB     | ########## | 100%\n",
            "\n",
            "aws-c-event-stream-0 | 47 KB     |            |   0%\n",
            "aws-c-event-stream-0 | 47 KB     | ########## | 100%\n",
            "\n",
            "entrypoints-0.4      | 9 KB      |            |   0%\n",
            "entrypoints-0.4      | 9 KB      | ########## | 100%\n",
            "\n",
            "libzip-1.9.2         | 97 KB     |            |   0%\n",
            "libzip-1.9.2         | 97 KB     | ########## | 100%\n",
            "\n",
            "fonts-conda-forge-1  | 4 KB      |            |   0%\n",
            "fonts-conda-forge-1  | 4 KB      | ########## | 100%\n",
            "\n",
            "streamz-0.6.3        | 61 KB     |            |   0%\n",
            "streamz-0.6.3        | 61 KB     | ########## | 100%\n",
            "\n",
            "aws-sdk-cpp-1.8.186  | 4.6 MB    |            |   0%\n",
            "aws-sdk-cpp-1.8.186  | 4.6 MB    | ########## | 100%\n",
            "aws-sdk-cpp-1.8.186  | 4.6 MB    | ########## | 100%\n",
            "\n",
            "c-blosc2-2.1.1       | 248 KB    |            |   0%\n",
            "c-blosc2-2.1.1       | 248 KB    | ########## | 100%\n",
            "\n",
            "pytz-2022.1          | 242 KB    |            |   0%\n",
            "pytz-2022.1          | 242 KB    | ########## | 100%\n",
            "pytz-2022.1          | 242 KB    | ########## | 100%\n",
            "\n",
            "imagecodecs-2021.8.2 | 7.2 MB    |            |   0%\n",
            "imagecodecs-2021.8.2 | 7.2 MB    | ###5       |  36%\n",
            "imagecodecs-2021.8.2 | 7.2 MB    | ####7      |  48%\n",
            "imagecodecs-2021.8.2 | 7.2 MB    | #####9     |  59%\n",
            "imagecodecs-2021.8.2 | 7.2 MB    | #######    |  70%\n",
            "imagecodecs-2021.8.2 | 7.2 MB    | ########1  |  82%\n",
            "imagecodecs-2021.8.2 | 7.2 MB    | #########4 |  95%\n",
            "imagecodecs-2021.8.2 | 7.2 MB    | ########## | 100%\n",
            "\n",
            "poppler-data-0.4.11  | 3.6 MB    |            |   0%\n",
            "poppler-data-0.4.11  | 3.6 MB    | #########1 |  91%\n",
            "poppler-data-0.4.11  | 3.6 MB    | ########## | 100%\n",
            "\n",
            "pandocfilters-1.5.0  | 11 KB     |            |   0%\n",
            "pandocfilters-1.5.0  | 11 KB     | ########## | 100%\n",
            "\n",
            "google-api-core-2.8. | 70 KB     |            |   0%\n",
            "google-api-core-2.8. | 70 KB     | ########## | 100%\n",
            "\n",
            "cugraph-21.12.00     | 7.2 MB    |            |   0%\n",
            "cugraph-21.12.00     | 7.2 MB    |            |   0%\n",
            "cugraph-21.12.00     | 7.2 MB    |            |   1%\n",
            "cugraph-21.12.00     | 7.2 MB    | 3          |   3%\n",
            "cugraph-21.12.00     | 7.2 MB    | #5         |  16%\n",
            "cugraph-21.12.00     | 7.2 MB    | ###9       |  40%\n",
            "cugraph-21.12.00     | 7.2 MB    | ########## | 100%\n",
            "cugraph-21.12.00     | 7.2 MB    | ########## | 100%\n",
            "\n",
            "multidict-6.0.2      | 49 KB     |            |   0%\n",
            "multidict-6.0.2      | 49 KB     | ########## | 100%\n",
            "\n",
            "tblib-1.7.0          | 15 KB     |            |   0%\n",
            "tblib-1.7.0          | 15 KB     | ########## | 100%\n",
            "\n",
            "send2trash-1.8.0     | 17 KB     |            |   0%\n",
            "send2trash-1.8.0     | 17 KB     | ########## | 100%\n",
            "\n",
            "ptxcompiler-0.2.0    | 5.6 MB    |            |   0%\n",
            "ptxcompiler-0.2.0    | 5.6 MB    |            |   0%\n",
            "ptxcompiler-0.2.0    | 5.6 MB    | #######8   |  79%\n",
            "ptxcompiler-0.2.0    | 5.6 MB    | ########## | 100%\n",
            "ptxcompiler-0.2.0    | 5.6 MB    | ########## | 100%\n",
            "\n",
            "backcall-0.2.0       | 13 KB     |            |   0%\n",
            "backcall-0.2.0       | 13 KB     | ########## | 100%\n",
            "\n",
            "ucx-1.11.2+gef2bbcf  | 11.9 MB   |            |   0%\n",
            "ucx-1.11.2+gef2bbcf  | 11.9 MB   |            |   0%\n",
            "ucx-1.11.2+gef2bbcf  | 11.9 MB   | #9         |  20%\n",
            "ucx-1.11.2+gef2bbcf  | 11.9 MB   | #####1     |  51%\n",
            "ucx-1.11.2+gef2bbcf  | 11.9 MB   | ########5  |  86%\n",
            "ucx-1.11.2+gef2bbcf  | 11.9 MB   | ########## | 100%\n",
            "\n",
            "libxml2-2.9.12       | 772 KB    |            |   0%\n",
            "libxml2-2.9.12       | 772 KB    | ########## | 100%\n",
            "libxml2-2.9.12       | 772 KB    | ########## | 100%\n",
            "\n",
            "ipython_genutils-0.2 | 21 KB     |            |   0%\n",
            "ipython_genutils-0.2 | 21 KB     | ########## | 100%\n",
            "\n",
            "nest-asyncio-1.5.5   | 9 KB      |            |   0%\n",
            "nest-asyncio-1.5.5   | 9 KB      | ########## | 100%\n",
            "\n",
            "libcumlprims-21.12.0 | 3.7 MB    |            |   0%\n",
            "libcumlprims-21.12.0 | 3.7 MB    | ########## | 100%\n",
            "libcumlprims-21.12.0 | 3.7 MB    | ########## | 100%\n",
            "\n",
            "libbrotlicommon-1.0. | 65 KB     |            |   0%\n",
            "libbrotlicommon-1.0. | 65 KB     | ########## | 100%\n",
            "\n",
            "boost-1.74.0         | 342 KB    |            |   0%\n",
            "boost-1.74.0         | 342 KB    | ########## | 100%\n",
            "boost-1.74.0         | 342 KB    | ########## | 100%\n",
            "\n",
            "dlpack-0.5           | 12 KB     |            |   0%\n",
            "dlpack-0.5           | 12 KB     | ########## | 100%\n",
            "\n",
            "argon2-cffi-21.3.0   | 15 KB     |            |   0%\n",
            "argon2-cffi-21.3.0   | 15 KB     | ########## | 100%\n",
            "\n",
            "libcugraph-21.12.00  | 259.4 MB  |            |   0%\n",
            "libcugraph-21.12.00  | 259.4 MB  |            |   0%\n",
            "libcugraph-21.12.00  | 259.4 MB  | 2          |   2%\n",
            "libcugraph-21.12.00  | 259.4 MB  | 3          |   4%\n",
            "libcugraph-21.12.00  | 259.4 MB  | 6          |   6%\n",
            "libcugraph-21.12.00  | 259.4 MB  | 8          |   8%\n",
            "libcugraph-21.12.00  | 259.4 MB  | #          |  10%\n",
            "libcugraph-21.12.00  | 259.4 MB  | #2         |  12%\n",
            "libcugraph-21.12.00  | 259.4 MB  | #4         |  14%\n",
            "libcugraph-21.12.00  | 259.4 MB  | #6         |  16%\n",
            "libcugraph-21.12.00  | 259.4 MB  | #8         |  18%\n",
            "libcugraph-21.12.00  | 259.4 MB  | ##         |  20%\n",
            "libcugraph-21.12.00  | 259.4 MB  | ##1        |  22%\n",
            "libcugraph-21.12.00  | 259.4 MB  | ##3        |  23%\n",
            "libcugraph-21.12.00  | 259.4 MB  | ##5        |  25%\n",
            "libcugraph-21.12.00  | 259.4 MB  | ##6        |  27%\n",
            "libcugraph-21.12.00  | 259.4 MB  | ##8        |  29%\n",
            "libcugraph-21.12.00  | 259.4 MB  | ###        |  31%\n",
            "libcugraph-21.12.00  | 259.4 MB  | ###2       |  32%\n",
            "libcugraph-21.12.00  | 259.4 MB  | ###4       |  34%\n",
            "libcugraph-21.12.00  | 259.4 MB  | ###6       |  36%\n",
            "libcugraph-21.12.00  | 259.4 MB  | ###8       |  38%\n",
            "libcugraph-21.12.00  | 259.4 MB  | ####       |  40%\n",
            "libcugraph-21.12.00  | 259.4 MB  | ####1      |  42%\n",
            "libcugraph-21.12.00  | 259.4 MB  | ####3      |  44%\n",
            "libcugraph-21.12.00  | 259.4 MB  | ####5      |  46%\n",
            "libcugraph-21.12.00  | 259.4 MB  | ####7      |  48%\n",
            "libcugraph-21.12.00  | 259.4 MB  | ####9      |  50%\n",
            "libcugraph-21.12.00  | 259.4 MB  | #####1     |  52%\n",
            "libcugraph-21.12.00  | 259.4 MB  | #####3     |  54%\n",
            "libcugraph-21.12.00  | 259.4 MB  | #####5     |  56%\n",
            "libcugraph-21.12.00  | 259.4 MB  | #####7     |  58%\n",
            "libcugraph-21.12.00  | 259.4 MB  | #####9     |  60%\n",
            "libcugraph-21.12.00  | 259.4 MB  | ######1    |  62%\n",
            "libcugraph-21.12.00  | 259.4 MB  | ######3    |  64%\n",
            "libcugraph-21.12.00  | 259.4 MB  | ######5    |  66%\n",
            "libcugraph-21.12.00  | 259.4 MB  | ######7    |  68%\n",
            "libcugraph-21.12.00  | 259.4 MB  | ######9    |  70%\n",
            "libcugraph-21.12.00  | 259.4 MB  | #######1   |  72%\n",
            "libcugraph-21.12.00  | 259.4 MB  | #######3   |  74%\n",
            "libcugraph-21.12.00  | 259.4 MB  | #######5   |  76%\n",
            "libcugraph-21.12.00  | 259.4 MB  | #######7   |  78%\n",
            "libcugraph-21.12.00  | 259.4 MB  | #######9   |  80%\n",
            "libcugraph-21.12.00  | 259.4 MB  | ########1  |  82%\n",
            "libcugraph-21.12.00  | 259.4 MB  | ########3  |  84%\n",
            "libcugraph-21.12.00  | 259.4 MB  | ########5  |  86%\n",
            "libcugraph-21.12.00  | 259.4 MB  | ########7  |  88%\n",
            "libcugraph-21.12.00  | 259.4 MB  | ########9  |  90%\n",
            "libcugraph-21.12.00  | 259.4 MB  | #########1 |  92%\n",
            "libcugraph-21.12.00  | 259.4 MB  | #########3 |  94%\n",
            "libcugraph-21.12.00  | 259.4 MB  | #########5 |  96%\n",
            "libcugraph-21.12.00  | 259.4 MB  | #########7 |  98%\n",
            "libcugraph-21.12.00  | 259.4 MB  | #########9 | 100%\n",
            "libcugraph-21.12.00  | 259.4 MB  | ########## | 100%\n",
            "\n",
            "nbconvert-pandoc-6.5 | 4 KB      |            |   0%\n",
            "nbconvert-pandoc-6.5 | 4 KB      | ########## | 100%\n",
            "\n",
            "fonts-conda-ecosyste | 4 KB      |            |   0%\n",
            "fonts-conda-ecosyste | 4 KB      | ########## | 100%\n",
            "\n",
            "blosc-1.21.1         | 47 KB     |            |   0%\n",
            "blosc-1.21.1         | 47 KB     | ########## | 100%\n",
            "\n",
            "libdeflate-1.8       | 67 KB     |            |   0%\n",
            "libdeflate-1.8       | 67 KB     | ########## | 100%\n",
            "\n",
            "defusedxml-0.7.1     | 23 KB     |            |   0%\n",
            "defusedxml-0.7.1     | 23 KB     | ########## | 100%\n",
            "\n",
            "websocket-client-1.3 | 41 KB     |            |   0%\n",
            "websocket-client-1.3 | 41 KB     | ########## | 100%\n",
            "\n",
            "dask-core-2021.11.2  | 783 KB    |            |   0%\n",
            "dask-core-2021.11.2  | 783 KB    | ########## | 100%\n",
            "dask-core-2021.11.2  | 783 KB    | ########## | 100%\n",
            "\n",
            "libcudf_kafka-21.12. | 126 KB    |            |   0%\n",
            "libcudf_kafka-21.12. | 126 KB    | #2         |  13%\n",
            "libcudf_kafka-21.12. | 126 KB    | ########## | 100%\n",
            "libcudf_kafka-21.12. | 126 KB    | ########## | 100%\n",
            "\n",
            "charset-normalizer-2 | 35 KB     |            |   0%\n",
            "charset-normalizer-2 | 35 KB     | ########## | 100%\n",
            "\n",
            "libcrc32c-1.1.2      | 20 KB     |            |   0%\n",
            "libcrc32c-1.1.2      | 20 KB     | ########## | 100%\n",
            "\n",
            "pyparsing-3.0.9      | 79 KB     |            |   0%\n",
            "pyparsing-3.0.9      | 79 KB     | ########## | 100%\n",
            "\n",
            "pyyaml-6.0           | 178 KB    |            |   0%\n",
            "pyyaml-6.0           | 178 KB    | ########## | 100%\n",
            "\n",
            "gflags-2.2.2         | 114 KB    |            |   0%\n",
            "gflags-2.2.2         | 114 KB    | ########## | 100%\n",
            "\n",
            "dask-sql-2022.1.0    | 19.7 MB   |            |   0%\n",
            "dask-sql-2022.1.0    | 19.7 MB   | ##5        |  26%\n",
            "dask-sql-2022.1.0    | 19.7 MB   | ######1    |  62%\n",
            "dask-sql-2022.1.0    | 19.7 MB   | #########1 |  91%\n",
            "dask-sql-2022.1.0    | 19.7 MB   | ########## | 100%\n",
            "\n",
            "abseil-cpp-20210324. | 1010 KB   |            |   0%\n",
            "abseil-cpp-20210324. | 1010 KB   | ########## | 100%\n",
            "abseil-cpp-20210324. | 1010 KB   | ########## | 100%\n",
            "\n",
            "pyzmq-23.2.0         | 474 KB    |            |   0%\n",
            "pyzmq-23.2.0         | 474 KB    | ########## | 100%\n",
            "pyzmq-23.2.0         | 474 KB    | ########## | 100%\n",
            "\n",
            "xorg-libx11-1.7.2    | 941 KB    |            |   0%\n",
            "xorg-libx11-1.7.2    | 941 KB    | ########## | 100%\n",
            "xorg-libx11-1.7.2    | 941 KB    | ########## | 100%\n",
            "\n",
            "xorg-xextproto-7.3.0 | 28 KB     |            |   0%\n",
            "xorg-xextproto-7.3.0 | 28 KB     | ########## | 100%\n",
            "\n",
            "xorg-kbproto-1.0.7   | 27 KB     |            |   0%\n",
            "xorg-kbproto-1.0.7   | 27 KB     | ########## | 100%\n",
            "\n",
            "cairo-1.16.0         | 1.5 MB    |            |   0%\n",
            "cairo-1.16.0         | 1.5 MB    | ########## | 100%\n",
            "cairo-1.16.0         | 1.5 MB    | ########## | 100%\n",
            "\n",
            "cusignal-21.12.00    | 1.1 MB    |            |   0%\n",
            "cusignal-21.12.00    | 1.1 MB    | 1          |   1%\n",
            "cusignal-21.12.00    | 1.1 MB    | ###2       |  33%\n",
            "cusignal-21.12.00    | 1.1 MB    | ########## | 100%\n",
            "cusignal-21.12.00    | 1.1 MB    | ########## | 100%\n",
            "\n",
            "fastapi-0.78.0       | 44 KB     |            |   0%\n",
            "fastapi-0.78.0       | 44 KB     | ########## | 100%\n",
            "\n",
            "bokeh-2.4.0          | 13.5 MB   |            |   0%\n",
            "bokeh-2.4.0          | 13.5 MB   | ####4      |  45%\n",
            "bokeh-2.4.0          | 13.5 MB   | #######    |  71%\n",
            "bokeh-2.4.0          | 13.5 MB   | ########7  |  88%\n",
            "bokeh-2.4.0          | 13.5 MB   | ########## | 100%\n",
            "\n",
            "freexl-1.0.6         | 48 KB     |            |   0%\n",
            "freexl-1.0.6         | 48 KB     | ########## | 100%\n",
            "freexl-1.0.6         | 48 KB     | ########## | 100%\n",
            "\n",
            "markupsafe-2.1.1     | 22 KB     |            |   0%\n",
            "markupsafe-2.1.1     | 22 KB     | ########## | 100%\n",
            "\n",
            "xorg-libsm-1.2.3     | 26 KB     |            |   0%\n",
            "xorg-libsm-1.2.3     | 26 KB     | ########## | 100%\n",
            "\n",
            "aws-c-common-0.6.2   | 168 KB    |            |   0%\n",
            "aws-c-common-0.6.2   | 168 KB    | ########## | 100%\n",
            "\n",
            "geos-3.9.1           | 1.1 MB    |            |   0%\n",
            "geos-3.9.1           | 1.1 MB    | ########## | 100%\n",
            "geos-3.9.1           | 1.1 MB    | ########## | 100%\n",
            "\n",
            "libbrotlidec-1.0.9   | 33 KB     |            |   0%\n",
            "libbrotlidec-1.0.9   | 33 KB     | ########## | 100%\n",
            "\n",
            "webencodings-0.5.1   | 12 KB     |            |   0%\n",
            "webencodings-0.5.1   | 12 KB     | ########## | 100%\n",
            "\n",
            "asgiref-3.5.2        | 22 KB     |            |   0%\n",
            "asgiref-3.5.2        | 22 KB     | ########## | 100%\n",
            "\n",
            "conda-4.12.0         | 1.0 MB    |            |   0%\n",
            "conda-4.12.0         | 1.0 MB    | ########## | 100%\n",
            "conda-4.12.0         | 1.0 MB    | ########## | 100%\n",
            "\n",
            "expat-2.4.8          | 187 KB    |            |   0%\n",
            "expat-2.4.8          | 187 KB    | ########## | 100%\n",
            "\n",
            "json-c-0.15          | 274 KB    |            |   0%\n",
            "json-c-0.15          | 274 KB    | ########## | 100%\n",
            "\n",
            "xorg-libice-1.0.10   | 58 KB     |            |   0%\n",
            "xorg-libice-1.0.10   | 58 KB     | ########## | 100%\n",
            "\n",
            "cloudpickle-2.1.0    | 25 KB     |            |   0%\n",
            "cloudpickle-2.1.0    | 25 KB     | ########## | 100%\n",
            "\n",
            "s2n-1.0.10           | 442 KB    |            |   0%\n",
            "s2n-1.0.10           | 442 KB    | ########## | 100%\n",
            "s2n-1.0.10           | 442 KB    | ########## | 100%\n",
            "\n",
            "xorg-inputproto-2.3. | 19 KB     |            |   0%\n",
            "xorg-inputproto-2.3. | 19 KB     | ########## | 100%\n",
            "\n",
            "libzopfli-1.0.3      | 164 KB    |            |   0%\n",
            "libzopfli-1.0.3      | 164 KB    | ########## | 100%\n",
            "\n",
            "ipywidgets-7.7.1     | 103 KB    |            |   0%\n",
            "ipywidgets-7.7.1     | 103 KB    | ########## | 100%\n",
            "\n",
            "cachetools-5.0.0     | 12 KB     |            |   0%\n",
            "cachetools-5.0.0     | 12 KB     | ########## | 100%\n",
            "\n",
            "cuml-21.12.00        | 9.4 MB    |            |   0%\n",
            "cuml-21.12.00        | 9.4 MB    |            |   0%\n",
            "cuml-21.12.00        | 9.4 MB    | ##8        |  28%\n",
            "cuml-21.12.00        | 9.4 MB    | #######4   |  75%\n",
            "cuml-21.12.00        | 9.4 MB    | ########## | 100%\n",
            "cuml-21.12.00        | 9.4 MB    | ########## | 100%\n",
            "\n",
            "librmm-21.12.00      | 688 KB    |            |   0%\n",
            "librmm-21.12.00      | 688 KB    | 2          |   2%\n",
            "librmm-21.12.00      | 688 KB    | ########## | 100%\n",
            "librmm-21.12.00      | 688 KB    | ########## | 100%\n",
            "\n",
            "matplotlib-inline-0. | 11 KB     |            |   0%\n",
            "matplotlib-inline-0. | 11 KB     | ########## | 100%\n",
            "\n",
            "distributed-2021.11. | 1.1 MB    |            |   0%\n",
            "distributed-2021.11. | 1.1 MB    | ########## | 100%\n",
            "distributed-2021.11. | 1.1 MB    | ########## | 100%\n",
            "\n",
            "cucim-21.12.00       | 3.2 MB    |            |   0%\n",
            "cucim-21.12.00       | 3.2 MB    |            |   0%\n",
            "cucim-21.12.00       | 3.2 MB    | ######4    |  65%\n",
            "cucim-21.12.00       | 3.2 MB    | ########## | 100%\n",
            "cucim-21.12.00       | 3.2 MB    | ########## | 100%\n",
            "\n",
            "freetype-2.10.4      | 890 KB    |            |   0%\n",
            "freetype-2.10.4      | 890 KB    | ########## | 100%\n",
            "freetype-2.10.4      | 890 KB    | ########## | 100%\n",
            "\n",
            "krb5-1.19.3          | 1.4 MB    |            |   0%\n",
            "krb5-1.19.3          | 1.4 MB    | 1          |   1%\n",
            "krb5-1.19.3          | 1.4 MB    | ########## | 100%\n",
            "krb5-1.19.3          | 1.4 MB    | ########## | 100%\n",
            "\n",
            "xorg-libxi-1.7.10    | 46 KB     |            |   0%\n",
            "xorg-libxi-1.7.10    | 46 KB     | ########## | 100%\n",
            "\n",
            "grpcio-1.38.1        | 2.2 MB    |            |   0%\n",
            "grpcio-1.38.1        | 2.2 MB    | ########## | 100%\n",
            "grpcio-1.38.1        | 2.2 MB    | ########## | 100%\n",
            "\n",
            "markdown-3.3.7       | 67 KB     |            |   0%\n",
            "markdown-3.3.7       | 67 KB     | ########## | 100%\n",
            "\n",
            "charls-2.2.0         | 138 KB    |            |   0%\n",
            "charls-2.2.0         | 138 KB    | ########## | 100%\n",
            "\n",
            "libutf8proc-2.7.0    | 98 KB     |            |   0%\n",
            "libutf8proc-2.7.0    | 98 KB     | ########## | 100%\n",
            "\n",
            "dask-cuda-21.12.00   | 123 KB    |            |   0%\n",
            "dask-cuda-21.12.00   | 123 KB    | #2         |  13%\n",
            "dask-cuda-21.12.00   | 123 KB    | ########## | 100%\n",
            "\n",
            "libxcb-1.13          | 391 KB    |            |   0%\n",
            "libxcb-1.13          | 391 KB    | ########## | 100%\n",
            "libxcb-1.13          | 391 KB    | ########## | 100%\n",
            "\n",
            "libdap4-3.20.6       | 11.3 MB   |            |   0%\n",
            "libdap4-3.20.6       | 11.3 MB   | #####8     |  59%\n",
            "libdap4-3.20.6       | 11.3 MB   | ########## | 100%\n",
            "libdap4-3.20.6       | 11.3 MB   | ########## | 100%\n",
            "\n",
            "pyct-0.4.6           | 3 KB      |            |   0%\n",
            "pyct-0.4.6           | 3 KB      | ########## | 100%\n",
            "\n",
            "arrow-cpp-5.0.0      | 23.3 MB   |            |   0%\n",
            "arrow-cpp-5.0.0      | 23.3 MB   | ##2        |  23%\n",
            "arrow-cpp-5.0.0      | 23.3 MB   | ##9        |  29%\n",
            "arrow-cpp-5.0.0      | 23.3 MB   | ###5       |  35%\n",
            "arrow-cpp-5.0.0      | 23.3 MB   | ####       |  40%\n",
            "arrow-cpp-5.0.0      | 23.3 MB   | ####5      |  45%\n",
            "arrow-cpp-5.0.0      | 23.3 MB   | ####9      |  49%\n",
            "arrow-cpp-5.0.0      | 23.3 MB   | #####3     |  54%\n",
            "arrow-cpp-5.0.0      | 23.3 MB   | #####7     |  58%\n",
            "arrow-cpp-5.0.0      | 23.3 MB   | ######1    |  61%\n",
            "arrow-cpp-5.0.0      | 23.3 MB   | ######5    |  65%\n",
            "arrow-cpp-5.0.0      | 23.3 MB   | ######8    |  69%\n",
            "arrow-cpp-5.0.0      | 23.3 MB   | #######2   |  72%\n",
            "arrow-cpp-5.0.0      | 23.3 MB   | #######6   |  76%\n",
            "arrow-cpp-5.0.0      | 23.3 MB   | ########5  |  86%\n",
            "arrow-cpp-5.0.0      | 23.3 MB   | ########## | 100%\n",
            "arrow-cpp-5.0.0      | 23.3 MB   | ########## | 100%\n",
            "\n",
            "treelite-2.1.0       | 1.4 MB    |            |   0%\n",
            "treelite-2.1.0       | 1.4 MB    | ########## | 100%\n",
            "treelite-2.1.0       | 1.4 MB    | ########## | 100%\n",
            "\n",
            "scipy-1.7.3          | 21.8 MB   |            |   0%\n",
            "scipy-1.7.3          | 21.8 MB   | #7         |  18%\n",
            "scipy-1.7.3          | 21.8 MB   | ##3        |  23%\n",
            "scipy-1.7.3          | 21.8 MB   | ##7        |  28%\n",
            "scipy-1.7.3          | 21.8 MB   | ###2       |  32%\n",
            "scipy-1.7.3          | 21.8 MB   | ###6       |  37%\n",
            "scipy-1.7.3          | 21.8 MB   | ####       |  41%\n",
            "scipy-1.7.3          | 21.8 MB   | ####4      |  45%\n",
            "scipy-1.7.3          | 21.8 MB   | ####8      |  49%\n",
            "scipy-1.7.3          | 21.8 MB   | #####2     |  52%\n",
            "scipy-1.7.3          | 21.8 MB   | #####6     |  56%\n",
            "scipy-1.7.3          | 21.8 MB   | ######     |  60%\n",
            "scipy-1.7.3          | 21.8 MB   | ######4    |  64%\n",
            "scipy-1.7.3          | 21.8 MB   | ######8    |  68%\n",
            "scipy-1.7.3          | 21.8 MB   | #######1   |  72%\n",
            "scipy-1.7.3          | 21.8 MB   | #######6   |  76%\n",
            "scipy-1.7.3          | 21.8 MB   | ########3  |  83%\n",
            "scipy-1.7.3          | 21.8 MB   | ########## | 100%\n",
            "scipy-1.7.3          | 21.8 MB   | ########## | 100%\n",
            "\n",
            "numba-0.55.2         | 3.8 MB    |            |   0%\n",
            "numba-0.55.2         | 3.8 MB    | ########## | 100%\n",
            "numba-0.55.2         | 3.8 MB    | ########## | 100%\n",
            "\n",
            "lerc-3.0             | 216 KB    |            |   0%\n",
            "lerc-3.0             | 216 KB    | ########## | 100%\n",
            "\n",
            "jupyter_server-1.18. | 241 KB    |            |   0%\n",
            "jupyter_server-1.18. | 241 KB    | ########## | 100%\n",
            "\n",
            "mapclassify-2.4.3    | 36 KB     |            |   0%\n",
            "mapclassify-2.4.3    | 36 KB     | ########## | 100%\n",
            "\n",
            "gcsfs-2022.5.0       | 25 KB     |            |   0%\n",
            "gcsfs-2022.5.0       | 25 KB     | ########## | 100%\n",
            "\n",
            "debugpy-1.6.0        | 2.0 MB    |            |   0%\n",
            "debugpy-1.6.0        | 2.0 MB    | ########## | 100%\n",
            "debugpy-1.6.0        | 2.0 MB    | ########## | 100%\n",
            "\n",
            "libxgboost-1.5.0dev. | 128.2 MB  |            |   0%\n",
            "libxgboost-1.5.0dev. | 128.2 MB  |            |   0%\n",
            "libxgboost-1.5.0dev. | 128.2 MB  |            |   0%\n",
            "libxgboost-1.5.0dev. | 128.2 MB  |            |   0%\n",
            "libxgboost-1.5.0dev. | 128.2 MB  | 1          |   2%\n",
            "libxgboost-1.5.0dev. | 128.2 MB  | 4          |   5%\n",
            "libxgboost-1.5.0dev. | 128.2 MB  | 8          |   8%\n",
            "libxgboost-1.5.0dev. | 128.2 MB  | #1         |  11%\n",
            "libxgboost-1.5.0dev. | 128.2 MB  | #4         |  14%\n",
            "libxgboost-1.5.0dev. | 128.2 MB  | #7         |  18%\n",
            "libxgboost-1.5.0dev. | 128.2 MB  | ##         |  21%\n",
            "libxgboost-1.5.0dev. | 128.2 MB  | ##3        |  24%\n",
            "libxgboost-1.5.0dev. | 128.2 MB  | ##6        |  27%\n",
            "libxgboost-1.5.0dev. | 128.2 MB  | ##9        |  29%\n",
            "libxgboost-1.5.0dev. | 128.2 MB  | ###2       |  33%\n",
            "libxgboost-1.5.0dev. | 128.2 MB  | ###5       |  35%\n",
            "libxgboost-1.5.0dev. | 128.2 MB  | ###8       |  39%\n",
            "libxgboost-1.5.0dev. | 128.2 MB  | ####2      |  42%\n",
            "libxgboost-1.5.0dev. | 128.2 MB  | ####4      |  44%\n",
            "libxgboost-1.5.0dev. | 128.2 MB  | ####6      |  46%\n",
            "libxgboost-1.5.0dev. | 128.2 MB  | ####7      |  48%\n",
            "libxgboost-1.5.0dev. | 128.2 MB  | ####9      |  49%\n",
            "libxgboost-1.5.0dev. | 128.2 MB  | #####2     |  52%\n",
            "libxgboost-1.5.0dev. | 128.2 MB  | #####4     |  54%\n",
            "libxgboost-1.5.0dev. | 128.2 MB  | #####6     |  56%\n",
            "libxgboost-1.5.0dev. | 128.2 MB  | #####9     |  60%\n",
            "libxgboost-1.5.0dev. | 128.2 MB  | ######3    |  64%\n",
            "libxgboost-1.5.0dev. | 128.2 MB  | ######7    |  67%\n",
            "libxgboost-1.5.0dev. | 128.2 MB  | #######1   |  71%\n",
            "libxgboost-1.5.0dev. | 128.2 MB  | #######4   |  75%\n",
            "libxgboost-1.5.0dev. | 128.2 MB  | #######8   |  79%\n",
            "libxgboost-1.5.0dev. | 128.2 MB  | ########2  |  83%\n",
            "libxgboost-1.5.0dev. | 128.2 MB  | ########6  |  87%\n",
            "libxgboost-1.5.0dev. | 128.2 MB  | #########1 |  91%\n",
            "libxgboost-1.5.0dev. | 128.2 MB  | #########5 |  95%\n",
            "libxgboost-1.5.0dev. | 128.2 MB  | #########9 |  99%\n",
            "libxgboost-1.5.0dev. | 128.2 MB  | ########## | 100%\n",
            "\n",
            "openjpeg-2.4.0       | 444 KB    |            |   0%\n",
            "openjpeg-2.4.0       | 444 KB    | ########## | 100%\n",
            "openjpeg-2.4.0       | 444 KB    | ########## | 100%\n",
            "\n",
            "nodejs-14.17.4       | 15.8 MB   |            |   0%\n",
            "nodejs-14.17.4       | 15.8 MB   | #####3     |  53%\n",
            "nodejs-14.17.4       | 15.8 MB   | ########   |  80%\n",
            "nodejs-14.17.4       | 15.8 MB   | #########9 |  99%\n",
            "nodejs-14.17.4       | 15.8 MB   | ########## | 100%\n",
            "\n",
            "oauthlib-3.2.0       | 90 KB     |            |   0%\n",
            "oauthlib-3.2.0       | 90 KB     | ########## | 100%\n",
            "\n",
            "pyasn1-0.4.8         | 53 KB     |            |   0%\n",
            "pyasn1-0.4.8         | 53 KB     | ########## | 100%\n",
            "\n",
            "asynctest-0.13.0     | 24 KB     |            |   0%\n",
            "asynctest-0.13.0     | 24 KB     | ########## | 100%\n",
            "\n",
            "libcudf-21.12.02     | 288.2 MB  |            |   0%\n",
            "libcudf-21.12.02     | 288.2 MB  |            |   0%\n",
            "libcudf-21.12.02     | 288.2 MB  |            |   0%\n",
            "libcudf-21.12.02     | 288.2 MB  |            |   0%\n",
            "libcudf-21.12.02     | 288.2 MB  |            |   1%\n",
            "libcudf-21.12.02     | 288.2 MB  | 1          |   2%\n",
            "libcudf-21.12.02     | 288.2 MB  | 3          |   3%\n",
            "libcudf-21.12.02     | 288.2 MB  | 4          |   5%\n",
            "libcudf-21.12.02     | 288.2 MB  | 6          |   6%\n",
            "libcudf-21.12.02     | 288.2 MB  | 7          |   8%\n",
            "libcudf-21.12.02     | 288.2 MB  | 8          |   9%\n",
            "libcudf-21.12.02     | 288.2 MB  | #          |  10%\n",
            "libcudf-21.12.02     | 288.2 MB  | #1         |  12%\n",
            "libcudf-21.12.02     | 288.2 MB  | #3         |  13%\n",
            "libcudf-21.12.02     | 288.2 MB  | #4         |  15%\n",
            "libcudf-21.12.02     | 288.2 MB  | #6         |  16%\n",
            "libcudf-21.12.02     | 288.2 MB  | #7         |  18%\n",
            "libcudf-21.12.02     | 288.2 MB  | #9         |  19%\n",
            "libcudf-21.12.02     | 288.2 MB  | ##         |  21%\n",
            "libcudf-21.12.02     | 288.2 MB  | ##2        |  22%\n",
            "libcudf-21.12.02     | 288.2 MB  | ##3        |  23%\n",
            "libcudf-21.12.02     | 288.2 MB  | ##4        |  25%\n",
            "libcudf-21.12.02     | 288.2 MB  | ##6        |  26%\n",
            "libcudf-21.12.02     | 288.2 MB  | ##7        |  28%\n",
            "libcudf-21.12.02     | 288.2 MB  | ##9        |  29%\n",
            "libcudf-21.12.02     | 288.2 MB  | ###        |  31%\n",
            "libcudf-21.12.02     | 288.2 MB  | ###1       |  32%\n",
            "libcudf-21.12.02     | 288.2 MB  | ###3       |  33%\n",
            "libcudf-21.12.02     | 288.2 MB  | ###4       |  35%\n",
            "libcudf-21.12.02     | 288.2 MB  | ###6       |  36%\n",
            "libcudf-21.12.02     | 288.2 MB  | ###7       |  38%\n",
            "libcudf-21.12.02     | 288.2 MB  | ###8       |  39%\n",
            "libcudf-21.12.02     | 288.2 MB  | ####       |  40%\n",
            "libcudf-21.12.02     | 288.2 MB  | ####1      |  42%\n",
            "libcudf-21.12.02     | 288.2 MB  | ####3      |  43%\n",
            "libcudf-21.12.02     | 288.2 MB  | ####4      |  45%\n",
            "libcudf-21.12.02     | 288.2 MB  | ####6      |  46%\n",
            "libcudf-21.12.02     | 288.2 MB  | ####7      |  47%\n",
            "libcudf-21.12.02     | 288.2 MB  | ####8      |  49%\n",
            "libcudf-21.12.02     | 288.2 MB  | #####      |  50%\n",
            "libcudf-21.12.02     | 288.2 MB  | #####1     |  52%\n",
            "libcudf-21.12.02     | 288.2 MB  | #####3     |  53%\n",
            "libcudf-21.12.02     | 288.2 MB  | #####4     |  55%\n",
            "libcudf-21.12.02     | 288.2 MB  | #####5     |  56%\n",
            "libcudf-21.12.02     | 288.2 MB  | #####7     |  57%\n",
            "libcudf-21.12.02     | 288.2 MB  | #####8     |  59%\n",
            "libcudf-21.12.02     | 288.2 MB  | ######     |  60%\n",
            "libcudf-21.12.02     | 288.2 MB  | ######1    |  62%\n",
            "libcudf-21.12.02     | 288.2 MB  | ######2    |  63%\n",
            "libcudf-21.12.02     | 288.2 MB  | ######4    |  64%\n",
            "libcudf-21.12.02     | 288.2 MB  | ######5    |  66%\n",
            "libcudf-21.12.02     | 288.2 MB  | ######7    |  67%\n",
            "libcudf-21.12.02     | 288.2 MB  | ######8    |  69%\n",
            "libcudf-21.12.02     | 288.2 MB  | ######9    |  70%\n",
            "libcudf-21.12.02     | 288.2 MB  | #######1   |  71%\n",
            "libcudf-21.12.02     | 288.2 MB  | #######2   |  73%\n",
            "libcudf-21.12.02     | 288.2 MB  | #######4   |  74%\n",
            "libcudf-21.12.02     | 288.2 MB  | #######5   |  76%\n",
            "libcudf-21.12.02     | 288.2 MB  | #######7   |  77%\n",
            "libcudf-21.12.02     | 288.2 MB  | #######8   |  78%\n",
            "libcudf-21.12.02     | 288.2 MB  | #######9   |  80%\n",
            "libcudf-21.12.02     | 288.2 MB  | ########1  |  81%\n",
            "libcudf-21.12.02     | 288.2 MB  | ########2  |  83%\n",
            "libcudf-21.12.02     | 288.2 MB  | ########4  |  84%\n",
            "libcudf-21.12.02     | 288.2 MB  | ########5  |  85%\n",
            "libcudf-21.12.02     | 288.2 MB  | ########6  |  87%\n",
            "libcudf-21.12.02     | 288.2 MB  | ########8  |  88%\n",
            "libcudf-21.12.02     | 288.2 MB  | ########9  |  90%\n",
            "libcudf-21.12.02     | 288.2 MB  | #########1 |  91%\n",
            "libcudf-21.12.02     | 288.2 MB  | #########2 |  93%\n",
            "libcudf-21.12.02     | 288.2 MB  | #########3 |  94%\n",
            "libcudf-21.12.02     | 288.2 MB  | #########5 |  95%\n",
            "libcudf-21.12.02     | 288.2 MB  | #########6 |  97%\n",
            "libcudf-21.12.02     | 288.2 MB  | #########8 |  98%\n",
            "libcudf-21.12.02     | 288.2 MB  | #########9 | 100%\n",
            "libcudf-21.12.02     | 288.2 MB  | ########## | 100%\n",
            "\n",
            "hdf4-4.2.15          | 950 KB    |            |   0%\n",
            "hdf4-4.2.15          | 950 KB    | ########## | 100%\n",
            "hdf4-4.2.15          | 950 KB    | ########## | 100%\n",
            "\n",
            "xorg-libxtst-1.2.3   | 31 KB     |            |   0%\n",
            "xorg-libxtst-1.2.3   | 31 KB     | ########## | 100%\n",
            "\n",
            "fsspec-2022.5.0      | 96 KB     |            |   0%\n",
            "fsspec-2022.5.0      | 96 KB     | ########## | 100%\n",
            "\n",
            "protobuf-3.16.0      | 342 KB    |            |   0%\n",
            "protobuf-3.16.0      | 342 KB    | ########## | 100%\n",
            "protobuf-3.16.0      | 342 KB    | ########## | 100%\n",
            "\n",
            "libevent-2.1.10      | 1.1 MB    |            |   0%\n",
            "libevent-2.1.10      | 1.1 MB    | ########## | 100%\n",
            "libevent-2.1.10      | 1.1 MB    | ########## | 100%\n",
            "\n",
            "kealib-1.4.15        | 188 KB    |            |   0%\n",
            "kealib-1.4.15        | 188 KB    | ########## | 100%\n",
            "\n",
            "backports-1.0        | 4 KB      |            |   0%\n",
            "backports-1.0        | 4 KB      | ########## | 100%\n",
            "\n",
            "pickleshare-0.7.5    | 9 KB      |            |   0%\n",
            "pickleshare-0.7.5    | 9 KB      | ########## | 100%\n",
            "\n",
            "brunsli-0.1          | 200 KB    |            |   0%\n",
            "brunsli-0.1          | 200 KB    | ########## | 100%\n",
            "\n",
            "faiss-proc-1.0.0     | 24 KB     |            |   0%\n",
            "faiss-proc-1.0.0     | 24 KB     | ######7    |  68%\n",
            "faiss-proc-1.0.0     | 24 KB     | ########## | 100%\n",
            "\n",
            "xorg-recordproto-1.1 | 8 KB      |            |   0%\n",
            "xorg-recordproto-1.1 | 8 KB      | ########## | 100%\n",
            "\n",
            "librttopo-1.1.0      | 235 KB    |            |   0%\n",
            "librttopo-1.1.0      | 235 KB    | ########## | 100%\n",
            "\n",
            "aws-c-io-0.10.5      | 121 KB    |            |   0%\n",
            "aws-c-io-0.10.5      | 121 KB    | ########## | 100%\n",
            "\n",
            "brotli-1.0.9         | 18 KB     |            |   0%\n",
            "brotli-1.0.9         | 18 KB     | ########## | 100%\n",
            "\n",
            "backports.zoneinfo-0 | 47 KB     |            |   0%\n",
            "backports.zoneinfo-0 | 47 KB     | ########## | 100%\n",
            "\n",
            "aws-c-cal-0.5.11     | 37 KB     |            |   0%\n",
            "aws-c-cal-0.5.11     | 37 KB     | ########## | 100%\n",
            "\n",
            "arrow-cpp-proc-3.0.0 | 24 KB     |            |   0%\n",
            "arrow-cpp-proc-3.0.0 | 24 KB     | ########## | 100%\n",
            "\n",
            "font-ttf-ubuntu-0.83 | 1.9 MB    |            |   0%\n",
            "font-ttf-ubuntu-0.83 | 1.9 MB    | ########## | 100%\n",
            "font-ttf-ubuntu-0.83 | 1.9 MB    | ########## | 100%\n",
            "\n",
            "locket-1.0.0         | 8 KB      |            |   0%\n",
            "locket-1.0.0         | 8 KB      | ########## | 100%\n",
            "\n",
            "libgfortran5-12.1.0  | 1.8 MB    |            |   0%\n",
            "libgfortran5-12.1.0  | 1.8 MB    | ########## | 100%\n",
            "libgfortran5-12.1.0  | 1.8 MB    | ########## | 100%\n",
            "\n",
            "pyee-8.1.0           | 14 KB     |            |   0%\n",
            "pyee-8.1.0           | 14 KB     | ########## | 100%\n",
            "\n",
            "ipython-7.33.0       | 1.1 MB    |            |   0%\n",
            "ipython-7.33.0       | 1.1 MB    | ########## | 100%\n",
            "ipython-7.33.0       | 1.1 MB    | ########## | 100%\n",
            "\n",
            "cudf-21.12.02        | 12.6 MB   |            |   0%\n",
            "cudf-21.12.02        | 12.6 MB   |            |   0%\n",
            "cudf-21.12.02        | 12.6 MB   |            |   1%\n",
            "cudf-21.12.02        | 12.6 MB   | 3          |   3%\n",
            "cudf-21.12.02        | 12.6 MB   | #2         |  13%\n",
            "cudf-21.12.02        | 12.6 MB   | ####3      |  43%\n",
            "cudf-21.12.02        | 12.6 MB   | #######5   |  75%\n",
            "cudf-21.12.02        | 12.6 MB   | ########## | 100%\n",
            "cudf-21.12.02        | 12.6 MB   | ########## | 100%\n",
            "\n",
            "importlib-metadata-4 | 33 KB     |            |   0%\n",
            "importlib-metadata-4 | 33 KB     | ########## | 100%\n",
            "\n",
            "boost-cpp-1.74.0     | 16.3 MB   |            |   0%\n",
            "boost-cpp-1.74.0     | 16.3 MB   | #####2     |  52%\n",
            "boost-cpp-1.74.0     | 16.3 MB   | ########## | 100%\n",
            "boost-cpp-1.74.0     | 16.3 MB   | ########## | 100%\n",
            "\n",
            "cyrus-sasl-2.1.27    | 228 KB    |            |   0%\n",
            "cyrus-sasl-2.1.27    | 228 KB    | ########## | 100%\n",
            "\n",
            "alsa-lib-1.2.3.2     | 554 KB    |            |   0%\n",
            "alsa-lib-1.2.3.2     | 554 KB    | ########## | 100%\n",
            "alsa-lib-1.2.3.2     | 554 KB    | ########## | 100%\n",
            "\n",
            "glog-0.5.0           | 104 KB    |            |   0%\n",
            "glog-0.5.0           | 104 KB    | ########## | 100%\n",
            "\n",
            "rmm-21.12.00         | 943 KB    |            |   0%\n",
            "rmm-21.12.00         | 943 KB    | 1          |   2%\n",
            "rmm-21.12.00         | 943 KB    | #3         |  14%\n",
            "rmm-21.12.00         | 943 KB    | #####7     |  58%\n",
            "rmm-21.12.00         | 943 KB    | ########## | 100%\n",
            "rmm-21.12.00         | 943 KB    | ########## | 100%\n",
            "\n",
            "google-cloud-storage | 74 KB     |            |   0%\n",
            "google-cloud-storage | 74 KB     | ########## | 100%\n",
            "\n",
            "importlib_metadata-4 | 4 KB      |            |   0%\n",
            "importlib_metadata-4 | 4 KB      | ########## | 100%\n",
            "\n",
            "xorg-libxau-1.0.9    | 13 KB     |            |   0%\n",
            "xorg-libxau-1.0.9    | 13 KB     | ########## | 100%\n",
            "\n",
            "snappy-1.1.9         | 35 KB     |            |   0%\n",
            "snappy-1.1.9         | 35 KB     | ########## | 100%\n",
            "\n",
            "spdlog-1.8.5         | 352 KB    |            |   0%\n",
            "spdlog-1.8.5         | 352 KB    | ########## | 100%\n",
            "spdlog-1.8.5         | 352 KB    | ########## | 100%\n",
            "\n",
            "google-crc32c-1.1.2  | 24 KB     |            |   0%\n",
            "google-crc32c-1.1.2  | 24 KB     | ########## | 100%\n",
            "\n",
            "nbconvert-6.5.0      | 6 KB      |            |   0%\n",
            "nbconvert-6.5.0      | 6 KB      | ########## | 100%\n",
            "\n",
            "zlib-1.2.12          | 91 KB     |            |   0%\n",
            "zlib-1.2.12          | 91 KB     | ########## | 100%\n",
            "\n",
            "libuv-1.42.0         | 1.0 MB    |            |   0%\n",
            "libuv-1.42.0         | 1.0 MB    | ########## | 100%\n",
            "libuv-1.42.0         | 1.0 MB    | ########## | 100%\n",
            "\n",
            "pydeck-0.5.0         | 3.6 MB    |            |   0%\n",
            "pydeck-0.5.0         | 3.6 MB    | ####2      |  43%\n",
            "pydeck-0.5.0         | 3.6 MB    | ######5    |  66%\n",
            "pydeck-0.5.0         | 3.6 MB    | ########9  |  89%\n",
            "pydeck-0.5.0         | 3.6 MB    | ########## | 100%\n",
            "\n",
            "typing_extensions-4. | 27 KB     |            |   0%\n",
            "typing_extensions-4. | 27 KB     | ########## | 100%\n",
            "\n",
            "anyio-3.6.1          | 153 KB    |            |   0%\n",
            "anyio-3.6.1          | 153 KB    | ########## | 100%\n",
            "\n",
            "zipp-3.8.0           | 12 KB     |            |   0%\n",
            "zipp-3.8.0           | 12 KB     | ########## | 100%\n",
            "\n",
            "simpervisor-0.4      | 9 KB      |            |   0%\n",
            "simpervisor-0.4      | 9 KB      | ########## | 100%\n",
            "\n",
            "xarray-0.20.2        | 628 KB    |            |   0%\n",
            "xarray-0.20.2        | 628 KB    | ########## | 100%\n",
            "xarray-0.20.2        | 628 KB    | ########## | 100%\n",
            "\n",
            "pyjwt-2.4.0          | 19 KB     |            |   0%\n",
            "pyjwt-2.4.0          | 19 KB     | ########## | 100%\n",
            "\n",
            "jedi-0.18.1          | 1008 KB   |            |   0%\n",
            "jedi-0.18.1          | 1008 KB   | ########## | 100%\n",
            "jedi-0.18.1          | 1008 KB   | ########## | 100%\n",
            "\n",
            "datashape-0.5.4      | 49 KB     |            |   0%\n",
            "datashape-0.5.4      | 49 KB     | ########## | 100%\n",
            "\n",
            "requests-oauthlib-1. | 22 KB     |            |   0%\n",
            "requests-oauthlib-1. | 22 KB     | ########## | 100%\n",
            "\n",
            "nbformat-5.4.0       | 104 KB    |            |   0%\n",
            "nbformat-5.4.0       | 104 KB    | ########## | 100%\n",
            "\n",
            "param-1.12.2         | 72 KB     |            |   0%\n",
            "param-1.12.2         | 72 KB     | ########## | 100%\n",
            "\n",
            "orc-1.6.9            | 746 KB    |            |   0%\n",
            "orc-1.6.9            | 746 KB    | ########## | 100%\n",
            "orc-1.6.9            | 746 KB    | ########## | 100%\n",
            "\n",
            "jupyterlab_pygments- | 17 KB     |            |   0%\n",
            "jupyterlab_pygments- | 17 KB     | ########## | 100%\n",
            "\n",
            "libbrotlienc-1.0.9   | 287 KB    |            |   0%\n",
            "libbrotlienc-1.0.9   | 287 KB    | ########## | 100%\n",
            "\n",
            "munch-2.5.0          | 12 KB     |            |   0%\n",
            "munch-2.5.0          | 12 KB     | ########## | 100%\n",
            "\n",
            "tzcode-2022a         | 69 KB     |            |   0%\n",
            "tzcode-2022a         | 69 KB     | ########## | 100%\n",
            "\n",
            "cfitsio-3.470        | 1.3 MB    |            |   0%\n",
            "cfitsio-3.470        | 1.3 MB    | ########## | 100%\n",
            "cfitsio-3.470        | 1.3 MB    | ########## | 100%\n",
            "\n",
            "fontconfig-2.14.0    | 305 KB    |            |   0%\n",
            "fontconfig-2.14.0    | 305 KB    | ########## | 100%\n",
            "\n",
            "libprotobuf-3.16.0   | 2.5 MB    |            |   0%\n",
            "libprotobuf-3.16.0   | 2.5 MB    | ########## | 100%\n",
            "libprotobuf-3.16.0   | 2.5 MB    | ########## | 100%\n",
            "\n",
            "heapdict-1.0.1       | 7 KB      |            |   0%\n",
            "heapdict-1.0.1       | 7 KB      | ########## | 100%\n",
            "\n",
            "dask-cudf-21.12.02   | 112 KB    |            |   0%\n",
            "dask-cudf-21.12.02   | 112 KB    | #4         |  14%\n",
            "dask-cudf-21.12.02   | 112 KB    | ########## | 100%\n",
            "\n",
            "cycler-0.11.0        | 10 KB     |            |   0%\n",
            "cycler-0.11.0        | 10 KB     | ########## | 100%\n",
            "\n",
            "libarchive-3.5.2     | 1.6 MB    |            |   0%\n",
            "libarchive-3.5.2     | 1.6 MB    | ########## | 100%\n",
            "libarchive-3.5.2     | 1.6 MB    | ########## | 100%\n",
            "\n",
            "python-tzdata-2022.1 | 151 KB    |            |   0%\n",
            "python-tzdata-2022.1 | 151 KB    | ########## | 100%\n",
            "python-tzdata-2022.1 | 151 KB    | ########## | 100%\n",
            "\n",
            "pydantic-1.9.1       | 2.2 MB    |            |   0%\n",
            "pydantic-1.9.1       | 2.2 MB    | ########## | 100%\n",
            "pydantic-1.9.1       | 2.2 MB    | ########## | 100%\n",
            "\n",
            "zstd-1.5.2           | 448 KB    |            |   0%\n",
            "zstd-1.5.2           | 448 KB    | ########## | 100%\n",
            "\n",
            "yarl-1.7.2           | 132 KB    |            |   0%\n",
            "yarl-1.7.2           | 132 KB    | ########## | 100%\n",
            "\n",
            "cytoolz-0.11.2       | 382 KB    |            |   0%\n",
            "cytoolz-0.11.2       | 382 KB    | ########## | 100%\n",
            "cytoolz-0.11.2       | 382 KB    | ########## | 100%\n",
            "\n",
            "py-xgboost-1.5.0dev. | 159 KB    |            |   0%\n",
            "py-xgboost-1.5.0dev. | 159 KB    | #          |  10%\n",
            "py-xgboost-1.5.0dev. | 159 KB    | ########## | 100%\n",
            "\n",
            "pygments-2.12.0      | 817 KB    |            |   0%\n",
            "pygments-2.12.0      | 817 KB    | ########## | 100%\n",
            "pygments-2.12.0      | 817 KB    | ########## | 100%\n",
            "\n",
            "typing-extensions-4. | 8 KB      |            |   0%\n",
            "typing-extensions-4. | 8 KB      | ########## | 100%\n",
            "\n",
            "nvtx-0.2.3           | 55 KB     |            |   0%\n",
            "nvtx-0.2.3           | 55 KB     | ########## | 100%\n",
            "\n",
            "libcucim-21.12.00    | 2.8 MB    |            |   0%\n",
            "libcucim-21.12.00    | 2.8 MB    |            |   1%\n",
            "libcucim-21.12.00    | 2.8 MB    | ########   |  81%\n",
            "libcucim-21.12.00    | 2.8 MB    | ########## | 100%\n",
            "\n",
            "libblas-3.9.0        | 12 KB     |            |   0%\n",
            "libblas-3.9.0        | 12 KB     | ########## | 100%\n",
            "\n",
            "pickle5-0.0.12       | 173 KB    |            |   0%\n",
            "pickle5-0.0.12       | 173 KB    | ########## | 100%\n",
            "\n",
            "kiwisolver-1.4.3     | 73 KB     |            |   0%\n",
            "kiwisolver-1.4.3     | 73 KB     | ########## | 100%\n",
            "\n",
            "libkml-1.3.0         | 591 KB    |            |   0%\n",
            "libkml-1.3.0         | 591 KB    | ########## | 100%\n",
            "libkml-1.3.0         | 591 KB    | ########## | 100%\n",
            "\n",
            "openssl-1.1.1p       | 2.1 MB    |            |   0%\n",
            "openssl-1.1.1p       | 2.1 MB    | ########## | 100%\n",
            "openssl-1.1.1p       | 2.1 MB    | ########## | 100%\n",
            "\n",
            "decorator-5.1.1      | 12 KB     |            |   0%\n",
            "decorator-5.1.1      | 12 KB     | ########## | 100%\n",
            "\n",
            "fastavro-1.5.2       | 461 KB    |            |   0%\n",
            "fastavro-1.5.2       | 461 KB    | ########## | 100%\n",
            "fastavro-1.5.2       | 461 KB    | ########## | 100%\n",
            "\n",
            "geotiff-1.7.0        | 296 KB    |            |   0%\n",
            "geotiff-1.7.0        | 296 KB    | ########## | 100%\n",
            "geotiff-1.7.0        | 296 KB    | ########## | 100%\n",
            "\n",
            "nbclient-0.6.5       | 65 KB     |            |   0%\n",
            "nbclient-0.6.5       | 65 KB     | ########## | 100%\n",
            "\n",
            "zeromq-4.3.4         | 351 KB    |            |   0%\n",
            "zeromq-4.3.4         | 351 KB    | ########## | 100%\n",
            "\n",
            "libgpg-error-1.45    | 286 KB    |            |   0%\n",
            "libgpg-error-1.45    | 286 KB    | ########## | 100%\n",
            "\n",
            "h11-0.13.0           | 46 KB     |            |   0%\n",
            "h11-0.13.0           | 46 KB     | ########## | 100%\n",
            "\n",
            "pcre-8.45            | 253 KB    |            |   0%\n",
            "pcre-8.45            | 253 KB    | ########## | 100%\n",
            "\n",
            "ucx-py-0.23.0        | 353 KB    |            |   0%\n",
            "ucx-py-0.23.0        | 353 KB    | 4          |   5%\n",
            "ucx-py-0.23.0        | 353 KB    | ########## | 100%\n",
            "\n",
            "libaec-1.0.6         | 45 KB     |            |   0%\n",
            "libaec-1.0.6         | 45 KB     | ########## | 100%\n",
            "\n",
            "tornado-6.1          | 646 KB    |            |   0%\n",
            "tornado-6.1          | 646 KB    | ########## | 100%\n",
            "tornado-6.1          | 646 KB    | ########## | 100%\n",
            "\n",
            "aiosignal-1.2.0      | 12 KB     |            |   0%\n",
            "aiosignal-1.2.0      | 12 KB     | ########## | 100%\n",
            "\n",
            "jpeg-9e              | 269 KB    |            |   0%\n",
            "jpeg-9e              | 269 KB    | ########## | 100%\n",
            "\n",
            "cudatoolkit-11.2.72  | 933.4 MB  |            |   0%\n",
            "cudatoolkit-11.2.72  | 933.4 MB  | ########## | 100%\n",
            "cudatoolkit-11.2.72  | 933.4 MB  | ########## | 100%\n",
            "\n",
            "pandoc-2.18          | 12.5 MB   |            |   0%\n",
            "pandoc-2.18          | 12.5 MB   | ##1        |  21%\n",
            "pandoc-2.18          | 12.5 MB   | ##7        |  28%\n",
            "pandoc-2.18          | 12.5 MB   | ###4       |  34%\n",
            "pandoc-2.18          | 12.5 MB   | ####       |  41%\n",
            "pandoc-2.18          | 12.5 MB   | ####7      |  47%\n",
            "pandoc-2.18          | 12.5 MB   | #####3     |  54%\n",
            "pandoc-2.18          | 12.5 MB   | ######     |  60%\n",
            "pandoc-2.18          | 12.5 MB   | ######6    |  67%\n",
            "pandoc-2.18          | 12.5 MB   | #######3   |  74%\n",
            "pandoc-2.18          | 12.5 MB   | ########   |  80%\n",
            "pandoc-2.18          | 12.5 MB   | ########7  |  87%\n",
            "pandoc-2.18          | 12.5 MB   | #########3 |  94%\n",
            "pandoc-2.18          | 12.5 MB   | ########## | 100%\n",
            "\n",
            "imageio-2.13.1       | 3.1 MB    |            |   0%\n",
            "imageio-2.13.1       | 3.1 MB    | ########## | 100%\n",
            "imageio-2.13.1       | 3.1 MB    | ########## | 100%\n",
            "\n",
            "xorg-renderproto-0.1 | 9 KB      |            |   0%\n",
            "xorg-renderproto-0.1 | 9 KB      | ########## | 100%\n",
            "\n",
            "pyviz_comms-2.2.0    | 31 KB     |            |   0%\n",
            "pyviz_comms-2.2.0    | 31 KB     | ########## | 100%\n",
            "\n",
            "pillow-8.3.1         | 692 KB    |            |   0%\n",
            "pillow-8.3.1         | 692 KB    | ########## | 100%\n",
            "pillow-8.3.1         | 692 KB    | ########## | 100%\n",
            "\n",
            "pyu2f-0.1.5          | 31 KB     |            |   0%\n",
            "pyu2f-0.1.5          | 31 KB     | ########## | 100%\n",
            "\n",
            "xorg-libxdmcp-1.1.3  | 19 KB     |            |   0%\n",
            "xorg-libxdmcp-1.1.3  | 19 KB     | ########## | 100%\n",
            "\n",
            "matplotlib-base-3.4. | 7.2 MB    |            |   0%\n",
            "matplotlib-base-3.4. | 7.2 MB    | ##2        |  23%\n",
            "matplotlib-base-3.4. | 7.2 MB    | ###4       |  35%\n",
            "matplotlib-base-3.4. | 7.2 MB    | ####6      |  46%\n",
            "matplotlib-base-3.4. | 7.2 MB    | #####8     |  58%\n",
            "matplotlib-base-3.4. | 7.2 MB    | ######8    |  69%\n",
            "matplotlib-base-3.4. | 7.2 MB    | #######9   |  80%\n",
            "matplotlib-base-3.4. | 7.2 MB    | #########1 |  92%\n",
            "matplotlib-base-3.4. | 7.2 MB    | ########## | 100%\n",
            "\n",
            "libuuid-2.32.1       | 28 KB     |            |   0%\n",
            "libuuid-2.32.1       | 28 KB     | ########## | 100%\n",
            "\n",
            "frozenlist-1.3.0     | 43 KB     |            |   0%\n",
            "frozenlist-1.3.0     | 43 KB     | ########## | 100%\n",
            "\n",
            "font-ttf-source-code | 684 KB    |            |   0%\n",
            "font-ttf-source-code | 684 KB    | ########## | 100%\n",
            "font-ttf-source-code | 684 KB    | ########## | 100%\n",
            "\n",
            "postgresql-13.5      | 5.3 MB    |            |   0%\n",
            "postgresql-13.5      | 5.3 MB    | ########## | 100%\n",
            "postgresql-13.5      | 5.3 MB    | ########## | 100%\n",
            "\n",
            "terminado-0.15.0     | 28 KB     |            |   0%\n",
            "terminado-0.15.0     | 28 KB     | ########## | 100%\n",
            "\n",
            "pyrsistent-0.18.1    | 91 KB     |            |   0%\n",
            "pyrsistent-0.18.1    | 91 KB     | ########## | 100%\n",
            "\n",
            "ptyprocess-0.7.0     | 16 KB     |            |   0%\n",
            "ptyprocess-0.7.0     | 16 KB     | ########## | 100%\n",
            "\n",
            "keyutils-1.6.1       | 115 KB    |            |   0%\n",
            "keyutils-1.6.1       | 115 KB    | ########## | 100%\n",
            "\n",
            "prometheus_client-0. | 49 KB     |            |   0%\n",
            "prometheus_client-0. | 49 KB     | ########## | 100%\n",
            "\n",
            "networkx-2.7.1       | 1.5 MB    |            |   0%\n",
            "networkx-2.7.1       | 1.5 MB    | ########## | 100%\n",
            "networkx-2.7.1       | 1.5 MB    | ########## | 100%\n",
            "\n",
            "tinycss2-1.1.1       | 23 KB     |            |   0%\n",
            "tinycss2-1.1.1       | 23 KB     | ########## | 100%\n",
            "\n",
            "colorcet-3.0.0       | 1.5 MB    |            |   0%\n",
            "colorcet-3.0.0       | 1.5 MB    | ########## | 100%\n",
            "colorcet-3.0.0       | 1.5 MB    | ########## | 100%\n",
            "\n",
            "appdirs-1.4.4        | 13 KB     |            |   0%\n",
            "appdirs-1.4.4        | 13 KB     | ########## | 100%\n",
            "\n",
            "ucx-proc-1.0.0       | 9 KB      |            |   0%\n",
            "ucx-proc-1.0.0       | 9 KB      | ########## | 100%\n",
            "ucx-proc-1.0.0       | 9 KB      | ########## | 100%\n",
            "\n",
            "tabulate-0.8.10      | 29 KB     |            |   0%\n",
            "tabulate-0.8.10      | 29 KB     | ########## | 100%\n",
            "\n",
            "certifi-2022.6.15    | 155 KB    |            |   0%\n",
            "certifi-2022.6.15    | 155 KB    | ########## | 100%\n",
            "\n",
            "attrs-21.4.0         | 49 KB     |            |   0%\n",
            "attrs-21.4.0         | 49 KB     | ########## | 100%\n",
            "\n",
            "libwebp-1.2.2        | 85 KB     |            |   0%\n",
            "libwebp-1.2.2        | 85 KB     | ########## | 100%\n",
            "Preparing transaction: ...working... done\n",
            "Verifying transaction: ...working... done\n",
            "Executing transaction: ...working... By downloading and using the CUDA Toolkit conda packages, you accept the terms and conditions of the CUDA End User License Agreement (EULA): https://docs.nvidia.com/cuda/eula/index.html\n",
            "\n",
            "done\n",
            "RAPIDS conda installation complete.  Updating Colab's libraries...\n",
            "Copying /usr/local/lib/libcudf.so to /usr/lib/libcudf.so\n",
            "Copying /usr/local/lib/libnccl.so to /usr/lib/libnccl.so\n",
            "Copying /usr/local/lib/libcuml.so to /usr/lib/libcuml.so\n",
            "Copying /usr/local/lib/libcugraph.so to /usr/lib/libcugraph.so\n",
            "Copying /usr/local/lib/libxgboost.so to /usr/lib/libxgboost.so\n",
            "Copying /usr/local/lib/libcuspatial.so to /usr/lib/libcuspatial.so\n",
            "Copying /usr/local/lib/libgeos.so to /usr/lib/libgeos.so\n",
            "Copying /usr/local/lib/libgeos_c.so to /usr/lib/libgeos_c.so\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOOdZDzIItEG",
        "outputId": "41603374-6d3a-4528-ef43-2670f8bce445"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive/Amex/parquet')"
      ],
      "metadata": {
        "id": "6lJRhid0ItBS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ok6vV7YjIs-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# XGBoost Starter - LB 0.793\n",
        "In this notebook we build and train an XGBoost model using @raddar Kaggle dataset from [here][1] with discussion [here][2]. Then we engineer features suggested by @huseyincot in his notebooks [here][3] and [here][4]. This XGB model achieves CV 0.792 LB 0.793! When training with XGB, we use a special XGB dataloader called `DeviceQuantileDMatrix` which uses a small GPU memory footprint. This allows us to engineer more additional columns and train with more rows of data. Our feature engineering is performed using [RAPIDS][5] on the GPU to create new features quickly.\n",
        "\n",
        "[1]: https://www.kaggle.com/datasets/raddar/amex-data-integer-dtypes-parquet-format\n",
        "[2]: https://www.kaggle.com/competitions/amex-default-prediction/discussion/328514\n",
        "[3]: https://www.kaggle.com/code/huseyincot/amex-catboost-0-793\n",
        "[4]: https://www.kaggle.com/code/huseyincot/amex-agg-data-how-it-created\n",
        "[5]: https://rapids.ai/"
      ],
      "metadata": {
        "id": "rda9uzwxp0N0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Libraries"
      ],
      "metadata": {
        "id": "vMo1TkPZp0N4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LOAD LIBRARIES\n",
        "import pandas as pd, numpy as np # CPU libraries\n",
        "import cupy, cudf # GPU libraries\n",
        "import matplotlib.pyplot as plt, gc, os\n",
        "\n",
        "print('RAPIDS version',cudf.__version__)"
      ],
      "metadata": {
        "id": "GRgokt4bp0N4",
        "outputId": "c0d7e860-d55e-44a1-a0b8-b2e334469e45",
        "execution": {
          "iopub.status.busy": "2022-06-29T20:19:23.648645Z",
          "iopub.execute_input": "2022-06-29T20:19:23.649024Z",
          "iopub.status.idle": "2022-06-29T20:19:28.137314Z",
          "shell.execute_reply.started": "2022-06-29T20:19:23.648929Z",
          "shell.execute_reply": "2022-06-29T20:19:28.136267Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RAPIDS version 21.12.02\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# VERSION NAME FOR SAVED MODEL FILES\n",
        "VER = 1\n",
        "\n",
        "# TRAIN RANDOM SEED\n",
        "SEED = 42\n",
        "\n",
        "# FILL NAN VALUE\n",
        "NAN_VALUE = -127 # will fit in int8\n",
        "\n",
        "# FOLDS PER MODEL\n",
        "FOLDS = 5"
      ],
      "metadata": {
        "id": "Sct61n7Yp0N5",
        "execution": {
          "iopub.status.busy": "2022-06-29T20:19:30.471076Z",
          "iopub.execute_input": "2022-06-29T20:19:30.471479Z",
          "iopub.status.idle": "2022-06-29T20:19:30.476777Z",
          "shell.execute_reply.started": "2022-06-29T20:19:30.471444Z",
          "shell.execute_reply": "2022-06-29T20:19:30.475713Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Process and Feature Engineer Train Data\n",
        "We will load @raddar Kaggle dataset from [here][1] with discussion [here][2]. Then we will engineer features suggested by @huseyincot in his notebooks [here][3] and [here][4]. We will use [RAPIDS][5] and the GPU to create new features quickly.\n",
        "\n",
        "[1]: https://www.kaggle.com/datasets/raddar/amex-data-integer-dtypes-parquet-format\n",
        "[2]: https://www.kaggle.com/competitions/amex-default-prediction/discussion/328514\n",
        "[3]: https://www.kaggle.com/code/huseyincot/amex-catboost-0-793\n",
        "[4]: https://www.kaggle.com/code/huseyincot/amex-agg-data-how-it-created\n",
        "[5]: https://rapids.ai/"
      ],
      "metadata": {
        "id": "vEV9Z8ZIp0N6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_file(path = '', usecols = None):\n",
        "    # LOAD DATAFRAME\n",
        "    if usecols is not None: df = cudf.read_parquet(path, columns=usecols)\n",
        "    else: df = cudf.read_parquet(path)\n",
        "    # REDUCE DTYPE FOR CUSTOMER AND DATE\n",
        "    df['customer_ID'] = df['customer_ID'].str[-16:].str.hex_to_int().astype('int64')\n",
        "    df.S_2 = cudf.to_datetime( df.S_2 )\n",
        "    # SORT BY CUSTOMER AND DATE (so agg('last') works correctly)\n",
        "    #df = df.sort_values(['customer_ID','S_2'])\n",
        "    #df = df.reset_index(drop=True)\n",
        "    # FILL NAN\n",
        "    #df = df.fillna(NAN_VALUE) \n",
        "    print('shape of data:', df.shape)\n",
        "    \n",
        "    return df\n",
        "\n",
        "print('Reading train data...')\n",
        "TRAIN_PATH = 'train.parquet'\n",
        "train = read_file(path = TRAIN_PATH)"
      ],
      "metadata": {
        "id": "QWJevsrgp0N6",
        "outputId": "e17d03a1-e45e-4721-e664-ddd525e70161",
        "execution": {
          "iopub.status.busy": "2022-06-29T20:20:28.301583Z",
          "iopub.execute_input": "2022-06-29T20:20:28.305157Z",
          "iopub.status.idle": "2022-06-29T20:21:09.754217Z",
          "shell.execute_reply.started": "2022-06-29T20:20:28.305123Z",
          "shell.execute_reply": "2022-06-29T20:21:09.752494Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading train data...\n",
            "shape of data: (5531451, 190)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def handle_na(df,NAN_VALUE):\n",
        "  df = df.fillna(NAN_VALUE)\n",
        "  # train[num_cols] = train[num_cols].fillna(NAN_VALUE)\n",
        "  # for column in cat_cols:\n",
        "  #   train[column] = train[column].fillna(train[column].mode()[0])\n",
        "  return df "
      ],
      "metadata": {
        "id": "-Yyk7OV_p0N7",
        "execution": {
          "iopub.status.busy": "2022-06-29T20:21:15.241058Z",
          "iopub.execute_input": "2022-06-29T20:21:15.241396Z",
          "iopub.status.idle": "2022-06-29T20:21:15.246186Z",
          "shell.execute_reply.started": "2022-06-29T20:21:15.241368Z",
          "shell.execute_reply": "2022-06-29T20:21:15.245150Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#NA\n",
        "train = handle_na(train, NAN_VALUE)"
      ],
      "metadata": {
        "id": "9xIA0kjOp0N7",
        "execution": {
          "iopub.status.busy": "2022-06-29T20:21:17.182767Z",
          "iopub.execute_input": "2022-06-29T20:21:17.183383Z",
          "iopub.status.idle": "2022-06-29T20:21:17.715653Z",
          "shell.execute_reply.started": "2022-06-29T20:21:17.183345Z",
          "shell.execute_reply": "2022-06-29T20:21:17.714584Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_cols = [c for c in list(train.columns) if c not in ['customer_ID','S_2']]\n",
        "cat_features = [\"B_30\",\"B_38\",\"D_114\",\"D_116\",\"D_117\",\"D_120\",\"D_126\",\"D_63\",\"D_64\",\"D_66\",\"D_68\"]\n",
        "num_features = [col for col in all_cols if col not in cat_features]"
      ],
      "metadata": {
        "id": "FKk-_Pk0p0N8",
        "execution": {
          "iopub.status.busy": "2022-06-29T20:21:20.399246Z",
          "iopub.execute_input": "2022-06-29T20:21:20.399580Z",
          "iopub.status.idle": "2022-06-29T20:21:20.407826Z",
          "shell.execute_reply.started": "2022-06-29T20:21:20.399553Z",
          "shell.execute_reply": "2022-06-29T20:21:20.406795Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "growth = []\n",
        "\n",
        "for i in num_features:\n",
        "  if len(train[train[i]<=0]) == 0: growth.append(i)\n",
        "\n",
        "growth"
      ],
      "metadata": {
        "id": "MWqItLINkqMk",
        "outputId": "12caeb21-71a9-4905-8b46-8d231940ea11",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['R_1',\n",
              " 'B_5',\n",
              " 'B_9',\n",
              " 'S_5',\n",
              " 'B_11',\n",
              " 'B_12',\n",
              " 'D_58',\n",
              " 'D_60',\n",
              " 'B_18',\n",
              " 'R_6',\n",
              " 'B_21',\n",
              " 'D_71',\n",
              " 'B_23',\n",
              " 'B_24',\n",
              " 'S_16',\n",
              " 'S_17',\n",
              " 'S_19',\n",
              " 'B_36']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def process_and_feature_engineer(df, cat_features, num_features, growth):\n",
        "    # FEATURE ENGINEERING FROM \n",
        "    # https://www.kaggle.com/code/huseyincot/amex-agg-data-how-it-created\n",
        "\n",
        "\n",
        "    test_num_agg = df.groupby(\"customer_ID\")[num_features].agg(['mean', 'std', 'max', 'min', 'first', 'last'])\n",
        "      \n",
        "    for i in growth:\n",
        "      test_num_agg[i, 'pctchange'] = (test_num_agg[i]['last']/test_num_agg[i]['first']-1) * 100\n",
        "\n",
        "    \n",
        "    test_num_agg['D_54', 'abschange'] = test_num_agg['D_54']['last']-test_num_agg['D_54']['first']\n",
        "    \n",
        "    test_num_agg.columns = ['_'.join(x) for x in test_num_agg.columns]\n",
        "\n",
        "    test_cat_agg = df.groupby(\"customer_ID\")[cat_features].agg(['count', 'last', 'nunique'])\n",
        "    test_cat_agg.columns = ['_'.join(x) for x in test_cat_agg.columns]\n",
        "\n",
        "    df = cudf.concat([test_num_agg, test_cat_agg], axis=1)\n",
        "    del test_num_agg, test_cat_agg\n",
        "    print('shape after engineering', df.shape )\n",
        "    \n",
        "    return df\n",
        "\n",
        "train = process_and_feature_engineer(train,cat_features, num_features, growth)"
      ],
      "metadata": {
        "id": "T_PlHaBLp0N8",
        "outputId": "70c05ff9-f090-4cee-a157-d9ad44da396b",
        "execution": {
          "iopub.status.busy": "2022-06-29T20:21:26.330013Z",
          "iopub.execute_input": "2022-06-29T20:21:26.330583Z",
          "iopub.status.idle": "2022-06-29T20:21:28.655556Z",
          "shell.execute_reply.started": "2022-06-29T20:21:26.330544Z",
          "shell.execute_reply": "2022-06-29T20:21:28.654487Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape after engineering (458913, 1114)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ADD TARGETS\n",
        "targets = cudf.read_csv('train_labels.csv')\n",
        "targets['customer_ID'] = targets['customer_ID'].str[-16:].str.hex_to_int().astype('int64')\n",
        "targets = targets.set_index('customer_ID')\n",
        "train = train.merge(targets, left_index=True, right_index=True, how='left')\n",
        "train.target = train.target.astype('int8')\n",
        "del targets\n",
        "\n",
        "# NEEDED TO MAKE CV DETERMINISTIC (cudf merge above randomly shuffles rows)\n",
        "train = train.sort_index().reset_index()\n",
        "\n",
        "# FEATURES\n",
        "FEATURES = train.columns[1:-1]\n",
        "print(f'There are {len(FEATURES)} features!')"
      ],
      "metadata": {
        "id": "5EPlkwdMp0N9",
        "outputId": "99224a75-010e-4b52-ca33-7ab001c00ce2",
        "execution": {
          "iopub.status.busy": "2022-06-29T20:21:57.379414Z",
          "iopub.execute_input": "2022-06-29T20:21:57.379758Z",
          "iopub.status.idle": "2022-06-29T20:21:59.318025Z",
          "shell.execute_reply.started": "2022-06-29T20:21:57.379730Z",
          "shell.execute_reply": "2022-06-29T20:21:59.316930Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1114 features!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wdVTcmf9PjVL",
        "outputId": "d6030cdb-5ece-494e-a685-717f6f7798ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting optuna\n",
            "  Downloading optuna-2.10.1-py3-none-any.whl (308 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 308 kB 9.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/site-packages (from optuna) (21.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/site-packages (from optuna) (4.59.0)\n",
            "Collecting cliff\n",
            "  Downloading cliff-3.10.1-py3-none-any.whl (81 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 81 kB 8.4 MB/s \n",
            "\u001b[?25hCollecting colorlog\n",
            "  Downloading colorlog-6.6.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting cmaes>=0.8.2\n",
            "  Downloading cmaes-0.8.2-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/site-packages (from optuna) (1.21.6)\n",
            "Collecting alembic\n",
            "  Downloading alembic-1.8.0-py3-none-any.whl (209 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 209 kB 55.8 MB/s \n",
            "\u001b[?25hCollecting sqlalchemy>=1.1.0\n",
            "  Downloading SQLAlchemy-1.4.39-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.6 MB 58.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.7/site-packages (from optuna) (1.7.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/site-packages (from optuna) (6.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/site-packages (from packaging>=20.0->optuna) (3.0.9)\n",
            "Collecting greenlet!=0.4.17\n",
            "  Downloading greenlet-1.1.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (150 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 150 kB 64.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/site-packages (from sqlalchemy>=1.1.0->optuna) (4.11.4)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.2.1-py3-none-any.whl (78 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 78 kB 7.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.7/site-packages (from alembic->optuna) (5.8.0)\n",
            "Collecting PrettyTable>=0.7.2\n",
            "  Downloading prettytable-3.3.0-py3-none-any.whl (26 kB)\n",
            "Collecting autopage>=0.4.0\n",
            "  Downloading autopage-0.5.1-py3-none-any.whl (29 kB)\n",
            "Collecting pbr!=2.1.0,>=2.0.0\n",
            "  Downloading pbr-5.9.0-py2.py3-none-any.whl (112 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 112 kB 62.0 MB/s \n",
            "\u001b[?25hCollecting cmd2>=1.0.0\n",
            "  Downloading cmd2-2.4.1-py3-none-any.whl (146 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 146 kB 41.6 MB/s \n",
            "\u001b[?25hCollecting stevedore>=2.0.1\n",
            "  Downloading stevedore-3.5.0-py3-none-any.whl (49 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 49 kB 6.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/site-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/site-packages (from cmd2>=1.0.0->cliff->optuna) (21.4.0)\n",
            "Collecting pyperclip>=1.6\n",
            "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/site-packages (from cmd2>=1.0.0->cliff->optuna) (4.2.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/site-packages (from importlib-metadata->sqlalchemy>=1.1.0->optuna) (3.8.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/site-packages (from Mako->alembic->optuna) (2.1.1)\n",
            "Building wheels for collected packages: pyperclip\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11137 sha256=eeb171f60c0707878ca5e92abcb30e2b5f19f7a435243746f92041ccc14963fb\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/18/84/8f69f8b08169c7bae2dde6bd7daf0c19fca8c8e500ee620a28\n",
            "Successfully built pyperclip\n",
            "Installing collected packages: pyperclip, pbr, greenlet, stevedore, sqlalchemy, PrettyTable, Mako, cmd2, autopage, colorlog, cmaes, cliff, alembic, optuna\n",
            "Successfully installed Mako-1.2.1 PrettyTable-3.3.0 alembic-1.8.0 autopage-0.5.1 cliff-3.10.1 cmaes-0.8.2 cmd2-2.4.1 colorlog-6.6.0 greenlet-1.1.2 optuna-2.10.1 pbr-5.9.0 pyperclip-1.8.2 sqlalchemy-1.4.39 stevedore-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "from sklearn.model_selection import KFold\n",
        "import xgboost as xgb"
      ],
      "metadata": {
        "id": "Rwzecx3zp9dC",
        "execution": {
          "iopub.status.busy": "2022-06-29T20:22:05.860070Z",
          "iopub.execute_input": "2022-06-29T20:22:05.860680Z",
          "iopub.status.idle": "2022-06-29T20:22:05.958002Z",
          "shell.execute_reply.started": "2022-06-29T20:22:05.860635Z",
          "shell.execute_reply": "2022-06-29T20:22:05.956910Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def amex_metric_mod(y_true, y_pred):\n",
        "\n",
        "    labels     = np.transpose(np.array([y_true, y_pred]))\n",
        "    labels     = labels[labels[:, 1].argsort()[::-1]]\n",
        "    weights    = np.where(labels[:,0]==0, 20, 1)\n",
        "    cut_vals   = labels[np.cumsum(weights) <= int(0.04 * np.sum(weights))]\n",
        "    top_four   = np.sum(cut_vals[:,0]) / np.sum(labels[:,0])\n",
        "\n",
        "    gini = [0,0]\n",
        "    for i in [1,0]:\n",
        "        labels         = np.transpose(np.array([y_true, y_pred]))\n",
        "        labels         = labels[labels[:, i].argsort()[::-1]]\n",
        "        weight         = np.where(labels[:,0]==0, 20, 1)\n",
        "        weight_random  = np.cumsum(weight / np.sum(weight))\n",
        "        total_pos      = np.sum(labels[:, 0] *  weight)\n",
        "        cum_pos_found  = np.cumsum(labels[:, 0] * weight)\n",
        "        lorentz        = cum_pos_found / total_pos\n",
        "        gini[i]        = np.sum((lorentz - weight_random) * weight)\n",
        "\n",
        "    return 0.5 * (gini[1]/gini[0] + top_four)"
      ],
      "metadata": {
        "id": "J_irDxMwOCHH",
        "execution": {
          "iopub.status.busy": "2022-06-29T20:22:09.538198Z",
          "iopub.execute_input": "2022-06-29T20:22:09.538537Z",
          "iopub.status.idle": "2022-06-29T20:22:09.549057Z",
          "shell.execute_reply.started": "2022-06-29T20:22:09.538510Z",
          "shell.execute_reply": "2022-06-29T20:22:09.548052Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NEEDED WITH DeviceQuantileDMatrix BELOW\n",
        "class IterLoadForDMatrix(xgb.core.DataIter):\n",
        "    def __init__(self, df=None, features=None, target=None, batch_size=256*1024):\n",
        "        self.features = features\n",
        "        self.target = target\n",
        "        self.df = df\n",
        "        self.it = 0 # set iterator to 0\n",
        "        self.batch_size = batch_size\n",
        "        self.batches = int( np.ceil( len(df) / self.batch_size ) )\n",
        "        super().__init__()\n",
        "\n",
        "    def reset(self):\n",
        "        '''Reset the iterator'''\n",
        "        self.it = 0\n",
        "\n",
        "    def next(self, input_data):\n",
        "        '''Yield next batch of data.'''\n",
        "        if self.it == self.batches:\n",
        "            return 0 # Return 0 when there's no more batch.\n",
        "        \n",
        "        a = self.it * self.batch_size\n",
        "        b = min( (self.it + 1) * self.batch_size, len(self.df) )\n",
        "        dt = cudf.DataFrame(self.df.iloc[a:b])\n",
        "        input_data(data=dt[self.features], label=dt[self.target]) #, weight=dt['weight'])\n",
        "        self.it += 1\n",
        "        return 1"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-06-29T20:22:13.597696Z",
          "iopub.execute_input": "2022-06-29T20:22:13.598050Z",
          "iopub.status.idle": "2022-06-29T20:22:13.609193Z",
          "shell.execute_reply.started": "2022-06-29T20:22:13.598022Z",
          "shell.execute_reply": "2022-06-29T20:22:13.607740Z"
        },
        "trusted": true,
        "id": "Pry4EU1SIfK8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = train.to_pandas() # free GPU memory"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-06-29T20:22:51.791419Z",
          "iopub.execute_input": "2022-06-29T20:22:51.791999Z",
          "iopub.status.idle": "2022-06-29T20:22:51.908305Z",
          "shell.execute_reply.started": "2022-06-29T20:22:51.791837Z",
          "shell.execute_reply": "2022-06-29T20:22:51.904352Z"
        },
        "trusted": true,
        "id": "mFbIZIhfIfK8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# optuna\n",
        "\n",
        "def objective(trial, IterLoadForDMatrix, train):\n",
        "    \n",
        "    param = {\n",
        "        'booster':'gbtree',\n",
        "        'tree_method':'gpu_hist', \n",
        "        \"objective\": \"binary:logistic\",\n",
        "        'lambda': trial.suggest_loguniform(\n",
        "            'lambda', 1e-3, 10.0\n",
        "        ),\n",
        "        'alpha': trial.suggest_loguniform(\n",
        "            'alpha', 1e-3, 10.0\n",
        "        ),\n",
        "        'colsample_bytree': trial.suggest_float(\n",
        "            'colsample_bytree', 0.5,1,step=0.1\n",
        "        ),\n",
        "        'subsample': trial.suggest_float(\n",
        "            'subsample', 0.5,1,step=0.1\n",
        "        ),\n",
        "        'learning_rate': trial.suggest_float(\n",
        "            'learning_rate', 0.001,0.05,step=0.001\n",
        "        ),\n",
        "        'n_estimators': trial.suggest_int(\n",
        "            \"n_estimators\", 80,1000,10\n",
        "        ),\n",
        "        'max_depth': trial.suggest_int(\n",
        "            'max_depth', 2,10,1\n",
        "        ),\n",
        "        'random_state': 99,\n",
        "        'min_child_weight': trial.suggest_int(\n",
        "            'min_child_weight', 1,256,1\n",
        "        ),\n",
        "    }\n",
        "    \n",
        "    \n",
        "\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    oof = []\n",
        "    gc.collect()\n",
        "    \n",
        "    skf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    \n",
        "    for fold,(train_idx, valid_idx) in enumerate(skf.split(\n",
        "            train, train.target )):\n",
        "        \n",
        "        # TRAIN, VALID, TEST FOR FOLD K\n",
        "        Xy_train = IterLoadForDMatrix(train.loc[train_idx], FEATURES, 'target')\n",
        "        \n",
        "        X_valid = train.loc[valid_idx, FEATURES]\n",
        "        y_valid = train.loc[valid_idx, 'target']\n",
        "      \n",
        "        dtrain = xgb.DeviceQuantileDMatrix(Xy_train, max_bin=256)\n",
        "        dvalid = xgb.DMatrix(data=X_valid, label=y_valid)\n",
        "      \n",
        "        \n",
        "\n",
        "        \n",
        "        # TRAIN MODEL FOLD K\n",
        "        model = xgb.train(param, \n",
        "                  dtrain=dtrain,\n",
        "                  evals=[(dtrain,'train'),(dvalid,'valid')],\n",
        "                  num_boost_round=9999,\n",
        "                  early_stopping_rounds=100,\n",
        "                  verbose_eval=300\n",
        "                  ) \n",
        "      \n",
        "        \n",
        "        # INFER OOF FOLD K\n",
        "        oof_preds = model.predict(dvalid)\n",
        "        #acc = amex_metric_mod(y_valid.values, oof_preds)\n",
        "    \n",
        "    \n",
        "        # SAVE OOF\n",
        "        df = train.loc[valid_idx, ['customer_ID','target'] ].copy()\n",
        "        df['oof_pred'] = oof_preds\n",
        "        oof.append(df)\n",
        "\n",
        "              \n",
        "\n",
        "\n",
        "        del dtrain, Xy_train, df\n",
        "        del X_valid, y_valid, dvalid, model\n",
        "        _ = gc.collect()\n",
        "    \n",
        "\n",
        "    oof = pd.concat(oof,axis=0,ignore_index=True).set_index('customer_ID')\n",
        "    metric = amex_metric_mod(oof.target.values, oof.oof_pred.values)\n",
        "        \n",
        "    return metric"
      ],
      "metadata": {
        "id": "DR_vG55kqmne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(lambda trial: objective(\n",
        "        trial, IterLoadForDMatrix, train), n_trials= 90) "
      ],
      "metadata": {
        "id": "2XVMjHCxtcgc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce6f9d39-de80-40ce-e0aa-6ca85503bda4"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-07-01 06:33:46,322]\u001b[0m A new study created in memory with name: no-name-665da325-8d78-4cc0-8806-4c5b5438351d\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[06:34:01] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[06:34:01] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.66580\tvalid-logloss:0.66592\n",
            "[300]\ttrain-logloss:0.20954\tvalid-logloss:0.22145\n",
            "[600]\ttrain-logloss:0.19874\tvalid-logloss:0.21856\n",
            "[900]\ttrain-logloss:0.19016\tvalid-logloss:0.21788\n",
            "[1178]\ttrain-logloss:0.18305\tvalid-logloss:0.21776\n",
            "[06:36:17] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[06:36:18] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.66585\tvalid-logloss:0.66584\n",
            "[300]\ttrain-logloss:0.20972\tvalid-logloss:0.21940\n",
            "[600]\ttrain-logloss:0.19869\tvalid-logloss:0.21690\n",
            "[900]\ttrain-logloss:0.19006\tvalid-logloss:0.21643\n",
            "[1103]\ttrain-logloss:0.18489\tvalid-logloss:0.21638\n",
            "[06:38:27] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[06:38:27] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.66584\tvalid-logloss:0.66600\n",
            "[300]\ttrain-logloss:0.20900\tvalid-logloss:0.22291\n",
            "[600]\ttrain-logloss:0.19805\tvalid-logloss:0.22052\n",
            "[900]\ttrain-logloss:0.18940\tvalid-logloss:0.22001\n",
            "[1200]\ttrain-logloss:0.18170\tvalid-logloss:0.21977\n",
            "[1220]\ttrain-logloss:0.18121\tvalid-logloss:0.21980\n",
            "[06:40:46] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[06:40:46] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.66583\tvalid-logloss:0.66598\n",
            "[300]\ttrain-logloss:0.20882\tvalid-logloss:0.22282\n",
            "[600]\ttrain-logloss:0.19820\tvalid-logloss:0.22050\n",
            "[900]\ttrain-logloss:0.18947\tvalid-logloss:0.22002\n",
            "[1194]\ttrain-logloss:0.18189\tvalid-logloss:0.22003\n",
            "[06:43:03] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[06:43:04] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.66587\tvalid-logloss:0.66583\n",
            "[300]\ttrain-logloss:0.21021\tvalid-logloss:0.21956\n",
            "[600]\ttrain-logloss:0.19889\tvalid-logloss:0.21686\n",
            "[900]\ttrain-logloss:0.19013\tvalid-logloss:0.21612\n",
            "[1200]\ttrain-logloss:0.18249\tvalid-logloss:0.21599\n",
            "[1247]\ttrain-logloss:0.18134\tvalid-logloss:0.21599\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-07-01 06:45:12,949]\u001b[0m Trial 0 finished with value: 0.7905649969412591 and parameters: {'lambda': 0.05125480869275412, 'alpha': 0.006465257748534867, 'colsample_bytree': 0.9, 'subsample': 0.6, 'learning_rate': 0.042, 'n_estimators': 330, 'max_depth': 7, 'min_child_weight': 190}. Best is trial 0 with value: 0.7905649969412591.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[06:45:26] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[06:45:26] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.67001\tvalid-logloss:0.67006\n",
            "[300]\ttrain-logloss:0.21521\tvalid-logloss:0.22434\n",
            "[600]\ttrain-logloss:0.20495\tvalid-logloss:0.21988\n",
            "[900]\ttrain-logloss:0.19838\tvalid-logloss:0.21849\n",
            "[1200]\ttrain-logloss:0.19280\tvalid-logloss:0.21778\n",
            "[1500]\ttrain-logloss:0.18761\tvalid-logloss:0.21744\n",
            "[1800]\ttrain-logloss:0.18282\tvalid-logloss:0.21723\n",
            "[2100]\ttrain-logloss:0.17824\tvalid-logloss:0.21718\n",
            "[2112]\ttrain-logloss:0.17806\tvalid-logloss:0.21718\n",
            "[06:48:26] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[06:48:26] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.67006\tvalid-logloss:0.67002\n",
            "[300]\ttrain-logloss:0.21556\tvalid-logloss:0.22198\n",
            "[600]\ttrain-logloss:0.20542\tvalid-logloss:0.21788\n",
            "[900]\ttrain-logloss:0.19884\tvalid-logloss:0.21669\n",
            "[1200]\ttrain-logloss:0.19328\tvalid-logloss:0.21629\n",
            "[1500]\ttrain-logloss:0.18812\tvalid-logloss:0.21595\n",
            "[1800]\ttrain-logloss:0.18327\tvalid-logloss:0.21578\n",
            "[1964]\ttrain-logloss:0.18066\tvalid-logloss:0.21577\n",
            "[06:51:17] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[06:51:17] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.67000\tvalid-logloss:0.67008\n",
            "[300]\ttrain-logloss:0.21490\tvalid-logloss:0.22521\n",
            "[600]\ttrain-logloss:0.20452\tvalid-logloss:0.22099\n",
            "[900]\ttrain-logloss:0.19824\tvalid-logloss:0.21980\n",
            "[1200]\ttrain-logloss:0.19242\tvalid-logloss:0.21914\n",
            "[1500]\ttrain-logloss:0.18728\tvalid-logloss:0.21890\n",
            "[1780]\ttrain-logloss:0.18271\tvalid-logloss:0.21884\n",
            "[06:53:51] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[06:53:51] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.66999\tvalid-logloss:0.67015\n",
            "[300]\ttrain-logloss:0.21477\tvalid-logloss:0.22564\n",
            "[600]\ttrain-logloss:0.20442\tvalid-logloss:0.22148\n",
            "[900]\ttrain-logloss:0.19762\tvalid-logloss:0.22031\n",
            "[1200]\ttrain-logloss:0.19211\tvalid-logloss:0.21996\n",
            "[1500]\ttrain-logloss:0.18692\tvalid-logloss:0.21979\n",
            "[1800]\ttrain-logloss:0.18207\tvalid-logloss:0.21968\n",
            "[1869]\ttrain-logloss:0.18102\tvalid-logloss:0.21970\n",
            "[06:56:32] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[06:56:33] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.67002\tvalid-logloss:0.67002\n",
            "[300]\ttrain-logloss:0.21593\tvalid-logloss:0.22221\n",
            "[600]\ttrain-logloss:0.20589\tvalid-logloss:0.21779\n",
            "[900]\ttrain-logloss:0.19927\tvalid-logloss:0.21647\n",
            "[1200]\ttrain-logloss:0.19343\tvalid-logloss:0.21585\n",
            "[1500]\ttrain-logloss:0.18832\tvalid-logloss:0.21549\n",
            "[1800]\ttrain-logloss:0.18346\tvalid-logloss:0.21538\n",
            "[2100]\ttrain-logloss:0.17905\tvalid-logloss:0.21528\n",
            "[2159]\ttrain-logloss:0.17821\tvalid-logloss:0.21528\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-07-01 06:59:22,670]\u001b[0m Trial 1 finished with value: 0.792043560559337 and parameters: {'lambda': 0.016812500015756786, 'alpha': 0.06990510390370101, 'colsample_bytree': 0.8, 'subsample': 1.0, 'learning_rate': 0.037000000000000005, 'n_estimators': 850, 'max_depth': 5, 'min_child_weight': 89}. Best is trial 1 with value: 0.792043560559337.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[06:59:35] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[06:59:35] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.67427\tvalid-logloss:0.67426\n",
            "[300]\ttrain-logloss:0.22969\tvalid-logloss:0.23259\n",
            "[600]\ttrain-logloss:0.22034\tvalid-logloss:0.22504\n",
            "[900]\ttrain-logloss:0.21583\tvalid-logloss:0.22209\n",
            "[1200]\ttrain-logloss:0.21284\tvalid-logloss:0.22053\n",
            "[1500]\ttrain-logloss:0.21040\tvalid-logloss:0.21957\n",
            "[1800]\ttrain-logloss:0.20834\tvalid-logloss:0.21891\n",
            "[2100]\ttrain-logloss:0.20639\tvalid-logloss:0.21849\n",
            "[2400]\ttrain-logloss:0.20464\tvalid-logloss:0.21817\n",
            "[2700]\ttrain-logloss:0.20297\tvalid-logloss:0.21787\n",
            "[3000]\ttrain-logloss:0.20136\tvalid-logloss:0.21763\n",
            "[3300]\ttrain-logloss:0.19977\tvalid-logloss:0.21745\n",
            "[3600]\ttrain-logloss:0.19823\tvalid-logloss:0.21726\n",
            "[3900]\ttrain-logloss:0.19678\tvalid-logloss:0.21713\n",
            "[4153]\ttrain-logloss:0.19556\tvalid-logloss:0.21705\n",
            "[07:04:12] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[07:04:12] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.67430\tvalid-logloss:0.67420\n",
            "[300]\ttrain-logloss:0.23020\tvalid-logloss:0.23056\n",
            "[600]\ttrain-logloss:0.22073\tvalid-logloss:0.22306\n",
            "[900]\ttrain-logloss:0.21623\tvalid-logloss:0.22025\n",
            "[1200]\ttrain-logloss:0.21322\tvalid-logloss:0.21879\n",
            "[1500]\ttrain-logloss:0.21081\tvalid-logloss:0.21795\n",
            "[1800]\ttrain-logloss:0.20870\tvalid-logloss:0.21741\n",
            "[2100]\ttrain-logloss:0.20679\tvalid-logloss:0.21704\n",
            "[2400]\ttrain-logloss:0.20501\tvalid-logloss:0.21678\n",
            "[2700]\ttrain-logloss:0.20332\tvalid-logloss:0.21657\n",
            "[3000]\ttrain-logloss:0.20166\tvalid-logloss:0.21642\n",
            "[3300]\ttrain-logloss:0.20008\tvalid-logloss:0.21630\n",
            "[3600]\ttrain-logloss:0.19856\tvalid-logloss:0.21620\n",
            "[3900]\ttrain-logloss:0.19711\tvalid-logloss:0.21610\n",
            "[4073]\ttrain-logloss:0.19628\tvalid-logloss:0.21610\n",
            "[07:08:40] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[07:08:40] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.67425\tvalid-logloss:0.67433\n",
            "[300]\ttrain-logloss:0.22943\tvalid-logloss:0.23372\n",
            "[600]\ttrain-logloss:0.21993\tvalid-logloss:0.22613\n",
            "[900]\ttrain-logloss:0.21547\tvalid-logloss:0.22335\n",
            "[1200]\ttrain-logloss:0.21239\tvalid-logloss:0.22189\n",
            "[1500]\ttrain-logloss:0.20997\tvalid-logloss:0.22104\n",
            "[1800]\ttrain-logloss:0.20785\tvalid-logloss:0.22043\n",
            "[2100]\ttrain-logloss:0.20598\tvalid-logloss:0.22001\n",
            "[2400]\ttrain-logloss:0.20411\tvalid-logloss:0.21963\n",
            "[2700]\ttrain-logloss:0.20248\tvalid-logloss:0.21937\n",
            "[3000]\ttrain-logloss:0.20086\tvalid-logloss:0.21919\n",
            "[3300]\ttrain-logloss:0.19927\tvalid-logloss:0.21902\n",
            "[3600]\ttrain-logloss:0.19776\tvalid-logloss:0.21891\n",
            "[3900]\ttrain-logloss:0.19628\tvalid-logloss:0.21881\n",
            "[4200]\ttrain-logloss:0.19483\tvalid-logloss:0.21871\n",
            "[4473]\ttrain-logloss:0.19357\tvalid-logloss:0.21870\n",
            "[07:13:31] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[07:13:31] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.67420\tvalid-logloss:0.67431\n",
            "[300]\ttrain-logloss:0.22939\tvalid-logloss:0.23385\n",
            "[600]\ttrain-logloss:0.21985\tvalid-logloss:0.22646\n",
            "[900]\ttrain-logloss:0.21535\tvalid-logloss:0.22377\n",
            "[1200]\ttrain-logloss:0.21229\tvalid-logloss:0.22240\n",
            "[1500]\ttrain-logloss:0.20986\tvalid-logloss:0.22151\n",
            "[1800]\ttrain-logloss:0.20772\tvalid-logloss:0.22094\n",
            "[2100]\ttrain-logloss:0.20578\tvalid-logloss:0.22065\n",
            "[2400]\ttrain-logloss:0.20392\tvalid-logloss:0.22036\n",
            "[2700]\ttrain-logloss:0.20220\tvalid-logloss:0.22017\n",
            "[3000]\ttrain-logloss:0.20055\tvalid-logloss:0.22009\n",
            "[3300]\ttrain-logloss:0.19892\tvalid-logloss:0.21998\n",
            "[3600]\ttrain-logloss:0.19739\tvalid-logloss:0.21994\n",
            "[3603]\ttrain-logloss:0.19738\tvalid-logloss:0.21994\n",
            "[07:17:27] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[07:17:27] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.67428\tvalid-logloss:0.67424\n",
            "[300]\ttrain-logloss:0.23040\tvalid-logloss:0.23074\n",
            "[600]\ttrain-logloss:0.22090\tvalid-logloss:0.22309\n",
            "[900]\ttrain-logloss:0.21640\tvalid-logloss:0.22015\n",
            "[1200]\ttrain-logloss:0.21339\tvalid-logloss:0.21865\n",
            "[1500]\ttrain-logloss:0.21097\tvalid-logloss:0.21779\n",
            "[1800]\ttrain-logloss:0.20886\tvalid-logloss:0.21720\n",
            "[2100]\ttrain-logloss:0.20690\tvalid-logloss:0.21676\n",
            "[2400]\ttrain-logloss:0.20510\tvalid-logloss:0.21647\n",
            "[2700]\ttrain-logloss:0.20343\tvalid-logloss:0.21624\n",
            "[3000]\ttrain-logloss:0.20184\tvalid-logloss:0.21607\n",
            "[3300]\ttrain-logloss:0.20030\tvalid-logloss:0.21589\n",
            "[3600]\ttrain-logloss:0.19880\tvalid-logloss:0.21577\n",
            "[3900]\ttrain-logloss:0.19733\tvalid-logloss:0.21567\n",
            "[4200]\ttrain-logloss:0.19590\tvalid-logloss:0.21556\n",
            "[4500]\ttrain-logloss:0.19446\tvalid-logloss:0.21550\n",
            "[4581]\ttrain-logloss:0.19410\tvalid-logloss:0.21551\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-07-01 07:22:12,056]\u001b[0m Trial 2 finished with value: 0.7919378322941155 and parameters: {'lambda': 0.006988785305159202, 'alpha': 0.5231694699592085, 'colsample_bytree': 0.7, 'subsample': 1.0, 'learning_rate': 0.032, 'n_estimators': 970, 'max_depth': 3, 'min_child_weight': 47}. Best is trial 1 with value: 0.792043560559337.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[07:22:25] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[07:22:25] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68342\tvalid-logloss:0.68345\n",
            "[300]\ttrain-logloss:0.22963\tvalid-logloss:0.23468\n",
            "[600]\ttrain-logloss:0.21626\tvalid-logloss:0.22411\n",
            "[900]\ttrain-logloss:0.21062\tvalid-logloss:0.22095\n",
            "[1200]\ttrain-logloss:0.20672\tvalid-logloss:0.21955\n",
            "[1500]\ttrain-logloss:0.20337\tvalid-logloss:0.21876\n",
            "[1800]\ttrain-logloss:0.20027\tvalid-logloss:0.21827\n",
            "[2100]\ttrain-logloss:0.19743\tvalid-logloss:0.21789\n",
            "[2400]\ttrain-logloss:0.19473\tvalid-logloss:0.21760\n",
            "[2700]\ttrain-logloss:0.19213\tvalid-logloss:0.21740\n",
            "[3000]\ttrain-logloss:0.18962\tvalid-logloss:0.21728\n",
            "[3300]\ttrain-logloss:0.18721\tvalid-logloss:0.21715\n",
            "[3600]\ttrain-logloss:0.18492\tvalid-logloss:0.21706\n",
            "[3900]\ttrain-logloss:0.18268\tvalid-logloss:0.21699\n",
            "[4200]\ttrain-logloss:0.18041\tvalid-logloss:0.21692\n",
            "[4483]\ttrain-logloss:0.17828\tvalid-logloss:0.21684\n",
            "[07:30:22] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[07:30:22] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68350\tvalid-logloss:0.68348\n",
            "[300]\ttrain-logloss:0.23012\tvalid-logloss:0.23250\n",
            "[600]\ttrain-logloss:0.21674\tvalid-logloss:0.22192\n",
            "[900]\ttrain-logloss:0.21111\tvalid-logloss:0.21897\n",
            "[1200]\ttrain-logloss:0.20715\tvalid-logloss:0.21771\n",
            "[1500]\ttrain-logloss:0.20386\tvalid-logloss:0.21698\n",
            "[1800]\ttrain-logloss:0.20081\tvalid-logloss:0.21660\n",
            "[2100]\ttrain-logloss:0.19798\tvalid-logloss:0.21632\n",
            "[2400]\ttrain-logloss:0.19526\tvalid-logloss:0.21613\n",
            "[2700]\ttrain-logloss:0.19269\tvalid-logloss:0.21593\n",
            "[3000]\ttrain-logloss:0.19016\tvalid-logloss:0.21575\n",
            "[3300]\ttrain-logloss:0.18763\tvalid-logloss:0.21571\n",
            "[3600]\ttrain-logloss:0.18528\tvalid-logloss:0.21568\n",
            "[3632]\ttrain-logloss:0.18500\tvalid-logloss:0.21568\n",
            "[07:36:51] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[07:36:51] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68347\tvalid-logloss:0.68352\n",
            "[300]\ttrain-logloss:0.22936\tvalid-logloss:0.23567\n",
            "[600]\ttrain-logloss:0.21592\tvalid-logloss:0.22530\n",
            "[900]\ttrain-logloss:0.21016\tvalid-logloss:0.22232\n",
            "[1200]\ttrain-logloss:0.20620\tvalid-logloss:0.22105\n",
            "[1500]\ttrain-logloss:0.20286\tvalid-logloss:0.22033\n",
            "[1800]\ttrain-logloss:0.19983\tvalid-logloss:0.21985\n",
            "[2100]\ttrain-logloss:0.19700\tvalid-logloss:0.21956\n",
            "[2400]\ttrain-logloss:0.19435\tvalid-logloss:0.21928\n",
            "[2700]\ttrain-logloss:0.19183\tvalid-logloss:0.21916\n",
            "[3000]\ttrain-logloss:0.18925\tvalid-logloss:0.21903\n",
            "[3300]\ttrain-logloss:0.18672\tvalid-logloss:0.21893\n",
            "[3600]\ttrain-logloss:0.18439\tvalid-logloss:0.21888\n",
            "[3652]\ttrain-logloss:0.18398\tvalid-logloss:0.21889\n",
            "[07:43:15] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[07:43:15] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68347\tvalid-logloss:0.68354\n",
            "[300]\ttrain-logloss:0.22926\tvalid-logloss:0.23579\n",
            "[600]\ttrain-logloss:0.21574\tvalid-logloss:0.22543\n",
            "[900]\ttrain-logloss:0.21007\tvalid-logloss:0.22250\n",
            "[1200]\ttrain-logloss:0.20615\tvalid-logloss:0.22130\n",
            "[1500]\ttrain-logloss:0.20272\tvalid-logloss:0.22063\n",
            "[1800]\ttrain-logloss:0.19966\tvalid-logloss:0.22023\n",
            "[2100]\ttrain-logloss:0.19684\tvalid-logloss:0.21992\n",
            "[2400]\ttrain-logloss:0.19405\tvalid-logloss:0.21976\n",
            "[2700]\ttrain-logloss:0.19149\tvalid-logloss:0.21964\n",
            "[3000]\ttrain-logloss:0.18901\tvalid-logloss:0.21955\n",
            "[3300]\ttrain-logloss:0.18663\tvalid-logloss:0.21952\n",
            "[3341]\ttrain-logloss:0.18631\tvalid-logloss:0.21952\n",
            "[07:49:07] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[07:49:07] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68346\tvalid-logloss:0.68348\n",
            "[300]\ttrain-logloss:0.23013\tvalid-logloss:0.23246\n",
            "[600]\ttrain-logloss:0.21676\tvalid-logloss:0.22190\n",
            "[900]\ttrain-logloss:0.21114\tvalid-logloss:0.21893\n",
            "[1200]\ttrain-logloss:0.20721\tvalid-logloss:0.21766\n",
            "[1500]\ttrain-logloss:0.20377\tvalid-logloss:0.21689\n",
            "[1800]\ttrain-logloss:0.20071\tvalid-logloss:0.21643\n",
            "[2100]\ttrain-logloss:0.19788\tvalid-logloss:0.21606\n",
            "[2400]\ttrain-logloss:0.19520\tvalid-logloss:0.21583\n",
            "[2700]\ttrain-logloss:0.19265\tvalid-logloss:0.21563\n",
            "[3000]\ttrain-logloss:0.19007\tvalid-logloss:0.21552\n",
            "[3300]\ttrain-logloss:0.18766\tvalid-logloss:0.21546\n",
            "[3382]\ttrain-logloss:0.18700\tvalid-logloss:0.21547\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-07-01 07:54:52,902]\u001b[0m Trial 3 finished with value: 0.792396678019532 and parameters: {'lambda': 0.017513794796470725, 'alpha': 0.005485920008482219, 'colsample_bytree': 0.8, 'subsample': 0.5, 'learning_rate': 0.015, 'n_estimators': 950, 'max_depth': 7, 'min_child_weight': 222}. Best is trial 3 with value: 0.792396678019532.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[07:55:05] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[07:55:06] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68460\tvalid-logloss:0.68465\n",
            "[300]\ttrain-logloss:0.22391\tvalid-logloss:0.23452\n",
            "[600]\ttrain-logloss:0.20614\tvalid-logloss:0.22273\n",
            "[900]\ttrain-logloss:0.19779\tvalid-logloss:0.21978\n",
            "[1200]\ttrain-logloss:0.19123\tvalid-logloss:0.21851\n",
            "[1500]\ttrain-logloss:0.18529\tvalid-logloss:0.21774\n",
            "[1800]\ttrain-logloss:0.17977\tvalid-logloss:0.21728\n",
            "[2100]\ttrain-logloss:0.17454\tvalid-logloss:0.21689\n",
            "[2400]\ttrain-logloss:0.16971\tvalid-logloss:0.21675\n",
            "[2700]\ttrain-logloss:0.16504\tvalid-logloss:0.21660\n",
            "[3000]\ttrain-logloss:0.16048\tvalid-logloss:0.21651\n",
            "[3300]\ttrain-logloss:0.15605\tvalid-logloss:0.21644\n",
            "[3342]\ttrain-logloss:0.15540\tvalid-logloss:0.21645\n",
            "[08:03:04] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[08:03:04] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68461\tvalid-logloss:0.68462\n",
            "[300]\ttrain-logloss:0.22456\tvalid-logloss:0.23234\n",
            "[600]\ttrain-logloss:0.20668\tvalid-logloss:0.22049\n",
            "[900]\ttrain-logloss:0.19837\tvalid-logloss:0.21777\n",
            "[1200]\ttrain-logloss:0.19175\tvalid-logloss:0.21654\n",
            "[1500]\ttrain-logloss:0.18587\tvalid-logloss:0.21588\n",
            "[1800]\ttrain-logloss:0.18021\tvalid-logloss:0.21552\n",
            "[2100]\ttrain-logloss:0.17507\tvalid-logloss:0.21531\n",
            "[2400]\ttrain-logloss:0.17010\tvalid-logloss:0.21518\n",
            "[2700]\ttrain-logloss:0.16532\tvalid-logloss:0.21508\n",
            "[2916]\ttrain-logloss:0.16211\tvalid-logloss:0.21507\n",
            "[08:10:06] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[08:10:06] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68459\tvalid-logloss:0.68466\n",
            "[300]\ttrain-logloss:0.22375\tvalid-logloss:0.23546\n",
            "[600]\ttrain-logloss:0.20589\tvalid-logloss:0.22395\n",
            "[900]\ttrain-logloss:0.19744\tvalid-logloss:0.22127\n",
            "[1200]\ttrain-logloss:0.19076\tvalid-logloss:0.22012\n",
            "[1500]\ttrain-logloss:0.18498\tvalid-logloss:0.21947\n",
            "[1800]\ttrain-logloss:0.17935\tvalid-logloss:0.21909\n",
            "[2100]\ttrain-logloss:0.17419\tvalid-logloss:0.21887\n",
            "[2400]\ttrain-logloss:0.16930\tvalid-logloss:0.21874\n",
            "[2700]\ttrain-logloss:0.16451\tvalid-logloss:0.21868\n",
            "[3000]\ttrain-logloss:0.15993\tvalid-logloss:0.21858\n",
            "[3150]\ttrain-logloss:0.15772\tvalid-logloss:0.21856\n",
            "[08:17:35] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[08:17:35] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68458\tvalid-logloss:0.68467\n",
            "[300]\ttrain-logloss:0.22360\tvalid-logloss:0.23563\n",
            "[600]\ttrain-logloss:0.20575\tvalid-logloss:0.22430\n",
            "[900]\ttrain-logloss:0.19728\tvalid-logloss:0.22162\n",
            "[1200]\ttrain-logloss:0.19080\tvalid-logloss:0.22048\n",
            "[1500]\ttrain-logloss:0.18486\tvalid-logloss:0.21986\n",
            "[1800]\ttrain-logloss:0.17933\tvalid-logloss:0.21956\n",
            "[2100]\ttrain-logloss:0.17420\tvalid-logloss:0.21934\n",
            "[2400]\ttrain-logloss:0.16933\tvalid-logloss:0.21919\n",
            "[2700]\ttrain-logloss:0.16465\tvalid-logloss:0.21916\n",
            "[2729]\ttrain-logloss:0.16421\tvalid-logloss:0.21916\n",
            "[08:24:05] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[08:24:05] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68460\tvalid-logloss:0.68463\n",
            "[300]\ttrain-logloss:0.22466\tvalid-logloss:0.23240\n",
            "[600]\ttrain-logloss:0.20693\tvalid-logloss:0.22058\n",
            "[900]\ttrain-logloss:0.19861\tvalid-logloss:0.21772\n",
            "[1200]\ttrain-logloss:0.19183\tvalid-logloss:0.21642\n",
            "[1500]\ttrain-logloss:0.18585\tvalid-logloss:0.21573\n",
            "[1800]\ttrain-logloss:0.18032\tvalid-logloss:0.21532\n",
            "[2100]\ttrain-logloss:0.17510\tvalid-logloss:0.21508\n",
            "[2400]\ttrain-logloss:0.17005\tvalid-logloss:0.21491\n",
            "[2700]\ttrain-logloss:0.16532\tvalid-logloss:0.21478\n",
            "[2952]\ttrain-logloss:0.16152\tvalid-logloss:0.21475\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-07-01 08:30:58,267]\u001b[0m Trial 4 finished with value: 0.7928876868966832 and parameters: {'lambda': 0.23146545302192975, 'alpha': 5.788576126592169, 'colsample_bytree': 0.8, 'subsample': 0.8, 'learning_rate': 0.013000000000000001, 'n_estimators': 860, 'max_depth': 10, 'min_child_weight': 153}. Best is trial 4 with value: 0.7928876868966832.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[08:31:10] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[08:31:11] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68649\tvalid-logloss:0.68656\n",
            "[300]\ttrain-logloss:0.23104\tvalid-logloss:0.24366\n",
            "[600]\ttrain-logloss:0.20347\tvalid-logloss:0.22468\n",
            "[900]\ttrain-logloss:0.19162\tvalid-logloss:0.22068\n",
            "[1200]\ttrain-logloss:0.18304\tvalid-logloss:0.21894\n",
            "[1500]\ttrain-logloss:0.17589\tvalid-logloss:0.21795\n",
            "[1800]\ttrain-logloss:0.16965\tvalid-logloss:0.21734\n",
            "[2100]\ttrain-logloss:0.16391\tvalid-logloss:0.21692\n",
            "[2400]\ttrain-logloss:0.15861\tvalid-logloss:0.21670\n",
            "[2700]\ttrain-logloss:0.15363\tvalid-logloss:0.21646\n",
            "[3000]\ttrain-logloss:0.14878\tvalid-logloss:0.21632\n",
            "[3300]\ttrain-logloss:0.14395\tvalid-logloss:0.21621\n",
            "[3600]\ttrain-logloss:0.13940\tvalid-logloss:0.21613\n",
            "[3750]\ttrain-logloss:0.13716\tvalid-logloss:0.21611\n",
            "[08:39:24] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[08:39:25] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68651\tvalid-logloss:0.68653\n",
            "[300]\ttrain-logloss:0.23150\tvalid-logloss:0.24184\n",
            "[600]\ttrain-logloss:0.20388\tvalid-logloss:0.22249\n",
            "[900]\ttrain-logloss:0.19209\tvalid-logloss:0.21865\n",
            "[1200]\ttrain-logloss:0.18345\tvalid-logloss:0.21702\n",
            "[1500]\ttrain-logloss:0.17640\tvalid-logloss:0.21620\n",
            "[1800]\ttrain-logloss:0.16991\tvalid-logloss:0.21567\n",
            "[2100]\ttrain-logloss:0.16417\tvalid-logloss:0.21532\n",
            "[2400]\ttrain-logloss:0.15863\tvalid-logloss:0.21508\n",
            "[2700]\ttrain-logloss:0.15365\tvalid-logloss:0.21499\n",
            "[3000]\ttrain-logloss:0.14884\tvalid-logloss:0.21488\n",
            "[3253]\ttrain-logloss:0.14496\tvalid-logloss:0.21485\n",
            "[08:46:41] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[08:46:42] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68650\tvalid-logloss:0.68656\n",
            "[300]\ttrain-logloss:0.23089\tvalid-logloss:0.24446\n",
            "[600]\ttrain-logloss:0.20321\tvalid-logloss:0.22562\n",
            "[900]\ttrain-logloss:0.19138\tvalid-logloss:0.22192\n",
            "[1200]\ttrain-logloss:0.18287\tvalid-logloss:0.22033\n",
            "[1500]\ttrain-logloss:0.17587\tvalid-logloss:0.21949\n",
            "[1800]\ttrain-logloss:0.16952\tvalid-logloss:0.21895\n",
            "[2100]\ttrain-logloss:0.16376\tvalid-logloss:0.21862\n",
            "[2400]\ttrain-logloss:0.15841\tvalid-logloss:0.21842\n",
            "[2700]\ttrain-logloss:0.15321\tvalid-logloss:0.21826\n",
            "[3000]\ttrain-logloss:0.14834\tvalid-logloss:0.21819\n",
            "[3300]\ttrain-logloss:0.14368\tvalid-logloss:0.21811\n",
            "[3425]\ttrain-logloss:0.14178\tvalid-logloss:0.21811\n",
            "[08:54:12] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[08:54:12] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68649\tvalid-logloss:0.68656\n",
            "[300]\ttrain-logloss:0.23072\tvalid-logloss:0.24451\n",
            "[600]\ttrain-logloss:0.20301\tvalid-logloss:0.22583\n",
            "[900]\ttrain-logloss:0.19116\tvalid-logloss:0.22224\n",
            "[1200]\ttrain-logloss:0.18260\tvalid-logloss:0.22069\n",
            "[1500]\ttrain-logloss:0.17555\tvalid-logloss:0.21983\n",
            "[1800]\ttrain-logloss:0.16918\tvalid-logloss:0.21940\n",
            "[2100]\ttrain-logloss:0.16335\tvalid-logloss:0.21915\n",
            "[2400]\ttrain-logloss:0.15784\tvalid-logloss:0.21894\n",
            "[2700]\ttrain-logloss:0.15244\tvalid-logloss:0.21880\n",
            "[2870]\ttrain-logloss:0.14962\tvalid-logloss:0.21880\n",
            "[09:00:39] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[09:00:40] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68650\tvalid-logloss:0.68653\n",
            "[300]\ttrain-logloss:0.23155\tvalid-logloss:0.24182\n",
            "[600]\ttrain-logloss:0.20393\tvalid-logloss:0.22252\n",
            "[900]\ttrain-logloss:0.19205\tvalid-logloss:0.21866\n",
            "[1200]\ttrain-logloss:0.18357\tvalid-logloss:0.21704\n",
            "[1500]\ttrain-logloss:0.17628\tvalid-logloss:0.21613\n",
            "[1800]\ttrain-logloss:0.17002\tvalid-logloss:0.21558\n",
            "[2100]\ttrain-logloss:0.16442\tvalid-logloss:0.21520\n",
            "[2400]\ttrain-logloss:0.15896\tvalid-logloss:0.21494\n",
            "[2700]\ttrain-logloss:0.15384\tvalid-logloss:0.21476\n",
            "[3000]\ttrain-logloss:0.14886\tvalid-logloss:0.21466\n",
            "[3142]\ttrain-logloss:0.14669\tvalid-logloss:0.21464\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-07-01 09:07:27,939]\u001b[0m Trial 5 finished with value: 0.7938171644083507 and parameters: {'lambda': 1.2133864929301732, 'alpha': 0.07062978137188772, 'colsample_bytree': 0.8, 'subsample': 0.8, 'learning_rate': 0.010000000000000002, 'n_estimators': 230, 'max_depth': 8, 'min_child_weight': 21}. Best is trial 5 with value: 0.7938171644083507.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[09:07:41] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[09:07:41] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68366\tvalid-logloss:0.68367\n",
            "[300]\ttrain-logloss:0.25592\tvalid-logloss:0.25659\n",
            "[600]\ttrain-logloss:0.23731\tvalid-logloss:0.23895\n",
            "[900]\ttrain-logloss:0.23086\tvalid-logloss:0.23305\n",
            "[1200]\ttrain-logloss:0.22714\tvalid-logloss:0.22965\n",
            "[1500]\ttrain-logloss:0.22458\tvalid-logloss:0.22739\n",
            "[1800]\ttrain-logloss:0.22269\tvalid-logloss:0.22579\n",
            "[2100]\ttrain-logloss:0.22120\tvalid-logloss:0.22456\n",
            "[2400]\ttrain-logloss:0.22000\tvalid-logloss:0.22365\n",
            "[2700]\ttrain-logloss:0.21897\tvalid-logloss:0.22288\n",
            "[3000]\ttrain-logloss:0.21810\tvalid-logloss:0.22222\n",
            "[3300]\ttrain-logloss:0.21732\tvalid-logloss:0.22169\n",
            "[3600]\ttrain-logloss:0.21663\tvalid-logloss:0.22124\n",
            "[3900]\ttrain-logloss:0.21601\tvalid-logloss:0.22084\n",
            "[4200]\ttrain-logloss:0.21542\tvalid-logloss:0.22054\n",
            "[4500]\ttrain-logloss:0.21488\tvalid-logloss:0.22025\n",
            "[4800]\ttrain-logloss:0.21437\tvalid-logloss:0.22001\n",
            "[5100]\ttrain-logloss:0.21389\tvalid-logloss:0.21979\n",
            "[5400]\ttrain-logloss:0.21343\tvalid-logloss:0.21960\n",
            "[5700]\ttrain-logloss:0.21299\tvalid-logloss:0.21941\n",
            "[6000]\ttrain-logloss:0.21256\tvalid-logloss:0.21923\n",
            "[6300]\ttrain-logloss:0.21214\tvalid-logloss:0.21907\n",
            "[6600]\ttrain-logloss:0.21174\tvalid-logloss:0.21891\n",
            "[6900]\ttrain-logloss:0.21135\tvalid-logloss:0.21880\n",
            "[7200]\ttrain-logloss:0.21097\tvalid-logloss:0.21868\n",
            "[7500]\ttrain-logloss:0.21060\tvalid-logloss:0.21856\n",
            "[7800]\ttrain-logloss:0.21024\tvalid-logloss:0.21845\n",
            "[8100]\ttrain-logloss:0.20990\tvalid-logloss:0.21834\n",
            "[8400]\ttrain-logloss:0.20956\tvalid-logloss:0.21825\n",
            "[8700]\ttrain-logloss:0.20922\tvalid-logloss:0.21816\n",
            "[9000]\ttrain-logloss:0.20889\tvalid-logloss:0.21810\n",
            "[9300]\ttrain-logloss:0.20858\tvalid-logloss:0.21805\n",
            "[9600]\ttrain-logloss:0.20827\tvalid-logloss:0.21799\n",
            "[9900]\ttrain-logloss:0.20795\tvalid-logloss:0.21792\n",
            "[9998]\ttrain-logloss:0.20785\tvalid-logloss:0.21790\n",
            "[09:17:13] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[09:17:13] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68367\tvalid-logloss:0.68361\n",
            "[300]\ttrain-logloss:0.25625\tvalid-logloss:0.25487\n",
            "[600]\ttrain-logloss:0.23776\tvalid-logloss:0.23690\n",
            "[900]\ttrain-logloss:0.23135\tvalid-logloss:0.23089\n",
            "[1200]\ttrain-logloss:0.22757\tvalid-logloss:0.22750\n",
            "[1500]\ttrain-logloss:0.22502\tvalid-logloss:0.22529\n",
            "[1800]\ttrain-logloss:0.22314\tvalid-logloss:0.22373\n",
            "[2100]\ttrain-logloss:0.22165\tvalid-logloss:0.22255\n",
            "[2400]\ttrain-logloss:0.22043\tvalid-logloss:0.22163\n",
            "[2700]\ttrain-logloss:0.21938\tvalid-logloss:0.22088\n",
            "[3000]\ttrain-logloss:0.21848\tvalid-logloss:0.22029\n",
            "[3300]\ttrain-logloss:0.21770\tvalid-logloss:0.21979\n",
            "[3600]\ttrain-logloss:0.21701\tvalid-logloss:0.21939\n",
            "[3900]\ttrain-logloss:0.21638\tvalid-logloss:0.21904\n",
            "[4200]\ttrain-logloss:0.21579\tvalid-logloss:0.21876\n",
            "[4500]\ttrain-logloss:0.21522\tvalid-logloss:0.21849\n",
            "[4800]\ttrain-logloss:0.21468\tvalid-logloss:0.21823\n",
            "[5100]\ttrain-logloss:0.21418\tvalid-logloss:0.21803\n",
            "[5400]\ttrain-logloss:0.21371\tvalid-logloss:0.21786\n",
            "[5700]\ttrain-logloss:0.21325\tvalid-logloss:0.21769\n",
            "[6000]\ttrain-logloss:0.21281\tvalid-logloss:0.21756\n",
            "[6300]\ttrain-logloss:0.21240\tvalid-logloss:0.21743\n",
            "[6600]\ttrain-logloss:0.21199\tvalid-logloss:0.21731\n",
            "[6900]\ttrain-logloss:0.21162\tvalid-logloss:0.21721\n",
            "[7200]\ttrain-logloss:0.21123\tvalid-logloss:0.21710\n",
            "[7500]\ttrain-logloss:0.21085\tvalid-logloss:0.21700\n",
            "[7800]\ttrain-logloss:0.21051\tvalid-logloss:0.21691\n",
            "[8100]\ttrain-logloss:0.21016\tvalid-logloss:0.21686\n",
            "[8400]\ttrain-logloss:0.20981\tvalid-logloss:0.21679\n",
            "[8700]\ttrain-logloss:0.20948\tvalid-logloss:0.21670\n",
            "[9000]\ttrain-logloss:0.20914\tvalid-logloss:0.21664\n",
            "[9300]\ttrain-logloss:0.20881\tvalid-logloss:0.21658\n",
            "[9600]\ttrain-logloss:0.20850\tvalid-logloss:0.21653\n",
            "[9900]\ttrain-logloss:0.20819\tvalid-logloss:0.21648\n",
            "[9998]\ttrain-logloss:0.20808\tvalid-logloss:0.21646\n",
            "[09:26:45] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[09:26:45] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68364\tvalid-logloss:0.68369\n",
            "[300]\ttrain-logloss:0.25562\tvalid-logloss:0.25773\n",
            "[600]\ttrain-logloss:0.23702\tvalid-logloss:0.23976\n",
            "[900]\ttrain-logloss:0.23064\tvalid-logloss:0.23397\n",
            "[1200]\ttrain-logloss:0.22688\tvalid-logloss:0.23068\n",
            "[1500]\ttrain-logloss:0.22428\tvalid-logloss:0.22843\n",
            "[1800]\ttrain-logloss:0.22239\tvalid-logloss:0.22688\n",
            "[2100]\ttrain-logloss:0.22093\tvalid-logloss:0.22571\n",
            "[2400]\ttrain-logloss:0.21970\tvalid-logloss:0.22477\n",
            "[2700]\ttrain-logloss:0.21869\tvalid-logloss:0.22407\n",
            "[3000]\ttrain-logloss:0.21778\tvalid-logloss:0.22345\n",
            "[3300]\ttrain-logloss:0.21699\tvalid-logloss:0.22294\n",
            "[3600]\ttrain-logloss:0.21629\tvalid-logloss:0.22254\n",
            "[3900]\ttrain-logloss:0.21565\tvalid-logloss:0.22218\n",
            "[4200]\ttrain-logloss:0.21504\tvalid-logloss:0.22186\n",
            "[4500]\ttrain-logloss:0.21450\tvalid-logloss:0.22162\n",
            "[4800]\ttrain-logloss:0.21397\tvalid-logloss:0.22137\n",
            "[5100]\ttrain-logloss:0.21350\tvalid-logloss:0.22117\n",
            "[5400]\ttrain-logloss:0.21304\tvalid-logloss:0.22099\n",
            "[5700]\ttrain-logloss:0.21259\tvalid-logloss:0.22082\n",
            "[6000]\ttrain-logloss:0.21215\tvalid-logloss:0.22067\n",
            "[6300]\ttrain-logloss:0.21173\tvalid-logloss:0.22052\n",
            "[6600]\ttrain-logloss:0.21134\tvalid-logloss:0.22040\n",
            "[6900]\ttrain-logloss:0.21096\tvalid-logloss:0.22029\n",
            "[7200]\ttrain-logloss:0.21058\tvalid-logloss:0.22020\n",
            "[7500]\ttrain-logloss:0.21022\tvalid-logloss:0.22011\n",
            "[7800]\ttrain-logloss:0.20987\tvalid-logloss:0.22001\n",
            "[8100]\ttrain-logloss:0.20952\tvalid-logloss:0.21991\n",
            "[8400]\ttrain-logloss:0.20918\tvalid-logloss:0.21982\n",
            "[8700]\ttrain-logloss:0.20884\tvalid-logloss:0.21972\n",
            "[9000]\ttrain-logloss:0.20851\tvalid-logloss:0.21965\n",
            "[9300]\ttrain-logloss:0.20819\tvalid-logloss:0.21957\n",
            "[9600]\ttrain-logloss:0.20787\tvalid-logloss:0.21952\n",
            "[9900]\ttrain-logloss:0.20756\tvalid-logloss:0.21948\n",
            "[9998]\ttrain-logloss:0.20746\tvalid-logloss:0.21947\n",
            "[09:36:07] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[09:36:07] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68364\tvalid-logloss:0.68370\n",
            "[300]\ttrain-logloss:0.25557\tvalid-logloss:0.25823\n",
            "[600]\ttrain-logloss:0.23708\tvalid-logloss:0.24005\n",
            "[900]\ttrain-logloss:0.23059\tvalid-logloss:0.23395\n",
            "[1200]\ttrain-logloss:0.22678\tvalid-logloss:0.23063\n",
            "[1500]\ttrain-logloss:0.22414\tvalid-logloss:0.22847\n",
            "[1800]\ttrain-logloss:0.22221\tvalid-logloss:0.22697\n",
            "[2100]\ttrain-logloss:0.22073\tvalid-logloss:0.22588\n",
            "[2400]\ttrain-logloss:0.21952\tvalid-logloss:0.22502\n",
            "[2700]\ttrain-logloss:0.21847\tvalid-logloss:0.22434\n",
            "[3000]\ttrain-logloss:0.21759\tvalid-logloss:0.22377\n",
            "[3300]\ttrain-logloss:0.21679\tvalid-logloss:0.22329\n",
            "[3600]\ttrain-logloss:0.21611\tvalid-logloss:0.22289\n",
            "[3900]\ttrain-logloss:0.21546\tvalid-logloss:0.22254\n",
            "[4200]\ttrain-logloss:0.21488\tvalid-logloss:0.22225\n",
            "[4500]\ttrain-logloss:0.21433\tvalid-logloss:0.22199\n",
            "[4800]\ttrain-logloss:0.21381\tvalid-logloss:0.22177\n",
            "[5100]\ttrain-logloss:0.21332\tvalid-logloss:0.22158\n",
            "[5400]\ttrain-logloss:0.21285\tvalid-logloss:0.22142\n",
            "[5700]\ttrain-logloss:0.21241\tvalid-logloss:0.22127\n",
            "[6000]\ttrain-logloss:0.21198\tvalid-logloss:0.22114\n",
            "[6300]\ttrain-logloss:0.21156\tvalid-logloss:0.22102\n",
            "[6600]\ttrain-logloss:0.21116\tvalid-logloss:0.22092\n",
            "[6900]\ttrain-logloss:0.21076\tvalid-logloss:0.22080\n",
            "[7200]\ttrain-logloss:0.21037\tvalid-logloss:0.22071\n",
            "[7500]\ttrain-logloss:0.21000\tvalid-logloss:0.22061\n",
            "[7800]\ttrain-logloss:0.20963\tvalid-logloss:0.22052\n",
            "[8100]\ttrain-logloss:0.20928\tvalid-logloss:0.22043\n",
            "[8400]\ttrain-logloss:0.20892\tvalid-logloss:0.22035\n",
            "[8700]\ttrain-logloss:0.20858\tvalid-logloss:0.22029\n",
            "[9000]\ttrain-logloss:0.20826\tvalid-logloss:0.22025\n",
            "[9300]\ttrain-logloss:0.20793\tvalid-logloss:0.22021\n",
            "[9600]\ttrain-logloss:0.20760\tvalid-logloss:0.22017\n",
            "[9900]\ttrain-logloss:0.20728\tvalid-logloss:0.22013\n",
            "[9998]\ttrain-logloss:0.20718\tvalid-logloss:0.22012\n",
            "[09:45:19] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[09:45:19] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68365\tvalid-logloss:0.68363\n",
            "[300]\ttrain-logloss:0.25640\tvalid-logloss:0.25542\n",
            "[600]\ttrain-logloss:0.23787\tvalid-logloss:0.23714\n",
            "[900]\ttrain-logloss:0.23148\tvalid-logloss:0.23109\n",
            "[1200]\ttrain-logloss:0.22775\tvalid-logloss:0.22764\n",
            "[1500]\ttrain-logloss:0.22518\tvalid-logloss:0.22538\n",
            "[1800]\ttrain-logloss:0.22329\tvalid-logloss:0.22375\n",
            "[2100]\ttrain-logloss:0.22181\tvalid-logloss:0.22257\n",
            "[2400]\ttrain-logloss:0.22057\tvalid-logloss:0.22159\n",
            "[2700]\ttrain-logloss:0.21954\tvalid-logloss:0.22085\n",
            "[3000]\ttrain-logloss:0.21865\tvalid-logloss:0.22024\n",
            "[3300]\ttrain-logloss:0.21786\tvalid-logloss:0.21969\n",
            "[3600]\ttrain-logloss:0.21717\tvalid-logloss:0.21929\n",
            "[3900]\ttrain-logloss:0.21651\tvalid-logloss:0.21890\n",
            "[4200]\ttrain-logloss:0.21593\tvalid-logloss:0.21861\n",
            "[4500]\ttrain-logloss:0.21535\tvalid-logloss:0.21829\n",
            "[4800]\ttrain-logloss:0.21484\tvalid-logloss:0.21807\n",
            "[5100]\ttrain-logloss:0.21435\tvalid-logloss:0.21788\n",
            "[5400]\ttrain-logloss:0.21388\tvalid-logloss:0.21766\n",
            "[5700]\ttrain-logloss:0.21342\tvalid-logloss:0.21748\n",
            "[6000]\ttrain-logloss:0.21299\tvalid-logloss:0.21731\n",
            "[6300]\ttrain-logloss:0.21258\tvalid-logloss:0.21718\n",
            "[6600]\ttrain-logloss:0.21218\tvalid-logloss:0.21705\n",
            "[6900]\ttrain-logloss:0.21181\tvalid-logloss:0.21695\n",
            "[7200]\ttrain-logloss:0.21144\tvalid-logloss:0.21683\n",
            "[7500]\ttrain-logloss:0.21108\tvalid-logloss:0.21673\n",
            "[7800]\ttrain-logloss:0.21073\tvalid-logloss:0.21664\n",
            "[8100]\ttrain-logloss:0.21038\tvalid-logloss:0.21654\n",
            "[8400]\ttrain-logloss:0.21003\tvalid-logloss:0.21646\n",
            "[8700]\ttrain-logloss:0.20970\tvalid-logloss:0.21638\n",
            "[9000]\ttrain-logloss:0.20937\tvalid-logloss:0.21632\n",
            "[9300]\ttrain-logloss:0.20905\tvalid-logloss:0.21624\n",
            "[9600]\ttrain-logloss:0.20873\tvalid-logloss:0.21617\n",
            "[9900]\ttrain-logloss:0.20842\tvalid-logloss:0.21611\n",
            "[9998]\ttrain-logloss:0.20832\tvalid-logloss:0.21608\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-07-01 09:54:46,336]\u001b[0m Trial 6 finished with value: 0.791331256970088 and parameters: {'lambda': 0.017713544659322473, 'alpha': 4.104097538044086, 'colsample_bytree': 0.7, 'subsample': 0.8, 'learning_rate': 0.017, 'n_estimators': 920, 'max_depth': 2, 'min_child_weight': 167}. Best is trial 5 with value: 0.7938171644083507.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[09:55:00] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[09:55:00] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.69181\tvalid-logloss:0.69182\n",
            "[300]\ttrain-logloss:0.44281\tvalid-logloss:0.44464\n",
            "[600]\ttrain-logloss:0.33680\tvalid-logloss:0.34017\n",
            "[900]\ttrain-logloss:0.28451\tvalid-logloss:0.28911\n",
            "[1200]\ttrain-logloss:0.25690\tvalid-logloss:0.26265\n",
            "[1500]\ttrain-logloss:0.24135\tvalid-logloss:0.24813\n",
            "[1800]\ttrain-logloss:0.23212\tvalid-logloss:0.23983\n",
            "[2100]\ttrain-logloss:0.22623\tvalid-logloss:0.23481\n",
            "[2400]\ttrain-logloss:0.22212\tvalid-logloss:0.23157\n",
            "[2700]\ttrain-logloss:0.21889\tvalid-logloss:0.22928\n",
            "[3000]\ttrain-logloss:0.21622\tvalid-logloss:0.22754\n",
            "[3300]\ttrain-logloss:0.21398\tvalid-logloss:0.22621\n",
            "[3600]\ttrain-logloss:0.21205\tvalid-logloss:0.22514\n",
            "[3900]\ttrain-logloss:0.21034\tvalid-logloss:0.22426\n",
            "[4200]\ttrain-logloss:0.20878\tvalid-logloss:0.22350\n",
            "[4500]\ttrain-logloss:0.20735\tvalid-logloss:0.22285\n",
            "[4800]\ttrain-logloss:0.20604\tvalid-logloss:0.22228\n",
            "[5100]\ttrain-logloss:0.20479\tvalid-logloss:0.22178\n",
            "[5400]\ttrain-logloss:0.20362\tvalid-logloss:0.22134\n",
            "[5700]\ttrain-logloss:0.20247\tvalid-logloss:0.22092\n",
            "[6000]\ttrain-logloss:0.20135\tvalid-logloss:0.22055\n",
            "[6300]\ttrain-logloss:0.20030\tvalid-logloss:0.22022\n",
            "[6600]\ttrain-logloss:0.19929\tvalid-logloss:0.21993\n",
            "[6900]\ttrain-logloss:0.19828\tvalid-logloss:0.21966\n",
            "[7200]\ttrain-logloss:0.19733\tvalid-logloss:0.21942\n",
            "[7500]\ttrain-logloss:0.19638\tvalid-logloss:0.21920\n",
            "[7800]\ttrain-logloss:0.19549\tvalid-logloss:0.21901\n",
            "[8100]\ttrain-logloss:0.19462\tvalid-logloss:0.21882\n",
            "[8400]\ttrain-logloss:0.19376\tvalid-logloss:0.21865\n",
            "[8700]\ttrain-logloss:0.19292\tvalid-logloss:0.21850\n",
            "[9000]\ttrain-logloss:0.19205\tvalid-logloss:0.21836\n",
            "[9300]\ttrain-logloss:0.19124\tvalid-logloss:0.21823\n",
            "[9600]\ttrain-logloss:0.19045\tvalid-logloss:0.21810\n",
            "[9900]\ttrain-logloss:0.18966\tvalid-logloss:0.21799\n",
            "[9998]\ttrain-logloss:0.18940\tvalid-logloss:0.21795\n",
            "[10:15:09] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[10:15:09] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.69181\tvalid-logloss:0.69181\n",
            "[300]\ttrain-logloss:0.44304\tvalid-logloss:0.44386\n",
            "[600]\ttrain-logloss:0.33710\tvalid-logloss:0.33880\n",
            "[900]\ttrain-logloss:0.28492\tvalid-logloss:0.28760\n",
            "[1200]\ttrain-logloss:0.25724\tvalid-logloss:0.26093\n",
            "[1500]\ttrain-logloss:0.24168\tvalid-logloss:0.24626\n",
            "[1800]\ttrain-logloss:0.23251\tvalid-logloss:0.23791\n",
            "[2100]\ttrain-logloss:0.22665\tvalid-logloss:0.23280\n",
            "[2400]\ttrain-logloss:0.22255\tvalid-logloss:0.22948\n",
            "[2700]\ttrain-logloss:0.21936\tvalid-logloss:0.22714\n",
            "[3000]\ttrain-logloss:0.21667\tvalid-logloss:0.22540\n",
            "[3300]\ttrain-logloss:0.21444\tvalid-logloss:0.22406\n",
            "[3600]\ttrain-logloss:0.21249\tvalid-logloss:0.22299\n",
            "[3900]\ttrain-logloss:0.21078\tvalid-logloss:0.22211\n",
            "[4200]\ttrain-logloss:0.20925\tvalid-logloss:0.22138\n",
            "[4500]\ttrain-logloss:0.20785\tvalid-logloss:0.22076\n",
            "[4800]\ttrain-logloss:0.20654\tvalid-logloss:0.22021\n",
            "[5100]\ttrain-logloss:0.20533\tvalid-logloss:0.21974\n",
            "[5400]\ttrain-logloss:0.20412\tvalid-logloss:0.21931\n",
            "[5700]\ttrain-logloss:0.20301\tvalid-logloss:0.21893\n",
            "[6000]\ttrain-logloss:0.20192\tvalid-logloss:0.21859\n",
            "[6300]\ttrain-logloss:0.20089\tvalid-logloss:0.21829\n",
            "[6600]\ttrain-logloss:0.19985\tvalid-logloss:0.21802\n",
            "[6900]\ttrain-logloss:0.19884\tvalid-logloss:0.21778\n",
            "[7200]\ttrain-logloss:0.19788\tvalid-logloss:0.21756\n",
            "[7500]\ttrain-logloss:0.19692\tvalid-logloss:0.21736\n",
            "[7800]\ttrain-logloss:0.19603\tvalid-logloss:0.21718\n",
            "[8100]\ttrain-logloss:0.19515\tvalid-logloss:0.21703\n",
            "[8400]\ttrain-logloss:0.19428\tvalid-logloss:0.21688\n",
            "[8700]\ttrain-logloss:0.19342\tvalid-logloss:0.21675\n",
            "[9000]\ttrain-logloss:0.19254\tvalid-logloss:0.21662\n",
            "[9300]\ttrain-logloss:0.19173\tvalid-logloss:0.21651\n",
            "[9600]\ttrain-logloss:0.19094\tvalid-logloss:0.21640\n",
            "[9900]\ttrain-logloss:0.19011\tvalid-logloss:0.21630\n",
            "[9998]\ttrain-logloss:0.18986\tvalid-logloss:0.21627\n",
            "[10:35:15] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[10:35:15] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.69182\tvalid-logloss:0.69183\n",
            "[300]\ttrain-logloss:0.44281\tvalid-logloss:0.44494\n",
            "[600]\ttrain-logloss:0.33671\tvalid-logloss:0.34057\n",
            "[900]\ttrain-logloss:0.28436\tvalid-logloss:0.28980\n",
            "[1200]\ttrain-logloss:0.25664\tvalid-logloss:0.26336\n",
            "[1500]\ttrain-logloss:0.24107\tvalid-logloss:0.24894\n",
            "[1800]\ttrain-logloss:0.23185\tvalid-logloss:0.24072\n",
            "[2100]\ttrain-logloss:0.22598\tvalid-logloss:0.23576\n",
            "[2400]\ttrain-logloss:0.22188\tvalid-logloss:0.23255\n",
            "[2700]\ttrain-logloss:0.21865\tvalid-logloss:0.23026\n",
            "[3000]\ttrain-logloss:0.21600\tvalid-logloss:0.22855\n",
            "[3300]\ttrain-logloss:0.21378\tvalid-logloss:0.22725\n",
            "[3600]\ttrain-logloss:0.21185\tvalid-logloss:0.22620\n",
            "[3900]\ttrain-logloss:0.21016\tvalid-logloss:0.22536\n",
            "[4200]\ttrain-logloss:0.20863\tvalid-logloss:0.22465\n",
            "[4500]\ttrain-logloss:0.20722\tvalid-logloss:0.22405\n",
            "[4800]\ttrain-logloss:0.20591\tvalid-logloss:0.22351\n",
            "[5100]\ttrain-logloss:0.20468\tvalid-logloss:0.22303\n",
            "[5400]\ttrain-logloss:0.20352\tvalid-logloss:0.22262\n",
            "[5700]\ttrain-logloss:0.20240\tvalid-logloss:0.22225\n",
            "[6000]\ttrain-logloss:0.20132\tvalid-logloss:0.22190\n",
            "[6300]\ttrain-logloss:0.20027\tvalid-logloss:0.22160\n",
            "[6600]\ttrain-logloss:0.19925\tvalid-logloss:0.22133\n",
            "[6900]\ttrain-logloss:0.19823\tvalid-logloss:0.22107\n",
            "[7200]\ttrain-logloss:0.19726\tvalid-logloss:0.22086\n",
            "[7500]\ttrain-logloss:0.19630\tvalid-logloss:0.22065\n",
            "[7800]\ttrain-logloss:0.19542\tvalid-logloss:0.22047\n",
            "[8100]\ttrain-logloss:0.19453\tvalid-logloss:0.22031\n",
            "[8400]\ttrain-logloss:0.19366\tvalid-logloss:0.22016\n",
            "[8700]\ttrain-logloss:0.19282\tvalid-logloss:0.22001\n",
            "[9000]\ttrain-logloss:0.19197\tvalid-logloss:0.21988\n",
            "[9300]\ttrain-logloss:0.19117\tvalid-logloss:0.21976\n",
            "[9600]\ttrain-logloss:0.19037\tvalid-logloss:0.21965\n",
            "[9900]\ttrain-logloss:0.18960\tvalid-logloss:0.21955\n",
            "[9998]\ttrain-logloss:0.18934\tvalid-logloss:0.21952\n",
            "[10:55:02] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[10:55:02] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.69181\tvalid-logloss:0.69182\n",
            "[300]\ttrain-logloss:0.44279\tvalid-logloss:0.44519\n",
            "[600]\ttrain-logloss:0.33667\tvalid-logloss:0.34089\n",
            "[900]\ttrain-logloss:0.28437\tvalid-logloss:0.29008\n",
            "[1200]\ttrain-logloss:0.25665\tvalid-logloss:0.26365\n",
            "[1500]\ttrain-logloss:0.24104\tvalid-logloss:0.24911\n",
            "[1800]\ttrain-logloss:0.23178\tvalid-logloss:0.24083\n",
            "[2100]\ttrain-logloss:0.22594\tvalid-logloss:0.23590\n",
            "[2400]\ttrain-logloss:0.22182\tvalid-logloss:0.23268\n",
            "[2700]\ttrain-logloss:0.21859\tvalid-logloss:0.23038\n",
            "[3000]\ttrain-logloss:0.21585\tvalid-logloss:0.22865\n",
            "[3300]\ttrain-logloss:0.21364\tvalid-logloss:0.22737\n",
            "[3600]\ttrain-logloss:0.21173\tvalid-logloss:0.22635\n",
            "[3900]\ttrain-logloss:0.21001\tvalid-logloss:0.22552\n",
            "[4200]\ttrain-logloss:0.20847\tvalid-logloss:0.22485\n",
            "[4500]\ttrain-logloss:0.20709\tvalid-logloss:0.22426\n",
            "[4800]\ttrain-logloss:0.20579\tvalid-logloss:0.22376\n",
            "[5100]\ttrain-logloss:0.20456\tvalid-logloss:0.22330\n",
            "[5400]\ttrain-logloss:0.20339\tvalid-logloss:0.22290\n",
            "[5700]\ttrain-logloss:0.20226\tvalid-logloss:0.22254\n",
            "[6000]\ttrain-logloss:0.20117\tvalid-logloss:0.22221\n",
            "[6300]\ttrain-logloss:0.20011\tvalid-logloss:0.22192\n",
            "[6600]\ttrain-logloss:0.19910\tvalid-logloss:0.22166\n",
            "[6900]\ttrain-logloss:0.19813\tvalid-logloss:0.22143\n",
            "[7200]\ttrain-logloss:0.19715\tvalid-logloss:0.22121\n",
            "[7500]\ttrain-logloss:0.19624\tvalid-logloss:0.22103\n",
            "[7800]\ttrain-logloss:0.19532\tvalid-logloss:0.22085\n",
            "[8100]\ttrain-logloss:0.19444\tvalid-logloss:0.22068\n",
            "[8400]\ttrain-logloss:0.19357\tvalid-logloss:0.22054\n",
            "[8700]\ttrain-logloss:0.19272\tvalid-logloss:0.22040\n",
            "[9000]\ttrain-logloss:0.19190\tvalid-logloss:0.22028\n",
            "[9300]\ttrain-logloss:0.19110\tvalid-logloss:0.22017\n",
            "[9600]\ttrain-logloss:0.19031\tvalid-logloss:0.22006\n",
            "[9900]\ttrain-logloss:0.18951\tvalid-logloss:0.21997\n",
            "[9998]\ttrain-logloss:0.18925\tvalid-logloss:0.21994\n",
            "[11:14:49] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[11:14:49] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.69182\tvalid-logloss:0.69182\n",
            "[300]\ttrain-logloss:0.44320\tvalid-logloss:0.44393\n",
            "[600]\ttrain-logloss:0.33721\tvalid-logloss:0.33889\n",
            "[900]\ttrain-logloss:0.28504\tvalid-logloss:0.28765\n",
            "[1200]\ttrain-logloss:0.25739\tvalid-logloss:0.26089\n",
            "[1500]\ttrain-logloss:0.24187\tvalid-logloss:0.24623\n",
            "[1800]\ttrain-logloss:0.23270\tvalid-logloss:0.23784\n",
            "[2100]\ttrain-logloss:0.22686\tvalid-logloss:0.23274\n",
            "[2400]\ttrain-logloss:0.22273\tvalid-logloss:0.22942\n",
            "[2700]\ttrain-logloss:0.21953\tvalid-logloss:0.22710\n",
            "[3000]\ttrain-logloss:0.21686\tvalid-logloss:0.22535\n",
            "[3300]\ttrain-logloss:0.21465\tvalid-logloss:0.22401\n",
            "[3600]\ttrain-logloss:0.21273\tvalid-logloss:0.22295\n",
            "[3900]\ttrain-logloss:0.21102\tvalid-logloss:0.22207\n",
            "[4200]\ttrain-logloss:0.20948\tvalid-logloss:0.22134\n",
            "[4500]\ttrain-logloss:0.20808\tvalid-logloss:0.22072\n",
            "[4800]\ttrain-logloss:0.20675\tvalid-logloss:0.22017\n",
            "[5100]\ttrain-logloss:0.20554\tvalid-logloss:0.21970\n",
            "[5400]\ttrain-logloss:0.20438\tvalid-logloss:0.21926\n",
            "[5700]\ttrain-logloss:0.20327\tvalid-logloss:0.21888\n",
            "[6000]\ttrain-logloss:0.20220\tvalid-logloss:0.21854\n",
            "[6300]\ttrain-logloss:0.20114\tvalid-logloss:0.21823\n",
            "[6600]\ttrain-logloss:0.20013\tvalid-logloss:0.21794\n",
            "[6900]\ttrain-logloss:0.19915\tvalid-logloss:0.21768\n",
            "[7200]\ttrain-logloss:0.19823\tvalid-logloss:0.21745\n",
            "[7500]\ttrain-logloss:0.19731\tvalid-logloss:0.21725\n",
            "[7800]\ttrain-logloss:0.19641\tvalid-logloss:0.21706\n",
            "[8100]\ttrain-logloss:0.19549\tvalid-logloss:0.21688\n",
            "[8400]\ttrain-logloss:0.19462\tvalid-logloss:0.21670\n",
            "[8700]\ttrain-logloss:0.19374\tvalid-logloss:0.21655\n",
            "[9000]\ttrain-logloss:0.19289\tvalid-logloss:0.21641\n",
            "[9300]\ttrain-logloss:0.19209\tvalid-logloss:0.21628\n",
            "[9600]\ttrain-logloss:0.19123\tvalid-logloss:0.21616\n",
            "[9900]\ttrain-logloss:0.19044\tvalid-logloss:0.21605\n",
            "[9998]\ttrain-logloss:0.19016\tvalid-logloss:0.21601\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-07-01 11:34:31,920]\u001b[0m Trial 7 finished with value: 0.7917555106062141 and parameters: {'lambda': 0.0017450663135313543, 'alpha': 8.871020877983462, 'colsample_bytree': 0.9, 'subsample': 0.9, 'learning_rate': 0.002, 'n_estimators': 230, 'max_depth': 7, 'min_child_weight': 59}. Best is trial 5 with value: 0.7938171644083507.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[11:34:45] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[11:34:45] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.69184\tvalid-logloss:0.69184\n",
            "[300]\ttrain-logloss:0.44418\tvalid-logloss:0.44537\n",
            "[600]\ttrain-logloss:0.33814\tvalid-logloss:0.34041\n",
            "[900]\ttrain-logloss:0.28585\tvalid-logloss:0.28906\n",
            "[1200]\ttrain-logloss:0.25811\tvalid-logloss:0.26219\n",
            "[1500]\ttrain-logloss:0.24253\tvalid-logloss:0.24744\n",
            "[1800]\ttrain-logloss:0.23337\tvalid-logloss:0.23905\n",
            "[2100]\ttrain-logloss:0.22762\tvalid-logloss:0.23401\n",
            "[2400]\ttrain-logloss:0.22381\tvalid-logloss:0.23081\n",
            "[2700]\ttrain-logloss:0.22098\tvalid-logloss:0.22858\n",
            "[3000]\ttrain-logloss:0.21871\tvalid-logloss:0.22689\n",
            "[3300]\ttrain-logloss:0.21687\tvalid-logloss:0.22557\n",
            "[3600]\ttrain-logloss:0.21529\tvalid-logloss:0.22451\n",
            "[3900]\ttrain-logloss:0.21392\tvalid-logloss:0.22365\n",
            "[4200]\ttrain-logloss:0.21270\tvalid-logloss:0.22292\n",
            "[4500]\ttrain-logloss:0.21156\tvalid-logloss:0.22230\n",
            "[4800]\ttrain-logloss:0.21054\tvalid-logloss:0.22176\n",
            "[5100]\ttrain-logloss:0.20957\tvalid-logloss:0.22131\n",
            "[5400]\ttrain-logloss:0.20864\tvalid-logloss:0.22090\n",
            "[5700]\ttrain-logloss:0.20777\tvalid-logloss:0.22055\n",
            "[6000]\ttrain-logloss:0.20695\tvalid-logloss:0.22024\n",
            "[6300]\ttrain-logloss:0.20615\tvalid-logloss:0.21997\n",
            "[6600]\ttrain-logloss:0.20537\tvalid-logloss:0.21973\n",
            "[6900]\ttrain-logloss:0.20462\tvalid-logloss:0.21951\n",
            "[7200]\ttrain-logloss:0.20390\tvalid-logloss:0.21930\n",
            "[7500]\ttrain-logloss:0.20319\tvalid-logloss:0.21912\n",
            "[7800]\ttrain-logloss:0.20250\tvalid-logloss:0.21894\n",
            "[8100]\ttrain-logloss:0.20181\tvalid-logloss:0.21880\n",
            "[8400]\ttrain-logloss:0.20113\tvalid-logloss:0.21865\n",
            "[8700]\ttrain-logloss:0.20047\tvalid-logloss:0.21851\n",
            "[9000]\ttrain-logloss:0.19982\tvalid-logloss:0.21839\n",
            "[9300]\ttrain-logloss:0.19918\tvalid-logloss:0.21827\n",
            "[9600]\ttrain-logloss:0.19855\tvalid-logloss:0.21816\n",
            "[9900]\ttrain-logloss:0.19793\tvalid-logloss:0.21805\n",
            "[9998]\ttrain-logloss:0.19773\tvalid-logloss:0.21801\n",
            "[11:56:12] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[11:56:12] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.69185\tvalid-logloss:0.69185\n",
            "[300]\ttrain-logloss:0.44447\tvalid-logloss:0.44472\n",
            "[600]\ttrain-logloss:0.33857\tvalid-logloss:0.33931\n",
            "[900]\ttrain-logloss:0.28634\tvalid-logloss:0.28767\n",
            "[1200]\ttrain-logloss:0.25859\tvalid-logloss:0.26057\n",
            "[1500]\ttrain-logloss:0.24300\tvalid-logloss:0.24562\n",
            "[1800]\ttrain-logloss:0.23382\tvalid-logloss:0.23705\n",
            "[2100]\ttrain-logloss:0.22809\tvalid-logloss:0.23187\n",
            "[2400]\ttrain-logloss:0.22424\tvalid-logloss:0.22857\n",
            "[2700]\ttrain-logloss:0.22142\tvalid-logloss:0.22630\n",
            "[3000]\ttrain-logloss:0.21916\tvalid-logloss:0.22459\n",
            "[3300]\ttrain-logloss:0.21729\tvalid-logloss:0.22326\n",
            "[3600]\ttrain-logloss:0.21573\tvalid-logloss:0.22223\n",
            "[3900]\ttrain-logloss:0.21436\tvalid-logloss:0.22139\n",
            "[4200]\ttrain-logloss:0.21311\tvalid-logloss:0.22068\n",
            "[4500]\ttrain-logloss:0.21198\tvalid-logloss:0.22012\n",
            "[4800]\ttrain-logloss:0.21093\tvalid-logloss:0.21963\n",
            "[5100]\ttrain-logloss:0.20997\tvalid-logloss:0.21920\n",
            "[5400]\ttrain-logloss:0.20902\tvalid-logloss:0.21885\n",
            "[5700]\ttrain-logloss:0.20816\tvalid-logloss:0.21852\n",
            "[6000]\ttrain-logloss:0.20733\tvalid-logloss:0.21825\n",
            "[6300]\ttrain-logloss:0.20653\tvalid-logloss:0.21800\n",
            "[6600]\ttrain-logloss:0.20575\tvalid-logloss:0.21778\n",
            "[6900]\ttrain-logloss:0.20499\tvalid-logloss:0.21759\n",
            "[7200]\ttrain-logloss:0.20425\tvalid-logloss:0.21741\n",
            "[7500]\ttrain-logloss:0.20354\tvalid-logloss:0.21725\n",
            "[7800]\ttrain-logloss:0.20284\tvalid-logloss:0.21711\n",
            "[8100]\ttrain-logloss:0.20217\tvalid-logloss:0.21697\n",
            "[8400]\ttrain-logloss:0.20150\tvalid-logloss:0.21686\n",
            "[8700]\ttrain-logloss:0.20084\tvalid-logloss:0.21674\n",
            "[9000]\ttrain-logloss:0.20021\tvalid-logloss:0.21665\n",
            "[9300]\ttrain-logloss:0.19957\tvalid-logloss:0.21654\n",
            "[9600]\ttrain-logloss:0.19893\tvalid-logloss:0.21645\n",
            "[9900]\ttrain-logloss:0.19833\tvalid-logloss:0.21636\n",
            "[9998]\ttrain-logloss:0.19813\tvalid-logloss:0.21634\n",
            "[12:17:37] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[12:17:37] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.69184\tvalid-logloss:0.69185\n",
            "[300]\ttrain-logloss:0.44415\tvalid-logloss:0.44583\n",
            "[600]\ttrain-logloss:0.33805\tvalid-logloss:0.34103\n",
            "[900]\ttrain-logloss:0.28566\tvalid-logloss:0.28985\n",
            "[1200]\ttrain-logloss:0.25788\tvalid-logloss:0.26310\n",
            "[1500]\ttrain-logloss:0.24229\tvalid-logloss:0.24844\n",
            "[1800]\ttrain-logloss:0.23312\tvalid-logloss:0.24009\n",
            "[2100]\ttrain-logloss:0.22734\tvalid-logloss:0.23510\n",
            "[2400]\ttrain-logloss:0.22349\tvalid-logloss:0.23195\n",
            "[2700]\ttrain-logloss:0.22065\tvalid-logloss:0.22974\n",
            "[3000]\ttrain-logloss:0.21838\tvalid-logloss:0.22808\n",
            "[3300]\ttrain-logloss:0.21652\tvalid-logloss:0.22681\n",
            "[3600]\ttrain-logloss:0.21493\tvalid-logloss:0.22581\n",
            "[3900]\ttrain-logloss:0.21352\tvalid-logloss:0.22499\n",
            "[4200]\ttrain-logloss:0.21229\tvalid-logloss:0.22430\n",
            "[4500]\ttrain-logloss:0.21117\tvalid-logloss:0.22373\n",
            "[4800]\ttrain-logloss:0.21014\tvalid-logloss:0.22325\n",
            "[5100]\ttrain-logloss:0.20914\tvalid-logloss:0.22281\n",
            "[5400]\ttrain-logloss:0.20822\tvalid-logloss:0.22244\n",
            "[5700]\ttrain-logloss:0.20734\tvalid-logloss:0.22212\n",
            "[6000]\ttrain-logloss:0.20649\tvalid-logloss:0.22184\n",
            "[6300]\ttrain-logloss:0.20568\tvalid-logloss:0.22158\n",
            "[6600]\ttrain-logloss:0.20491\tvalid-logloss:0.22136\n",
            "[6900]\ttrain-logloss:0.20415\tvalid-logloss:0.22116\n",
            "[7200]\ttrain-logloss:0.20341\tvalid-logloss:0.22098\n",
            "[7500]\ttrain-logloss:0.20269\tvalid-logloss:0.22081\n",
            "[7800]\ttrain-logloss:0.20199\tvalid-logloss:0.22065\n",
            "[8100]\ttrain-logloss:0.20131\tvalid-logloss:0.22051\n",
            "[8400]\ttrain-logloss:0.20064\tvalid-logloss:0.22037\n",
            "[8700]\ttrain-logloss:0.19998\tvalid-logloss:0.22025\n",
            "[9000]\ttrain-logloss:0.19933\tvalid-logloss:0.22014\n",
            "[9300]\ttrain-logloss:0.19870\tvalid-logloss:0.22004\n",
            "[9600]\ttrain-logloss:0.19807\tvalid-logloss:0.21994\n",
            "[9900]\ttrain-logloss:0.19745\tvalid-logloss:0.21985\n",
            "[9998]\ttrain-logloss:0.19725\tvalid-logloss:0.21983\n",
            "[12:38:53] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[12:38:53] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.69184\tvalid-logloss:0.69185\n",
            "[300]\ttrain-logloss:0.44413\tvalid-logloss:0.44616\n",
            "[600]\ttrain-logloss:0.33802\tvalid-logloss:0.34150\n",
            "[900]\ttrain-logloss:0.28569\tvalid-logloss:0.29027\n",
            "[1200]\ttrain-logloss:0.25793\tvalid-logloss:0.26347\n",
            "[1500]\ttrain-logloss:0.24234\tvalid-logloss:0.24871\n",
            "[1800]\ttrain-logloss:0.23311\tvalid-logloss:0.24029\n",
            "[2100]\ttrain-logloss:0.22735\tvalid-logloss:0.23523\n",
            "[2400]\ttrain-logloss:0.22350\tvalid-logloss:0.23206\n",
            "[2700]\ttrain-logloss:0.22065\tvalid-logloss:0.22985\n",
            "[3000]\ttrain-logloss:0.21836\tvalid-logloss:0.22819\n",
            "[3300]\ttrain-logloss:0.21649\tvalid-logloss:0.22693\n",
            "[3600]\ttrain-logloss:0.21489\tvalid-logloss:0.22593\n",
            "[3900]\ttrain-logloss:0.21349\tvalid-logloss:0.22512\n",
            "[4200]\ttrain-logloss:0.21224\tvalid-logloss:0.22444\n",
            "[4500]\ttrain-logloss:0.21111\tvalid-logloss:0.22387\n",
            "[4800]\ttrain-logloss:0.21004\tvalid-logloss:0.22339\n",
            "[5100]\ttrain-logloss:0.20906\tvalid-logloss:0.22298\n",
            "[5400]\ttrain-logloss:0.20813\tvalid-logloss:0.22262\n",
            "[5700]\ttrain-logloss:0.20726\tvalid-logloss:0.22231\n",
            "[6000]\ttrain-logloss:0.20643\tvalid-logloss:0.22202\n",
            "[6300]\ttrain-logloss:0.20564\tvalid-logloss:0.22178\n",
            "[6600]\ttrain-logloss:0.20486\tvalid-logloss:0.22156\n",
            "[6900]\ttrain-logloss:0.20411\tvalid-logloss:0.22138\n",
            "[7200]\ttrain-logloss:0.20337\tvalid-logloss:0.22120\n",
            "[7500]\ttrain-logloss:0.20266\tvalid-logloss:0.22105\n",
            "[7800]\ttrain-logloss:0.20197\tvalid-logloss:0.22091\n",
            "[8100]\ttrain-logloss:0.20129\tvalid-logloss:0.22077\n",
            "[8400]\ttrain-logloss:0.20063\tvalid-logloss:0.22064\n",
            "[8700]\ttrain-logloss:0.19996\tvalid-logloss:0.22053\n",
            "[9000]\ttrain-logloss:0.19932\tvalid-logloss:0.22043\n",
            "[9300]\ttrain-logloss:0.19869\tvalid-logloss:0.22033\n",
            "[9600]\ttrain-logloss:0.19807\tvalid-logloss:0.22024\n",
            "[9900]\ttrain-logloss:0.19746\tvalid-logloss:0.22016\n",
            "[9998]\ttrain-logloss:0.19726\tvalid-logloss:0.22014\n",
            "[13:00:06] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[13:00:06] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.69184\tvalid-logloss:0.69184\n",
            "[300]\ttrain-logloss:0.44451\tvalid-logloss:0.44470\n",
            "[600]\ttrain-logloss:0.33868\tvalid-logloss:0.33942\n",
            "[900]\ttrain-logloss:0.28642\tvalid-logloss:0.28778\n",
            "[1200]\ttrain-logloss:0.25867\tvalid-logloss:0.26066\n",
            "[1500]\ttrain-logloss:0.24315\tvalid-logloss:0.24575\n",
            "[1800]\ttrain-logloss:0.23399\tvalid-logloss:0.23716\n",
            "[2100]\ttrain-logloss:0.22824\tvalid-logloss:0.23200\n",
            "[2400]\ttrain-logloss:0.22442\tvalid-logloss:0.22872\n",
            "[2700]\ttrain-logloss:0.22158\tvalid-logloss:0.22644\n",
            "[3000]\ttrain-logloss:0.21935\tvalid-logloss:0.22476\n",
            "[3300]\ttrain-logloss:0.21749\tvalid-logloss:0.22344\n",
            "[3600]\ttrain-logloss:0.21592\tvalid-logloss:0.22240\n",
            "[3900]\ttrain-logloss:0.21454\tvalid-logloss:0.22155\n",
            "[4200]\ttrain-logloss:0.21330\tvalid-logloss:0.22084\n",
            "[4500]\ttrain-logloss:0.21218\tvalid-logloss:0.22024\n",
            "[4800]\ttrain-logloss:0.21112\tvalid-logloss:0.21973\n",
            "[5100]\ttrain-logloss:0.21014\tvalid-logloss:0.21929\n",
            "[5400]\ttrain-logloss:0.20922\tvalid-logloss:0.21891\n",
            "[5700]\ttrain-logloss:0.20833\tvalid-logloss:0.21856\n",
            "[6000]\ttrain-logloss:0.20749\tvalid-logloss:0.21827\n",
            "[6300]\ttrain-logloss:0.20667\tvalid-logloss:0.21800\n",
            "[6600]\ttrain-logloss:0.20591\tvalid-logloss:0.21777\n",
            "[6900]\ttrain-logloss:0.20516\tvalid-logloss:0.21754\n",
            "[7200]\ttrain-logloss:0.20443\tvalid-logloss:0.21735\n",
            "[7500]\ttrain-logloss:0.20371\tvalid-logloss:0.21716\n",
            "[7800]\ttrain-logloss:0.20300\tvalid-logloss:0.21700\n",
            "[8100]\ttrain-logloss:0.20233\tvalid-logloss:0.21685\n",
            "[8400]\ttrain-logloss:0.20166\tvalid-logloss:0.21671\n",
            "[8700]\ttrain-logloss:0.20098\tvalid-logloss:0.21659\n",
            "[9000]\ttrain-logloss:0.20033\tvalid-logloss:0.21648\n",
            "[9300]\ttrain-logloss:0.19970\tvalid-logloss:0.21637\n",
            "[9600]\ttrain-logloss:0.19907\tvalid-logloss:0.21626\n",
            "[9900]\ttrain-logloss:0.19845\tvalid-logloss:0.21617\n",
            "[9998]\ttrain-logloss:0.19826\tvalid-logloss:0.21614\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-07-01 13:21:13,569]\u001b[0m Trial 8 finished with value: 0.7915764917448348 and parameters: {'lambda': 2.047429960080577, 'alpha': 1.2906829207072164, 'colsample_bytree': 0.7, 'subsample': 0.5, 'learning_rate': 0.002, 'n_estimators': 390, 'max_depth': 10, 'min_child_weight': 205}. Best is trial 5 with value: 0.7938171644083507.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[13:21:27] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[13:21:27] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.67960\tvalid-logloss:0.67963\n",
            "[300]\ttrain-logloss:0.22448\tvalid-logloss:0.23059\n",
            "[600]\ttrain-logloss:0.21157\tvalid-logloss:0.22248\n",
            "[900]\ttrain-logloss:0.20457\tvalid-logloss:0.21975\n",
            "[1200]\ttrain-logloss:0.19925\tvalid-logloss:0.21843\n",
            "[1500]\ttrain-logloss:0.19466\tvalid-logloss:0.21769\n",
            "[1800]\ttrain-logloss:0.19040\tvalid-logloss:0.21725\n",
            "[2100]\ttrain-logloss:0.18640\tvalid-logloss:0.21687\n",
            "[2400]\ttrain-logloss:0.18264\tvalid-logloss:0.21665\n",
            "[2700]\ttrain-logloss:0.17900\tvalid-logloss:0.21651\n",
            "[3000]\ttrain-logloss:0.17552\tvalid-logloss:0.21633\n",
            "[3300]\ttrain-logloss:0.17213\tvalid-logloss:0.21627\n",
            "[3351]\ttrain-logloss:0.17152\tvalid-logloss:0.21628\n",
            "[13:26:17] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[13:26:17] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.67962\tvalid-logloss:0.67961\n",
            "[300]\ttrain-logloss:0.22493\tvalid-logloss:0.22869\n",
            "[600]\ttrain-logloss:0.21186\tvalid-logloss:0.22076\n",
            "[900]\ttrain-logloss:0.20486\tvalid-logloss:0.21830\n",
            "[1200]\ttrain-logloss:0.19942\tvalid-logloss:0.21707\n",
            "[1500]\ttrain-logloss:0.19481\tvalid-logloss:0.21649\n",
            "[1800]\ttrain-logloss:0.19054\tvalid-logloss:0.21606\n",
            "[2100]\ttrain-logloss:0.18656\tvalid-logloss:0.21577\n",
            "[2400]\ttrain-logloss:0.18279\tvalid-logloss:0.21557\n",
            "[2596]\ttrain-logloss:0.18043\tvalid-logloss:0.21556\n",
            "[13:30:10] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[13:30:10] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.67962\tvalid-logloss:0.67970\n",
            "[300]\ttrain-logloss:0.22421\tvalid-logloss:0.23155\n",
            "[600]\ttrain-logloss:0.21113\tvalid-logloss:0.22369\n",
            "[900]\ttrain-logloss:0.20410\tvalid-logloss:0.22119\n",
            "[1200]\ttrain-logloss:0.19870\tvalid-logloss:0.22010\n",
            "[1500]\ttrain-logloss:0.19421\tvalid-logloss:0.21946\n",
            "[1800]\ttrain-logloss:0.18995\tvalid-logloss:0.21910\n",
            "[2100]\ttrain-logloss:0.18594\tvalid-logloss:0.21887\n",
            "[2400]\ttrain-logloss:0.18209\tvalid-logloss:0.21870\n",
            "[2700]\ttrain-logloss:0.17859\tvalid-logloss:0.21851\n",
            "[3000]\ttrain-logloss:0.17509\tvalid-logloss:0.21839\n",
            "[3229]\ttrain-logloss:0.17248\tvalid-logloss:0.21838\n",
            "[13:34:45] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[13:34:45] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.67960\tvalid-logloss:0.67968\n",
            "[300]\ttrain-logloss:0.22415\tvalid-logloss:0.23153\n",
            "[600]\ttrain-logloss:0.21106\tvalid-logloss:0.22392\n",
            "[900]\ttrain-logloss:0.20405\tvalid-logloss:0.22149\n",
            "[1200]\ttrain-logloss:0.19860\tvalid-logloss:0.22042\n",
            "[1500]\ttrain-logloss:0.19384\tvalid-logloss:0.21981\n",
            "[1800]\ttrain-logloss:0.18968\tvalid-logloss:0.21948\n",
            "[2100]\ttrain-logloss:0.18563\tvalid-logloss:0.21932\n",
            "[2400]\ttrain-logloss:0.18179\tvalid-logloss:0.21916\n",
            "[2623]\ttrain-logloss:0.17895\tvalid-logloss:0.21912\n",
            "[13:38:33] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[13:38:33] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.67964\tvalid-logloss:0.67961\n",
            "[300]\ttrain-logloss:0.22524\tvalid-logloss:0.22863\n",
            "[600]\ttrain-logloss:0.21206\tvalid-logloss:0.22061\n",
            "[900]\ttrain-logloss:0.20501\tvalid-logloss:0.21796\n",
            "[1200]\ttrain-logloss:0.19974\tvalid-logloss:0.21680\n",
            "[1500]\ttrain-logloss:0.19514\tvalid-logloss:0.21611\n",
            "[1800]\ttrain-logloss:0.19086\tvalid-logloss:0.21567\n",
            "[2100]\ttrain-logloss:0.18709\tvalid-logloss:0.21539\n",
            "[2400]\ttrain-logloss:0.18328\tvalid-logloss:0.21513\n",
            "[2700]\ttrain-logloss:0.17958\tvalid-logloss:0.21496\n",
            "[3000]\ttrain-logloss:0.17611\tvalid-logloss:0.21487\n",
            "[3268]\ttrain-logloss:0.17305\tvalid-logloss:0.21480\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-07-01 13:42:58,249]\u001b[0m Trial 9 finished with value: 0.7927954536294124 and parameters: {'lambda': 0.04910349517082459, 'alpha': 0.20777245156779073, 'colsample_bytree': 0.9, 'subsample': 0.8, 'learning_rate': 0.021, 'n_estimators': 930, 'max_depth': 5, 'min_child_weight': 24}. Best is trial 5 with value: 0.7938171644083507.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[13:43:11] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[13:43:11] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.67498\tvalid-logloss:0.67508\n",
            "[300]\ttrain-logloss:0.20557\tvalid-logloss:0.22200\n",
            "[600]\ttrain-logloss:0.19120\tvalid-logloss:0.21804\n",
            "[900]\ttrain-logloss:0.18006\tvalid-logloss:0.21716\n",
            "[1200]\ttrain-logloss:0.17083\tvalid-logloss:0.21665\n",
            "[1500]\ttrain-logloss:0.16242\tvalid-logloss:0.21650\n",
            "[1715]\ttrain-logloss:0.15654\tvalid-logloss:0.21648\n",
            "[13:46:50] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[13:46:51] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.67506\tvalid-logloss:0.67510\n",
            "[300]\ttrain-logloss:0.20595\tvalid-logloss:0.21985\n",
            "[600]\ttrain-logloss:0.19160\tvalid-logloss:0.21642\n",
            "[900]\ttrain-logloss:0.18092\tvalid-logloss:0.21549\n",
            "[1200]\ttrain-logloss:0.17110\tvalid-logloss:0.21527\n",
            "[1336]\ttrain-logloss:0.16698\tvalid-logloss:0.21533\n",
            "[13:49:47] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[13:49:47] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.67493\tvalid-logloss:0.67508\n",
            "[300]\ttrain-logloss:0.20513\tvalid-logloss:0.22318\n",
            "[600]\ttrain-logloss:0.19066\tvalid-logloss:0.21980\n",
            "[900]\ttrain-logloss:0.17999\tvalid-logloss:0.21886\n",
            "[1200]\ttrain-logloss:0.17055\tvalid-logloss:0.21846\n",
            "[1394]\ttrain-logloss:0.16469\tvalid-logloss:0.21841\n",
            "[13:52:46] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[13:52:47] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.67497\tvalid-logloss:0.67516\n",
            "[300]\ttrain-logloss:0.20509\tvalid-logloss:0.22359\n",
            "[600]\ttrain-logloss:0.19074\tvalid-logloss:0.22027\n",
            "[900]\ttrain-logloss:0.18032\tvalid-logloss:0.21950\n",
            "[1200]\ttrain-logloss:0.17087\tvalid-logloss:0.21934\n",
            "[1284]\ttrain-logloss:0.16853\tvalid-logloss:0.21935\n",
            "[13:55:32] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[13:55:32] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.67500\tvalid-logloss:0.67503\n",
            "[300]\ttrain-logloss:0.20626\tvalid-logloss:0.21976\n",
            "[600]\ttrain-logloss:0.19175\tvalid-logloss:0.21619\n",
            "[900]\ttrain-logloss:0.18087\tvalid-logloss:0.21516\n",
            "[1200]\ttrain-logloss:0.17141\tvalid-logloss:0.21483\n",
            "[1500]\ttrain-logloss:0.16274\tvalid-logloss:0.21469\n",
            "[1620]\ttrain-logloss:0.15933\tvalid-logloss:0.21471\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-07-01 13:58:45,870]\u001b[0m Trial 10 finished with value: 0.7931458880896914 and parameters: {'lambda': 9.496391067231826, 'alpha': 0.04100140855291813, 'colsample_bytree': 0.5, 'subsample': 0.7, 'learning_rate': 0.028, 'n_estimators': 100, 'max_depth': 9, 'min_child_weight': 108}. Best is trial 5 with value: 0.7938171644083507.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[13:58:59] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[13:58:59] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.67434\tvalid-logloss:0.67444\n",
            "[300]\ttrain-logloss:0.20471\tvalid-logloss:0.22161\n",
            "[600]\ttrain-logloss:0.19031\tvalid-logloss:0.21796\n",
            "[900]\ttrain-logloss:0.17918\tvalid-logloss:0.21696\n",
            "[1200]\ttrain-logloss:0.16966\tvalid-logloss:0.21665\n",
            "[1500]\ttrain-logloss:0.16087\tvalid-logloss:0.21654\n",
            "[1573]\ttrain-logloss:0.15883\tvalid-logloss:0.21658\n",
            "[14:02:21] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[14:02:21] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.67441\tvalid-logloss:0.67447\n",
            "[300]\ttrain-logloss:0.20516\tvalid-logloss:0.21934\n",
            "[600]\ttrain-logloss:0.19065\tvalid-logloss:0.21610\n",
            "[900]\ttrain-logloss:0.17961\tvalid-logloss:0.21532\n",
            "[1200]\ttrain-logloss:0.16971\tvalid-logloss:0.21514\n",
            "[1286]\ttrain-logloss:0.16721\tvalid-logloss:0.21516\n",
            "[14:05:10] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[14:05:10] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.67428\tvalid-logloss:0.67443\n",
            "[300]\ttrain-logloss:0.20446\tvalid-logloss:0.22309\n",
            "[600]\ttrain-logloss:0.18984\tvalid-logloss:0.21976\n",
            "[900]\ttrain-logloss:0.17880\tvalid-logloss:0.21901\n",
            "[1200]\ttrain-logloss:0.16905\tvalid-logloss:0.21878\n",
            "[1468]\ttrain-logloss:0.16080\tvalid-logloss:0.21871\n",
            "[14:08:18] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[14:08:18] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.67433\tvalid-logloss:0.67452\n",
            "[300]\ttrain-logloss:0.20427\tvalid-logloss:0.22309\n",
            "[600]\ttrain-logloss:0.18978\tvalid-logloss:0.21988\n",
            "[900]\ttrain-logloss:0.17897\tvalid-logloss:0.21930\n",
            "[1091]\ttrain-logloss:0.17271\tvalid-logloss:0.21926\n",
            "[14:10:41] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[14:10:41] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.67433\tvalid-logloss:0.67437\n",
            "[300]\ttrain-logloss:0.20547\tvalid-logloss:0.21962\n",
            "[600]\ttrain-logloss:0.19067\tvalid-logloss:0.21627\n",
            "[900]\ttrain-logloss:0.17967\tvalid-logloss:0.21531\n",
            "[1200]\ttrain-logloss:0.16980\tvalid-logloss:0.21503\n",
            "[1383]\ttrain-logloss:0.16408\tvalid-logloss:0.21497\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-07-01 14:13:28,528]\u001b[0m Trial 11 finished with value: 0.7927708363297638 and parameters: {'lambda': 9.374190357127842, 'alpha': 0.036198714186781764, 'colsample_bytree': 0.5, 'subsample': 0.7, 'learning_rate': 0.029, 'n_estimators': 120, 'max_depth': 9, 'min_child_weight': 107}. Best is trial 5 with value: 0.7938171644083507.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[14:13:41] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[14:13:41] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.66255\tvalid-logloss:0.66278\n",
            "[300]\ttrain-logloss:0.16673\tvalid-logloss:0.21921\n",
            "[600]\ttrain-logloss:0.13158\tvalid-logloss:0.21842\n",
            "[630]\ttrain-logloss:0.12845\tvalid-logloss:0.21851\n",
            "[14:15:19] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[14:15:19] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.66262\tvalid-logloss:0.66276\n",
            "[300]\ttrain-logloss:0.16722\tvalid-logloss:0.21725\n",
            "[600]\ttrain-logloss:0.13169\tvalid-logloss:0.21679\n",
            "[632]\ttrain-logloss:0.12851\tvalid-logloss:0.21681\n",
            "[14:16:56] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[14:16:56] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.66250\tvalid-logloss:0.66283\n",
            "[300]\ttrain-logloss:0.16590\tvalid-logloss:0.22122\n",
            "[600]\ttrain-logloss:0.13077\tvalid-logloss:0.22070\n",
            "[618]\ttrain-logloss:0.12914\tvalid-logloss:0.22071\n",
            "[14:18:30] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[14:18:30] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.66253\tvalid-logloss:0.66287\n",
            "[300]\ttrain-logloss:0.16564\tvalid-logloss:0.22163\n",
            "[574]\ttrain-logloss:0.13273\tvalid-logloss:0.22128\n",
            "[14:19:59] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[14:19:59] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.66259\tvalid-logloss:0.66277\n",
            "[300]\ttrain-logloss:0.16725\tvalid-logloss:0.21751\n",
            "[600]\ttrain-logloss:0.13220\tvalid-logloss:0.21698\n",
            "[603]\ttrain-logloss:0.13184\tvalid-logloss:0.21701\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-07-01 14:21:19,841]\u001b[0m Trial 12 finished with value: 0.7902586346234852 and parameters: {'lambda': 0.9765751912823211, 'alpha': 0.023222702322783444, 'colsample_bytree': 0.5, 'subsample': 0.7, 'learning_rate': 0.047, 'n_estimators': 580, 'max_depth': 8, 'min_child_weight': 3}. Best is trial 5 with value: 0.7938171644083507.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[14:21:32] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[14:21:33] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68731\tvalid-logloss:0.68733\n",
            "[300]\ttrain-logloss:0.25056\tvalid-logloss:0.25482\n",
            "[600]\ttrain-logloss:0.22244\tvalid-logloss:0.22951\n",
            "[900]\ttrain-logloss:0.21484\tvalid-logloss:0.22404\n",
            "[1200]\ttrain-logloss:0.21036\tvalid-logloss:0.22152\n",
            "[1500]\ttrain-logloss:0.20695\tvalid-logloss:0.22011\n",
            "[1800]\ttrain-logloss:0.20410\tvalid-logloss:0.21925\n",
            "[2100]\ttrain-logloss:0.20144\tvalid-logloss:0.21862\n",
            "[2400]\ttrain-logloss:0.19904\tvalid-logloss:0.21820\n",
            "[2700]\ttrain-logloss:0.19679\tvalid-logloss:0.21782\n",
            "[3000]\ttrain-logloss:0.19460\tvalid-logloss:0.21752\n",
            "[3300]\ttrain-logloss:0.19248\tvalid-logloss:0.21732\n",
            "[3600]\ttrain-logloss:0.19047\tvalid-logloss:0.21710\n",
            "[3900]\ttrain-logloss:0.18845\tvalid-logloss:0.21694\n",
            "[4200]\ttrain-logloss:0.18650\tvalid-logloss:0.21686\n",
            "[4500]\ttrain-logloss:0.18458\tvalid-logloss:0.21680\n",
            "[4800]\ttrain-logloss:0.18268\tvalid-logloss:0.21669\n",
            "[5100]\ttrain-logloss:0.18082\tvalid-logloss:0.21662\n",
            "[5400]\ttrain-logloss:0.17907\tvalid-logloss:0.21655\n",
            "[5700]\ttrain-logloss:0.17732\tvalid-logloss:0.21649\n",
            "[6000]\ttrain-logloss:0.17557\tvalid-logloss:0.21645\n",
            "[6133]\ttrain-logloss:0.17481\tvalid-logloss:0.21645\n",
            "[14:33:32] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[14:33:32] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68736\tvalid-logloss:0.68735\n",
            "[300]\ttrain-logloss:0.25099\tvalid-logloss:0.25304\n",
            "[600]\ttrain-logloss:0.22284\tvalid-logloss:0.22716\n",
            "[900]\ttrain-logloss:0.21526\tvalid-logloss:0.22169\n",
            "[1200]\ttrain-logloss:0.21085\tvalid-logloss:0.21937\n",
            "[1500]\ttrain-logloss:0.20741\tvalid-logloss:0.21812\n",
            "[1800]\ttrain-logloss:0.20450\tvalid-logloss:0.21736\n",
            "[2100]\ttrain-logloss:0.20189\tvalid-logloss:0.21685\n",
            "[2400]\ttrain-logloss:0.19949\tvalid-logloss:0.21652\n",
            "[2700]\ttrain-logloss:0.19718\tvalid-logloss:0.21625\n",
            "[3000]\ttrain-logloss:0.19496\tvalid-logloss:0.21604\n",
            "[3300]\ttrain-logloss:0.19286\tvalid-logloss:0.21589\n",
            "[3600]\ttrain-logloss:0.19082\tvalid-logloss:0.21578\n",
            "[3900]\ttrain-logloss:0.18877\tvalid-logloss:0.21570\n",
            "[4200]\ttrain-logloss:0.18687\tvalid-logloss:0.21564\n",
            "[4500]\ttrain-logloss:0.18495\tvalid-logloss:0.21557\n",
            "[4686]\ttrain-logloss:0.18377\tvalid-logloss:0.21556\n",
            "[14:43:00] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[14:43:00] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68732\tvalid-logloss:0.68736\n",
            "[300]\ttrain-logloss:0.25029\tvalid-logloss:0.25576\n",
            "[600]\ttrain-logloss:0.22201\tvalid-logloss:0.23066\n",
            "[900]\ttrain-logloss:0.21445\tvalid-logloss:0.22540\n",
            "[1200]\ttrain-logloss:0.20997\tvalid-logloss:0.22309\n",
            "[1500]\ttrain-logloss:0.20653\tvalid-logloss:0.22184\n",
            "[1800]\ttrain-logloss:0.20362\tvalid-logloss:0.22101\n",
            "[2100]\ttrain-logloss:0.20106\tvalid-logloss:0.22046\n",
            "[2400]\ttrain-logloss:0.19864\tvalid-logloss:0.22003\n",
            "[2700]\ttrain-logloss:0.19629\tvalid-logloss:0.21973\n",
            "[3000]\ttrain-logloss:0.19409\tvalid-logloss:0.21947\n",
            "[3300]\ttrain-logloss:0.19193\tvalid-logloss:0.21927\n",
            "[3600]\ttrain-logloss:0.18989\tvalid-logloss:0.21915\n",
            "[3900]\ttrain-logloss:0.18782\tvalid-logloss:0.21905\n",
            "[4200]\ttrain-logloss:0.18584\tvalid-logloss:0.21891\n",
            "[4500]\ttrain-logloss:0.18390\tvalid-logloss:0.21879\n",
            "[4800]\ttrain-logloss:0.18201\tvalid-logloss:0.21874\n",
            "[5100]\ttrain-logloss:0.18016\tvalid-logloss:0.21866\n",
            "[5200]\ttrain-logloss:0.17955\tvalid-logloss:0.21867\n",
            "[14:53:01] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[14:53:01] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68734\tvalid-logloss:0.68738\n",
            "[300]\ttrain-logloss:0.25018\tvalid-logloss:0.25597\n",
            "[600]\ttrain-logloss:0.22202\tvalid-logloss:0.23072\n",
            "[900]\ttrain-logloss:0.21433\tvalid-logloss:0.22545\n",
            "[1200]\ttrain-logloss:0.20986\tvalid-logloss:0.22313\n",
            "[1500]\ttrain-logloss:0.20643\tvalid-logloss:0.22194\n",
            "[1800]\ttrain-logloss:0.20359\tvalid-logloss:0.22111\n",
            "[2100]\ttrain-logloss:0.20096\tvalid-logloss:0.22062\n",
            "[2400]\ttrain-logloss:0.19855\tvalid-logloss:0.22025\n",
            "[2700]\ttrain-logloss:0.19628\tvalid-logloss:0.21998\n",
            "[3000]\ttrain-logloss:0.19410\tvalid-logloss:0.21978\n",
            "[3300]\ttrain-logloss:0.19199\tvalid-logloss:0.21964\n",
            "[3600]\ttrain-logloss:0.18989\tvalid-logloss:0.21951\n",
            "[3900]\ttrain-logloss:0.18792\tvalid-logloss:0.21941\n",
            "[4200]\ttrain-logloss:0.18593\tvalid-logloss:0.21934\n",
            "[4500]\ttrain-logloss:0.18402\tvalid-logloss:0.21929\n",
            "[4657]\ttrain-logloss:0.18307\tvalid-logloss:0.21927\n",
            "[15:02:06] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[15:02:06] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68732\tvalid-logloss:0.68733\n",
            "[300]\ttrain-logloss:0.25111\tvalid-logloss:0.25314\n",
            "[600]\ttrain-logloss:0.22305\tvalid-logloss:0.22737\n",
            "[900]\ttrain-logloss:0.21539\tvalid-logloss:0.22188\n",
            "[1200]\ttrain-logloss:0.21099\tvalid-logloss:0.21947\n",
            "[1500]\ttrain-logloss:0.20753\tvalid-logloss:0.21813\n",
            "[1800]\ttrain-logloss:0.20463\tvalid-logloss:0.21728\n",
            "[2100]\ttrain-logloss:0.20195\tvalid-logloss:0.21671\n",
            "[2400]\ttrain-logloss:0.19956\tvalid-logloss:0.21628\n",
            "[2700]\ttrain-logloss:0.19721\tvalid-logloss:0.21598\n",
            "[3000]\ttrain-logloss:0.19504\tvalid-logloss:0.21572\n",
            "[3300]\ttrain-logloss:0.19289\tvalid-logloss:0.21554\n",
            "[3600]\ttrain-logloss:0.19087\tvalid-logloss:0.21538\n",
            "[3900]\ttrain-logloss:0.18885\tvalid-logloss:0.21526\n",
            "[4200]\ttrain-logloss:0.18685\tvalid-logloss:0.21513\n",
            "[4500]\ttrain-logloss:0.18483\tvalid-logloss:0.21501\n",
            "[4800]\ttrain-logloss:0.18295\tvalid-logloss:0.21496\n",
            "[5100]\ttrain-logloss:0.18111\tvalid-logloss:0.21488\n",
            "[5400]\ttrain-logloss:0.17930\tvalid-logloss:0.21482\n",
            "[5633]\ttrain-logloss:0.17792\tvalid-logloss:0.21481\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-07-01 15:12:55,470]\u001b[0m Trial 13 finished with value: 0.7929749772708361 and parameters: {'lambda': 9.622466201489145, 'alpha': 0.0014998764535004093, 'colsample_bytree': 0.6, 'subsample': 0.6, 'learning_rate': 0.009000000000000001, 'n_estimators': 80, 'max_depth': 9, 'min_child_weight': 250}. Best is trial 5 with value: 0.7938171644083507.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[15:13:08] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[15:13:08] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.67742\tvalid-logloss:0.67754\n",
            "[300]\ttrain-logloss:0.20955\tvalid-logloss:0.22398\n",
            "[600]\ttrain-logloss:0.19621\tvalid-logloss:0.21901\n",
            "[900]\ttrain-logloss:0.18782\tvalid-logloss:0.21769\n",
            "[1200]\ttrain-logloss:0.18047\tvalid-logloss:0.21700\n",
            "[1500]\ttrain-logloss:0.17373\tvalid-logloss:0.21663\n",
            "[1800]\ttrain-logloss:0.16764\tvalid-logloss:0.21647\n",
            "[1846]\ttrain-logloss:0.16678\tvalid-logloss:0.21647\n",
            "[15:16:46] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[15:16:46] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.67744\tvalid-logloss:0.67746\n",
            "[300]\ttrain-logloss:0.21013\tvalid-logloss:0.22168\n",
            "[600]\ttrain-logloss:0.19697\tvalid-logloss:0.21705\n",
            "[900]\ttrain-logloss:0.18835\tvalid-logloss:0.21591\n",
            "[1200]\ttrain-logloss:0.18113\tvalid-logloss:0.21547\n",
            "[1500]\ttrain-logloss:0.17466\tvalid-logloss:0.21527\n",
            "[1740]\ttrain-logloss:0.16961\tvalid-logloss:0.21522\n",
            "[15:20:12] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[15:20:12] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.67746\tvalid-logloss:0.67758\n",
            "[300]\ttrain-logloss:0.20923\tvalid-logloss:0.22492\n",
            "[600]\ttrain-logloss:0.19612\tvalid-logloss:0.22028\n",
            "[900]\ttrain-logloss:0.18747\tvalid-logloss:0.21899\n",
            "[1200]\ttrain-logloss:0.18016\tvalid-logloss:0.21858\n",
            "[1500]\ttrain-logloss:0.17343\tvalid-logloss:0.21824\n",
            "[1703]\ttrain-logloss:0.16915\tvalid-logloss:0.21817\n",
            "[15:23:32] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[15:23:32] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.67742\tvalid-logloss:0.67756\n",
            "[300]\ttrain-logloss:0.20905\tvalid-logloss:0.22541\n",
            "[600]\ttrain-logloss:0.19593\tvalid-logloss:0.22107\n",
            "[900]\ttrain-logloss:0.18714\tvalid-logloss:0.21998\n",
            "[1200]\ttrain-logloss:0.17990\tvalid-logloss:0.21959\n",
            "[1500]\ttrain-logloss:0.17347\tvalid-logloss:0.21935\n",
            "[1617]\ttrain-logloss:0.17098\tvalid-logloss:0.21937\n",
            "[15:26:42] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[15:26:42] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.67745\tvalid-logloss:0.67749\n",
            "[300]\ttrain-logloss:0.21013\tvalid-logloss:0.22207\n",
            "[600]\ttrain-logloss:0.19699\tvalid-logloss:0.21727\n",
            "[900]\ttrain-logloss:0.18835\tvalid-logloss:0.21586\n",
            "[1200]\ttrain-logloss:0.18100\tvalid-logloss:0.21520\n",
            "[1500]\ttrain-logloss:0.17458\tvalid-logloss:0.21497\n",
            "[1800]\ttrain-logloss:0.16828\tvalid-logloss:0.21483\n",
            "[2100]\ttrain-logloss:0.16271\tvalid-logloss:0.21468\n",
            "[2228]\ttrain-logloss:0.16032\tvalid-logloss:0.21472\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-07-01 15:30:42,324]\u001b[0m Trial 14 finished with value: 0.7931511657368182 and parameters: {'lambda': 1.6005899506916341, 'alpha': 0.2196963535468911, 'colsample_bytree': 0.6, 'subsample': 0.9, 'learning_rate': 0.024, 'n_estimators': 570, 'max_depth': 8, 'min_child_weight': 124}. Best is trial 5 with value: 0.7938171644083507.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[15:30:55] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[15:30:55] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.67878\tvalid-logloss:0.67883\n",
            "[300]\ttrain-logloss:0.21851\tvalid-logloss:0.22769\n",
            "[600]\ttrain-logloss:0.20519\tvalid-logloss:0.22097\n",
            "[900]\ttrain-logloss:0.19783\tvalid-logloss:0.21891\n",
            "[1200]\ttrain-logloss:0.19204\tvalid-logloss:0.21796\n",
            "[1500]\ttrain-logloss:0.18687\tvalid-logloss:0.21737\n",
            "[1800]\ttrain-logloss:0.18216\tvalid-logloss:0.21707\n",
            "[2100]\ttrain-logloss:0.17757\tvalid-logloss:0.21681\n",
            "[2400]\ttrain-logloss:0.17320\tvalid-logloss:0.21671\n",
            "[2510]\ttrain-logloss:0.17172\tvalid-logloss:0.21671\n",
            "[15:35:04] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[15:35:04] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.67877\tvalid-logloss:0.67876\n",
            "[300]\ttrain-logloss:0.21897\tvalid-logloss:0.22557\n",
            "[600]\ttrain-logloss:0.20589\tvalid-logloss:0.21909\n",
            "[900]\ttrain-logloss:0.19859\tvalid-logloss:0.21727\n",
            "[1200]\ttrain-logloss:0.19259\tvalid-logloss:0.21647\n",
            "[1500]\ttrain-logloss:0.18735\tvalid-logloss:0.21604\n",
            "[1800]\ttrain-logloss:0.18246\tvalid-logloss:0.21582\n",
            "[2100]\ttrain-logloss:0.17793\tvalid-logloss:0.21562\n",
            "[2353]\ttrain-logloss:0.17412\tvalid-logloss:0.21559\n",
            "[15:39:00] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[15:39:00] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.67878\tvalid-logloss:0.67886\n",
            "[300]\ttrain-logloss:0.21829\tvalid-logloss:0.22853\n",
            "[600]\ttrain-logloss:0.20510\tvalid-logloss:0.22207\n",
            "[900]\ttrain-logloss:0.19762\tvalid-logloss:0.22019\n",
            "[1200]\ttrain-logloss:0.19181\tvalid-logloss:0.21935\n",
            "[1500]\ttrain-logloss:0.18666\tvalid-logloss:0.21896\n",
            "[1800]\ttrain-logloss:0.18187\tvalid-logloss:0.21873\n",
            "[2100]\ttrain-logloss:0.17719\tvalid-logloss:0.21863\n",
            "[2400]\ttrain-logloss:0.17267\tvalid-logloss:0.21858\n",
            "[2522]\ttrain-logloss:0.17106\tvalid-logloss:0.21859\n",
            "[15:43:08] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[15:43:08] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.67875\tvalid-logloss:0.67884\n",
            "[300]\ttrain-logloss:0.21811\tvalid-logloss:0.22882\n",
            "[600]\ttrain-logloss:0.20501\tvalid-logloss:0.22267\n",
            "[900]\ttrain-logloss:0.19759\tvalid-logloss:0.22087\n",
            "[1200]\ttrain-logloss:0.19169\tvalid-logloss:0.22006\n",
            "[1500]\ttrain-logloss:0.18635\tvalid-logloss:0.21969\n",
            "[1800]\ttrain-logloss:0.18134\tvalid-logloss:0.21950\n",
            "[2100]\ttrain-logloss:0.17678\tvalid-logloss:0.21937\n",
            "[2137]\ttrain-logloss:0.17621\tvalid-logloss:0.21936\n",
            "[15:46:39] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[15:46:39] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.67879\tvalid-logloss:0.67878\n",
            "[300]\ttrain-logloss:0.21917\tvalid-logloss:0.22558\n",
            "[600]\ttrain-logloss:0.20611\tvalid-logloss:0.21909\n",
            "[900]\ttrain-logloss:0.19858\tvalid-logloss:0.21719\n",
            "[1200]\ttrain-logloss:0.19240\tvalid-logloss:0.21627\n",
            "[1500]\ttrain-logloss:0.18710\tvalid-logloss:0.21578\n",
            "[1800]\ttrain-logloss:0.18230\tvalid-logloss:0.21546\n",
            "[2100]\ttrain-logloss:0.17780\tvalid-logloss:0.21521\n",
            "[2400]\ttrain-logloss:0.17344\tvalid-logloss:0.21515\n",
            "[2700]\ttrain-logloss:0.16922\tvalid-logloss:0.21505\n",
            "[2940]\ttrain-logloss:0.16601\tvalid-logloss:0.21503\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-07-01 15:51:16,149]\u001b[0m Trial 15 finished with value: 0.7923189295379203 and parameters: {'lambda': 0.4889514714587894, 'alpha': 0.20519018612863799, 'colsample_bytree': 1.0, 'subsample': 0.9, 'learning_rate': 0.022000000000000002, 'n_estimators': 630, 'max_depth': 6, 'min_child_weight': 71}. Best is trial 5 with value: 0.7938171644083507.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[15:51:29] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[15:51:29] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68723\tvalid-logloss:0.68727\n",
            "[300]\ttrain-logloss:0.24571\tvalid-logloss:0.25250\n",
            "[600]\ttrain-logloss:0.21739\tvalid-logloss:0.22817\n",
            "[900]\ttrain-logloss:0.20912\tvalid-logloss:0.22313\n",
            "[1200]\ttrain-logloss:0.20395\tvalid-logloss:0.22077\n",
            "[1500]\ttrain-logloss:0.19983\tvalid-logloss:0.21940\n",
            "[1800]\ttrain-logloss:0.19652\tvalid-logloss:0.21858\n",
            "[2100]\ttrain-logloss:0.19351\tvalid-logloss:0.21802\n",
            "[2400]\ttrain-logloss:0.19070\tvalid-logloss:0.21759\n",
            "[2700]\ttrain-logloss:0.18798\tvalid-logloss:0.21726\n",
            "[3000]\ttrain-logloss:0.18546\tvalid-logloss:0.21701\n",
            "[3300]\ttrain-logloss:0.18306\tvalid-logloss:0.21681\n",
            "[3600]\ttrain-logloss:0.18073\tvalid-logloss:0.21662\n",
            "[3900]\ttrain-logloss:0.17844\tvalid-logloss:0.21651\n",
            "[4200]\ttrain-logloss:0.17623\tvalid-logloss:0.21639\n",
            "[4500]\ttrain-logloss:0.17406\tvalid-logloss:0.21629\n",
            "[4800]\ttrain-logloss:0.17188\tvalid-logloss:0.21625\n",
            "[5100]\ttrain-logloss:0.16983\tvalid-logloss:0.21621\n",
            "[5400]\ttrain-logloss:0.16775\tvalid-logloss:0.21617\n",
            "[5700]\ttrain-logloss:0.16576\tvalid-logloss:0.21612\n",
            "[6000]\ttrain-logloss:0.16374\tvalid-logloss:0.21607\n",
            "[6114]\ttrain-logloss:0.16296\tvalid-logloss:0.21607\n",
            "[16:02:45] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[16:02:45] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68724\tvalid-logloss:0.68724\n",
            "[300]\ttrain-logloss:0.24624\tvalid-logloss:0.25053\n",
            "[600]\ttrain-logloss:0.21787\tvalid-logloss:0.22577\n",
            "[900]\ttrain-logloss:0.20956\tvalid-logloss:0.22076\n",
            "[1200]\ttrain-logloss:0.20450\tvalid-logloss:0.21857\n",
            "[1500]\ttrain-logloss:0.20039\tvalid-logloss:0.21735\n",
            "[1800]\ttrain-logloss:0.19698\tvalid-logloss:0.21662\n",
            "[2100]\ttrain-logloss:0.19395\tvalid-logloss:0.21611\n",
            "[2400]\ttrain-logloss:0.19114\tvalid-logloss:0.21576\n",
            "[2700]\ttrain-logloss:0.18839\tvalid-logloss:0.21550\n",
            "[3000]\ttrain-logloss:0.18592\tvalid-logloss:0.21529\n",
            "[3300]\ttrain-logloss:0.18355\tvalid-logloss:0.21513\n",
            "[3600]\ttrain-logloss:0.18110\tvalid-logloss:0.21500\n",
            "[3900]\ttrain-logloss:0.17887\tvalid-logloss:0.21489\n",
            "[4200]\ttrain-logloss:0.17661\tvalid-logloss:0.21482\n",
            "[4500]\ttrain-logloss:0.17436\tvalid-logloss:0.21476\n",
            "[4800]\ttrain-logloss:0.17224\tvalid-logloss:0.21471\n",
            "[5100]\ttrain-logloss:0.17011\tvalid-logloss:0.21467\n",
            "[5277]\ttrain-logloss:0.16882\tvalid-logloss:0.21466\n",
            "[16:12:34] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[16:12:34] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68724\tvalid-logloss:0.68729\n",
            "[300]\ttrain-logloss:0.24551\tvalid-logloss:0.25318\n",
            "[600]\ttrain-logloss:0.21707\tvalid-logloss:0.22908\n",
            "[900]\ttrain-logloss:0.20875\tvalid-logloss:0.22412\n",
            "[1200]\ttrain-logloss:0.20365\tvalid-logloss:0.22191\n",
            "[1500]\ttrain-logloss:0.19964\tvalid-logloss:0.22070\n",
            "[1800]\ttrain-logloss:0.19626\tvalid-logloss:0.21993\n",
            "[2100]\ttrain-logloss:0.19325\tvalid-logloss:0.21942\n",
            "[2400]\ttrain-logloss:0.19040\tvalid-logloss:0.21908\n",
            "[2700]\ttrain-logloss:0.18770\tvalid-logloss:0.21879\n",
            "[3000]\ttrain-logloss:0.18511\tvalid-logloss:0.21859\n",
            "[3300]\ttrain-logloss:0.18272\tvalid-logloss:0.21840\n",
            "[3600]\ttrain-logloss:0.18034\tvalid-logloss:0.21824\n",
            "[3900]\ttrain-logloss:0.17799\tvalid-logloss:0.21814\n",
            "[4200]\ttrain-logloss:0.17575\tvalid-logloss:0.21804\n",
            "[4500]\ttrain-logloss:0.17346\tvalid-logloss:0.21797\n",
            "[4800]\ttrain-logloss:0.17131\tvalid-logloss:0.21791\n",
            "[5100]\ttrain-logloss:0.16922\tvalid-logloss:0.21788\n",
            "[5165]\ttrain-logloss:0.16878\tvalid-logloss:0.21788\n",
            "[16:22:05] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[16:22:05] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68722\tvalid-logloss:0.68727\n",
            "[300]\ttrain-logloss:0.24547\tvalid-logloss:0.25356\n",
            "[600]\ttrain-logloss:0.21698\tvalid-logloss:0.22933\n",
            "[900]\ttrain-logloss:0.20862\tvalid-logloss:0.22447\n",
            "[1200]\ttrain-logloss:0.20351\tvalid-logloss:0.22237\n",
            "[1500]\ttrain-logloss:0.19945\tvalid-logloss:0.22118\n",
            "[1800]\ttrain-logloss:0.19606\tvalid-logloss:0.22045\n",
            "[2100]\ttrain-logloss:0.19301\tvalid-logloss:0.21994\n",
            "[2400]\ttrain-logloss:0.19019\tvalid-logloss:0.21959\n",
            "[2700]\ttrain-logloss:0.18752\tvalid-logloss:0.21933\n",
            "[3000]\ttrain-logloss:0.18498\tvalid-logloss:0.21913\n",
            "[3300]\ttrain-logloss:0.18256\tvalid-logloss:0.21899\n",
            "[3600]\ttrain-logloss:0.18022\tvalid-logloss:0.21887\n",
            "[3900]\ttrain-logloss:0.17795\tvalid-logloss:0.21877\n",
            "[4200]\ttrain-logloss:0.17573\tvalid-logloss:0.21871\n",
            "[4500]\ttrain-logloss:0.17356\tvalid-logloss:0.21865\n",
            "[4705]\ttrain-logloss:0.17212\tvalid-logloss:0.21865\n",
            "[16:30:45] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[16:30:46] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68723\tvalid-logloss:0.68725\n",
            "[300]\ttrain-logloss:0.24638\tvalid-logloss:0.25074\n",
            "[600]\ttrain-logloss:0.21804\tvalid-logloss:0.22604\n",
            "[900]\ttrain-logloss:0.20974\tvalid-logloss:0.22099\n",
            "[1200]\ttrain-logloss:0.20459\tvalid-logloss:0.21870\n",
            "[1500]\ttrain-logloss:0.20048\tvalid-logloss:0.21742\n",
            "[1800]\ttrain-logloss:0.19705\tvalid-logloss:0.21663\n",
            "[2100]\ttrain-logloss:0.19394\tvalid-logloss:0.21604\n",
            "[2400]\ttrain-logloss:0.19108\tvalid-logloss:0.21566\n",
            "[2700]\ttrain-logloss:0.18841\tvalid-logloss:0.21532\n",
            "[3000]\ttrain-logloss:0.18579\tvalid-logloss:0.21509\n",
            "[3300]\ttrain-logloss:0.18341\tvalid-logloss:0.21492\n",
            "[3600]\ttrain-logloss:0.18099\tvalid-logloss:0.21476\n",
            "[3900]\ttrain-logloss:0.17869\tvalid-logloss:0.21465\n",
            "[4200]\ttrain-logloss:0.17647\tvalid-logloss:0.21453\n",
            "[4500]\ttrain-logloss:0.17424\tvalid-logloss:0.21446\n",
            "[4800]\ttrain-logloss:0.17208\tvalid-logloss:0.21438\n",
            "[5100]\ttrain-logloss:0.17003\tvalid-logloss:0.21432\n",
            "[5400]\ttrain-logloss:0.16796\tvalid-logloss:0.21427\n",
            "[5700]\ttrain-logloss:0.16594\tvalid-logloss:0.21423\n",
            "[5993]\ttrain-logloss:0.16399\tvalid-logloss:0.21421\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-07-01 16:41:32,975]\u001b[0m Trial 16 finished with value: 0.7937053558492164 and parameters: {'lambda': 2.1586753375207275, 'alpha': 1.1341806945985091, 'colsample_bytree': 0.6, 'subsample': 0.9, 'learning_rate': 0.009000000000000001, 'n_estimators': 730, 'max_depth': 8, 'min_child_weight': 156}. Best is trial 5 with value: 0.7938171644083507.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[16:41:46] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[16:41:46] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68809\tvalid-logloss:0.68811\n",
            "[300]\ttrain-logloss:0.26821\tvalid-logloss:0.27044\n",
            "[600]\ttrain-logloss:0.23313\tvalid-logloss:0.23706\n",
            "[900]\ttrain-logloss:0.22352\tvalid-logloss:0.22919\n",
            "[1200]\ttrain-logloss:0.21876\tvalid-logloss:0.22572\n",
            "[1500]\ttrain-logloss:0.21542\tvalid-logloss:0.22349\n",
            "[1800]\ttrain-logloss:0.21291\tvalid-logloss:0.22200\n",
            "[2100]\ttrain-logloss:0.21083\tvalid-logloss:0.22094\n",
            "[2400]\ttrain-logloss:0.20905\tvalid-logloss:0.22015\n",
            "[2700]\ttrain-logloss:0.20751\tvalid-logloss:0.21953\n",
            "[3000]\ttrain-logloss:0.20610\tvalid-logloss:0.21905\n",
            "[3300]\ttrain-logloss:0.20480\tvalid-logloss:0.21868\n",
            "[3600]\ttrain-logloss:0.20352\tvalid-logloss:0.21836\n",
            "[3900]\ttrain-logloss:0.20230\tvalid-logloss:0.21808\n",
            "[4200]\ttrain-logloss:0.20112\tvalid-logloss:0.21784\n",
            "[4500]\ttrain-logloss:0.19999\tvalid-logloss:0.21765\n",
            "[4800]\ttrain-logloss:0.19883\tvalid-logloss:0.21745\n",
            "[5100]\ttrain-logloss:0.19777\tvalid-logloss:0.21730\n",
            "[5400]\ttrain-logloss:0.19670\tvalid-logloss:0.21717\n",
            "[5700]\ttrain-logloss:0.19567\tvalid-logloss:0.21703\n",
            "[6000]\ttrain-logloss:0.19464\tvalid-logloss:0.21692\n",
            "[6300]\ttrain-logloss:0.19364\tvalid-logloss:0.21684\n",
            "[6600]\ttrain-logloss:0.19269\tvalid-logloss:0.21675\n",
            "[6900]\ttrain-logloss:0.19177\tvalid-logloss:0.21668\n",
            "[7200]\ttrain-logloss:0.19084\tvalid-logloss:0.21659\n",
            "[7500]\ttrain-logloss:0.18991\tvalid-logloss:0.21653\n",
            "[7800]\ttrain-logloss:0.18900\tvalid-logloss:0.21647\n",
            "[8100]\ttrain-logloss:0.18807\tvalid-logloss:0.21642\n",
            "[8400]\ttrain-logloss:0.18721\tvalid-logloss:0.21636\n",
            "[8700]\ttrain-logloss:0.18633\tvalid-logloss:0.21630\n",
            "[9000]\ttrain-logloss:0.18546\tvalid-logloss:0.21625\n",
            "[9300]\ttrain-logloss:0.18460\tvalid-logloss:0.21622\n",
            "[9600]\ttrain-logloss:0.18377\tvalid-logloss:0.21619\n",
            "[9900]\ttrain-logloss:0.18288\tvalid-logloss:0.21615\n",
            "[9998]\ttrain-logloss:0.18261\tvalid-logloss:0.21613\n",
            "[16:55:26] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[16:55:26] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68810\tvalid-logloss:0.68808\n",
            "[300]\ttrain-logloss:0.26863\tvalid-logloss:0.26890\n",
            "[600]\ttrain-logloss:0.23354\tvalid-logloss:0.23502\n",
            "[900]\ttrain-logloss:0.22398\tvalid-logloss:0.22696\n",
            "[1200]\ttrain-logloss:0.21920\tvalid-logloss:0.22350\n",
            "[1500]\ttrain-logloss:0.21587\tvalid-logloss:0.22135\n",
            "[1800]\ttrain-logloss:0.21332\tvalid-logloss:0.21998\n",
            "[2100]\ttrain-logloss:0.21123\tvalid-logloss:0.21900\n",
            "[2400]\ttrain-logloss:0.20944\tvalid-logloss:0.21828\n",
            "[2700]\ttrain-logloss:0.20781\tvalid-logloss:0.21771\n",
            "[3000]\ttrain-logloss:0.20638\tvalid-logloss:0.21729\n",
            "[3300]\ttrain-logloss:0.20503\tvalid-logloss:0.21693\n",
            "[3600]\ttrain-logloss:0.20372\tvalid-logloss:0.21664\n",
            "[3900]\ttrain-logloss:0.20250\tvalid-logloss:0.21641\n",
            "[4200]\ttrain-logloss:0.20134\tvalid-logloss:0.21621\n",
            "[4500]\ttrain-logloss:0.20016\tvalid-logloss:0.21604\n",
            "[4800]\ttrain-logloss:0.19908\tvalid-logloss:0.21589\n",
            "[5100]\ttrain-logloss:0.19803\tvalid-logloss:0.21577\n",
            "[5400]\ttrain-logloss:0.19700\tvalid-logloss:0.21565\n",
            "[5700]\ttrain-logloss:0.19599\tvalid-logloss:0.21554\n",
            "[6000]\ttrain-logloss:0.19498\tvalid-logloss:0.21545\n",
            "[6300]\ttrain-logloss:0.19399\tvalid-logloss:0.21540\n",
            "[6600]\ttrain-logloss:0.19299\tvalid-logloss:0.21532\n",
            "[6900]\ttrain-logloss:0.19203\tvalid-logloss:0.21527\n",
            "[7200]\ttrain-logloss:0.19107\tvalid-logloss:0.21523\n",
            "[7500]\ttrain-logloss:0.19008\tvalid-logloss:0.21518\n",
            "[7800]\ttrain-logloss:0.18916\tvalid-logloss:0.21512\n",
            "[8100]\ttrain-logloss:0.18824\tvalid-logloss:0.21507\n",
            "[8400]\ttrain-logloss:0.18734\tvalid-logloss:0.21503\n",
            "[8700]\ttrain-logloss:0.18643\tvalid-logloss:0.21501\n",
            "[8824]\ttrain-logloss:0.18603\tvalid-logloss:0.21501\n",
            "[17:07:40] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[17:07:40] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68809\tvalid-logloss:0.68812\n",
            "[300]\ttrain-logloss:0.26803\tvalid-logloss:0.27135\n",
            "[600]\ttrain-logloss:0.23284\tvalid-logloss:0.23799\n",
            "[900]\ttrain-logloss:0.22322\tvalid-logloss:0.23012\n",
            "[1200]\ttrain-logloss:0.21843\tvalid-logloss:0.22672\n",
            "[1500]\ttrain-logloss:0.21512\tvalid-logloss:0.22463\n",
            "[1800]\ttrain-logloss:0.21260\tvalid-logloss:0.22321\n",
            "[2100]\ttrain-logloss:0.21048\tvalid-logloss:0.22219\n",
            "[2400]\ttrain-logloss:0.20866\tvalid-logloss:0.22146\n",
            "[2700]\ttrain-logloss:0.20707\tvalid-logloss:0.22091\n",
            "[3000]\ttrain-logloss:0.20564\tvalid-logloss:0.22046\n",
            "[3300]\ttrain-logloss:0.20432\tvalid-logloss:0.22011\n",
            "[3600]\ttrain-logloss:0.20303\tvalid-logloss:0.21982\n",
            "[3900]\ttrain-logloss:0.20182\tvalid-logloss:0.21963\n",
            "[4200]\ttrain-logloss:0.20071\tvalid-logloss:0.21941\n",
            "[4500]\ttrain-logloss:0.19959\tvalid-logloss:0.21924\n",
            "[4800]\ttrain-logloss:0.19850\tvalid-logloss:0.21909\n",
            "[5100]\ttrain-logloss:0.19742\tvalid-logloss:0.21896\n",
            "[5400]\ttrain-logloss:0.19638\tvalid-logloss:0.21885\n",
            "[5700]\ttrain-logloss:0.19532\tvalid-logloss:0.21875\n",
            "[6000]\ttrain-logloss:0.19430\tvalid-logloss:0.21864\n",
            "[6300]\ttrain-logloss:0.19329\tvalid-logloss:0.21855\n",
            "[6600]\ttrain-logloss:0.19233\tvalid-logloss:0.21848\n",
            "[6900]\ttrain-logloss:0.19135\tvalid-logloss:0.21839\n",
            "[7200]\ttrain-logloss:0.19038\tvalid-logloss:0.21832\n",
            "[7500]\ttrain-logloss:0.18946\tvalid-logloss:0.21826\n",
            "[7800]\ttrain-logloss:0.18852\tvalid-logloss:0.21822\n",
            "[8100]\ttrain-logloss:0.18757\tvalid-logloss:0.21818\n",
            "[8400]\ttrain-logloss:0.18666\tvalid-logloss:0.21814\n",
            "[8700]\ttrain-logloss:0.18574\tvalid-logloss:0.21809\n",
            "[9000]\ttrain-logloss:0.18485\tvalid-logloss:0.21806\n",
            "[9300]\ttrain-logloss:0.18397\tvalid-logloss:0.21801\n",
            "[9489]\ttrain-logloss:0.18341\tvalid-logloss:0.21800\n",
            "[17:20:26] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[17:20:26] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68809\tvalid-logloss:0.68812\n",
            "[300]\ttrain-logloss:0.26794\tvalid-logloss:0.27178\n",
            "[600]\ttrain-logloss:0.23278\tvalid-logloss:0.23829\n",
            "[900]\ttrain-logloss:0.22318\tvalid-logloss:0.23030\n",
            "[1200]\ttrain-logloss:0.21833\tvalid-logloss:0.22691\n",
            "[1500]\ttrain-logloss:0.21500\tvalid-logloss:0.22487\n",
            "[1800]\ttrain-logloss:0.21246\tvalid-logloss:0.22354\n",
            "[2100]\ttrain-logloss:0.21033\tvalid-logloss:0.22260\n",
            "[2400]\ttrain-logloss:0.20855\tvalid-logloss:0.22188\n",
            "[2700]\ttrain-logloss:0.20694\tvalid-logloss:0.22131\n",
            "[3000]\ttrain-logloss:0.20550\tvalid-logloss:0.22089\n",
            "[3300]\ttrain-logloss:0.20414\tvalid-logloss:0.22054\n",
            "[3600]\ttrain-logloss:0.20286\tvalid-logloss:0.22024\n",
            "[3900]\ttrain-logloss:0.20165\tvalid-logloss:0.22001\n",
            "[4200]\ttrain-logloss:0.20047\tvalid-logloss:0.21982\n",
            "[4500]\ttrain-logloss:0.19931\tvalid-logloss:0.21967\n",
            "[4800]\ttrain-logloss:0.19821\tvalid-logloss:0.21953\n",
            "[5100]\ttrain-logloss:0.19718\tvalid-logloss:0.21943\n",
            "[5400]\ttrain-logloss:0.19610\tvalid-logloss:0.21933\n",
            "[5700]\ttrain-logloss:0.19506\tvalid-logloss:0.21923\n",
            "[6000]\ttrain-logloss:0.19405\tvalid-logloss:0.21913\n",
            "[6300]\ttrain-logloss:0.19305\tvalid-logloss:0.21907\n",
            "[6600]\ttrain-logloss:0.19209\tvalid-logloss:0.21901\n",
            "[6900]\ttrain-logloss:0.19111\tvalid-logloss:0.21895\n",
            "[7200]\ttrain-logloss:0.19012\tvalid-logloss:0.21890\n",
            "[7500]\ttrain-logloss:0.18919\tvalid-logloss:0.21887\n",
            "[7800]\ttrain-logloss:0.18828\tvalid-logloss:0.21882\n",
            "[8100]\ttrain-logloss:0.18737\tvalid-logloss:0.21878\n",
            "[8400]\ttrain-logloss:0.18647\tvalid-logloss:0.21874\n",
            "[8456]\ttrain-logloss:0.18630\tvalid-logloss:0.21873\n",
            "[17:31:56] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[17:31:56] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68809\tvalid-logloss:0.68809\n",
            "[300]\ttrain-logloss:0.26864\tvalid-logloss:0.26906\n",
            "[600]\ttrain-logloss:0.23371\tvalid-logloss:0.23530\n",
            "[900]\ttrain-logloss:0.22416\tvalid-logloss:0.22720\n",
            "[1200]\ttrain-logloss:0.21935\tvalid-logloss:0.22368\n",
            "[1500]\ttrain-logloss:0.21605\tvalid-logloss:0.22157\n",
            "[1800]\ttrain-logloss:0.21354\tvalid-logloss:0.22015\n",
            "[2100]\ttrain-logloss:0.21144\tvalid-logloss:0.21913\n",
            "[2400]\ttrain-logloss:0.20962\tvalid-logloss:0.21837\n",
            "[2700]\ttrain-logloss:0.20802\tvalid-logloss:0.21778\n",
            "[3000]\ttrain-logloss:0.20658\tvalid-logloss:0.21731\n",
            "[3300]\ttrain-logloss:0.20519\tvalid-logloss:0.21693\n",
            "[3600]\ttrain-logloss:0.20389\tvalid-logloss:0.21660\n",
            "[3900]\ttrain-logloss:0.20265\tvalid-logloss:0.21634\n",
            "[4200]\ttrain-logloss:0.20147\tvalid-logloss:0.21612\n",
            "[4500]\ttrain-logloss:0.20032\tvalid-logloss:0.21592\n",
            "[4800]\ttrain-logloss:0.19920\tvalid-logloss:0.21575\n",
            "[5100]\ttrain-logloss:0.19814\tvalid-logloss:0.21560\n",
            "[5400]\ttrain-logloss:0.19709\tvalid-logloss:0.21548\n",
            "[5700]\ttrain-logloss:0.19606\tvalid-logloss:0.21535\n",
            "[6000]\ttrain-logloss:0.19502\tvalid-logloss:0.21524\n",
            "[6300]\ttrain-logloss:0.19407\tvalid-logloss:0.21515\n",
            "[6600]\ttrain-logloss:0.19309\tvalid-logloss:0.21506\n",
            "[6900]\ttrain-logloss:0.19215\tvalid-logloss:0.21499\n",
            "[7200]\ttrain-logloss:0.19126\tvalid-logloss:0.21493\n",
            "[7500]\ttrain-logloss:0.19031\tvalid-logloss:0.21484\n",
            "[7800]\ttrain-logloss:0.18941\tvalid-logloss:0.21479\n",
            "[8100]\ttrain-logloss:0.18849\tvalid-logloss:0.21474\n",
            "[8400]\ttrain-logloss:0.18764\tvalid-logloss:0.21469\n",
            "[8700]\ttrain-logloss:0.18675\tvalid-logloss:0.21463\n",
            "[9000]\ttrain-logloss:0.18587\tvalid-logloss:0.21458\n",
            "[9292]\ttrain-logloss:0.18504\tvalid-logloss:0.21454\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-07-01 17:44:18,571]\u001b[0m Trial 17 finished with value: 0.7928469591694995 and parameters: {'lambda': 3.000678397765375, 'alpha': 1.930293286981127, 'colsample_bytree': 0.6, 'subsample': 0.9, 'learning_rate': 0.008, 'n_estimators': 730, 'max_depth': 5, 'min_child_weight': 151}. Best is trial 5 with value: 0.7938171644083507.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[17:44:31] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[17:44:31] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68779\tvalid-logloss:0.68782\n",
            "[300]\ttrain-logloss:0.25416\tvalid-logloss:0.26080\n",
            "[600]\ttrain-logloss:0.22005\tvalid-logloss:0.23080\n",
            "[900]\ttrain-logloss:0.21085\tvalid-logloss:0.22481\n",
            "[1200]\ttrain-logloss:0.20556\tvalid-logloss:0.22221\n",
            "[1500]\ttrain-logloss:0.20146\tvalid-logloss:0.22065\n",
            "[1800]\ttrain-logloss:0.19829\tvalid-logloss:0.21972\n",
            "[2100]\ttrain-logloss:0.19530\tvalid-logloss:0.21906\n",
            "[2400]\ttrain-logloss:0.19285\tvalid-logloss:0.21861\n",
            "[2700]\ttrain-logloss:0.19033\tvalid-logloss:0.21826\n",
            "[3000]\ttrain-logloss:0.18801\tvalid-logloss:0.21797\n",
            "[3300]\ttrain-logloss:0.18578\tvalid-logloss:0.21774\n",
            "[3600]\ttrain-logloss:0.18371\tvalid-logloss:0.21757\n",
            "[3900]\ttrain-logloss:0.18166\tvalid-logloss:0.21741\n",
            "[4200]\ttrain-logloss:0.17969\tvalid-logloss:0.21732\n",
            "[4500]\ttrain-logloss:0.17775\tvalid-logloss:0.21726\n",
            "[4800]\ttrain-logloss:0.17590\tvalid-logloss:0.21722\n",
            "[5100]\ttrain-logloss:0.17405\tvalid-logloss:0.21718\n",
            "[5191]\ttrain-logloss:0.17350\tvalid-logloss:0.21717\n",
            "[17:54:36] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[17:54:37] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68779\tvalid-logloss:0.68780\n",
            "[300]\ttrain-logloss:0.25466\tvalid-logloss:0.25900\n",
            "[600]\ttrain-logloss:0.22065\tvalid-logloss:0.22848\n",
            "[900]\ttrain-logloss:0.21144\tvalid-logloss:0.22251\n",
            "[1200]\ttrain-logloss:0.20617\tvalid-logloss:0.22004\n",
            "[1500]\ttrain-logloss:0.20217\tvalid-logloss:0.21861\n",
            "[1800]\ttrain-logloss:0.19891\tvalid-logloss:0.21781\n",
            "[2100]\ttrain-logloss:0.19607\tvalid-logloss:0.21725\n",
            "[2400]\ttrain-logloss:0.19342\tvalid-logloss:0.21687\n",
            "[2700]\ttrain-logloss:0.19107\tvalid-logloss:0.21662\n",
            "[3000]\ttrain-logloss:0.18891\tvalid-logloss:0.21644\n",
            "[3300]\ttrain-logloss:0.18681\tvalid-logloss:0.21630\n",
            "[3600]\ttrain-logloss:0.18468\tvalid-logloss:0.21619\n",
            "[3900]\ttrain-logloss:0.18268\tvalid-logloss:0.21611\n",
            "[4200]\ttrain-logloss:0.18078\tvalid-logloss:0.21606\n",
            "[4500]\ttrain-logloss:0.17890\tvalid-logloss:0.21602\n",
            "[4800]\ttrain-logloss:0.17714\tvalid-logloss:0.21598\n",
            "[4980]\ttrain-logloss:0.17604\tvalid-logloss:0.21597\n",
            "[18:04:16] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[18:04:16] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68779\tvalid-logloss:0.68783\n",
            "[300]\ttrain-logloss:0.25396\tvalid-logloss:0.26156\n",
            "[600]\ttrain-logloss:0.21982\tvalid-logloss:0.23177\n",
            "[900]\ttrain-logloss:0.21065\tvalid-logloss:0.22589\n",
            "[1200]\ttrain-logloss:0.20547\tvalid-logloss:0.22341\n",
            "[1500]\ttrain-logloss:0.20134\tvalid-logloss:0.22195\n",
            "[1800]\ttrain-logloss:0.19792\tvalid-logloss:0.22108\n",
            "[2100]\ttrain-logloss:0.19503\tvalid-logloss:0.22054\n",
            "[2400]\ttrain-logloss:0.19267\tvalid-logloss:0.22018\n",
            "[2700]\ttrain-logloss:0.19032\tvalid-logloss:0.21994\n",
            "[3000]\ttrain-logloss:0.18803\tvalid-logloss:0.21974\n",
            "[3300]\ttrain-logloss:0.18602\tvalid-logloss:0.21955\n",
            "[3600]\ttrain-logloss:0.18400\tvalid-logloss:0.21944\n",
            "[3900]\ttrain-logloss:0.18202\tvalid-logloss:0.21936\n",
            "[4200]\ttrain-logloss:0.18011\tvalid-logloss:0.21926\n",
            "[4500]\ttrain-logloss:0.17819\tvalid-logloss:0.21918\n",
            "[4800]\ttrain-logloss:0.17643\tvalid-logloss:0.21912\n",
            "[5100]\ttrain-logloss:0.17457\tvalid-logloss:0.21909\n",
            "[5400]\ttrain-logloss:0.17265\tvalid-logloss:0.21907\n",
            "[5436]\ttrain-logloss:0.17245\tvalid-logloss:0.21908\n",
            "[18:14:35] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[18:14:35] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68778\tvalid-logloss:0.68783\n",
            "[300]\ttrain-logloss:0.25389\tvalid-logloss:0.26173\n",
            "[600]\ttrain-logloss:0.21974\tvalid-logloss:0.23188\n",
            "[900]\ttrain-logloss:0.21052\tvalid-logloss:0.22613\n",
            "[1200]\ttrain-logloss:0.20530\tvalid-logloss:0.22379\n",
            "[1500]\ttrain-logloss:0.20120\tvalid-logloss:0.22244\n",
            "[1800]\ttrain-logloss:0.19788\tvalid-logloss:0.22158\n",
            "[2100]\ttrain-logloss:0.19513\tvalid-logloss:0.22102\n",
            "[2400]\ttrain-logloss:0.19272\tvalid-logloss:0.22060\n",
            "[2700]\ttrain-logloss:0.19028\tvalid-logloss:0.22028\n",
            "[3000]\ttrain-logloss:0.18809\tvalid-logloss:0.22007\n",
            "[3300]\ttrain-logloss:0.18600\tvalid-logloss:0.21995\n",
            "[3600]\ttrain-logloss:0.18393\tvalid-logloss:0.21985\n",
            "[3900]\ttrain-logloss:0.18187\tvalid-logloss:0.21975\n",
            "[4200]\ttrain-logloss:0.17982\tvalid-logloss:0.21968\n",
            "[4500]\ttrain-logloss:0.17791\tvalid-logloss:0.21960\n",
            "[4800]\ttrain-logloss:0.17610\tvalid-logloss:0.21958\n",
            "[4936]\ttrain-logloss:0.17528\tvalid-logloss:0.21957\n",
            "[18:23:59] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[18:23:59] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68780\tvalid-logloss:0.68781\n",
            "[300]\ttrain-logloss:0.25475\tvalid-logloss:0.25908\n",
            "[600]\ttrain-logloss:0.22079\tvalid-logloss:0.22873\n",
            "[900]\ttrain-logloss:0.21162\tvalid-logloss:0.22277\n",
            "[1200]\ttrain-logloss:0.20634\tvalid-logloss:0.22020\n",
            "[1500]\ttrain-logloss:0.20226\tvalid-logloss:0.21870\n",
            "[1800]\ttrain-logloss:0.19889\tvalid-logloss:0.21777\n",
            "[2100]\ttrain-logloss:0.19591\tvalid-logloss:0.21710\n",
            "[2400]\ttrain-logloss:0.19319\tvalid-logloss:0.21668\n",
            "[2700]\ttrain-logloss:0.19079\tvalid-logloss:0.21642\n",
            "[3000]\ttrain-logloss:0.18848\tvalid-logloss:0.21616\n",
            "[3300]\ttrain-logloss:0.18638\tvalid-logloss:0.21595\n",
            "[3600]\ttrain-logloss:0.18428\tvalid-logloss:0.21578\n",
            "[3900]\ttrain-logloss:0.18228\tvalid-logloss:0.21564\n",
            "[4200]\ttrain-logloss:0.18042\tvalid-logloss:0.21557\n",
            "[4500]\ttrain-logloss:0.17841\tvalid-logloss:0.21547\n",
            "[4800]\ttrain-logloss:0.17654\tvalid-logloss:0.21539\n",
            "[5100]\ttrain-logloss:0.17480\tvalid-logloss:0.21532\n",
            "[5400]\ttrain-logloss:0.17308\tvalid-logloss:0.21527\n",
            "[5700]\ttrain-logloss:0.17142\tvalid-logloss:0.21522\n",
            "[5936]\ttrain-logloss:0.17004\tvalid-logloss:0.21519\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-07-01 18:34:59,146]\u001b[0m Trial 18 finished with value: 0.7922723843181907 and parameters: {'lambda': 0.225337367261222, 'alpha': 0.7761738602477747, 'colsample_bytree': 1.0, 'subsample': 1.0, 'learning_rate': 0.008, 'n_estimators': 450, 'max_depth': 8, 'min_child_weight': 176}. Best is trial 5 with value: 0.7938171644083507.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[18:35:11] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[18:35:12] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.69250\tvalid-logloss:0.69250\n",
            "[300]\ttrain-logloss:0.54092\tvalid-logloss:0.54144\n",
            "[600]\ttrain-logloss:0.44670\tvalid-logloss:0.44774\n",
            "[900]\ttrain-logloss:0.38443\tvalid-logloss:0.38598\n",
            "[1200]\ttrain-logloss:0.34168\tvalid-logloss:0.34367\n",
            "[1500]\ttrain-logloss:0.31157\tvalid-logloss:0.31395\n",
            "[1800]\ttrain-logloss:0.28997\tvalid-logloss:0.29271\n",
            "[2100]\ttrain-logloss:0.27417\tvalid-logloss:0.27724\n",
            "[2400]\ttrain-logloss:0.26251\tvalid-logloss:0.26591\n",
            "[2700]\ttrain-logloss:0.25375\tvalid-logloss:0.25745\n",
            "[3000]\ttrain-logloss:0.24708\tvalid-logloss:0.25108\n",
            "[3300]\ttrain-logloss:0.24194\tvalid-logloss:0.24624\n",
            "[3600]\ttrain-logloss:0.23793\tvalid-logloss:0.24250\n",
            "[3900]\ttrain-logloss:0.23471\tvalid-logloss:0.23957\n",
            "[4200]\ttrain-logloss:0.23211\tvalid-logloss:0.23724\n",
            "[4500]\ttrain-logloss:0.22995\tvalid-logloss:0.23536\n",
            "[4800]\ttrain-logloss:0.22809\tvalid-logloss:0.23378\n",
            "[5100]\ttrain-logloss:0.22642\tvalid-logloss:0.23240\n",
            "[5400]\ttrain-logloss:0.22492\tvalid-logloss:0.23121\n",
            "[5700]\ttrain-logloss:0.22359\tvalid-logloss:0.23018\n",
            "[6000]\ttrain-logloss:0.22242\tvalid-logloss:0.22929\n",
            "[6300]\ttrain-logloss:0.22139\tvalid-logloss:0.22851\n",
            "[6600]\ttrain-logloss:0.22044\tvalid-logloss:0.22782\n",
            "[6900]\ttrain-logloss:0.21958\tvalid-logloss:0.22720\n",
            "[7200]\ttrain-logloss:0.21879\tvalid-logloss:0.22664\n",
            "[7500]\ttrain-logloss:0.21806\tvalid-logloss:0.22614\n",
            "[7800]\ttrain-logloss:0.21737\tvalid-logloss:0.22566\n",
            "[8100]\ttrain-logloss:0.21672\tvalid-logloss:0.22523\n",
            "[8400]\ttrain-logloss:0.21611\tvalid-logloss:0.22483\n",
            "[8700]\ttrain-logloss:0.21553\tvalid-logloss:0.22446\n",
            "[9000]\ttrain-logloss:0.21499\tvalid-logloss:0.22411\n",
            "[9300]\ttrain-logloss:0.21446\tvalid-logloss:0.22378\n",
            "[9600]\ttrain-logloss:0.21395\tvalid-logloss:0.22347\n",
            "[9900]\ttrain-logloss:0.21346\tvalid-logloss:0.22317\n",
            "[9998]\ttrain-logloss:0.21330\tvalid-logloss:0.22308\n",
            "[18:52:38] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[18:52:38] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.69250\tvalid-logloss:0.69250\n",
            "[300]\ttrain-logloss:0.54111\tvalid-logloss:0.54106\n",
            "[600]\ttrain-logloss:0.44702\tvalid-logloss:0.44705\n",
            "[900]\ttrain-logloss:0.38481\tvalid-logloss:0.38496\n",
            "[1200]\ttrain-logloss:0.34207\tvalid-logloss:0.34240\n",
            "[1500]\ttrain-logloss:0.31199\tvalid-logloss:0.31254\n",
            "[1800]\ttrain-logloss:0.29041\tvalid-logloss:0.29120\n",
            "[2100]\ttrain-logloss:0.27460\tvalid-logloss:0.27563\n",
            "[2400]\ttrain-logloss:0.26295\tvalid-logloss:0.26421\n",
            "[2700]\ttrain-logloss:0.25419\tvalid-logloss:0.25568\n",
            "[3000]\ttrain-logloss:0.24754\tvalid-logloss:0.24926\n",
            "[3300]\ttrain-logloss:0.24242\tvalid-logloss:0.24436\n",
            "[3600]\ttrain-logloss:0.23841\tvalid-logloss:0.24058\n",
            "[3900]\ttrain-logloss:0.23520\tvalid-logloss:0.23759\n",
            "[4200]\ttrain-logloss:0.23261\tvalid-logloss:0.23521\n",
            "[4500]\ttrain-logloss:0.23046\tvalid-logloss:0.23327\n",
            "[4800]\ttrain-logloss:0.22860\tvalid-logloss:0.23164\n",
            "[5100]\ttrain-logloss:0.22694\tvalid-logloss:0.23024\n",
            "[5400]\ttrain-logloss:0.22543\tvalid-logloss:0.22902\n",
            "[5700]\ttrain-logloss:0.22411\tvalid-logloss:0.22797\n",
            "[6000]\ttrain-logloss:0.22296\tvalid-logloss:0.22707\n",
            "[6300]\ttrain-logloss:0.22193\tvalid-logloss:0.22629\n",
            "[6600]\ttrain-logloss:0.22099\tvalid-logloss:0.22559\n",
            "[6900]\ttrain-logloss:0.22011\tvalid-logloss:0.22497\n",
            "[7200]\ttrain-logloss:0.21931\tvalid-logloss:0.22440\n",
            "[7500]\ttrain-logloss:0.21856\tvalid-logloss:0.22389\n",
            "[7800]\ttrain-logloss:0.21786\tvalid-logloss:0.22343\n",
            "[8100]\ttrain-logloss:0.21720\tvalid-logloss:0.22300\n",
            "[8400]\ttrain-logloss:0.21659\tvalid-logloss:0.22260\n",
            "[8700]\ttrain-logloss:0.21600\tvalid-logloss:0.22224\n",
            "[9000]\ttrain-logloss:0.21545\tvalid-logloss:0.22190\n",
            "[9300]\ttrain-logloss:0.21492\tvalid-logloss:0.22159\n",
            "[9600]\ttrain-logloss:0.21440\tvalid-logloss:0.22129\n",
            "[9900]\ttrain-logloss:0.21393\tvalid-logloss:0.22102\n",
            "[9998]\ttrain-logloss:0.21376\tvalid-logloss:0.22093\n",
            "[19:10:11] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[19:10:11] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.69250\tvalid-logloss:0.69251\n",
            "[300]\ttrain-logloss:0.54091\tvalid-logloss:0.54177\n",
            "[600]\ttrain-logloss:0.44667\tvalid-logloss:0.44820\n",
            "[900]\ttrain-logloss:0.38438\tvalid-logloss:0.38646\n",
            "[1200]\ttrain-logloss:0.34159\tvalid-logloss:0.34418\n",
            "[1500]\ttrain-logloss:0.31145\tvalid-logloss:0.31455\n",
            "[1800]\ttrain-logloss:0.28980\tvalid-logloss:0.29336\n",
            "[2100]\ttrain-logloss:0.27397\tvalid-logloss:0.27797\n",
            "[2400]\ttrain-logloss:0.26229\tvalid-logloss:0.26667\n",
            "[2700]\ttrain-logloss:0.25350\tvalid-logloss:0.25824\n",
            "[3000]\ttrain-logloss:0.24683\tvalid-logloss:0.25192\n",
            "[3300]\ttrain-logloss:0.24169\tvalid-logloss:0.24710\n",
            "[3600]\ttrain-logloss:0.23767\tvalid-logloss:0.24338\n",
            "[3900]\ttrain-logloss:0.23447\tvalid-logloss:0.24047\n",
            "[4200]\ttrain-logloss:0.23185\tvalid-logloss:0.23815\n",
            "[4500]\ttrain-logloss:0.22967\tvalid-logloss:0.23627\n",
            "[4800]\ttrain-logloss:0.22780\tvalid-logloss:0.23469\n",
            "[5100]\ttrain-logloss:0.22614\tvalid-logloss:0.23333\n",
            "[5400]\ttrain-logloss:0.22463\tvalid-logloss:0.23214\n",
            "[5700]\ttrain-logloss:0.22332\tvalid-logloss:0.23112\n",
            "[6000]\ttrain-logloss:0.22217\tvalid-logloss:0.23024\n",
            "[6300]\ttrain-logloss:0.22113\tvalid-logloss:0.22947\n",
            "[6600]\ttrain-logloss:0.22019\tvalid-logloss:0.22879\n",
            "[6900]\ttrain-logloss:0.21933\tvalid-logloss:0.22818\n",
            "[7200]\ttrain-logloss:0.21853\tvalid-logloss:0.22763\n",
            "[7500]\ttrain-logloss:0.21779\tvalid-logloss:0.22713\n",
            "[7800]\ttrain-logloss:0.21710\tvalid-logloss:0.22668\n",
            "[8100]\ttrain-logloss:0.21644\tvalid-logloss:0.22626\n",
            "[8400]\ttrain-logloss:0.21582\tvalid-logloss:0.22587\n",
            "[8700]\ttrain-logloss:0.21523\tvalid-logloss:0.22551\n",
            "[9000]\ttrain-logloss:0.21467\tvalid-logloss:0.22517\n",
            "[9300]\ttrain-logloss:0.21413\tvalid-logloss:0.22485\n",
            "[9600]\ttrain-logloss:0.21363\tvalid-logloss:0.22457\n",
            "[9900]\ttrain-logloss:0.21315\tvalid-logloss:0.22429\n",
            "[9998]\ttrain-logloss:0.21299\tvalid-logloss:0.22420\n",
            "[19:27:26] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[19:27:27] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.69250\tvalid-logloss:0.69251\n",
            "[300]\ttrain-logloss:0.54083\tvalid-logloss:0.54192\n",
            "[600]\ttrain-logloss:0.44660\tvalid-logloss:0.44849\n",
            "[900]\ttrain-logloss:0.38428\tvalid-logloss:0.38684\n",
            "[1200]\ttrain-logloss:0.34148\tvalid-logloss:0.34463\n",
            "[1500]\ttrain-logloss:0.31135\tvalid-logloss:0.31502\n",
            "[1800]\ttrain-logloss:0.28970\tvalid-logloss:0.29382\n",
            "[2100]\ttrain-logloss:0.27387\tvalid-logloss:0.27841\n",
            "[2400]\ttrain-logloss:0.26222\tvalid-logloss:0.26712\n",
            "[2700]\ttrain-logloss:0.25343\tvalid-logloss:0.25866\n",
            "[3000]\ttrain-logloss:0.24678\tvalid-logloss:0.25230\n",
            "[3300]\ttrain-logloss:0.24162\tvalid-logloss:0.24744\n",
            "[3600]\ttrain-logloss:0.23762\tvalid-logloss:0.24372\n",
            "[3900]\ttrain-logloss:0.23441\tvalid-logloss:0.24080\n",
            "[4200]\ttrain-logloss:0.23180\tvalid-logloss:0.23845\n",
            "[4500]\ttrain-logloss:0.22963\tvalid-logloss:0.23655\n",
            "[4800]\ttrain-logloss:0.22775\tvalid-logloss:0.23495\n",
            "[5100]\ttrain-logloss:0.22609\tvalid-logloss:0.23358\n",
            "[5400]\ttrain-logloss:0.22458\tvalid-logloss:0.23238\n",
            "[5700]\ttrain-logloss:0.22326\tvalid-logloss:0.23134\n",
            "[6000]\ttrain-logloss:0.22209\tvalid-logloss:0.23046\n",
            "[6300]\ttrain-logloss:0.22106\tvalid-logloss:0.22969\n",
            "[6600]\ttrain-logloss:0.22012\tvalid-logloss:0.22901\n",
            "[6900]\ttrain-logloss:0.21926\tvalid-logloss:0.22841\n",
            "[7200]\ttrain-logloss:0.21846\tvalid-logloss:0.22786\n",
            "[7500]\ttrain-logloss:0.21771\tvalid-logloss:0.22737\n",
            "[7800]\ttrain-logloss:0.21701\tvalid-logloss:0.22692\n",
            "[8100]\ttrain-logloss:0.21635\tvalid-logloss:0.22651\n",
            "[8400]\ttrain-logloss:0.21573\tvalid-logloss:0.22613\n",
            "[8700]\ttrain-logloss:0.21515\tvalid-logloss:0.22579\n",
            "[9000]\ttrain-logloss:0.21459\tvalid-logloss:0.22546\n",
            "[9300]\ttrain-logloss:0.21407\tvalid-logloss:0.22517\n",
            "[9600]\ttrain-logloss:0.21356\tvalid-logloss:0.22489\n",
            "[9900]\ttrain-logloss:0.21308\tvalid-logloss:0.22462\n",
            "[9998]\ttrain-logloss:0.21292\tvalid-logloss:0.22454\n",
            "[19:44:33] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[19:44:33] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.69250\tvalid-logloss:0.69250\n",
            "[300]\ttrain-logloss:0.54112\tvalid-logloss:0.54111\n",
            "[600]\ttrain-logloss:0.44704\tvalid-logloss:0.44715\n",
            "[900]\ttrain-logloss:0.38485\tvalid-logloss:0.38515\n",
            "[1200]\ttrain-logloss:0.34211\tvalid-logloss:0.34261\n",
            "[1500]\ttrain-logloss:0.31205\tvalid-logloss:0.31276\n",
            "[1800]\ttrain-logloss:0.29046\tvalid-logloss:0.29138\n",
            "[2100]\ttrain-logloss:0.27469\tvalid-logloss:0.27582\n",
            "[2400]\ttrain-logloss:0.26304\tvalid-logloss:0.26441\n",
            "[2700]\ttrain-logloss:0.25430\tvalid-logloss:0.25588\n",
            "[3000]\ttrain-logloss:0.24767\tvalid-logloss:0.24946\n",
            "[3300]\ttrain-logloss:0.24256\tvalid-logloss:0.24456\n",
            "[3600]\ttrain-logloss:0.23857\tvalid-logloss:0.24077\n",
            "[3900]\ttrain-logloss:0.23538\tvalid-logloss:0.23779\n",
            "[4200]\ttrain-logloss:0.23276\tvalid-logloss:0.23539\n",
            "[4500]\ttrain-logloss:0.23061\tvalid-logloss:0.23346\n",
            "[4800]\ttrain-logloss:0.22875\tvalid-logloss:0.23184\n",
            "[5100]\ttrain-logloss:0.22708\tvalid-logloss:0.23044\n",
            "[5400]\ttrain-logloss:0.22559\tvalid-logloss:0.22923\n",
            "[5700]\ttrain-logloss:0.22427\tvalid-logloss:0.22818\n",
            "[6000]\ttrain-logloss:0.22313\tvalid-logloss:0.22729\n",
            "[6300]\ttrain-logloss:0.22209\tvalid-logloss:0.22650\n",
            "[6600]\ttrain-logloss:0.22116\tvalid-logloss:0.22581\n",
            "[6900]\ttrain-logloss:0.22030\tvalid-logloss:0.22518\n",
            "[7200]\ttrain-logloss:0.21950\tvalid-logloss:0.22462\n",
            "[7500]\ttrain-logloss:0.21876\tvalid-logloss:0.22411\n",
            "[7800]\ttrain-logloss:0.21808\tvalid-logloss:0.22366\n",
            "[8100]\ttrain-logloss:0.21743\tvalid-logloss:0.22323\n",
            "[8400]\ttrain-logloss:0.21682\tvalid-logloss:0.22284\n",
            "[8700]\ttrain-logloss:0.21624\tvalid-logloss:0.22248\n",
            "[9000]\ttrain-logloss:0.21568\tvalid-logloss:0.22214\n",
            "[9300]\ttrain-logloss:0.21515\tvalid-logloss:0.22183\n",
            "[9600]\ttrain-logloss:0.21463\tvalid-logloss:0.22153\n",
            "[9900]\ttrain-logloss:0.21415\tvalid-logloss:0.22125\n",
            "[9998]\ttrain-logloss:0.21400\tvalid-logloss:0.22116\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-07-01 20:01:56,517]\u001b[0m Trial 19 finished with value: 0.7849123897100745 and parameters: {'lambda': 0.617527578351882, 'alpha': 0.012739073212939513, 'colsample_bytree': 0.6, 'subsample': 0.8, 'learning_rate': 0.001, 'n_estimators': 760, 'max_depth': 6, 'min_child_weight': 141}. Best is trial 5 with value: 0.7938171644083507.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[20:02:09] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[20:02:09] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68573\tvalid-logloss:0.68573\n",
            "[300]\ttrain-logloss:0.24968\tvalid-logloss:0.25167\n",
            "[600]\ttrain-logloss:0.22821\tvalid-logloss:0.23222\n",
            "[900]\ttrain-logloss:0.22135\tvalid-logloss:0.22696\n",
            "[1200]\ttrain-logloss:0.21714\tvalid-logloss:0.22407\n",
            "[1500]\ttrain-logloss:0.21399\tvalid-logloss:0.22224\n",
            "[1800]\ttrain-logloss:0.21154\tvalid-logloss:0.22099\n",
            "[2100]\ttrain-logloss:0.20947\tvalid-logloss:0.22015\n",
            "[2400]\ttrain-logloss:0.20762\tvalid-logloss:0.21948\n",
            "[2700]\ttrain-logloss:0.20587\tvalid-logloss:0.21896\n",
            "[3000]\ttrain-logloss:0.20429\tvalid-logloss:0.21855\n",
            "[3300]\ttrain-logloss:0.20277\tvalid-logloss:0.21822\n",
            "[3600]\ttrain-logloss:0.20135\tvalid-logloss:0.21793\n",
            "[3900]\ttrain-logloss:0.19998\tvalid-logloss:0.21768\n",
            "[4200]\ttrain-logloss:0.19863\tvalid-logloss:0.21748\n",
            "[4500]\ttrain-logloss:0.19735\tvalid-logloss:0.21729\n",
            "[4800]\ttrain-logloss:0.19604\tvalid-logloss:0.21715\n",
            "[5100]\ttrain-logloss:0.19482\tvalid-logloss:0.21702\n",
            "[5400]\ttrain-logloss:0.19358\tvalid-logloss:0.21687\n",
            "[5700]\ttrain-logloss:0.19238\tvalid-logloss:0.21674\n",
            "[6000]\ttrain-logloss:0.19119\tvalid-logloss:0.21664\n",
            "[6300]\ttrain-logloss:0.19002\tvalid-logloss:0.21655\n",
            "[6600]\ttrain-logloss:0.18888\tvalid-logloss:0.21649\n",
            "[6900]\ttrain-logloss:0.18776\tvalid-logloss:0.21642\n",
            "[7200]\ttrain-logloss:0.18664\tvalid-logloss:0.21635\n",
            "[7500]\ttrain-logloss:0.18554\tvalid-logloss:0.21628\n",
            "[7800]\ttrain-logloss:0.18442\tvalid-logloss:0.21625\n",
            "[8100]\ttrain-logloss:0.18334\tvalid-logloss:0.21620\n",
            "[8400]\ttrain-logloss:0.18230\tvalid-logloss:0.21618\n",
            "[8531]\ttrain-logloss:0.18182\tvalid-logloss:0.21618\n",
            "[20:12:17] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[20:12:17] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68574\tvalid-logloss:0.68570\n",
            "[300]\ttrain-logloss:0.25000\tvalid-logloss:0.25011\n",
            "[600]\ttrain-logloss:0.22862\tvalid-logloss:0.23026\n",
            "[900]\ttrain-logloss:0.22176\tvalid-logloss:0.22492\n",
            "[1200]\ttrain-logloss:0.21747\tvalid-logloss:0.22207\n",
            "[1500]\ttrain-logloss:0.21438\tvalid-logloss:0.22037\n",
            "[1800]\ttrain-logloss:0.21190\tvalid-logloss:0.21926\n",
            "[2100]\ttrain-logloss:0.20980\tvalid-logloss:0.21846\n",
            "[2400]\ttrain-logloss:0.20797\tvalid-logloss:0.21788\n",
            "[2700]\ttrain-logloss:0.20620\tvalid-logloss:0.21740\n",
            "[3000]\ttrain-logloss:0.20464\tvalid-logloss:0.21709\n",
            "[3300]\ttrain-logloss:0.20311\tvalid-logloss:0.21680\n",
            "[3600]\ttrain-logloss:0.20163\tvalid-logloss:0.21658\n",
            "[3900]\ttrain-logloss:0.20022\tvalid-logloss:0.21638\n",
            "[4200]\ttrain-logloss:0.19883\tvalid-logloss:0.21620\n",
            "[4500]\ttrain-logloss:0.19753\tvalid-logloss:0.21608\n",
            "[4800]\ttrain-logloss:0.19622\tvalid-logloss:0.21597\n",
            "[5100]\ttrain-logloss:0.19499\tvalid-logloss:0.21587\n",
            "[5400]\ttrain-logloss:0.19375\tvalid-logloss:0.21578\n",
            "[5700]\ttrain-logloss:0.19254\tvalid-logloss:0.21567\n",
            "[6000]\ttrain-logloss:0.19134\tvalid-logloss:0.21562\n",
            "[6300]\ttrain-logloss:0.19016\tvalid-logloss:0.21556\n",
            "[6600]\ttrain-logloss:0.18899\tvalid-logloss:0.21552\n",
            "[6900]\ttrain-logloss:0.18783\tvalid-logloss:0.21547\n",
            "[6980]\ttrain-logloss:0.18753\tvalid-logloss:0.21547\n",
            "[20:21:16] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[20:21:16] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68572\tvalid-logloss:0.68575\n",
            "[300]\ttrain-logloss:0.24931\tvalid-logloss:0.25263\n",
            "[600]\ttrain-logloss:0.22789\tvalid-logloss:0.23309\n",
            "[900]\ttrain-logloss:0.22100\tvalid-logloss:0.22779\n",
            "[1200]\ttrain-logloss:0.21675\tvalid-logloss:0.22504\n",
            "[1500]\ttrain-logloss:0.21366\tvalid-logloss:0.22334\n",
            "[1800]\ttrain-logloss:0.21120\tvalid-logloss:0.22221\n",
            "[2100]\ttrain-logloss:0.20908\tvalid-logloss:0.22144\n",
            "[2400]\ttrain-logloss:0.20720\tvalid-logloss:0.22084\n",
            "[2700]\ttrain-logloss:0.20549\tvalid-logloss:0.22039\n",
            "[3000]\ttrain-logloss:0.20391\tvalid-logloss:0.22005\n",
            "[3300]\ttrain-logloss:0.20239\tvalid-logloss:0.21978\n",
            "[3600]\ttrain-logloss:0.20092\tvalid-logloss:0.21951\n",
            "[3900]\ttrain-logloss:0.19947\tvalid-logloss:0.21932\n",
            "[4200]\ttrain-logloss:0.19814\tvalid-logloss:0.21915\n",
            "[4500]\ttrain-logloss:0.19682\tvalid-logloss:0.21899\n",
            "[4800]\ttrain-logloss:0.19557\tvalid-logloss:0.21885\n",
            "[5100]\ttrain-logloss:0.19429\tvalid-logloss:0.21871\n",
            "[5400]\ttrain-logloss:0.19305\tvalid-logloss:0.21863\n",
            "[5700]\ttrain-logloss:0.19184\tvalid-logloss:0.21852\n",
            "[6000]\ttrain-logloss:0.19065\tvalid-logloss:0.21844\n",
            "[6300]\ttrain-logloss:0.18946\tvalid-logloss:0.21837\n",
            "[6600]\ttrain-logloss:0.18832\tvalid-logloss:0.21831\n",
            "[6900]\ttrain-logloss:0.18716\tvalid-logloss:0.21823\n",
            "[7200]\ttrain-logloss:0.18603\tvalid-logloss:0.21817\n",
            "[7450]\ttrain-logloss:0.18511\tvalid-logloss:0.21814\n",
            "[20:30:04] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[20:30:04] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68571\tvalid-logloss:0.68576\n",
            "[300]\ttrain-logloss:0.24918\tvalid-logloss:0.25292\n",
            "[600]\ttrain-logloss:0.22782\tvalid-logloss:0.23318\n",
            "[900]\ttrain-logloss:0.22087\tvalid-logloss:0.22792\n",
            "[1200]\ttrain-logloss:0.21663\tvalid-logloss:0.22527\n",
            "[1500]\ttrain-logloss:0.21346\tvalid-logloss:0.22361\n",
            "[1800]\ttrain-logloss:0.21098\tvalid-logloss:0.22253\n",
            "[2100]\ttrain-logloss:0.20888\tvalid-logloss:0.22178\n",
            "[2400]\ttrain-logloss:0.20703\tvalid-logloss:0.22122\n",
            "[2700]\ttrain-logloss:0.20529\tvalid-logloss:0.22078\n",
            "[3000]\ttrain-logloss:0.20368\tvalid-logloss:0.22041\n",
            "[3300]\ttrain-logloss:0.20214\tvalid-logloss:0.22013\n",
            "[3600]\ttrain-logloss:0.20067\tvalid-logloss:0.21988\n",
            "[3900]\ttrain-logloss:0.19921\tvalid-logloss:0.21970\n",
            "[4200]\ttrain-logloss:0.19786\tvalid-logloss:0.21954\n",
            "[4500]\ttrain-logloss:0.19649\tvalid-logloss:0.21941\n",
            "[4800]\ttrain-logloss:0.19520\tvalid-logloss:0.21932\n",
            "[5100]\ttrain-logloss:0.19394\tvalid-logloss:0.21922\n",
            "[5400]\ttrain-logloss:0.19268\tvalid-logloss:0.21914\n",
            "[5700]\ttrain-logloss:0.19140\tvalid-logloss:0.21905\n",
            "[6000]\ttrain-logloss:0.19018\tvalid-logloss:0.21898\n",
            "[6300]\ttrain-logloss:0.18897\tvalid-logloss:0.21895\n",
            "[6600]\ttrain-logloss:0.18781\tvalid-logloss:0.21890\n",
            "[6753]\ttrain-logloss:0.18724\tvalid-logloss:0.21889\n",
            "[20:38:28] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[20:38:28] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68573\tvalid-logloss:0.68572\n",
            "[300]\ttrain-logloss:0.25005\tvalid-logloss:0.25010\n",
            "[600]\ttrain-logloss:0.22880\tvalid-logloss:0.23022\n",
            "[900]\ttrain-logloss:0.22194\tvalid-logloss:0.22488\n",
            "[1200]\ttrain-logloss:0.21770\tvalid-logloss:0.22204\n",
            "[1500]\ttrain-logloss:0.21458\tvalid-logloss:0.22026\n",
            "[1800]\ttrain-logloss:0.21210\tvalid-logloss:0.21909\n",
            "[2100]\ttrain-logloss:0.21004\tvalid-logloss:0.21829\n",
            "[2400]\ttrain-logloss:0.20817\tvalid-logloss:0.21768\n",
            "[2700]\ttrain-logloss:0.20647\tvalid-logloss:0.21719\n",
            "[3000]\ttrain-logloss:0.20491\tvalid-logloss:0.21681\n",
            "[3300]\ttrain-logloss:0.20340\tvalid-logloss:0.21649\n",
            "[3600]\ttrain-logloss:0.20194\tvalid-logloss:0.21622\n",
            "[3900]\ttrain-logloss:0.20056\tvalid-logloss:0.21600\n",
            "[4200]\ttrain-logloss:0.19920\tvalid-logloss:0.21582\n",
            "[4500]\ttrain-logloss:0.19788\tvalid-logloss:0.21567\n",
            "[4800]\ttrain-logloss:0.19657\tvalid-logloss:0.21553\n",
            "[5100]\ttrain-logloss:0.19534\tvalid-logloss:0.21540\n",
            "[5400]\ttrain-logloss:0.19410\tvalid-logloss:0.21529\n",
            "[5700]\ttrain-logloss:0.19291\tvalid-logloss:0.21521\n",
            "[6000]\ttrain-logloss:0.19174\tvalid-logloss:0.21512\n",
            "[6300]\ttrain-logloss:0.19056\tvalid-logloss:0.21504\n",
            "[6600]\ttrain-logloss:0.18939\tvalid-logloss:0.21497\n",
            "[6900]\ttrain-logloss:0.18824\tvalid-logloss:0.21490\n",
            "[7200]\ttrain-logloss:0.18712\tvalid-logloss:0.21486\n",
            "[7500]\ttrain-logloss:0.18603\tvalid-logloss:0.21480\n",
            "[7800]\ttrain-logloss:0.18495\tvalid-logloss:0.21474\n",
            "[8100]\ttrain-logloss:0.18386\tvalid-logloss:0.21471\n",
            "[8400]\ttrain-logloss:0.18280\tvalid-logloss:0.21465\n",
            "[8700]\ttrain-logloss:0.18175\tvalid-logloss:0.21462\n",
            "[9000]\ttrain-logloss:0.18072\tvalid-logloss:0.21457\n",
            "[9300]\ttrain-logloss:0.17963\tvalid-logloss:0.21455\n",
            "[9322]\ttrain-logloss:0.17956\tvalid-logloss:0.21456\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-07-01 20:49:35,153]\u001b[0m Trial 20 finished with value: 0.79224750118373 and parameters: {'lambda': 3.5260868570167054, 'alpha': 0.4461725270859897, 'colsample_bytree': 0.7, 'subsample': 0.9, 'learning_rate': 0.012, 'n_estimators': 250, 'max_depth': 4, 'min_child_weight': 26}. Best is trial 5 with value: 0.7938171644083507.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[20:49:48] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[20:49:48] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.67936\tvalid-logloss:0.67946\n",
            "[300]\ttrain-logloss:0.21147\tvalid-logloss:0.22530\n",
            "[600]\ttrain-logloss:0.19785\tvalid-logloss:0.21950\n",
            "[900]\ttrain-logloss:0.18960\tvalid-logloss:0.21789\n",
            "[1200]\ttrain-logloss:0.18270\tvalid-logloss:0.21716\n",
            "[1500]\ttrain-logloss:0.17641\tvalid-logloss:0.21665\n",
            "[1800]\ttrain-logloss:0.17060\tvalid-logloss:0.21642\n",
            "[2100]\ttrain-logloss:0.16524\tvalid-logloss:0.21629\n",
            "[2311]\ttrain-logloss:0.16172\tvalid-logloss:0.21630\n",
            "[20:54:14] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[20:54:15] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.67938\tvalid-logloss:0.67939\n",
            "[300]\ttrain-logloss:0.21213\tvalid-logloss:0.22305\n",
            "[600]\ttrain-logloss:0.19844\tvalid-logloss:0.21753\n",
            "[900]\ttrain-logloss:0.18994\tvalid-logloss:0.21607\n",
            "[1200]\ttrain-logloss:0.18316\tvalid-logloss:0.21551\n",
            "[1500]\ttrain-logloss:0.17690\tvalid-logloss:0.21526\n",
            "[1800]\ttrain-logloss:0.17087\tvalid-logloss:0.21515\n",
            "[1832]\ttrain-logloss:0.17025\tvalid-logloss:0.21514\n",
            "[20:57:53] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[20:57:53] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.67939\tvalid-logloss:0.67949\n",
            "[300]\ttrain-logloss:0.21133\tvalid-logloss:0.22640\n",
            "[600]\ttrain-logloss:0.19775\tvalid-logloss:0.22091\n",
            "[900]\ttrain-logloss:0.18926\tvalid-logloss:0.21936\n",
            "[1200]\ttrain-logloss:0.18239\tvalid-logloss:0.21870\n",
            "[1500]\ttrain-logloss:0.17608\tvalid-logloss:0.21825\n",
            "[1800]\ttrain-logloss:0.17034\tvalid-logloss:0.21811\n",
            "[2100]\ttrain-logloss:0.16486\tvalid-logloss:0.21802\n",
            "[2170]\ttrain-logloss:0.16359\tvalid-logloss:0.21802\n",
            "[21:02:03] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[21:02:03] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.67936\tvalid-logloss:0.67949\n",
            "[300]\ttrain-logloss:0.21125\tvalid-logloss:0.22664\n",
            "[600]\ttrain-logloss:0.19748\tvalid-logloss:0.22131\n",
            "[900]\ttrain-logloss:0.18896\tvalid-logloss:0.21981\n",
            "[1200]\ttrain-logloss:0.18227\tvalid-logloss:0.21924\n",
            "[1500]\ttrain-logloss:0.17600\tvalid-logloss:0.21896\n",
            "[1800]\ttrain-logloss:0.17033\tvalid-logloss:0.21882\n",
            "[1910]\ttrain-logloss:0.16833\tvalid-logloss:0.21883\n",
            "[21:05:45] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[21:05:45] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.67937\tvalid-logloss:0.67941\n",
            "[300]\ttrain-logloss:0.21220\tvalid-logloss:0.22325\n",
            "[600]\ttrain-logloss:0.19873\tvalid-logloss:0.21770\n",
            "[900]\ttrain-logloss:0.19021\tvalid-logloss:0.21606\n",
            "[1200]\ttrain-logloss:0.18323\tvalid-logloss:0.21532\n",
            "[1500]\ttrain-logloss:0.17709\tvalid-logloss:0.21493\n",
            "[1800]\ttrain-logloss:0.17131\tvalid-logloss:0.21478\n",
            "[2100]\ttrain-logloss:0.16602\tvalid-logloss:0.21469\n",
            "[2132]\ttrain-logloss:0.16544\tvalid-logloss:0.21470\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-07-01 21:09:39,281]\u001b[0m Trial 21 finished with value: 0.7936586629823614 and parameters: {'lambda': 1.4294512268102237, 'alpha': 0.15715572583286627, 'colsample_bytree': 0.6, 'subsample': 0.9, 'learning_rate': 0.021, 'n_estimators': 500, 'max_depth': 8, 'min_child_weight': 113}. Best is trial 5 with value: 0.7938171644083507.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[21:09:52] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[21:09:52] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68062\tvalid-logloss:0.68072\n",
            "[300]\ttrain-logloss:0.21263\tvalid-logloss:0.22645\n",
            "[600]\ttrain-logloss:0.19825\tvalid-logloss:0.21992\n",
            "[900]\ttrain-logloss:0.18984\tvalid-logloss:0.21814\n",
            "[1200]\ttrain-logloss:0.18286\tvalid-logloss:0.21730\n",
            "[1500]\ttrain-logloss:0.17644\tvalid-logloss:0.21680\n",
            "[1800]\ttrain-logloss:0.17062\tvalid-logloss:0.21652\n",
            "[2100]\ttrain-logloss:0.16518\tvalid-logloss:0.21634\n",
            "[2400]\ttrain-logloss:0.16029\tvalid-logloss:0.21623\n",
            "[2414]\ttrain-logloss:0.16007\tvalid-logloss:0.21623\n",
            "[21:14:31] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[21:14:32] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68066\tvalid-logloss:0.68067\n",
            "[300]\ttrain-logloss:0.21312\tvalid-logloss:0.22405\n",
            "[600]\ttrain-logloss:0.19848\tvalid-logloss:0.21783\n",
            "[900]\ttrain-logloss:0.18985\tvalid-logloss:0.21631\n",
            "[1200]\ttrain-logloss:0.18281\tvalid-logloss:0.21566\n",
            "[1500]\ttrain-logloss:0.17657\tvalid-logloss:0.21531\n",
            "[1800]\ttrain-logloss:0.17087\tvalid-logloss:0.21516\n",
            "[2100]\ttrain-logloss:0.16545\tvalid-logloss:0.21502\n",
            "[2400]\ttrain-logloss:0.16013\tvalid-logloss:0.21501\n",
            "[2411]\ttrain-logloss:0.15997\tvalid-logloss:0.21500\n",
            "[21:19:12] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[21:19:12] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68066\tvalid-logloss:0.68075\n",
            "[300]\ttrain-logloss:0.21227\tvalid-logloss:0.22739\n",
            "[600]\ttrain-logloss:0.19763\tvalid-logloss:0.22126\n",
            "[900]\ttrain-logloss:0.18906\tvalid-logloss:0.21964\n",
            "[1200]\ttrain-logloss:0.18224\tvalid-logloss:0.21887\n",
            "[1500]\ttrain-logloss:0.17608\tvalid-logloss:0.21846\n",
            "[1800]\ttrain-logloss:0.17036\tvalid-logloss:0.21830\n",
            "[2038]\ttrain-logloss:0.16596\tvalid-logloss:0.21826\n",
            "[21:23:11] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[21:23:11] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68063\tvalid-logloss:0.68075\n",
            "[300]\ttrain-logloss:0.21216\tvalid-logloss:0.22752\n",
            "[600]\ttrain-logloss:0.19761\tvalid-logloss:0.22157\n",
            "[900]\ttrain-logloss:0.18878\tvalid-logloss:0.22000\n",
            "[1200]\ttrain-logloss:0.18202\tvalid-logloss:0.21943\n",
            "[1500]\ttrain-logloss:0.17582\tvalid-logloss:0.21910\n",
            "[1800]\ttrain-logloss:0.17000\tvalid-logloss:0.21892\n",
            "[2100]\ttrain-logloss:0.16465\tvalid-logloss:0.21888\n",
            "[2361]\ttrain-logloss:0.16023\tvalid-logloss:0.21883\n",
            "[21:27:41] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[21:27:42] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68064\tvalid-logloss:0.68068\n",
            "[300]\ttrain-logloss:0.21316\tvalid-logloss:0.22435\n",
            "[600]\ttrain-logloss:0.19874\tvalid-logloss:0.21797\n",
            "[900]\ttrain-logloss:0.19006\tvalid-logloss:0.21622\n",
            "[1200]\ttrain-logloss:0.18293\tvalid-logloss:0.21539\n",
            "[1500]\ttrain-logloss:0.17672\tvalid-logloss:0.21501\n",
            "[1800]\ttrain-logloss:0.17103\tvalid-logloss:0.21478\n",
            "[2100]\ttrain-logloss:0.16562\tvalid-logloss:0.21467\n",
            "[2400]\ttrain-logloss:0.16045\tvalid-logloss:0.21460\n",
            "[2450]\ttrain-logloss:0.15968\tvalid-logloss:0.21461\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-07-01 21:32:11,442]\u001b[0m Trial 22 finished with value: 0.7926109434573945 and parameters: {'lambda': 0.2663186322819295, 'alpha': 0.09784226861999175, 'colsample_bytree': 0.6, 'subsample': 0.9, 'learning_rate': 0.019000000000000003, 'n_estimators': 480, 'max_depth': 8, 'min_child_weight': 95}. Best is trial 5 with value: 0.7938171644083507.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:32:24] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[21:32:24] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68923\tvalid-logloss:0.68924\n",
            "[300]\ttrain-logloss:0.28510\tvalid-logloss:0.28903\n",
            "[600]\ttrain-logloss:0.23349\tvalid-logloss:0.23999\n",
            "[900]\ttrain-logloss:0.22080\tvalid-logloss:0.22947\n",
            "[1200]\ttrain-logloss:0.21464\tvalid-logloss:0.22528\n",
            "[1500]\ttrain-logloss:0.21068\tvalid-logloss:0.22297\n",
            "[1800]\ttrain-logloss:0.20756\tvalid-logloss:0.22142\n",
            "[2100]\ttrain-logloss:0.20487\tvalid-logloss:0.22031\n",
            "[2400]\ttrain-logloss:0.20261\tvalid-logloss:0.21954\n",
            "[2700]\ttrain-logloss:0.20056\tvalid-logloss:0.21896\n",
            "[3000]\ttrain-logloss:0.19864\tvalid-logloss:0.21848\n",
            "[3300]\ttrain-logloss:0.19681\tvalid-logloss:0.21811\n",
            "[3600]\ttrain-logloss:0.19506\tvalid-logloss:0.21781\n",
            "[3900]\ttrain-logloss:0.19335\tvalid-logloss:0.21754\n",
            "[4200]\ttrain-logloss:0.19167\tvalid-logloss:0.21733\n",
            "[4500]\ttrain-logloss:0.19004\tvalid-logloss:0.21716\n",
            "[4800]\ttrain-logloss:0.18845\tvalid-logloss:0.21699\n",
            "[5100]\ttrain-logloss:0.18697\tvalid-logloss:0.21686\n",
            "[5400]\ttrain-logloss:0.18550\tvalid-logloss:0.21673\n",
            "[5700]\ttrain-logloss:0.18404\tvalid-logloss:0.21663\n",
            "[6000]\ttrain-logloss:0.18255\tvalid-logloss:0.21650\n",
            "[6300]\ttrain-logloss:0.18114\tvalid-logloss:0.21641\n",
            "[6600]\ttrain-logloss:0.17971\tvalid-logloss:0.21633\n",
            "[6900]\ttrain-logloss:0.17832\tvalid-logloss:0.21626\n",
            "[7200]\ttrain-logloss:0.17696\tvalid-logloss:0.21622\n",
            "[7500]\ttrain-logloss:0.17559\tvalid-logloss:0.21616\n",
            "[7800]\ttrain-logloss:0.17430\tvalid-logloss:0.21611\n",
            "[8100]\ttrain-logloss:0.17298\tvalid-logloss:0.21607\n",
            "[8400]\ttrain-logloss:0.17165\tvalid-logloss:0.21600\n",
            "[8700]\ttrain-logloss:0.17043\tvalid-logloss:0.21595\n",
            "[9000]\ttrain-logloss:0.16913\tvalid-logloss:0.21594\n",
            "[9017]\ttrain-logloss:0.16906\tvalid-logloss:0.21594\n",
            "[21:48:25] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[21:48:25] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68924\tvalid-logloss:0.68923\n",
            "[300]\ttrain-logloss:0.28554\tvalid-logloss:0.28749\n",
            "[600]\ttrain-logloss:0.23393\tvalid-logloss:0.23797\n",
            "[900]\ttrain-logloss:0.22133\tvalid-logloss:0.22728\n",
            "[1200]\ttrain-logloss:0.21510\tvalid-logloss:0.22304\n",
            "[1500]\ttrain-logloss:0.21110\tvalid-logloss:0.22080\n",
            "[1800]\ttrain-logloss:0.20794\tvalid-logloss:0.21934\n",
            "[2100]\ttrain-logloss:0.20536\tvalid-logloss:0.21838\n",
            "[2400]\ttrain-logloss:0.20297\tvalid-logloss:0.21765\n",
            "[2700]\ttrain-logloss:0.20084\tvalid-logloss:0.21714\n",
            "[3000]\ttrain-logloss:0.19889\tvalid-logloss:0.21676\n",
            "[3300]\ttrain-logloss:0.19707\tvalid-logloss:0.21643\n",
            "[3600]\ttrain-logloss:0.19531\tvalid-logloss:0.21618\n",
            "[3900]\ttrain-logloss:0.19362\tvalid-logloss:0.21597\n",
            "[4200]\ttrain-logloss:0.19199\tvalid-logloss:0.21580\n",
            "[4500]\ttrain-logloss:0.19037\tvalid-logloss:0.21564\n",
            "[4800]\ttrain-logloss:0.18880\tvalid-logloss:0.21552\n",
            "[5100]\ttrain-logloss:0.18729\tvalid-logloss:0.21543\n",
            "[5400]\ttrain-logloss:0.18574\tvalid-logloss:0.21534\n",
            "[5700]\ttrain-logloss:0.18433\tvalid-logloss:0.21526\n",
            "[6000]\ttrain-logloss:0.18286\tvalid-logloss:0.21519\n",
            "[6300]\ttrain-logloss:0.18142\tvalid-logloss:0.21514\n",
            "[6600]\ttrain-logloss:0.18000\tvalid-logloss:0.21509\n",
            "[6900]\ttrain-logloss:0.17864\tvalid-logloss:0.21505\n",
            "[7200]\ttrain-logloss:0.17722\tvalid-logloss:0.21499\n",
            "[7500]\ttrain-logloss:0.17584\tvalid-logloss:0.21495\n",
            "[7800]\ttrain-logloss:0.17455\tvalid-logloss:0.21493\n",
            "[7868]\ttrain-logloss:0.17429\tvalid-logloss:0.21493\n",
            "[22:02:32] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[22:02:32] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68923\tvalid-logloss:0.68925\n",
            "[300]\ttrain-logloss:0.28498\tvalid-logloss:0.28971\n",
            "[600]\ttrain-logloss:0.23320\tvalid-logloss:0.24086\n",
            "[900]\ttrain-logloss:0.22054\tvalid-logloss:0.23043\n",
            "[1200]\ttrain-logloss:0.21431\tvalid-logloss:0.22629\n",
            "[1500]\ttrain-logloss:0.21031\tvalid-logloss:0.22412\n",
            "[1800]\ttrain-logloss:0.20721\tvalid-logloss:0.22272\n",
            "[2100]\ttrain-logloss:0.20456\tvalid-logloss:0.22176\n",
            "[2400]\ttrain-logloss:0.20219\tvalid-logloss:0.22104\n",
            "[2700]\ttrain-logloss:0.20011\tvalid-logloss:0.22052\n",
            "[3000]\ttrain-logloss:0.19815\tvalid-logloss:0.22010\n",
            "[3300]\ttrain-logloss:0.19630\tvalid-logloss:0.21976\n",
            "[3600]\ttrain-logloss:0.19452\tvalid-logloss:0.21950\n",
            "[3900]\ttrain-logloss:0.19287\tvalid-logloss:0.21927\n",
            "[4200]\ttrain-logloss:0.19126\tvalid-logloss:0.21909\n",
            "[4500]\ttrain-logloss:0.18969\tvalid-logloss:0.21896\n",
            "[4800]\ttrain-logloss:0.18812\tvalid-logloss:0.21882\n",
            "[5100]\ttrain-logloss:0.18665\tvalid-logloss:0.21872\n",
            "[5400]\ttrain-logloss:0.18518\tvalid-logloss:0.21861\n",
            "[5700]\ttrain-logloss:0.18373\tvalid-logloss:0.21854\n",
            "[6000]\ttrain-logloss:0.18222\tvalid-logloss:0.21845\n",
            "[6300]\ttrain-logloss:0.18083\tvalid-logloss:0.21838\n",
            "[6600]\ttrain-logloss:0.17946\tvalid-logloss:0.21831\n",
            "[6900]\ttrain-logloss:0.17802\tvalid-logloss:0.21826\n",
            "[6999]\ttrain-logloss:0.17757\tvalid-logloss:0.21826\n",
            "[22:14:59] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[22:14:59] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68922\tvalid-logloss:0.68926\n",
            "[300]\ttrain-logloss:0.28489\tvalid-logloss:0.29006\n",
            "[600]\ttrain-logloss:0.23312\tvalid-logloss:0.24107\n",
            "[900]\ttrain-logloss:0.22044\tvalid-logloss:0.23063\n",
            "[1200]\ttrain-logloss:0.21419\tvalid-logloss:0.22654\n",
            "[1500]\ttrain-logloss:0.21026\tvalid-logloss:0.22442\n",
            "[1800]\ttrain-logloss:0.20711\tvalid-logloss:0.22303\n",
            "[2100]\ttrain-logloss:0.20440\tvalid-logloss:0.22207\n",
            "[2400]\ttrain-logloss:0.20211\tvalid-logloss:0.22138\n",
            "[2700]\ttrain-logloss:0.19997\tvalid-logloss:0.22085\n",
            "[3000]\ttrain-logloss:0.19802\tvalid-logloss:0.22044\n",
            "[3300]\ttrain-logloss:0.19623\tvalid-logloss:0.22015\n",
            "[3600]\ttrain-logloss:0.19444\tvalid-logloss:0.21989\n",
            "[3900]\ttrain-logloss:0.19275\tvalid-logloss:0.21970\n",
            "[4200]\ttrain-logloss:0.19109\tvalid-logloss:0.21952\n",
            "[4500]\ttrain-logloss:0.18944\tvalid-logloss:0.21937\n",
            "[4800]\ttrain-logloss:0.18790\tvalid-logloss:0.21925\n",
            "[5100]\ttrain-logloss:0.18638\tvalid-logloss:0.21916\n",
            "[5400]\ttrain-logloss:0.18489\tvalid-logloss:0.21905\n",
            "[5700]\ttrain-logloss:0.18347\tvalid-logloss:0.21899\n",
            "[6000]\ttrain-logloss:0.18203\tvalid-logloss:0.21895\n",
            "[6300]\ttrain-logloss:0.18065\tvalid-logloss:0.21891\n",
            "[6600]\ttrain-logloss:0.17925\tvalid-logloss:0.21885\n",
            "[6900]\ttrain-logloss:0.17780\tvalid-logloss:0.21882\n",
            "[7200]\ttrain-logloss:0.17639\tvalid-logloss:0.21879\n",
            "[7500]\ttrain-logloss:0.17506\tvalid-logloss:0.21876\n",
            "[7628]\ttrain-logloss:0.17449\tvalid-logloss:0.21875\n",
            "[22:28:28] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[22:28:28] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68923\tvalid-logloss:0.68923\n",
            "[300]\ttrain-logloss:0.28564\tvalid-logloss:0.28762\n",
            "[600]\ttrain-logloss:0.23412\tvalid-logloss:0.23809\n",
            "[900]\ttrain-logloss:0.22148\tvalid-logloss:0.22738\n",
            "[1200]\ttrain-logloss:0.21529\tvalid-logloss:0.22316\n",
            "[1500]\ttrain-logloss:0.21131\tvalid-logloss:0.22094\n",
            "[1800]\ttrain-logloss:0.20819\tvalid-logloss:0.21951\n",
            "[2100]\ttrain-logloss:0.20555\tvalid-logloss:0.21847\n",
            "[2400]\ttrain-logloss:0.20316\tvalid-logloss:0.21768\n",
            "[2700]\ttrain-logloss:0.20099\tvalid-logloss:0.21710\n",
            "[3000]\ttrain-logloss:0.19903\tvalid-logloss:0.21667\n",
            "[3300]\ttrain-logloss:0.19720\tvalid-logloss:0.21631\n",
            "[3600]\ttrain-logloss:0.19548\tvalid-logloss:0.21602\n",
            "[3900]\ttrain-logloss:0.19379\tvalid-logloss:0.21577\n",
            "[4200]\ttrain-logloss:0.19217\tvalid-logloss:0.21555\n",
            "[4500]\ttrain-logloss:0.19059\tvalid-logloss:0.21536\n",
            "[4800]\ttrain-logloss:0.18904\tvalid-logloss:0.21520\n",
            "[5100]\ttrain-logloss:0.18744\tvalid-logloss:0.21507\n",
            "[5400]\ttrain-logloss:0.18593\tvalid-logloss:0.21494\n",
            "[5700]\ttrain-logloss:0.18446\tvalid-logloss:0.21483\n",
            "[6000]\ttrain-logloss:0.18299\tvalid-logloss:0.21474\n",
            "[6300]\ttrain-logloss:0.18156\tvalid-logloss:0.21466\n",
            "[6600]\ttrain-logloss:0.18009\tvalid-logloss:0.21458\n",
            "[6900]\ttrain-logloss:0.17872\tvalid-logloss:0.21454\n",
            "[7200]\ttrain-logloss:0.17741\tvalid-logloss:0.21447\n",
            "[7500]\ttrain-logloss:0.17605\tvalid-logloss:0.21442\n",
            "[7800]\ttrain-logloss:0.17470\tvalid-logloss:0.21438\n",
            "[8100]\ttrain-logloss:0.17336\tvalid-logloss:0.21434\n",
            "[8185]\ttrain-logloss:0.17299\tvalid-logloss:0.21434\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-07-01 22:42:43,633]\u001b[0m Trial 23 finished with value: 0.7935360673788254 and parameters: {'lambda': 0.8151263126927004, 'alpha': 2.415122910684003, 'colsample_bytree': 0.8, 'subsample': 0.8, 'learning_rate': 0.006, 'n_estimators': 760, 'max_depth': 7, 'min_child_weight': 134}. Best is trial 5 with value: 0.7938171644083507.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[22:42:56] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[22:42:56] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68371\tvalid-logloss:0.68386\n",
            "[300]\ttrain-logloss:0.19941\tvalid-logloss:0.22976\n",
            "[600]\ttrain-logloss:0.17002\tvalid-logloss:0.22093\n",
            "[900]\ttrain-logloss:0.15204\tvalid-logloss:0.21883\n",
            "[1200]\ttrain-logloss:0.13897\tvalid-logloss:0.21803\n",
            "[1500]\ttrain-logloss:0.12757\tvalid-logloss:0.21763\n",
            "[1800]\ttrain-logloss:0.11759\tvalid-logloss:0.21748\n",
            "[2080]\ttrain-logloss:0.10944\tvalid-logloss:0.21748\n",
            "[22:49:09] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[22:49:09] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68372\tvalid-logloss:0.68383\n",
            "[300]\ttrain-logloss:0.19969\tvalid-logloss:0.22764\n",
            "[600]\ttrain-logloss:0.17078\tvalid-logloss:0.21885\n",
            "[900]\ttrain-logloss:0.15301\tvalid-logloss:0.21685\n",
            "[1200]\ttrain-logloss:0.13936\tvalid-logloss:0.21626\n",
            "[1500]\ttrain-logloss:0.12822\tvalid-logloss:0.21595\n",
            "[1800]\ttrain-logloss:0.11768\tvalid-logloss:0.21588\n",
            "[1870]\ttrain-logloss:0.11528\tvalid-logloss:0.21591\n",
            "[22:54:52] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[22:54:52] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68371\tvalid-logloss:0.68387\n",
            "[300]\ttrain-logloss:0.19893\tvalid-logloss:0.23056\n",
            "[600]\ttrain-logloss:0.16964\tvalid-logloss:0.22195\n",
            "[900]\ttrain-logloss:0.15155\tvalid-logloss:0.22009\n",
            "[1200]\ttrain-logloss:0.13846\tvalid-logloss:0.21949\n",
            "[1500]\ttrain-logloss:0.12764\tvalid-logloss:0.21922\n",
            "[1800]\ttrain-logloss:0.11702\tvalid-logloss:0.21916\n",
            "[1830]\ttrain-logloss:0.11619\tvalid-logloss:0.21918\n",
            "[23:00:26] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[23:00:27] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68371\tvalid-logloss:0.68388\n",
            "[300]\ttrain-logloss:0.19909\tvalid-logloss:0.23074\n",
            "[600]\ttrain-logloss:0.17024\tvalid-logloss:0.22245\n",
            "[900]\ttrain-logloss:0.15266\tvalid-logloss:0.22061\n",
            "[1200]\ttrain-logloss:0.13847\tvalid-logloss:0.21993\n",
            "[1500]\ttrain-logloss:0.12674\tvalid-logloss:0.21977\n",
            "[1605]\ttrain-logloss:0.12330\tvalid-logloss:0.21978\n",
            "[23:05:26] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[23:05:26] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68371\tvalid-logloss:0.68384\n",
            "[300]\ttrain-logloss:0.20003\tvalid-logloss:0.22769\n",
            "[600]\ttrain-logloss:0.17091\tvalid-logloss:0.21881\n",
            "[900]\ttrain-logloss:0.15379\tvalid-logloss:0.21682\n",
            "[1200]\ttrain-logloss:0.13982\tvalid-logloss:0.21598\n",
            "[1500]\ttrain-logloss:0.12833\tvalid-logloss:0.21563\n",
            "[1800]\ttrain-logloss:0.11768\tvalid-logloss:0.21543\n",
            "[2034]\ttrain-logloss:0.11057\tvalid-logloss:0.21539\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-07-01 23:11:21,219]\u001b[0m Trial 24 finished with value: 0.7927818759364109 and parameters: {'lambda': 4.550752335270396, 'alpha': 0.2743247858396947, 'colsample_bytree': 0.7, 'subsample': 1.0, 'learning_rate': 0.014000000000000002, 'n_estimators': 690, 'max_depth': 9, 'min_child_weight': 3}. Best is trial 5 with value: 0.7938171644083507.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[23:11:34] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[23:11:34] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68116\tvalid-logloss:0.68129\n",
            "[300]\ttrain-logloss:0.20414\tvalid-logloss:0.22471\n",
            "[600]\ttrain-logloss:0.18696\tvalid-logloss:0.21872\n",
            "[900]\ttrain-logloss:0.17599\tvalid-logloss:0.21717\n",
            "[1200]\ttrain-logloss:0.16666\tvalid-logloss:0.21647\n",
            "[1500]\ttrain-logloss:0.15852\tvalid-logloss:0.21613\n",
            "[1800]\ttrain-logloss:0.15146\tvalid-logloss:0.21596\n",
            "[2100]\ttrain-logloss:0.14442\tvalid-logloss:0.21588\n",
            "[2149]\ttrain-logloss:0.14343\tvalid-logloss:0.21587\n",
            "[23:16:29] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[23:16:30] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68118\tvalid-logloss:0.68125\n",
            "[300]\ttrain-logloss:0.20462\tvalid-logloss:0.22285\n",
            "[600]\ttrain-logloss:0.18738\tvalid-logloss:0.21714\n",
            "[900]\ttrain-logloss:0.17629\tvalid-logloss:0.21584\n",
            "[1200]\ttrain-logloss:0.16715\tvalid-logloss:0.21536\n",
            "[1500]\ttrain-logloss:0.15912\tvalid-logloss:0.21507\n",
            "[1800]\ttrain-logloss:0.15160\tvalid-logloss:0.21495\n",
            "[1855]\ttrain-logloss:0.15033\tvalid-logloss:0.21494\n",
            "[23:20:51] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[23:20:51] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68116\tvalid-logloss:0.68130\n",
            "[300]\ttrain-logloss:0.20383\tvalid-logloss:0.22603\n",
            "[600]\ttrain-logloss:0.18670\tvalid-logloss:0.22048\n",
            "[900]\ttrain-logloss:0.17555\tvalid-logloss:0.21912\n",
            "[1200]\ttrain-logloss:0.16675\tvalid-logloss:0.21856\n",
            "[1500]\ttrain-logloss:0.15838\tvalid-logloss:0.21834\n",
            "[1800]\ttrain-logloss:0.15086\tvalid-logloss:0.21815\n",
            "[1898]\ttrain-logloss:0.14861\tvalid-logloss:0.21814\n",
            "[23:25:15] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[23:25:15] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68115\tvalid-logloss:0.68132\n",
            "[300]\ttrain-logloss:0.20380\tvalid-logloss:0.22627\n",
            "[600]\ttrain-logloss:0.18650\tvalid-logloss:0.22083\n",
            "[900]\ttrain-logloss:0.17526\tvalid-logloss:0.21952\n",
            "[1200]\ttrain-logloss:0.16601\tvalid-logloss:0.21903\n",
            "[1500]\ttrain-logloss:0.15791\tvalid-logloss:0.21883\n",
            "[1620]\ttrain-logloss:0.15487\tvalid-logloss:0.21884\n",
            "[23:29:07] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[23:29:07] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68117\tvalid-logloss:0.68125\n",
            "[300]\ttrain-logloss:0.20476\tvalid-logloss:0.22291\n",
            "[600]\ttrain-logloss:0.18769\tvalid-logloss:0.21711\n",
            "[900]\ttrain-logloss:0.17619\tvalid-logloss:0.21557\n",
            "[1200]\ttrain-logloss:0.16667\tvalid-logloss:0.21489\n",
            "[1500]\ttrain-logloss:0.15877\tvalid-logloss:0.21455\n",
            "[1646]\ttrain-logloss:0.15516\tvalid-logloss:0.21451\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-07-01 23:32:50,649]\u001b[0m Trial 25 finished with value: 0.7935803801148614 and parameters: {'lambda': 1.2747363393949522, 'alpha': 0.09150364784719414, 'colsample_bytree': 0.5, 'subsample': 0.9, 'learning_rate': 0.018000000000000002, 'n_estimators': 220, 'max_depth': 10, 'min_child_weight': 79}. Best is trial 5 with value: 0.7938171644083507.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[23:33:04] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[23:33:04] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68984\tvalid-logloss:0.68986\n",
            "[300]\ttrain-logloss:0.30311\tvalid-logloss:0.30759\n",
            "[600]\ttrain-logloss:0.23813\tvalid-logloss:0.24572\n",
            "[900]\ttrain-logloss:0.22098\tvalid-logloss:0.23102\n",
            "[1200]\ttrain-logloss:0.21384\tvalid-logloss:0.22595\n",
            "[1500]\ttrain-logloss:0.20925\tvalid-logloss:0.22330\n",
            "[1800]\ttrain-logloss:0.20581\tvalid-logloss:0.22163\n",
            "[2100]\ttrain-logloss:0.20294\tvalid-logloss:0.22046\n",
            "[2400]\ttrain-logloss:0.20043\tvalid-logloss:0.21960\n",
            "[2700]\ttrain-logloss:0.19821\tvalid-logloss:0.21895\n",
            "[3000]\ttrain-logloss:0.19621\tvalid-logloss:0.21845\n",
            "[3300]\ttrain-logloss:0.19428\tvalid-logloss:0.21807\n",
            "[3600]\ttrain-logloss:0.19240\tvalid-logloss:0.21776\n",
            "[3900]\ttrain-logloss:0.19063\tvalid-logloss:0.21748\n",
            "[4200]\ttrain-logloss:0.18893\tvalid-logloss:0.21726\n",
            "[4500]\ttrain-logloss:0.18725\tvalid-logloss:0.21707\n",
            "[4800]\ttrain-logloss:0.18567\tvalid-logloss:0.21690\n",
            "[5100]\ttrain-logloss:0.18413\tvalid-logloss:0.21677\n",
            "[5400]\ttrain-logloss:0.18265\tvalid-logloss:0.21663\n",
            "[5700]\ttrain-logloss:0.18117\tvalid-logloss:0.21653\n",
            "[6000]\ttrain-logloss:0.17967\tvalid-logloss:0.21642\n",
            "[6300]\ttrain-logloss:0.17823\tvalid-logloss:0.21633\n",
            "[6600]\ttrain-logloss:0.17679\tvalid-logloss:0.21626\n",
            "[6900]\ttrain-logloss:0.17536\tvalid-logloss:0.21619\n",
            "[7200]\ttrain-logloss:0.17398\tvalid-logloss:0.21614\n",
            "[7500]\ttrain-logloss:0.17260\tvalid-logloss:0.21609\n",
            "[7800]\ttrain-logloss:0.17125\tvalid-logloss:0.21603\n",
            "[8100]\ttrain-logloss:0.16990\tvalid-logloss:0.21598\n",
            "[8400]\ttrain-logloss:0.16859\tvalid-logloss:0.21593\n",
            "[8700]\ttrain-logloss:0.16732\tvalid-logloss:0.21591\n",
            "[9000]\ttrain-logloss:0.16603\tvalid-logloss:0.21588\n",
            "[9300]\ttrain-logloss:0.16473\tvalid-logloss:0.21587\n",
            "[9600]\ttrain-logloss:0.16343\tvalid-logloss:0.21585\n",
            "[9635]\ttrain-logloss:0.16327\tvalid-logloss:0.21585\n",
            "[23:51:09] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[23:51:09] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68986\tvalid-logloss:0.68986\n",
            "[300]\ttrain-logloss:0.30354\tvalid-logloss:0.30617\n",
            "[600]\ttrain-logloss:0.23859\tvalid-logloss:0.24380\n",
            "[900]\ttrain-logloss:0.22151\tvalid-logloss:0.22892\n",
            "[1200]\ttrain-logloss:0.21431\tvalid-logloss:0.22374\n",
            "[1500]\ttrain-logloss:0.20969\tvalid-logloss:0.22111\n",
            "[1800]\ttrain-logloss:0.20625\tvalid-logloss:0.21953\n",
            "[2100]\ttrain-logloss:0.20347\tvalid-logloss:0.21848\n",
            "[2400]\ttrain-logloss:0.20088\tvalid-logloss:0.21770\n",
            "[2700]\ttrain-logloss:0.19860\tvalid-logloss:0.21714\n",
            "[3000]\ttrain-logloss:0.19652\tvalid-logloss:0.21670\n",
            "[3300]\ttrain-logloss:0.19456\tvalid-logloss:0.21636\n",
            "[3600]\ttrain-logloss:0.19275\tvalid-logloss:0.21609\n",
            "[3900]\ttrain-logloss:0.19100\tvalid-logloss:0.21586\n",
            "[4200]\ttrain-logloss:0.18931\tvalid-logloss:0.21568\n",
            "[4500]\ttrain-logloss:0.18764\tvalid-logloss:0.21552\n",
            "[4800]\ttrain-logloss:0.18602\tvalid-logloss:0.21539\n",
            "[5100]\ttrain-logloss:0.18441\tvalid-logloss:0.21527\n",
            "[5400]\ttrain-logloss:0.18284\tvalid-logloss:0.21516\n",
            "[5700]\ttrain-logloss:0.18131\tvalid-logloss:0.21508\n",
            "[6000]\ttrain-logloss:0.17982\tvalid-logloss:0.21501\n",
            "[6300]\ttrain-logloss:0.17834\tvalid-logloss:0.21495\n",
            "[6600]\ttrain-logloss:0.17690\tvalid-logloss:0.21489\n",
            "[6900]\ttrain-logloss:0.17550\tvalid-logloss:0.21485\n",
            "[7200]\ttrain-logloss:0.17407\tvalid-logloss:0.21480\n",
            "[7500]\ttrain-logloss:0.17268\tvalid-logloss:0.21477\n",
            "[7800]\ttrain-logloss:0.17136\tvalid-logloss:0.21473\n",
            "[7850]\ttrain-logloss:0.17116\tvalid-logloss:0.21474\n",
            "[00:06:08] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[00:06:09] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68985\tvalid-logloss:0.68987\n",
            "[300]\ttrain-logloss:0.30300\tvalid-logloss:0.30817\n",
            "[600]\ttrain-logloss:0.23785\tvalid-logloss:0.24647\n",
            "[900]\ttrain-logloss:0.22069\tvalid-logloss:0.23196\n",
            "[1200]\ttrain-logloss:0.21348\tvalid-logloss:0.22698\n",
            "[1500]\ttrain-logloss:0.20884\tvalid-logloss:0.22443\n",
            "[1800]\ttrain-logloss:0.20544\tvalid-logloss:0.22287\n",
            "[2100]\ttrain-logloss:0.20257\tvalid-logloss:0.22180\n",
            "[2400]\ttrain-logloss:0.20008\tvalid-logloss:0.22104\n",
            "[2700]\ttrain-logloss:0.19782\tvalid-logloss:0.22047\n",
            "[3000]\ttrain-logloss:0.19578\tvalid-logloss:0.22002\n",
            "[3300]\ttrain-logloss:0.19380\tvalid-logloss:0.21966\n",
            "[3600]\ttrain-logloss:0.19193\tvalid-logloss:0.21939\n",
            "[3900]\ttrain-logloss:0.19014\tvalid-logloss:0.21916\n",
            "[4200]\ttrain-logloss:0.18847\tvalid-logloss:0.21897\n",
            "[4500]\ttrain-logloss:0.18682\tvalid-logloss:0.21880\n",
            "[4800]\ttrain-logloss:0.18522\tvalid-logloss:0.21868\n",
            "[5100]\ttrain-logloss:0.18371\tvalid-logloss:0.21856\n",
            "[5400]\ttrain-logloss:0.18218\tvalid-logloss:0.21842\n",
            "[5700]\ttrain-logloss:0.18066\tvalid-logloss:0.21835\n",
            "[6000]\ttrain-logloss:0.17911\tvalid-logloss:0.21826\n",
            "[6300]\ttrain-logloss:0.17768\tvalid-logloss:0.21819\n",
            "[6600]\ttrain-logloss:0.17628\tvalid-logloss:0.21811\n",
            "[6900]\ttrain-logloss:0.17481\tvalid-logloss:0.21804\n",
            "[7200]\ttrain-logloss:0.17342\tvalid-logloss:0.21798\n",
            "[7500]\ttrain-logloss:0.17206\tvalid-logloss:0.21794\n",
            "[7800]\ttrain-logloss:0.17072\tvalid-logloss:0.21791\n",
            "[8100]\ttrain-logloss:0.16934\tvalid-logloss:0.21787\n",
            "[8400]\ttrain-logloss:0.16798\tvalid-logloss:0.21785\n",
            "[8455]\ttrain-logloss:0.16773\tvalid-logloss:0.21784\n",
            "[00:22:00] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[00:22:00] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68984\tvalid-logloss:0.68987\n",
            "[300]\ttrain-logloss:0.30294\tvalid-logloss:0.30859\n",
            "[600]\ttrain-logloss:0.23781\tvalid-logloss:0.24684\n",
            "[900]\ttrain-logloss:0.22065\tvalid-logloss:0.23221\n",
            "[1200]\ttrain-logloss:0.21339\tvalid-logloss:0.22718\n",
            "[1500]\ttrain-logloss:0.20879\tvalid-logloss:0.22467\n",
            "[1800]\ttrain-logloss:0.20537\tvalid-logloss:0.22316\n",
            "[2100]\ttrain-logloss:0.20247\tvalid-logloss:0.22212\n",
            "[2400]\ttrain-logloss:0.19993\tvalid-logloss:0.22138\n",
            "[2700]\ttrain-logloss:0.19764\tvalid-logloss:0.22082\n",
            "[3000]\ttrain-logloss:0.19558\tvalid-logloss:0.22038\n",
            "[3300]\ttrain-logloss:0.19371\tvalid-logloss:0.22005\n",
            "[3600]\ttrain-logloss:0.19188\tvalid-logloss:0.21979\n",
            "[3900]\ttrain-logloss:0.19012\tvalid-logloss:0.21957\n",
            "[4200]\ttrain-logloss:0.18837\tvalid-logloss:0.21938\n",
            "[4500]\ttrain-logloss:0.18664\tvalid-logloss:0.21923\n",
            "[4800]\ttrain-logloss:0.18508\tvalid-logloss:0.21912\n",
            "[5100]\ttrain-logloss:0.18355\tvalid-logloss:0.21900\n",
            "[5400]\ttrain-logloss:0.18202\tvalid-logloss:0.21890\n",
            "[5700]\ttrain-logloss:0.18049\tvalid-logloss:0.21882\n",
            "[6000]\ttrain-logloss:0.17901\tvalid-logloss:0.21875\n",
            "[6300]\ttrain-logloss:0.17758\tvalid-logloss:0.21870\n",
            "[6600]\ttrain-logloss:0.17617\tvalid-logloss:0.21862\n",
            "[6751]\ttrain-logloss:0.17543\tvalid-logloss:0.21862\n",
            "[00:34:51] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[00:34:51] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68985\tvalid-logloss:0.68986\n",
            "[300]\ttrain-logloss:0.30365\tvalid-logloss:0.30637\n",
            "[600]\ttrain-logloss:0.23875\tvalid-logloss:0.24403\n",
            "[900]\ttrain-logloss:0.22163\tvalid-logloss:0.22909\n",
            "[1200]\ttrain-logloss:0.21444\tvalid-logloss:0.22395\n",
            "[1500]\ttrain-logloss:0.20989\tvalid-logloss:0.22137\n",
            "[1800]\ttrain-logloss:0.20650\tvalid-logloss:0.21977\n",
            "[2100]\ttrain-logloss:0.20366\tvalid-logloss:0.21866\n",
            "[2400]\ttrain-logloss:0.20115\tvalid-logloss:0.21783\n",
            "[2700]\ttrain-logloss:0.19887\tvalid-logloss:0.21722\n",
            "[3000]\ttrain-logloss:0.19674\tvalid-logloss:0.21674\n",
            "[3300]\ttrain-logloss:0.19479\tvalid-logloss:0.21638\n",
            "[3600]\ttrain-logloss:0.19293\tvalid-logloss:0.21605\n",
            "[3900]\ttrain-logloss:0.19108\tvalid-logloss:0.21579\n",
            "[4200]\ttrain-logloss:0.18939\tvalid-logloss:0.21557\n",
            "[4500]\ttrain-logloss:0.18765\tvalid-logloss:0.21536\n",
            "[4800]\ttrain-logloss:0.18604\tvalid-logloss:0.21520\n",
            "[5100]\ttrain-logloss:0.18439\tvalid-logloss:0.21506\n",
            "[5400]\ttrain-logloss:0.18283\tvalid-logloss:0.21494\n",
            "[5700]\ttrain-logloss:0.18129\tvalid-logloss:0.21484\n",
            "[6000]\ttrain-logloss:0.17978\tvalid-logloss:0.21473\n",
            "[6300]\ttrain-logloss:0.17837\tvalid-logloss:0.21465\n",
            "[6600]\ttrain-logloss:0.17686\tvalid-logloss:0.21458\n",
            "[6900]\ttrain-logloss:0.17548\tvalid-logloss:0.21452\n",
            "[7200]\ttrain-logloss:0.17411\tvalid-logloss:0.21446\n",
            "[7500]\ttrain-logloss:0.17276\tvalid-logloss:0.21441\n",
            "[7800]\ttrain-logloss:0.17140\tvalid-logloss:0.21436\n",
            "[8100]\ttrain-logloss:0.17006\tvalid-logloss:0.21431\n",
            "[8400]\ttrain-logloss:0.16875\tvalid-logloss:0.21427\n",
            "[8700]\ttrain-logloss:0.16748\tvalid-logloss:0.21422\n",
            "[8849]\ttrain-logloss:0.16683\tvalid-logloss:0.21422\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-07-02 00:51:18,211]\u001b[0m Trial 26 finished with value: 0.7935442363196528 and parameters: {'lambda': 0.10320104830939367, 'alpha': 0.8237477581424577, 'colsample_bytree': 0.6, 'subsample': 0.8, 'learning_rate': 0.005, 'n_estimators': 500, 'max_depth': 8, 'min_child_weight': 120}. Best is trial 5 with value: 0.7938171644083507.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:51:31] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[00:51:31] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68528\tvalid-logloss:0.68532\n",
            "[300]\ttrain-logloss:0.22922\tvalid-logloss:0.23850\n",
            "[600]\ttrain-logloss:0.20786\tvalid-logloss:0.22430\n",
            "[900]\ttrain-logloss:0.19828\tvalid-logloss:0.22071\n",
            "[1200]\ttrain-logloss:0.19130\tvalid-logloss:0.21904\n",
            "[1500]\ttrain-logloss:0.18590\tvalid-logloss:0.21814\n",
            "[1800]\ttrain-logloss:0.18117\tvalid-logloss:0.21758\n",
            "[2100]\ttrain-logloss:0.17675\tvalid-logloss:0.21719\n",
            "[2400]\ttrain-logloss:0.17255\tvalid-logloss:0.21686\n",
            "[2700]\ttrain-logloss:0.16846\tvalid-logloss:0.21665\n",
            "[3000]\ttrain-logloss:0.16453\tvalid-logloss:0.21648\n",
            "[3300]\ttrain-logloss:0.16082\tvalid-logloss:0.21639\n",
            "[3600]\ttrain-logloss:0.15718\tvalid-logloss:0.21630\n",
            "[3725]\ttrain-logloss:0.15576\tvalid-logloss:0.21628\n",
            "[00:58:10] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[00:58:11] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68529\tvalid-logloss:0.68530\n",
            "[300]\ttrain-logloss:0.22957\tvalid-logloss:0.23646\n",
            "[600]\ttrain-logloss:0.20829\tvalid-logloss:0.22196\n",
            "[900]\ttrain-logloss:0.19873\tvalid-logloss:0.21860\n",
            "[1200]\ttrain-logloss:0.19205\tvalid-logloss:0.21713\n",
            "[1500]\ttrain-logloss:0.18638\tvalid-logloss:0.21634\n",
            "[1800]\ttrain-logloss:0.18154\tvalid-logloss:0.21584\n",
            "[2100]\ttrain-logloss:0.17707\tvalid-logloss:0.21553\n",
            "[2400]\ttrain-logloss:0.17290\tvalid-logloss:0.21529\n",
            "[2700]\ttrain-logloss:0.16905\tvalid-logloss:0.21515\n",
            "[3000]\ttrain-logloss:0.16528\tvalid-logloss:0.21508\n",
            "[3300]\ttrain-logloss:0.16172\tvalid-logloss:0.21504\n",
            "[3600]\ttrain-logloss:0.15826\tvalid-logloss:0.21497\n",
            "[3809]\ttrain-logloss:0.15593\tvalid-logloss:0.21494\n",
            "[01:04:55] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[01:04:55] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68527\tvalid-logloss:0.68532\n",
            "[300]\ttrain-logloss:0.22891\tvalid-logloss:0.23927\n",
            "[600]\ttrain-logloss:0.20755\tvalid-logloss:0.22523\n",
            "[900]\ttrain-logloss:0.19810\tvalid-logloss:0.22195\n",
            "[1200]\ttrain-logloss:0.19117\tvalid-logloss:0.22040\n",
            "[1500]\ttrain-logloss:0.18545\tvalid-logloss:0.21964\n",
            "[1800]\ttrain-logloss:0.18079\tvalid-logloss:0.21919\n",
            "[2100]\ttrain-logloss:0.17642\tvalid-logloss:0.21889\n",
            "[2400]\ttrain-logloss:0.17234\tvalid-logloss:0.21866\n",
            "[2700]\ttrain-logloss:0.16836\tvalid-logloss:0.21852\n",
            "[3000]\ttrain-logloss:0.16452\tvalid-logloss:0.21840\n",
            "[3300]\ttrain-logloss:0.16069\tvalid-logloss:0.21834\n",
            "[3562]\ttrain-logloss:0.15743\tvalid-logloss:0.21830\n",
            "[01:11:13] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[01:11:13] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68528\tvalid-logloss:0.68536\n",
            "[300]\ttrain-logloss:0.22890\tvalid-logloss:0.23956\n",
            "[600]\ttrain-logloss:0.20756\tvalid-logloss:0.22564\n",
            "[900]\ttrain-logloss:0.19808\tvalid-logloss:0.22251\n",
            "[1200]\ttrain-logloss:0.19119\tvalid-logloss:0.22105\n",
            "[1500]\ttrain-logloss:0.18556\tvalid-logloss:0.22030\n",
            "[1800]\ttrain-logloss:0.18072\tvalid-logloss:0.21982\n",
            "[2100]\ttrain-logloss:0.17617\tvalid-logloss:0.21958\n",
            "[2400]\ttrain-logloss:0.17193\tvalid-logloss:0.21937\n",
            "[2700]\ttrain-logloss:0.16774\tvalid-logloss:0.21923\n",
            "[3000]\ttrain-logloss:0.16384\tvalid-logloss:0.21912\n",
            "[3300]\ttrain-logloss:0.16010\tvalid-logloss:0.21905\n",
            "[3600]\ttrain-logloss:0.15645\tvalid-logloss:0.21900\n",
            "[3763]\ttrain-logloss:0.15450\tvalid-logloss:0.21900\n",
            "[01:17:51] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[01:17:51] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68528\tvalid-logloss:0.68530\n",
            "[300]\ttrain-logloss:0.22980\tvalid-logloss:0.23662\n",
            "[600]\ttrain-logloss:0.20845\tvalid-logloss:0.22221\n",
            "[900]\ttrain-logloss:0.19902\tvalid-logloss:0.21880\n",
            "[1200]\ttrain-logloss:0.19238\tvalid-logloss:0.21720\n",
            "[1500]\ttrain-logloss:0.18695\tvalid-logloss:0.21633\n",
            "[1800]\ttrain-logloss:0.18238\tvalid-logloss:0.21588\n",
            "[2100]\ttrain-logloss:0.17790\tvalid-logloss:0.21555\n",
            "[2400]\ttrain-logloss:0.17370\tvalid-logloss:0.21536\n",
            "[2700]\ttrain-logloss:0.16966\tvalid-logloss:0.21519\n",
            "[3000]\ttrain-logloss:0.16576\tvalid-logloss:0.21508\n",
            "[3300]\ttrain-logloss:0.16199\tvalid-logloss:0.21499\n",
            "[3600]\ttrain-logloss:0.15838\tvalid-logloss:0.21495\n",
            "[3900]\ttrain-logloss:0.15508\tvalid-logloss:0.21489\n",
            "[4090]\ttrain-logloss:0.15299\tvalid-logloss:0.21489\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-07-02 01:24:44,360]\u001b[0m Trial 27 finished with value: 0.7928965071314384 and parameters: {'lambda': 0.4202650662641379, 'alpha': 0.01858464941307577, 'colsample_bytree': 0.7, 'subsample': 1.0, 'learning_rate': 0.012, 'n_estimators': 390, 'max_depth': 7, 'min_child_weight': 35}. Best is trial 5 with value: 0.7938171644083507.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[01:24:57] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[01:24:57] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68673\tvalid-logloss:0.68674\n",
            "[300]\ttrain-logloss:0.24846\tvalid-logloss:0.25187\n",
            "[600]\ttrain-logloss:0.22440\tvalid-logloss:0.23025\n",
            "[900]\ttrain-logloss:0.21741\tvalid-logloss:0.22499\n",
            "[1200]\ttrain-logloss:0.21324\tvalid-logloss:0.22229\n",
            "[1500]\ttrain-logloss:0.21022\tvalid-logloss:0.22075\n",
            "[1800]\ttrain-logloss:0.20774\tvalid-logloss:0.21973\n",
            "[2100]\ttrain-logloss:0.20561\tvalid-logloss:0.21900\n",
            "[2400]\ttrain-logloss:0.20368\tvalid-logloss:0.21846\n",
            "[2700]\ttrain-logloss:0.20192\tvalid-logloss:0.21804\n",
            "[3000]\ttrain-logloss:0.20016\tvalid-logloss:0.21770\n",
            "[3300]\ttrain-logloss:0.19851\tvalid-logloss:0.21745\n",
            "[3600]\ttrain-logloss:0.19697\tvalid-logloss:0.21723\n",
            "[3900]\ttrain-logloss:0.19540\tvalid-logloss:0.21701\n",
            "[4200]\ttrain-logloss:0.19392\tvalid-logloss:0.21688\n",
            "[4500]\ttrain-logloss:0.19247\tvalid-logloss:0.21671\n",
            "[4800]\ttrain-logloss:0.19099\tvalid-logloss:0.21660\n",
            "[5100]\ttrain-logloss:0.18959\tvalid-logloss:0.21651\n",
            "[5400]\ttrain-logloss:0.18819\tvalid-logloss:0.21643\n",
            "[5700]\ttrain-logloss:0.18685\tvalid-logloss:0.21635\n",
            "[6000]\ttrain-logloss:0.18551\tvalid-logloss:0.21629\n",
            "[6273]\ttrain-logloss:0.18430\tvalid-logloss:0.21626\n",
            "[01:34:49] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[01:34:49] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68674\tvalid-logloss:0.68672\n",
            "[300]\ttrain-logloss:0.24898\tvalid-logloss:0.25016\n",
            "[600]\ttrain-logloss:0.22490\tvalid-logloss:0.22797\n",
            "[900]\ttrain-logloss:0.21784\tvalid-logloss:0.22267\n",
            "[1200]\ttrain-logloss:0.21371\tvalid-logloss:0.22015\n",
            "[1500]\ttrain-logloss:0.21073\tvalid-logloss:0.21873\n",
            "[1800]\ttrain-logloss:0.20826\tvalid-logloss:0.21782\n",
            "[2100]\ttrain-logloss:0.20613\tvalid-logloss:0.21722\n",
            "[2400]\ttrain-logloss:0.20414\tvalid-logloss:0.21677\n",
            "[2700]\ttrain-logloss:0.20231\tvalid-logloss:0.21643\n",
            "[3000]\ttrain-logloss:0.20060\tvalid-logloss:0.21621\n",
            "[3300]\ttrain-logloss:0.19897\tvalid-logloss:0.21603\n",
            "[3600]\ttrain-logloss:0.19736\tvalid-logloss:0.21588\n",
            "[3900]\ttrain-logloss:0.19578\tvalid-logloss:0.21574\n",
            "[4200]\ttrain-logloss:0.19432\tvalid-logloss:0.21561\n",
            "[4500]\ttrain-logloss:0.19280\tvalid-logloss:0.21552\n",
            "[4800]\ttrain-logloss:0.19134\tvalid-logloss:0.21547\n",
            "[4933]\ttrain-logloss:0.19073\tvalid-logloss:0.21545\n",
            "[01:42:40] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[01:42:40] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68674\tvalid-logloss:0.68677\n",
            "[300]\ttrain-logloss:0.24818\tvalid-logloss:0.25279\n",
            "[600]\ttrain-logloss:0.22407\tvalid-logloss:0.23119\n",
            "[900]\ttrain-logloss:0.21704\tvalid-logloss:0.22611\n",
            "[1200]\ttrain-logloss:0.21289\tvalid-logloss:0.22361\n",
            "[1500]\ttrain-logloss:0.20977\tvalid-logloss:0.22217\n",
            "[1800]\ttrain-logloss:0.20731\tvalid-logloss:0.22128\n",
            "[2100]\ttrain-logloss:0.20517\tvalid-logloss:0.22064\n",
            "[2400]\ttrain-logloss:0.20324\tvalid-logloss:0.22019\n",
            "[2700]\ttrain-logloss:0.20147\tvalid-logloss:0.21984\n",
            "[3000]\ttrain-logloss:0.19975\tvalid-logloss:0.21957\n",
            "[3300]\ttrain-logloss:0.19809\tvalid-logloss:0.21933\n",
            "[3600]\ttrain-logloss:0.19653\tvalid-logloss:0.21916\n",
            "[3900]\ttrain-logloss:0.19504\tvalid-logloss:0.21902\n",
            "[4200]\ttrain-logloss:0.19348\tvalid-logloss:0.21889\n",
            "[4500]\ttrain-logloss:0.19203\tvalid-logloss:0.21881\n",
            "[4800]\ttrain-logloss:0.19055\tvalid-logloss:0.21867\n",
            "[5100]\ttrain-logloss:0.18916\tvalid-logloss:0.21860\n",
            "[5400]\ttrain-logloss:0.18780\tvalid-logloss:0.21857\n",
            "[5700]\ttrain-logloss:0.18643\tvalid-logloss:0.21853\n",
            "[6000]\ttrain-logloss:0.18508\tvalid-logloss:0.21851\n",
            "[6249]\ttrain-logloss:0.18400\tvalid-logloss:0.21850\n",
            "[01:52:24] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[01:52:25] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68672\tvalid-logloss:0.68678\n",
            "[300]\ttrain-logloss:0.24809\tvalid-logloss:0.25302\n",
            "[600]\ttrain-logloss:0.22405\tvalid-logloss:0.23133\n",
            "[900]\ttrain-logloss:0.21698\tvalid-logloss:0.22626\n",
            "[1200]\ttrain-logloss:0.21279\tvalid-logloss:0.22384\n",
            "[1500]\ttrain-logloss:0.20978\tvalid-logloss:0.22245\n",
            "[1800]\ttrain-logloss:0.20730\tvalid-logloss:0.22158\n",
            "[2100]\ttrain-logloss:0.20514\tvalid-logloss:0.22095\n",
            "[2400]\ttrain-logloss:0.20317\tvalid-logloss:0.22050\n",
            "[2700]\ttrain-logloss:0.20140\tvalid-logloss:0.22018\n",
            "[3000]\ttrain-logloss:0.19970\tvalid-logloss:0.21997\n",
            "[3300]\ttrain-logloss:0.19806\tvalid-logloss:0.21979\n",
            "[3600]\ttrain-logloss:0.19644\tvalid-logloss:0.21963\n",
            "[3900]\ttrain-logloss:0.19488\tvalid-logloss:0.21948\n",
            "[4200]\ttrain-logloss:0.19336\tvalid-logloss:0.21939\n",
            "[4500]\ttrain-logloss:0.19193\tvalid-logloss:0.21932\n",
            "[4800]\ttrain-logloss:0.19047\tvalid-logloss:0.21924\n",
            "[5100]\ttrain-logloss:0.18904\tvalid-logloss:0.21919\n",
            "[5151]\ttrain-logloss:0.18880\tvalid-logloss:0.21920\n",
            "[02:00:23] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
            "Parameters: { \"n_estimators\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[02:00:23] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[0]\ttrain-logloss:0.68674\tvalid-logloss:0.68673\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "{'lambda': 1.2133864929301732, 'alpha': 0.07062978137188772, 'colsample_bytree': 0.8, 'subsample': 0.8, 'learning_rate': 0.010000000000000002, 'n_estimators': 230, 'max_depth': 8, 'min_child_weight': 21}"
      ],
      "metadata": {
        "id": "7sW60y39kqZt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_params = study.best_trial.params\n",
        "best_params['tree_method'] = 'gpu_hist'\n",
        "best_params['booster'] = 'gbtree'\n",
        "final_model = XGB.booster(**best_params,enable_categorical = True)\n",
        "final_model.save_model('XGB_final.xgb')"
      ],
      "metadata": {
        "id": "hzv7bWBlIfK9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_model = XGB.booster(**best_params,enable_categorical = True)\n",
        "final_model.save_model('XGB_final.xgb')\n",
        "#model = xgb.Booster()\n",
        "#model.load_model(f'XGB_v{VER}_fold0.xgb')"
      ],
      "metadata": {
        "id": "h8pGLdMmIfK9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save OOF Preds"
      ],
      "metadata": {
        "id": "Tkn5B21Tp0OA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CLEAR VRAM, RAM FOR INFERENCE BELOW\n",
        "del oof_xgb, oof\n",
        "_ = gc.collect()"
      ],
      "metadata": {
        "id": "Ttbu6b88p0OA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Importance"
      ],
      "metadata": {
        "id": "T_S5V_ZCp0OA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Process and Feature Engineer Test Data\n",
        "We will load @raddar Kaggle dataset from [here][1] with discussion [here][2]. Then we will engineer features suggested by @huseyincot in his notebooks [here][1] and [here][4]. We will use [RAPIDS][5] and the GPU to create new features quickly.\n",
        "\n",
        "[1]: https://www.kaggle.com/datasets/raddar/amex-data-integer-dtypes-parquet-format\n",
        "[2]: https://www.kaggle.com/competitions/amex-default-prediction/discussion/328514\n",
        "[3]: https://www.kaggle.com/code/huseyincot/amex-catboost-0-793\n",
        "[4]: https://www.kaggle.com/code/huseyincot/amex-agg-data-how-it-created\n",
        "[5]: https://rapids.ai/"
      ],
      "metadata": {
        "id": "3NnTqDaIp0OB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CALCULATE SIZE OF EACH SEPARATE TEST PART\n",
        "def get_rows(customers, test, NUM_PARTS = 4, verbose = ''):\n",
        "    chunk = len(customers)//NUM_PARTS\n",
        "    if verbose != '':\n",
        "        print(f'We will process {verbose} data as {NUM_PARTS} separate parts.')\n",
        "        print(f'There will be {chunk} customers in each part (except the last part).')\n",
        "        print('Below are number of rows in each part:')\n",
        "    rows = []\n",
        "\n",
        "    for k in range(NUM_PARTS):\n",
        "        if k==NUM_PARTS-1: cc = customers[k*chunk:]\n",
        "        else: cc = customers[k*chunk:(k+1)*chunk]\n",
        "        s = test.loc[test.customer_ID.isin(cc)].shape[0]\n",
        "        rows.append(s)\n",
        "    if verbose != '': print( rows )\n",
        "    return rows,chunk\n",
        "\n",
        "# COMPUTE SIZE OF 4 PARTS FOR TEST DATA\n",
        "NUM_PARTS = 4\n",
        "TEST_PATH = '../input/amex-data-integer-dtypes-parquet-format/test.parquet'\n",
        "\n",
        "print(f'Reading test data...')\n",
        "test = read_file(path = TEST_PATH, usecols = ['customer_ID','S_2'])\n",
        "test = handle_na(test,NAN_VALUE)\n",
        "customers = test[['customer_ID']].drop_duplicates().sort_index().values.flatten()\n",
        "rows,num_cust = get_rows(customers, test[['customer_ID']], NUM_PARTS = NUM_PARTS, verbose = 'test')"
      ],
      "metadata": {
        "id": "mLEPOC2ap0OB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Infer Test"
      ],
      "metadata": {
        "id": "JOK1diNsp0OB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# INFER TEST DATA IN PARTS\n",
        "skip_rows = 0\n",
        "skip_cust = 0\n",
        "test_preds = []\n",
        "\n",
        "for k in range(NUM_PARTS):\n",
        "    \n",
        "    # READ PART OF TEST DATA\n",
        "    print(f'\\nReading test data...')\n",
        "    test = read_file(path = TEST_PATH)\n",
        "    test = test.iloc[skip_rows:skip_rows+rows[k]]\n",
        "    skip_rows += rows[k]\n",
        "    print(f'=> Test part {k+1} has shape', test.shape )\n",
        "    \n",
        "    # PROCESS AND FEATURE ENGINEER PART OF TEST DATA\n",
        "    test = process_and_feature_engineer(test,cat_features, num_features)\n",
        "    if k==NUM_PARTS-1: test = test.loc[customers[skip_cust:]]\n",
        "    else: test = test.loc[customers[skip_cust:skip_cust+num_cust]]\n",
        "    skip_cust += num_cust\n",
        "    \n",
        "    # TEST DATA FOR XGB\n",
        "    X_test = test[FEATURES]\n",
        "    dtest = xgb.DMatrix(data=X_test)\n",
        "    test = test[['P_2_mean']] # reduce memory\n",
        "    del X_test\n",
        "    gc.collect()\n",
        "\n",
        "    # INFER XGB MODELS ON TEST DATA\n",
        "    model = xgb.Booster()\n",
        "    model.load_model('XGB_final.xgb')\n",
        "    preds = model.predict(dtest)\n",
        "    for f in range(1,FOLDS):\n",
        "        model.load_model(f'XGB_v{VER}_fold{f}.xgb')\n",
        "        preds += model.predict(dtest)\n",
        "    preds /= FOLDS\n",
        "    test_preds.append(preds)\n",
        "\n",
        "    # CLEAN MEMORY\n",
        "    del dtest, model\n",
        "    _ = gc.collect()"
      ],
      "metadata": {
        "id": "9OGciocgp0OC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Submission CSV"
      ],
      "metadata": {
        "id": "wgvQnNhip0OC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# WRITE SUBMISSION FILE\n",
        "test_preds = np.concatenate(test_preds)\n",
        "test = cudf.DataFrame(index=customers,data={'prediction':test_preds})\n",
        "sub = cudf.read_csv('../input/amex-default-prediction/sample_submission.csv')[['customer_ID']]\n",
        "sub['customer_ID_hash'] = sub['customer_ID'].str[-16:].str.hex_to_int().astype('int64')\n",
        "sub = sub.set_index('customer_ID_hash')\n",
        "sub = sub.merge(test[['prediction']], left_index=True, right_index=True, how='left')\n",
        "sub = sub.reset_index(drop=True)\n",
        "\n",
        "# DISPLAY PREDICTIONS\n",
        "sub.to_csv(f'submission_xgb_v{VER}.csv',index=False)\n",
        "print('Submission file shape is', sub.shape )\n",
        "sub.head()"
      ],
      "metadata": {
        "id": "XmDkNfhrp0OC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sub.to_csv(f'submission.csv',index=False)"
      ],
      "metadata": {
        "id": "feR6CECRp0OC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PLOT PREDICTIONS\n",
        "plt.hist(sub.to_pandas().prediction, bins=100)\n",
        "plt.title('Test Predictions')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lZwCEYdKp0OC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}